[2020-08-02 03:48:41,188] {logging_mixin.py:112} INFO - [2020-08-02 03:48:41,187] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=186
[2020-08-02 03:48:41,207] {scheduler_job.py:153} INFO - Started process (PID=186) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:41,210] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:48:41,211] {logging_mixin.py:112} INFO - [2020-08-02 03:48:41,211] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:41,228] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:41,292] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.085 seconds
[2020-08-02 03:48:43,307] {logging_mixin.py:112} INFO - [2020-08-02 03:48:43,307] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=214
[2020-08-02 03:48:43,314] {scheduler_job.py:153} INFO - Started process (PID=214) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:43,336] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:48:43,344] {logging_mixin.py:112} INFO - [2020-08-02 03:48:43,344] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:43,388] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:43,543] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.228 seconds
[2020-08-02 03:48:46,264] {logging_mixin.py:112} INFO - [2020-08-02 03:48:46,264] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=241
[2020-08-02 03:48:46,267] {scheduler_job.py:153} INFO - Started process (PID=241) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:46,271] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:48:46,272] {logging_mixin.py:112} INFO - [2020-08-02 03:48:46,272] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:46,297] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:46,333] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.066 seconds
[2020-08-02 03:48:48,284] {logging_mixin.py:112} INFO - [2020-08-02 03:48:48,284] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=261
[2020-08-02 03:48:48,289] {scheduler_job.py:153} INFO - Started process (PID=261) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:48,294] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:48:48,295] {logging_mixin.py:112} INFO - [2020-08-02 03:48:48,295] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:48,318] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:48,357] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-02 03:48:50,304] {logging_mixin.py:112} INFO - [2020-08-02 03:48:50,303] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=281
[2020-08-02 03:48:50,310] {scheduler_job.py:153} INFO - Started process (PID=281) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:50,316] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:48:50,317] {logging_mixin.py:112} INFO - [2020-08-02 03:48:50,317] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:50,340] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:50,381] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.071 seconds
[2020-08-02 03:48:52,324] {logging_mixin.py:112} INFO - [2020-08-02 03:48:52,324] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=300
[2020-08-02 03:48:52,329] {scheduler_job.py:153} INFO - Started process (PID=300) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:52,336] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:48:52,342] {logging_mixin.py:112} INFO - [2020-08-02 03:48:52,342] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:52,380] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:52,424] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.096 seconds
[2020-08-02 03:48:54,344] {logging_mixin.py:112} INFO - [2020-08-02 03:48:54,343] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=321
[2020-08-02 03:48:54,350] {scheduler_job.py:153} INFO - Started process (PID=321) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:54,356] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:48:54,357] {logging_mixin.py:112} INFO - [2020-08-02 03:48:54,357] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:54,388] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:54,423] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.074 seconds
[2020-08-02 03:48:56,357] {logging_mixin.py:112} INFO - [2020-08-02 03:48:56,357] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=341
[2020-08-02 03:48:56,359] {scheduler_job.py:153} INFO - Started process (PID=341) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:56,368] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:48:56,369] {logging_mixin.py:112} INFO - [2020-08-02 03:48:56,369] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:56,397] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:56,431] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.071 seconds
[2020-08-02 03:48:58,407] {logging_mixin.py:112} INFO - [2020-08-02 03:48:58,406] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=361
[2020-08-02 03:48:58,414] {scheduler_job.py:153} INFO - Started process (PID=361) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:58,426] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:48:58,427] {logging_mixin.py:112} INFO - [2020-08-02 03:48:58,427] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:58,460] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:48:58,496] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.082 seconds
[2020-08-02 03:49:00,450] {logging_mixin.py:112} INFO - [2020-08-02 03:49:00,449] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=381
[2020-08-02 03:49:00,453] {scheduler_job.py:153} INFO - Started process (PID=381) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:00,466] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:00,477] {logging_mixin.py:112} INFO - [2020-08-02 03:49:00,477] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:00,506] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:00,552] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.098 seconds
[2020-08-02 03:49:02,474] {logging_mixin.py:112} INFO - [2020-08-02 03:49:02,474] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=401
[2020-08-02 03:49:02,478] {scheduler_job.py:153} INFO - Started process (PID=401) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:02,482] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:02,483] {logging_mixin.py:112} INFO - [2020-08-02 03:49:02,483] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:02,520] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:02,578] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.100 seconds
[2020-08-02 03:49:04,481] {logging_mixin.py:112} INFO - [2020-08-02 03:49:04,481] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=420
[2020-08-02 03:49:04,486] {scheduler_job.py:153} INFO - Started process (PID=420) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:04,490] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:04,490] {logging_mixin.py:112} INFO - [2020-08-02 03:49:04,490] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:04,517] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:04,555] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.069 seconds
[2020-08-02 03:49:06,492] {logging_mixin.py:112} INFO - [2020-08-02 03:49:06,492] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=440
[2020-08-02 03:49:06,497] {scheduler_job.py:153} INFO - Started process (PID=440) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:06,503] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:06,508] {logging_mixin.py:112} INFO - [2020-08-02 03:49:06,508] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:06,548] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:06,615] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.118 seconds
[2020-08-02 03:49:08,529] {logging_mixin.py:112} INFO - [2020-08-02 03:49:08,529] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=465
[2020-08-02 03:49:08,535] {scheduler_job.py:153} INFO - Started process (PID=465) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:08,553] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:08,558] {logging_mixin.py:112} INFO - [2020-08-02 03:49:08,558] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:08,592] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:08,666] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.131 seconds
[2020-08-02 03:49:10,602] {logging_mixin.py:112} INFO - [2020-08-02 03:49:10,602] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=487
[2020-08-02 03:49:10,612] {scheduler_job.py:153} INFO - Started process (PID=487) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:10,626] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:10,635] {logging_mixin.py:112} INFO - [2020-08-02 03:49:10,634] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:10,678] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:10,750] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.139 seconds
[2020-08-02 03:49:13,646] {logging_mixin.py:112} INFO - [2020-08-02 03:49:13,646] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=521
[2020-08-02 03:49:13,649] {scheduler_job.py:153} INFO - Started process (PID=521) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:13,667] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:13,672] {logging_mixin.py:112} INFO - [2020-08-02 03:49:13,672] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:13,713] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:13,799] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.150 seconds
[2020-08-02 03:49:16,661] {logging_mixin.py:112} INFO - [2020-08-02 03:49:16,661] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=553
[2020-08-02 03:49:16,666] {scheduler_job.py:153} INFO - Started process (PID=553) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:16,681] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:16,693] {logging_mixin.py:112} INFO - [2020-08-02 03:49:16,693] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:16,746] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:16,837] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.171 seconds
[2020-08-02 03:49:19,705] {logging_mixin.py:112} INFO - [2020-08-02 03:49:19,705] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=584
[2020-08-02 03:49:19,713] {scheduler_job.py:153} INFO - Started process (PID=584) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:19,717] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:19,724] {logging_mixin.py:112} INFO - [2020-08-02 03:49:19,724] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:19,755] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:19,813] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.100 seconds
[2020-08-02 03:49:21,713] {logging_mixin.py:112} INFO - [2020-08-02 03:49:21,713] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=608
[2020-08-02 03:49:21,718] {scheduler_job.py:153} INFO - Started process (PID=608) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:21,735] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:21,737] {logging_mixin.py:112} INFO - [2020-08-02 03:49:21,737] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:21,770] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:21,827] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.109 seconds
[2020-08-02 03:49:23,745] {logging_mixin.py:112} INFO - [2020-08-02 03:49:23,744] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=628
[2020-08-02 03:49:23,749] {scheduler_job.py:153} INFO - Started process (PID=628) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:23,753] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:23,755] {logging_mixin.py:112} INFO - [2020-08-02 03:49:23,754] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:23,802] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:23,840] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.092 seconds
[2020-08-02 03:49:25,774] {logging_mixin.py:112} INFO - [2020-08-02 03:49:25,773] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=646
[2020-08-02 03:49:25,788] {scheduler_job.py:153} INFO - Started process (PID=646) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:25,800] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:25,803] {logging_mixin.py:112} INFO - [2020-08-02 03:49:25,803] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:25,904] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:25,961] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.173 seconds
[2020-08-02 03:49:27,824] {logging_mixin.py:112} INFO - [2020-08-02 03:49:27,823] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=668
[2020-08-02 03:49:27,828] {scheduler_job.py:153} INFO - Started process (PID=668) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:27,831] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:27,838] {logging_mixin.py:112} INFO - [2020-08-02 03:49:27,838] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:27,868] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:27,906] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.078 seconds
[2020-08-02 03:49:29,838] {logging_mixin.py:112} INFO - [2020-08-02 03:49:29,837] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=688
[2020-08-02 03:49:29,846] {scheduler_job.py:153} INFO - Started process (PID=688) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:29,867] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:29,869] {logging_mixin.py:112} INFO - [2020-08-02 03:49:29,869] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:29,896] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:29,962] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.116 seconds
[2020-08-02 03:49:31,861] {logging_mixin.py:112} INFO - [2020-08-02 03:49:31,861] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=708
[2020-08-02 03:49:31,866] {scheduler_job.py:153} INFO - Started process (PID=708) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:31,871] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:31,873] {logging_mixin.py:112} INFO - [2020-08-02 03:49:31,872] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:31,904] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:31,945] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.080 seconds
[2020-08-02 03:49:33,895] {logging_mixin.py:112} INFO - [2020-08-02 03:49:33,895] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=728
[2020-08-02 03:49:33,900] {scheduler_job.py:153} INFO - Started process (PID=728) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:33,904] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:33,906] {logging_mixin.py:112} INFO - [2020-08-02 03:49:33,906] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:33,950] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:34,007] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.108 seconds
[2020-08-02 03:49:35,908] {logging_mixin.py:112} INFO - [2020-08-02 03:49:35,907] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=746
[2020-08-02 03:49:35,913] {scheduler_job.py:153} INFO - Started process (PID=746) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:35,919] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:35,923] {logging_mixin.py:112} INFO - [2020-08-02 03:49:35,923] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:35,963] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:35,996] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.083 seconds
[2020-08-02 03:49:37,912] {logging_mixin.py:112} INFO - [2020-08-02 03:49:37,911] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=768
[2020-08-02 03:49:37,916] {scheduler_job.py:153} INFO - Started process (PID=768) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:37,924] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:37,926] {logging_mixin.py:112} INFO - [2020-08-02 03:49:37,926] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:37,964] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:38,007] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.091 seconds
[2020-08-02 03:49:39,928] {logging_mixin.py:112} INFO - [2020-08-02 03:49:39,928] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=786
[2020-08-02 03:49:39,931] {scheduler_job.py:153} INFO - Started process (PID=786) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:39,936] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:39,937] {logging_mixin.py:112} INFO - [2020-08-02 03:49:39,937] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:39,971] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:40,019] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.088 seconds
[2020-08-02 03:49:41,989] {logging_mixin.py:112} INFO - [2020-08-02 03:49:41,987] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=807
[2020-08-02 03:49:42,005] {scheduler_job.py:153} INFO - Started process (PID=807) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:42,008] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:42,009] {logging_mixin.py:112} INFO - [2020-08-02 03:49:42,009] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:42,037] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:42,076] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.071 seconds
[2020-08-02 03:49:43,989] {logging_mixin.py:112} INFO - [2020-08-02 03:49:43,988] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=827
[2020-08-02 03:49:43,996] {scheduler_job.py:153} INFO - Started process (PID=827) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:44,001] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:44,003] {logging_mixin.py:112} INFO - [2020-08-02 03:49:44,003] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:44,046] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:44,091] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.095 seconds
[2020-08-02 03:49:46,022] {logging_mixin.py:112} INFO - [2020-08-02 03:49:46,022] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=848
[2020-08-02 03:49:46,026] {scheduler_job.py:153} INFO - Started process (PID=848) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:46,029] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:46,032] {logging_mixin.py:112} INFO - [2020-08-02 03:49:46,031] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:46,068] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:46,124] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.099 seconds
[2020-08-02 03:49:48,044] {logging_mixin.py:112} INFO - [2020-08-02 03:49:48,043] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=868
[2020-08-02 03:49:48,047] {scheduler_job.py:153} INFO - Started process (PID=868) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:48,054] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:48,056] {logging_mixin.py:112} INFO - [2020-08-02 03:49:48,056] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:48,092] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:48,139] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.091 seconds
[2020-08-02 03:49:50,103] {logging_mixin.py:112} INFO - [2020-08-02 03:49:50,102] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=890
[2020-08-02 03:49:50,107] {scheduler_job.py:153} INFO - Started process (PID=890) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:50,110] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:50,111] {logging_mixin.py:112} INFO - [2020-08-02 03:49:50,111] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:50,133] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:50,173] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.066 seconds
[2020-08-02 03:49:52,117] {logging_mixin.py:112} INFO - [2020-08-02 03:49:52,117] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=910
[2020-08-02 03:49:52,123] {scheduler_job.py:153} INFO - Started process (PID=910) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:52,130] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:52,132] {logging_mixin.py:112} INFO - [2020-08-02 03:49:52,132] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:52,184] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:52,227] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.105 seconds
[2020-08-02 03:49:54,139] {logging_mixin.py:112} INFO - [2020-08-02 03:49:54,139] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=929
[2020-08-02 03:49:54,144] {scheduler_job.py:153} INFO - Started process (PID=929) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:54,148] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:54,151] {logging_mixin.py:112} INFO - [2020-08-02 03:49:54,150] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:54,214] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:54,255] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.110 seconds
[2020-08-02 03:49:56,160] {logging_mixin.py:112} INFO - [2020-08-02 03:49:56,160] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=950
[2020-08-02 03:49:56,164] {scheduler_job.py:153} INFO - Started process (PID=950) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:56,174] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:56,175] {logging_mixin.py:112} INFO - [2020-08-02 03:49:56,175] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:56,230] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:56,350] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.186 seconds
[2020-08-02 03:49:58,205] {logging_mixin.py:112} INFO - [2020-08-02 03:49:58,205] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=970
[2020-08-02 03:49:58,208] {scheduler_job.py:153} INFO - Started process (PID=970) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:58,213] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:49:58,214] {logging_mixin.py:112} INFO - [2020-08-02 03:49:58,214] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:58,248] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:49:58,319] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.110 seconds
[2020-08-02 03:50:00,217] {logging_mixin.py:112} INFO - [2020-08-02 03:50:00,216] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=990
[2020-08-02 03:50:00,220] {scheduler_job.py:153} INFO - Started process (PID=990) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:00,229] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:50:00,230] {logging_mixin.py:112} INFO - [2020-08-02 03:50:00,230] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:00,257] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:00,301] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.080 seconds
[2020-08-02 03:50:02,233] {logging_mixin.py:112} INFO - [2020-08-02 03:50:02,233] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1008
[2020-08-02 03:50:02,236] {scheduler_job.py:153} INFO - Started process (PID=1008) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:02,240] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:50:02,241] {logging_mixin.py:112} INFO - [2020-08-02 03:50:02,241] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:02,270] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:02,365] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.129 seconds
[2020-08-02 03:50:04,279] {logging_mixin.py:112} INFO - [2020-08-02 03:50:04,278] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1029
[2020-08-02 03:50:04,282] {scheduler_job.py:153} INFO - Started process (PID=1029) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:04,285] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:50:04,287] {logging_mixin.py:112} INFO - [2020-08-02 03:50:04,287] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:04,326] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:04,369] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.087 seconds
[2020-08-02 03:50:06,270] {logging_mixin.py:112} INFO - [2020-08-02 03:50:06,270] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1050
[2020-08-02 03:50:06,273] {scheduler_job.py:153} INFO - Started process (PID=1050) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:06,276] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:50:06,279] {logging_mixin.py:112} INFO - [2020-08-02 03:50:06,279] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:06,308] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:06,341] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-02 03:50:08,302] {logging_mixin.py:112} INFO - [2020-08-02 03:50:08,302] {settings.py:253} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1070
[2020-08-02 03:50:08,305] {scheduler_job.py:153} INFO - Started process (PID=1070) to work on /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:08,309] {scheduler_job.py:1560} INFO - Processing file /usr/local/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-02 03:50:08,315] {logging_mixin.py:112} INFO - [2020-08-02 03:50:08,312] {dagbag.py:403} INFO - Filling up the DagBag from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:08,350] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /usr/local/airflow/dags/bash_pipeline.py
[2020-08-02 03:50:08,394] {scheduler_job.py:161} INFO - Processing /usr/local/airflow/dags/bash_pipeline.py took 0.088 seconds
