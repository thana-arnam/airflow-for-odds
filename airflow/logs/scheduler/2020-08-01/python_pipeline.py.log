[2020-08-01 14:43:55,980] {scheduler_job.py:154} INFO - Started process (PID=58619) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:43:56,001] {logging_mixin.py:112} INFO - [2020-08-01 14:43:56,001] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:56,001] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:43:56,002] {logging_mixin.py:112} INFO - [2020-08-01 14:43:56,002] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:43:56,003] {logging_mixin.py:112} INFO - [2020-08-01 14:43:56,002] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 15
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:43:56,003] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:43:56,008] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.028 seconds
[2020-08-01 14:44:01,970] {scheduler_job.py:154} INFO - Started process (PID=58702) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:01,987] {logging_mixin.py:112} INFO - [2020-08-01 14:44:01,987] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:01,988] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:01,988] {logging_mixin.py:112} INFO - [2020-08-01 14:44:01,988] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:01,989] {logging_mixin.py:112} INFO - [2020-08-01 14:44:01,989] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 15
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:01,989] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:01,996] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.025 seconds
[2020-08-01 14:44:07,948] {scheduler_job.py:154} INFO - Started process (PID=58726) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:07,964] {logging_mixin.py:112} INFO - [2020-08-01 14:44:07,964] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:07,965] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:07,965] {logging_mixin.py:112} INFO - [2020-08-01 14:44:07,965] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:07,966] {logging_mixin.py:112} INFO - [2020-08-01 14:44:07,966] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 15
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:07,966] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:07,973] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.025 seconds
[2020-08-01 14:44:13,985] {scheduler_job.py:154} INFO - Started process (PID=58732) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:14,003] {logging_mixin.py:112} INFO - [2020-08-01 14:44:14,003] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:14,003] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:14,003] {logging_mixin.py:112} INFO - [2020-08-01 14:44:14,003] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:14,005] {logging_mixin.py:112} INFO - [2020-08-01 14:44:14,004] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 15
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:14,005] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:14,011] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.026 seconds
[2020-08-01 14:44:19,958] {scheduler_job.py:154} INFO - Started process (PID=58740) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:19,975] {logging_mixin.py:112} INFO - [2020-08-01 14:44:19,975] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:19,976] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:19,976] {logging_mixin.py:112} INFO - [2020-08-01 14:44:19,976] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:19,977] {logging_mixin.py:112} INFO - [2020-08-01 14:44:19,977] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 15
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:19,977] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:19,984] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.026 seconds
[2020-08-01 14:44:25,988] {scheduler_job.py:154} INFO - Started process (PID=58746) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:26,006] {logging_mixin.py:112} INFO - [2020-08-01 14:44:26,005] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:26,006] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:26,006] {logging_mixin.py:112} INFO - [2020-08-01 14:44:26,006] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:26,008] {logging_mixin.py:112} INFO - [2020-08-01 14:44:26,007] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 15
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:26,008] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:26,014] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.026 seconds
[2020-08-01 14:44:31,995] {scheduler_job.py:154} INFO - Started process (PID=58752) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:32,013] {logging_mixin.py:112} INFO - [2020-08-01 14:44:32,012] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:32,013] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:32,013] {logging_mixin.py:112} INFO - [2020-08-01 14:44:32,013] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:32,014] {logging_mixin.py:112} INFO - [2020-08-01 14:44:32,014] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 15
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:32,015] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:32,021] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.026 seconds
[2020-08-01 14:44:38,305] {scheduler_job.py:154} INFO - Started process (PID=58759) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:38,323] {logging_mixin.py:112} INFO - [2020-08-01 14:44:38,323] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:38,324] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:38,324] {logging_mixin.py:112} INFO - [2020-08-01 14:44:38,324] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:38,325] {logging_mixin.py:112} INFO - [2020-08-01 14:44:38,325] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 15
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:38,325] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:38,332] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.027 seconds
[2020-08-01 14:44:44,105] {scheduler_job.py:154} INFO - Started process (PID=58785) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:44,123] {logging_mixin.py:112} INFO - [2020-08-01 14:44:44,122] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:44,123] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:44,123] {logging_mixin.py:112} INFO - [2020-08-01 14:44:44,123] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:44,125] {logging_mixin.py:112} INFO - [2020-08-01 14:44:44,124] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 15
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:44,125] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:44,131] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.026 seconds
[2020-08-01 14:44:50,128] {scheduler_job.py:154} INFO - Started process (PID=58799) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:50,155] {logging_mixin.py:112} INFO - [2020-08-01 14:44:50,155] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:50,156] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:50,156] {logging_mixin.py:112} INFO - [2020-08-01 14:44:50,156] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:50,157] {logging_mixin.py:112} INFO - [2020-08-01 14:44:50,157] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 17
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:50,157] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:50,162] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.034 seconds
[2020-08-01 14:44:56,080] {scheduler_job.py:154} INFO - Started process (PID=58847) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:56,097] {logging_mixin.py:112} INFO - [2020-08-01 14:44:56,097] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:56,098] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:44:56,098] {logging_mixin.py:112} INFO - [2020-08-01 14:44:56,098] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:56,099] {logging_mixin.py:112} INFO - [2020-08-01 14:44:56,099] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 17
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:44:56,099] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:44:56,106] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.026 seconds
[2020-08-01 14:45:02,113] {scheduler_job.py:154} INFO - Started process (PID=58862) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:02,131] {logging_mixin.py:112} INFO - [2020-08-01 14:45:02,131] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:02,131] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:02,131] {logging_mixin.py:112} INFO - [2020-08-01 14:45:02,131] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:02,133] {logging_mixin.py:112} INFO - [2020-08-01 14:45:02,132] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 17
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:45:02,133] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:02,139] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.025 seconds
[2020-08-01 14:45:08,154] {scheduler_job.py:154} INFO - Started process (PID=58877) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:08,173] {logging_mixin.py:112} INFO - [2020-08-01 14:45:08,173] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:08,174] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:08,174] {logging_mixin.py:112} INFO - [2020-08-01 14:45:08,174] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:08,175] {logging_mixin.py:112} INFO - [2020-08-01 14:45:08,175] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 17
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:45:08,176] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:08,182] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.028 seconds
[2020-08-01 14:45:14,200] {scheduler_job.py:154} INFO - Started process (PID=58900) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:14,217] {logging_mixin.py:112} INFO - [2020-08-01 14:45:14,217] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:14,218] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:14,218] {logging_mixin.py:112} INFO - [2020-08-01 14:45:14,218] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:14,219] {logging_mixin.py:112} INFO - [2020-08-01 14:45:14,219] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 17
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:45:14,219] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:14,225] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.025 seconds
[2020-08-01 14:45:20,163] {scheduler_job.py:154} INFO - Started process (PID=58914) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:20,186] {logging_mixin.py:112} INFO - [2020-08-01 14:45:20,185] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:20,186] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:20,186] {logging_mixin.py:112} INFO - [2020-08-01 14:45:20,186] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:20,187] {logging_mixin.py:112} INFO - [2020-08-01 14:45:20,187] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 17
    def get_covid_data_today();
                              ^
SyntaxError: invalid syntax
[2020-08-01 14:45:20,187] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:20,195] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.031 seconds
[2020-08-01 14:45:26,275] {scheduler_job.py:154} INFO - Started process (PID=58945) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:26,292] {logging_mixin.py:112} INFO - [2020-08-01 14:45:26,292] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:26,292] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:26,292] {logging_mixin.py:112} INFO - [2020-08-01 14:45:26,292] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:26,303] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x119eca310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:45:26,304] {logging_mixin.py:112} INFO - [2020-08-01 14:45:26,303] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 24, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:45:26,304] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:26,312] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.037 seconds
[2020-08-01 14:45:32,538] {scheduler_job.py:154} INFO - Started process (PID=58960) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:32,557] {logging_mixin.py:112} INFO - [2020-08-01 14:45:32,556] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:32,557] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:32,557] {logging_mixin.py:112} INFO - [2020-08-01 14:45:32,557] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:32,559] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x116df1310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:45:32,560] {logging_mixin.py:112} INFO - [2020-08-01 14:45:32,559] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 24, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:45:32,560] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:32,566] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.028 seconds
[2020-08-01 14:45:38,245] {scheduler_job.py:154} INFO - Started process (PID=58971) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:38,263] {logging_mixin.py:112} INFO - [2020-08-01 14:45:38,263] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:38,264] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:38,264] {logging_mixin.py:112} INFO - [2020-08-01 14:45:38,264] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:38,265] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x1059bf310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:45:38,266] {logging_mixin.py:112} INFO - [2020-08-01 14:45:38,266] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 24, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:45:38,266] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:38,273] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.028 seconds
[2020-08-01 14:45:44,271] {scheduler_job.py:154} INFO - Started process (PID=58978) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:44,290] {logging_mixin.py:112} INFO - [2020-08-01 14:45:44,289] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:44,290] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:44,290] {logging_mixin.py:112} INFO - [2020-08-01 14:45:44,290] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:44,292] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x10d665310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:45:44,293] {logging_mixin.py:112} INFO - [2020-08-01 14:45:44,292] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 24, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:45:44,293] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:44,300] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.029 seconds
[2020-08-01 14:45:50,420] {scheduler_job.py:154} INFO - Started process (PID=58984) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:50,483] {logging_mixin.py:112} INFO - [2020-08-01 14:45:50,483] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:50,484] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:50,485] {logging_mixin.py:112} INFO - [2020-08-01 14:45:50,485] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:50,487] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x1158c6310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:45:50,489] {logging_mixin.py:112} INFO - [2020-08-01 14:45:50,488] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 24, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:45:50,489] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:50,497] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.077 seconds
[2020-08-01 14:45:56,378] {scheduler_job.py:154} INFO - Started process (PID=58998) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:56,395] {logging_mixin.py:112} INFO - [2020-08-01 14:45:56,395] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:56,396] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:45:56,396] {logging_mixin.py:112} INFO - [2020-08-01 14:45:56,396] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:56,397] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x11b0eb310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:45:56,398] {logging_mixin.py:112} INFO - [2020-08-01 14:45:56,398] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 24, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:45:56,398] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:45:56,405] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.027 seconds
[2020-08-01 14:46:02,283] {scheduler_job.py:154} INFO - Started process (PID=59055) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:02,301] {logging_mixin.py:112} INFO - [2020-08-01 14:46:02,300] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:02,301] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:02,301] {logging_mixin.py:112} INFO - [2020-08-01 14:46:02,301] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:02,304] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x10974b310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:02,304] {logging_mixin.py:112} INFO - [2020-08-01 14:46:02,304] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:02,304] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:02,310] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.027 seconds
[2020-08-01 14:46:08,312] {scheduler_job.py:154} INFO - Started process (PID=59070) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:08,329] {logging_mixin.py:112} INFO - [2020-08-01 14:46:08,329] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:08,330] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:08,330] {logging_mixin.py:112} INFO - [2020-08-01 14:46:08,330] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:08,331] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x10f175310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:08,332] {logging_mixin.py:112} INFO - [2020-08-01 14:46:08,331] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:08,332] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:08,339] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.027 seconds
[2020-08-01 14:46:14,344] {scheduler_job.py:154} INFO - Started process (PID=59087) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:14,361] {logging_mixin.py:112} INFO - [2020-08-01 14:46:14,361] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:14,362] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:14,362] {logging_mixin.py:112} INFO - [2020-08-01 14:46:14,362] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:14,364] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x10fb73310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:14,365] {logging_mixin.py:112} INFO - [2020-08-01 14:46:14,365] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:14,365] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:14,371] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.027 seconds
[2020-08-01 14:46:20,354] {scheduler_job.py:154} INFO - Started process (PID=59116) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:20,371] {logging_mixin.py:112} INFO - [2020-08-01 14:46:20,371] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:20,372] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:20,372] {logging_mixin.py:112} INFO - [2020-08-01 14:46:20,372] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:20,373] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x10db8c310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:20,374] {logging_mixin.py:112} INFO - [2020-08-01 14:46:20,374] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:20,374] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:20,381] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.028 seconds
[2020-08-01 14:46:26,364] {scheduler_job.py:154} INFO - Started process (PID=59130) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:26,381] {logging_mixin.py:112} INFO - [2020-08-01 14:46:26,381] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:26,382] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:26,382] {logging_mixin.py:112} INFO - [2020-08-01 14:46:26,382] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:26,384] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x11b249310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:26,384] {logging_mixin.py:112} INFO - [2020-08-01 14:46:26,384] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:26,384] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:26,391] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.027 seconds
[2020-08-01 14:46:32,451] {scheduler_job.py:154} INFO - Started process (PID=59137) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:32,471] {logging_mixin.py:112} INFO - [2020-08-01 14:46:32,470] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:32,471] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:32,471] {logging_mixin.py:112} INFO - [2020-08-01 14:46:32,471] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:32,473] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x1193a4310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:32,474] {logging_mixin.py:112} INFO - [2020-08-01 14:46:32,473] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:32,474] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:32,481] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.030 seconds
[2020-08-01 14:46:38,492] {scheduler_job.py:154} INFO - Started process (PID=59144) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:38,512] {logging_mixin.py:112} INFO - [2020-08-01 14:46:38,512] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:38,513] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:38,513] {logging_mixin.py:112} INFO - [2020-08-01 14:46:38,513] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:38,514] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x10ed94310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:38,515] {logging_mixin.py:112} INFO - [2020-08-01 14:46:38,515] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:38,515] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:38,522] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.031 seconds
[2020-08-01 14:46:44,539] {scheduler_job.py:154} INFO - Started process (PID=59159) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:44,557] {logging_mixin.py:112} INFO - [2020-08-01 14:46:44,557] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:44,557] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:44,558] {logging_mixin.py:112} INFO - [2020-08-01 14:46:44,558] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:44,559] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x11355b310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:44,560] {logging_mixin.py:112} INFO - [2020-08-01 14:46:44,559] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:44,560] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:44,566] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.027 seconds
[2020-08-01 14:46:50,470] {scheduler_job.py:154} INFO - Started process (PID=59173) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:50,488] {logging_mixin.py:112} INFO - [2020-08-01 14:46:50,487] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:50,488] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:50,488] {logging_mixin.py:112} INFO - [2020-08-01 14:46:50,488] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:50,490] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x10f6ee310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:50,491] {logging_mixin.py:112} INFO - [2020-08-01 14:46:50,490] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:50,491] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:50,497] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.027 seconds
[2020-08-01 14:46:56,508] {scheduler_job.py:154} INFO - Started process (PID=59187) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:56,526] {logging_mixin.py:112} INFO - [2020-08-01 14:46:56,526] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:56,528] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:46:56,528] {logging_mixin.py:112} INFO - [2020-08-01 14:46:56,528] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:56,529] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x110d60310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:46:56,530] {logging_mixin.py:112} INFO - [2020-08-01 14:46:56,530] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:46:56,530] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:46:56,536] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.028 seconds
[2020-08-01 14:47:02,502] {scheduler_job.py:154} INFO - Started process (PID=59202) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:02,521] {logging_mixin.py:112} INFO - [2020-08-01 14:47:02,521] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:02,521] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:02,522] {logging_mixin.py:112} INFO - [2020-08-01 14:47:02,522] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:02,523] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x115df7310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:47:02,524] {logging_mixin.py:112} INFO - [2020-08-01 14:47:02,523] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:47:02,524] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:02,531] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.028 seconds
[2020-08-01 14:47:08,672] {scheduler_job.py:154} INFO - Started process (PID=59224) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:08,695] {logging_mixin.py:112} INFO - [2020-08-01 14:47:08,695] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:08,696] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:08,696] {logging_mixin.py:112} INFO - [2020-08-01 14:47:08,696] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:08,698] {logging_mixin.py:112} WARNING - /Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/operators/dummy_operator.py:36: PendingDeprecationWarning: Invalid arguments were passed to DummyOperator (task_id: get_covid_data_today). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'python_callable': <function get_covid_data_today at 0x1167d2310>}
  super(DummyOperator, self).__init__(*args, **kwargs)
[2020-08-01 14:47:08,699] {logging_mixin.py:112} INFO - [2020-08-01 14:47:08,699] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py", line 25, in <module>
    t2 = PythonOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2020-08-01 14:47:08,700] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:08,707] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.036 seconds
[2020-08-01 14:47:14,566] {scheduler_job.py:154} INFO - Started process (PID=59243) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:14,584] {logging_mixin.py:112} INFO - [2020-08-01 14:47:14,583] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:14,584] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:14,584] {logging_mixin.py:112} INFO - [2020-08-01 14:47:14,584] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:14,587] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:14,591] {logging_mixin.py:112} INFO - [2020-08-01 14:47:14,590] {dag.py:1520} INFO - Creating ORM DAG for python_pipeline
[2020-08-01 14:47:14,597] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.032 seconds
[2020-08-01 14:47:20,560] {scheduler_job.py:154} INFO - Started process (PID=59280) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:20,578] {logging_mixin.py:112} INFO - [2020-08-01 14:47:20,578] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:20,579] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:20,579] {logging_mixin.py:112} INFO - [2020-08-01 14:47:20,579] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:20,581] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:20,594] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.034 seconds
[2020-08-01 14:47:26,540] {scheduler_job.py:154} INFO - Started process (PID=59286) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:26,557] {logging_mixin.py:112} INFO - [2020-08-01 14:47:26,557] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:26,558] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:26,558] {logging_mixin.py:112} INFO - [2020-08-01 14:47:26,558] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:26,560] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:26,572] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.033 seconds
[2020-08-01 14:47:32,682] {scheduler_job.py:154} INFO - Started process (PID=59293) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:32,704] {logging_mixin.py:112} INFO - [2020-08-01 14:47:32,704] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:32,705] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:32,705] {logging_mixin.py:112} INFO - [2020-08-01 14:47:32,705] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:32,707] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:32,725] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:47:32,732] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:32,733] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 14:47:38,628] {scheduler_job.py:154} INFO - Started process (PID=59307) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:38,647] {logging_mixin.py:112} INFO - [2020-08-01 14:47:38,647] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:38,648] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:38,648] {logging_mixin.py:112} INFO - [2020-08-01 14:47:38,648] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:38,650] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:38,665] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:47:38,672] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:38,674] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:47:44,758] {scheduler_job.py:154} INFO - Started process (PID=59323) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:44,777] {logging_mixin.py:112} INFO - [2020-08-01 14:47:44,777] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:44,778] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:44,778] {logging_mixin.py:112} INFO - [2020-08-01 14:47:44,778] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:44,780] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:44,796] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:47:44,803] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:44,805] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:47:50,679] {scheduler_job.py:154} INFO - Started process (PID=59329) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:50,698] {logging_mixin.py:112} INFO - [2020-08-01 14:47:50,698] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:50,698] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:50,699] {logging_mixin.py:112} INFO - [2020-08-01 14:47:50,699] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:50,701] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:50,717] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:47:50,724] {scheduler_job.py:766} INFO - Examining DAG run <DagRun python_pipeline @ 2020-08-01 07:47:47.280084+00:00: manual__2020-08-01T07:47:47.280084+00:00, externally triggered: True>
[2020-08-01 14:47:50,740] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:50,743] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: python_pipeline.start 2020-08-01 07:47:47.280084+00:00 [success]> in ORM
[2020-08-01 14:47:50,750] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.071 seconds
[2020-08-01 14:47:56,657] {scheduler_job.py:154} INFO - Started process (PID=59335) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:56,675] {logging_mixin.py:112} INFO - [2020-08-01 14:47:56,675] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:56,676] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:47:56,676] {logging_mixin.py:112} INFO - [2020-08-01 14:47:56,676] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:56,678] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:47:56,693] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:47:56,701] {scheduler_job.py:766} INFO - Examining DAG run <DagRun python_pipeline @ 2020-08-01 07:47:47.280084+00:00: manual__2020-08-01T07:47:47.280084+00:00, externally triggered: True>
[2020-08-01 14:47:56,719] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:56,721] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: python_pipeline.get_covid_data_today 2020-08-01 07:47:47.280084+00:00 [scheduled]> in ORM
[2020-08-01 14:47:56,728] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.071 seconds
[2020-08-01 14:48:07,992] {scheduler_job.py:154} INFO - Started process (PID=59344) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:08,010] {logging_mixin.py:112} INFO - [2020-08-01 14:48:08,010] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:08,010] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:48:08,010] {logging_mixin.py:112} INFO - [2020-08-01 14:48:08,010] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:08,013] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:08,027] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:48:08,034] {scheduler_job.py:766} INFO - Examining DAG run <DagRun python_pipeline @ 2020-08-01 07:47:47.280084+00:00: manual__2020-08-01T07:47:47.280084+00:00, externally triggered: True>
[2020-08-01 14:48:08,047] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:08,058] {logging_mixin.py:112} INFO - [2020-08-01 14:48:08,057] {dagbag.py:336} INFO - Marked zombie job <TaskInstance: python_pipeline.get_covid_data_today 2020-08-01 07:47:47.280084+00:00 [failed]> as failed
[2020-08-01 14:48:08,058] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.066 seconds
[2020-08-01 14:48:14,084] {scheduler_job.py:154} INFO - Started process (PID=59351) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:14,102] {logging_mixin.py:112} INFO - [2020-08-01 14:48:14,102] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:14,103] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:48:14,103] {logging_mixin.py:112} INFO - [2020-08-01 14:48:14,103] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:14,105] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:14,121] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:48:14,131] {scheduler_job.py:766} INFO - Examining DAG run <DagRun python_pipeline @ 2020-08-01 07:47:47.280084+00:00: manual__2020-08-01T07:47:47.280084+00:00, externally triggered: True>
[2020-08-01 14:48:14,147] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:14,158] {logging_mixin.py:112} INFO - [2020-08-01 14:48:14,158] {dagbag.py:336} INFO - Marked zombie job <TaskInstance: python_pipeline.get_covid_data_today 2020-08-01 07:47:47.280084+00:00 [failed]> as failed
[2020-08-01 14:48:14,159] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.075 seconds
[2020-08-01 14:48:20,093] {scheduler_job.py:154} INFO - Started process (PID=59368) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:20,117] {logging_mixin.py:112} INFO - [2020-08-01 14:48:20,117] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:20,118] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:48:20,118] {logging_mixin.py:112} INFO - [2020-08-01 14:48:20,118] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:20,121] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:20,136] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:48:20,143] {scheduler_job.py:766} INFO - Examining DAG run <DagRun python_pipeline @ 2020-08-01 07:47:47.280084+00:00: manual__2020-08-01T07:47:47.280084+00:00, externally triggered: True>
[2020-08-01 14:48:20,152] {logging_mixin.py:112} INFO - [2020-08-01 14:48:20,152] {dagrun.py:310} INFO - Marking run <DagRun python_pipeline @ 2020-08-01 07:47:47.280084+00:00: manual__2020-08-01T07:47:47.280084+00:00, externally triggered: True> failed
[2020-08-01 14:48:20,155] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:20,157] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.065 seconds
[2020-08-01 14:48:26,002] {scheduler_job.py:154} INFO - Started process (PID=59382) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:26,020] {logging_mixin.py:112} INFO - [2020-08-01 14:48:26,020] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:26,021] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:48:26,021] {logging_mixin.py:112} INFO - [2020-08-01 14:48:26,021] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:26,023] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:26,037] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:48:26,044] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:26,045] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:48:32,162] {scheduler_job.py:154} INFO - Started process (PID=59389) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:32,179] {logging_mixin.py:112} INFO - [2020-08-01 14:48:32,179] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:32,180] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:48:32,180] {logging_mixin.py:112} INFO - [2020-08-01 14:48:32,180] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:32,182] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:32,199] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:48:32,206] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:32,208] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:48:38,027] {scheduler_job.py:154} INFO - Started process (PID=59395) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:38,045] {logging_mixin.py:112} INFO - [2020-08-01 14:48:38,044] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:38,045] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:48:38,045] {logging_mixin.py:112} INFO - [2020-08-01 14:48:38,045] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:38,047] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:38,062] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:48:38,069] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:38,070] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:48:44,060] {scheduler_job.py:154} INFO - Started process (PID=59402) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:44,078] {logging_mixin.py:112} INFO - [2020-08-01 14:48:44,078] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:44,079] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:48:44,079] {logging_mixin.py:112} INFO - [2020-08-01 14:48:44,079] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:44,081] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:44,095] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:48:44,106] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:44,109] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 14:48:50,078] {scheduler_job.py:154} INFO - Started process (PID=59408) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:50,095] {logging_mixin.py:112} INFO - [2020-08-01 14:48:50,095] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:50,096] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:48:50,096] {logging_mixin.py:112} INFO - [2020-08-01 14:48:50,096] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:50,098] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:50,112] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:48:50,119] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:50,120] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:48:56,104] {scheduler_job.py:154} INFO - Started process (PID=59414) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:56,123] {logging_mixin.py:112} INFO - [2020-08-01 14:48:56,122] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:56,123] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:48:56,123] {logging_mixin.py:112} INFO - [2020-08-01 14:48:56,123] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:56,126] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:48:56,141] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:48:56,149] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:56,150] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:49:02,144] {scheduler_job.py:154} INFO - Started process (PID=59420) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:02,163] {logging_mixin.py:112} INFO - [2020-08-01 14:49:02,162] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:02,163] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:02,163] {logging_mixin.py:112} INFO - [2020-08-01 14:49:02,163] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:02,165] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:02,179] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:02,186] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:02,188] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:49:08,133] {scheduler_job.py:154} INFO - Started process (PID=59426) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:08,151] {logging_mixin.py:112} INFO - [2020-08-01 14:49:08,151] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:08,151] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:08,152] {logging_mixin.py:112} INFO - [2020-08-01 14:49:08,152] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:08,154] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:08,168] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:08,175] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:08,177] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:49:14,155] {scheduler_job.py:154} INFO - Started process (PID=59433) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:14,175] {logging_mixin.py:112} INFO - [2020-08-01 14:49:14,175] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:14,176] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:14,176] {logging_mixin.py:112} INFO - [2020-08-01 14:49:14,176] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:14,178] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:14,192] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:14,201] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:14,216] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.061 seconds
[2020-08-01 14:49:20,175] {scheduler_job.py:154} INFO - Started process (PID=59439) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:20,193] {logging_mixin.py:112} INFO - [2020-08-01 14:49:20,193] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:20,194] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:20,194] {logging_mixin.py:112} INFO - [2020-08-01 14:49:20,194] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:20,196] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:20,211] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:20,218] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:20,220] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:49:26,219] {scheduler_job.py:154} INFO - Started process (PID=59445) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:26,237] {logging_mixin.py:112} INFO - [2020-08-01 14:49:26,236] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:26,237] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:26,237] {logging_mixin.py:112} INFO - [2020-08-01 14:49:26,237] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:26,239] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:26,254] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:26,262] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:26,264] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:49:32,227] {scheduler_job.py:154} INFO - Started process (PID=59451) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:32,244] {logging_mixin.py:112} INFO - [2020-08-01 14:49:32,244] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:32,245] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:32,245] {logging_mixin.py:112} INFO - [2020-08-01 14:49:32,245] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:32,247] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:32,262] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:32,269] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:32,271] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:49:38,251] {scheduler_job.py:154} INFO - Started process (PID=59457) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:38,268] {logging_mixin.py:112} INFO - [2020-08-01 14:49:38,268] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:38,269] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:38,269] {logging_mixin.py:112} INFO - [2020-08-01 14:49:38,269] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:38,271] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:38,285] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:38,293] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:38,294] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:49:44,228] {scheduler_job.py:154} INFO - Started process (PID=59464) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:44,246] {logging_mixin.py:112} INFO - [2020-08-01 14:49:44,246] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:44,246] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:44,247] {logging_mixin.py:112} INFO - [2020-08-01 14:49:44,247] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:44,249] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:44,263] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:44,270] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:44,271] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:49:50,252] {scheduler_job.py:154} INFO - Started process (PID=59470) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:50,270] {logging_mixin.py:112} INFO - [2020-08-01 14:49:50,269] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:50,270] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:50,270] {logging_mixin.py:112} INFO - [2020-08-01 14:49:50,270] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:50,272] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:50,287] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:50,294] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:50,295] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:49:56,277] {scheduler_job.py:154} INFO - Started process (PID=59476) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:56,294] {logging_mixin.py:112} INFO - [2020-08-01 14:49:56,294] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:56,295] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:49:56,295] {logging_mixin.py:112} INFO - [2020-08-01 14:49:56,295] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:56,297] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:49:56,311] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:49:56,318] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:56,320] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:50:02,367] {scheduler_job.py:154} INFO - Started process (PID=59482) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:02,385] {logging_mixin.py:112} INFO - [2020-08-01 14:50:02,384] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:02,385] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:02,385] {logging_mixin.py:112} INFO - [2020-08-01 14:50:02,385] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:02,388] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:02,402] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:02,409] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:02,410] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:50:08,371] {scheduler_job.py:154} INFO - Started process (PID=59488) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:08,389] {logging_mixin.py:112} INFO - [2020-08-01 14:50:08,389] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:08,389] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:08,389] {logging_mixin.py:112} INFO - [2020-08-01 14:50:08,389] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:08,392] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:08,406] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:08,413] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:08,414] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:50:14,390] {scheduler_job.py:154} INFO - Started process (PID=59495) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:14,408] {logging_mixin.py:112} INFO - [2020-08-01 14:50:14,408] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:14,409] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:14,409] {logging_mixin.py:112} INFO - [2020-08-01 14:50:14,409] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:14,411] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:14,426] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:14,435] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:14,437] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 14:50:20,434] {scheduler_job.py:154} INFO - Started process (PID=59502) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:20,453] {logging_mixin.py:112} INFO - [2020-08-01 14:50:20,453] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:20,454] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:20,454] {logging_mixin.py:112} INFO - [2020-08-01 14:50:20,454] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:20,456] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:20,472] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:20,478] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:20,480] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:50:26,363] {scheduler_job.py:154} INFO - Started process (PID=59508) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:26,381] {logging_mixin.py:112} INFO - [2020-08-01 14:50:26,381] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:26,382] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:26,382] {logging_mixin.py:112} INFO - [2020-08-01 14:50:26,382] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:26,384] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:26,398] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:26,405] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:26,407] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:50:32,374] {scheduler_job.py:154} INFO - Started process (PID=59514) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:32,392] {logging_mixin.py:112} INFO - [2020-08-01 14:50:32,392] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:32,392] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:32,393] {logging_mixin.py:112} INFO - [2020-08-01 14:50:32,392] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:32,395] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:32,409] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:32,416] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:32,417] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:50:38,412] {scheduler_job.py:154} INFO - Started process (PID=59520) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:38,429] {logging_mixin.py:112} INFO - [2020-08-01 14:50:38,429] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:38,430] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:38,430] {logging_mixin.py:112} INFO - [2020-08-01 14:50:38,430] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:38,432] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:38,446] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:38,453] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:38,455] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:50:44,432] {scheduler_job.py:154} INFO - Started process (PID=59527) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:44,449] {logging_mixin.py:112} INFO - [2020-08-01 14:50:44,449] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:44,450] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:44,450] {logging_mixin.py:112} INFO - [2020-08-01 14:50:44,450] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:44,452] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:44,466] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:44,472] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:44,474] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 14:50:50,457] {scheduler_job.py:154} INFO - Started process (PID=59533) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:50,475] {logging_mixin.py:112} INFO - [2020-08-01 14:50:50,475] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:50,475] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:50,475] {logging_mixin.py:112} INFO - [2020-08-01 14:50:50,475] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:50,478] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:50,492] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:50,499] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:50,500] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:50:56,485] {scheduler_job.py:154} INFO - Started process (PID=59539) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:56,502] {logging_mixin.py:112} INFO - [2020-08-01 14:50:56,502] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:56,503] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:50:56,503] {logging_mixin.py:112} INFO - [2020-08-01 14:50:56,503] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:56,505] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:50:56,519] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:50:56,527] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:56,529] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:51:02,506] {scheduler_job.py:154} INFO - Started process (PID=59546) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:02,524] {logging_mixin.py:112} INFO - [2020-08-01 14:51:02,524] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:02,525] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:02,525] {logging_mixin.py:112} INFO - [2020-08-01 14:51:02,525] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:02,527] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:02,541] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:02,548] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:02,550] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:51:08,545] {scheduler_job.py:154} INFO - Started process (PID=59552) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:08,566] {logging_mixin.py:112} INFO - [2020-08-01 14:51:08,566] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:08,567] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:08,567] {logging_mixin.py:112} INFO - [2020-08-01 14:51:08,567] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:08,570] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:08,584] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:08,592] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:08,594] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 14:51:14,620] {scheduler_job.py:154} INFO - Started process (PID=59560) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:14,637] {logging_mixin.py:112} INFO - [2020-08-01 14:51:14,637] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:14,638] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:14,638] {logging_mixin.py:112} INFO - [2020-08-01 14:51:14,638] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:14,640] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:14,655] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:14,663] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:14,665] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:51:20,582] {scheduler_job.py:154} INFO - Started process (PID=59566) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:20,600] {logging_mixin.py:112} INFO - [2020-08-01 14:51:20,600] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:20,601] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:20,601] {logging_mixin.py:112} INFO - [2020-08-01 14:51:20,601] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:20,603] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:20,617] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:20,624] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:20,625] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:51:26,613] {scheduler_job.py:154} INFO - Started process (PID=59572) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:26,630] {logging_mixin.py:112} INFO - [2020-08-01 14:51:26,630] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:26,631] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:26,631] {logging_mixin.py:112} INFO - [2020-08-01 14:51:26,631] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:26,633] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:26,647] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:26,655] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:26,656] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:51:32,624] {scheduler_job.py:154} INFO - Started process (PID=59578) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:32,642] {logging_mixin.py:112} INFO - [2020-08-01 14:51:32,642] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:32,642] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:32,643] {logging_mixin.py:112} INFO - [2020-08-01 14:51:32,643] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:32,645] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:32,659] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:32,666] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:32,668] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:51:38,655] {scheduler_job.py:154} INFO - Started process (PID=59584) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:38,672] {logging_mixin.py:112} INFO - [2020-08-01 14:51:38,672] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:38,673] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:38,673] {logging_mixin.py:112} INFO - [2020-08-01 14:51:38,673] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:38,675] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:38,689] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:38,696] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:38,697] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:51:44,754] {scheduler_job.py:154} INFO - Started process (PID=59590) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:44,771] {logging_mixin.py:112} INFO - [2020-08-01 14:51:44,771] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:44,772] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:44,772] {logging_mixin.py:112} INFO - [2020-08-01 14:51:44,772] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:44,774] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:44,787] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:44,794] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:44,795] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 14:51:50,743] {scheduler_job.py:154} INFO - Started process (PID=59597) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:50,761] {logging_mixin.py:112} INFO - [2020-08-01 14:51:50,761] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:50,761] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:50,762] {logging_mixin.py:112} INFO - [2020-08-01 14:51:50,762] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:50,764] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:50,777] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:50,784] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:50,786] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:51:57,206] {scheduler_job.py:154} INFO - Started process (PID=59616) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:57,239] {logging_mixin.py:112} INFO - [2020-08-01 14:51:57,239] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:57,240] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:51:57,240] {logging_mixin.py:112} INFO - [2020-08-01 14:51:57,240] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:57,250] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:51:57,283] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:51:57,300] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:57,303] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.097 seconds
[2020-08-01 14:52:02,736] {scheduler_job.py:154} INFO - Started process (PID=59622) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:02,753] {logging_mixin.py:112} INFO - [2020-08-01 14:52:02,753] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:02,754] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:52:02,754] {logging_mixin.py:112} INFO - [2020-08-01 14:52:02,754] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:02,756] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:02,771] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:52:02,778] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:02,780] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:52:08,837] {scheduler_job.py:154} INFO - Started process (PID=59628) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:08,856] {logging_mixin.py:112} INFO - [2020-08-01 14:52:08,855] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:08,856] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:52:08,856] {logging_mixin.py:112} INFO - [2020-08-01 14:52:08,856] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:08,858] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:08,873] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:52:08,881] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:08,883] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:52:14,803] {scheduler_job.py:154} INFO - Started process (PID=59634) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:14,821] {logging_mixin.py:112} INFO - [2020-08-01 14:52:14,821] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:14,821] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:52:14,822] {logging_mixin.py:112} INFO - [2020-08-01 14:52:14,821] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:14,824] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:14,837] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:52:14,844] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:14,845] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:52:50,897] {scheduler_job.py:154} INFO - Started process (PID=59652) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:50,918] {logging_mixin.py:112} INFO - [2020-08-01 14:52:50,918] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:50,918] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:52:50,918] {logging_mixin.py:112} INFO - [2020-08-01 14:52:50,918] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:50,921] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:50,935] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:52:50,942] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:50,944] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 14:52:56,885] {scheduler_job.py:154} INFO - Started process (PID=59658) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:56,902] {logging_mixin.py:112} INFO - [2020-08-01 14:52:56,902] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:56,903] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:52:56,903] {logging_mixin.py:112} INFO - [2020-08-01 14:52:56,903] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:56,905] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:52:56,919] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:52:56,927] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:56,928] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:53:02,930] {scheduler_job.py:154} INFO - Started process (PID=59664) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:02,949] {logging_mixin.py:112} INFO - [2020-08-01 14:53:02,949] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:02,950] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:53:02,950] {logging_mixin.py:112} INFO - [2020-08-01 14:53:02,950] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:02,952] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:02,969] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:53:02,977] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:02,979] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 14:53:08,986] {scheduler_job.py:154} INFO - Started process (PID=59670) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:09,006] {logging_mixin.py:112} INFO - [2020-08-01 14:53:09,005] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:09,006] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:53:09,006] {logging_mixin.py:112} INFO - [2020-08-01 14:53:09,006] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:09,009] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:09,023] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:53:09,030] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:09,032] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:53:15,056] {scheduler_job.py:154} INFO - Started process (PID=59676) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:15,077] {logging_mixin.py:112} INFO - [2020-08-01 14:53:15,076] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:15,078] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:53:15,078] {logging_mixin.py:112} INFO - [2020-08-01 14:53:15,078] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:15,081] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:15,099] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:53:15,106] {scheduler_job.py:766} INFO - Examining DAG run <DagRun python_pipeline @ 2020-08-01 07:53:10.298269+00:00: manual__2020-08-01T07:53:10.298269+00:00, externally triggered: True>
[2020-08-01 14:53:15,124] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:15,127] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: python_pipeline.start 2020-08-01 07:53:10.298269+00:00 [success]> in ORM
[2020-08-01 14:53:15,134] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.079 seconds
[2020-08-01 14:53:21,195] {scheduler_job.py:154} INFO - Started process (PID=59683) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:21,214] {logging_mixin.py:112} INFO - [2020-08-01 14:53:21,214] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:21,215] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:53:21,215] {logging_mixin.py:112} INFO - [2020-08-01 14:53:21,215] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:21,217] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:21,233] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:53:21,240] {scheduler_job.py:766} INFO - Examining DAG run <DagRun python_pipeline @ 2020-08-01 07:53:10.298269+00:00: manual__2020-08-01T07:53:10.298269+00:00, externally triggered: True>
[2020-08-01 14:53:21,257] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:21,259] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: python_pipeline.get_covid_data_today 2020-08-01 07:53:10.298269+00:00 [scheduled]> in ORM
[2020-08-01 14:53:21,267] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.073 seconds
[2020-08-01 14:53:32,388] {scheduler_job.py:154} INFO - Started process (PID=59692) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:32,406] {logging_mixin.py:112} INFO - [2020-08-01 14:53:32,405] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:32,406] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:53:32,406] {logging_mixin.py:112} INFO - [2020-08-01 14:53:32,406] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:32,408] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:32,422] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:53:32,429] {scheduler_job.py:766} INFO - Examining DAG run <DagRun python_pipeline @ 2020-08-01 07:53:10.298269+00:00: manual__2020-08-01T07:53:10.298269+00:00, externally triggered: True>
[2020-08-01 14:53:32,442] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:32,444] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: python_pipeline.end 2020-08-01 07:53:10.298269+00:00 [success]> in ORM
[2020-08-01 14:53:32,451] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.063 seconds
[2020-08-01 14:53:38,383] {scheduler_job.py:154} INFO - Started process (PID=59698) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:38,401] {logging_mixin.py:112} INFO - [2020-08-01 14:53:38,401] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:38,402] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:53:38,402] {logging_mixin.py:112} INFO - [2020-08-01 14:53:38,402] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:38,404] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:38,418] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:53:38,427] {scheduler_job.py:766} INFO - Examining DAG run <DagRun python_pipeline @ 2020-08-01 07:53:10.298269+00:00: manual__2020-08-01T07:53:10.298269+00:00, externally triggered: True>
[2020-08-01 14:53:38,434] {logging_mixin.py:112} INFO - [2020-08-01 14:53:38,434] {dagrun.py:319} INFO - Marking run <DagRun python_pipeline @ 2020-08-01 07:53:10.298269+00:00: manual__2020-08-01T07:53:10.298269+00:00, externally triggered: True> successful
[2020-08-01 14:53:38,437] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:38,439] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.056 seconds
[2020-08-01 14:53:44,376] {scheduler_job.py:154} INFO - Started process (PID=59704) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:44,394] {logging_mixin.py:112} INFO - [2020-08-01 14:53:44,393] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:44,394] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:53:44,394] {logging_mixin.py:112} INFO - [2020-08-01 14:53:44,394] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:44,396] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:44,411] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:53:44,418] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:44,419] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:53:50,443] {scheduler_job.py:154} INFO - Started process (PID=59711) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:50,463] {logging_mixin.py:112} INFO - [2020-08-01 14:53:50,463] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:50,463] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:53:50,464] {logging_mixin.py:112} INFO - [2020-08-01 14:53:50,464] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:50,466] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:50,479] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:53:50,486] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:50,488] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:53:56,412] {scheduler_job.py:154} INFO - Started process (PID=59717) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:56,430] {logging_mixin.py:112} INFO - [2020-08-01 14:53:56,430] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:56,430] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:53:56,430] {logging_mixin.py:112} INFO - [2020-08-01 14:53:56,430] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:56,433] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:53:56,447] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:53:56,454] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:56,456] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:54:02,430] {scheduler_job.py:154} INFO - Started process (PID=59723) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:02,448] {logging_mixin.py:112} INFO - [2020-08-01 14:54:02,448] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:02,448] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:02,449] {logging_mixin.py:112} INFO - [2020-08-01 14:54:02,449] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:02,451] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:02,465] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:02,472] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:02,473] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:54:08,455] {scheduler_job.py:154} INFO - Started process (PID=59729) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:08,473] {logging_mixin.py:112} INFO - [2020-08-01 14:54:08,473] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:08,474] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:08,474] {logging_mixin.py:112} INFO - [2020-08-01 14:54:08,474] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:08,476] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:08,490] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:08,497] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:08,498] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:54:14,478] {scheduler_job.py:154} INFO - Started process (PID=59735) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:14,496] {logging_mixin.py:112} INFO - [2020-08-01 14:54:14,495] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:14,496] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:14,496] {logging_mixin.py:112} INFO - [2020-08-01 14:54:14,496] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:14,498] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:14,513] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:14,519] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:14,521] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:54:20,506] {scheduler_job.py:154} INFO - Started process (PID=59742) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:20,524] {logging_mixin.py:112} INFO - [2020-08-01 14:54:20,523] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:20,524] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:20,524] {logging_mixin.py:112} INFO - [2020-08-01 14:54:20,524] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:20,526] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:20,541] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:20,549] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:20,551] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:54:26,537] {scheduler_job.py:154} INFO - Started process (PID=59748) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:26,555] {logging_mixin.py:112} INFO - [2020-08-01 14:54:26,555] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:26,556] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:26,556] {logging_mixin.py:112} INFO - [2020-08-01 14:54:26,556] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:26,558] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:26,572] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:26,579] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:26,581] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:54:32,551] {scheduler_job.py:154} INFO - Started process (PID=59754) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:32,569] {logging_mixin.py:112} INFO - [2020-08-01 14:54:32,569] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:32,570] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:32,570] {logging_mixin.py:112} INFO - [2020-08-01 14:54:32,570] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:32,572] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:32,586] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:32,594] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:32,595] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:54:38,571] {scheduler_job.py:154} INFO - Started process (PID=59760) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:38,588] {logging_mixin.py:112} INFO - [2020-08-01 14:54:38,588] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:38,589] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:38,589] {logging_mixin.py:112} INFO - [2020-08-01 14:54:38,589] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:38,591] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:38,605] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:38,616] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:38,618] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 14:54:44,565] {scheduler_job.py:154} INFO - Started process (PID=59766) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:44,582] {logging_mixin.py:112} INFO - [2020-08-01 14:54:44,582] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:44,583] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:44,583] {logging_mixin.py:112} INFO - [2020-08-01 14:54:44,583] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:44,585] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:44,599] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:44,606] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:44,608] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:54:50,682] {scheduler_job.py:154} INFO - Started process (PID=59773) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:50,699] {logging_mixin.py:112} INFO - [2020-08-01 14:54:50,699] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:50,700] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:50,700] {logging_mixin.py:112} INFO - [2020-08-01 14:54:50,700] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:50,702] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:50,716] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:50,722] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:50,724] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 14:54:56,681] {scheduler_job.py:154} INFO - Started process (PID=59780) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:56,698] {logging_mixin.py:112} INFO - [2020-08-01 14:54:56,698] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:56,699] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:54:56,699] {logging_mixin.py:112} INFO - [2020-08-01 14:54:56,699] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:56,701] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:54:56,715] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:54:56,722] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:56,724] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:55:02,632] {scheduler_job.py:154} INFO - Started process (PID=59786) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:02,650] {logging_mixin.py:112} INFO - [2020-08-01 14:55:02,649] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:02,650] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:02,650] {logging_mixin.py:112} INFO - [2020-08-01 14:55:02,650] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:02,652] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:02,665] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:02,672] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:02,673] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 14:55:08,657] {scheduler_job.py:154} INFO - Started process (PID=59800) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:08,674] {logging_mixin.py:112} INFO - [2020-08-01 14:55:08,674] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:08,675] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:08,675] {logging_mixin.py:112} INFO - [2020-08-01 14:55:08,675] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:08,677] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:08,691] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:08,699] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:08,700] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:55:14,687] {scheduler_job.py:154} INFO - Started process (PID=59814) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:14,704] {logging_mixin.py:112} INFO - [2020-08-01 14:55:14,704] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:14,705] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:14,705] {logging_mixin.py:112} INFO - [2020-08-01 14:55:14,705] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:14,707] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:14,722] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:14,728] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:14,730] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:55:20,712] {scheduler_job.py:154} INFO - Started process (PID=59829) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:20,729] {logging_mixin.py:112} INFO - [2020-08-01 14:55:20,729] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:20,729] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:20,730] {logging_mixin.py:112} INFO - [2020-08-01 14:55:20,730] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:20,732] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:20,745] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:20,752] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:20,753] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 14:55:26,760] {scheduler_job.py:154} INFO - Started process (PID=59843) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:26,777] {logging_mixin.py:112} INFO - [2020-08-01 14:55:26,777] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:26,778] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:26,778] {logging_mixin.py:112} INFO - [2020-08-01 14:55:26,778] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:26,780] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:26,794] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:26,803] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:26,804] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:55:32,750] {scheduler_job.py:154} INFO - Started process (PID=59865) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:32,768] {logging_mixin.py:112} INFO - [2020-08-01 14:55:32,768] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:32,769] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:32,769] {logging_mixin.py:112} INFO - [2020-08-01 14:55:32,769] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:32,771] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:32,786] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:32,794] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:32,795] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:55:38,759] {scheduler_job.py:154} INFO - Started process (PID=59879) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:38,777] {logging_mixin.py:112} INFO - [2020-08-01 14:55:38,777] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:38,778] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:38,778] {logging_mixin.py:112} INFO - [2020-08-01 14:55:38,778] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:38,780] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:38,794] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:38,801] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:38,802] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:55:44,800] {scheduler_job.py:154} INFO - Started process (PID=59894) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:44,817] {logging_mixin.py:112} INFO - [2020-08-01 14:55:44,817] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:44,818] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:44,818] {logging_mixin.py:112} INFO - [2020-08-01 14:55:44,818] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:44,820] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:44,834] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:44,842] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:44,843] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:55:50,866] {scheduler_job.py:154} INFO - Started process (PID=59909) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:50,884] {logging_mixin.py:112} INFO - [2020-08-01 14:55:50,883] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:50,884] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:50,884] {logging_mixin.py:112} INFO - [2020-08-01 14:55:50,884] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:50,886] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:50,900] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:50,907] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:50,909] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:55:56,823] {scheduler_job.py:154} INFO - Started process (PID=59923) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:56,842] {logging_mixin.py:112} INFO - [2020-08-01 14:55:56,841] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:56,842] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:55:56,842] {logging_mixin.py:112} INFO - [2020-08-01 14:55:56,842] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:56,844] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:55:56,859] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:55:56,867] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:56,868] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:56:02,872] {scheduler_job.py:154} INFO - Started process (PID=59937) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:02,890] {logging_mixin.py:112} INFO - [2020-08-01 14:56:02,890] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:02,890] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:02,891] {logging_mixin.py:112} INFO - [2020-08-01 14:56:02,891] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:02,893] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:02,907] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:02,914] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:02,916] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:56:08,877] {scheduler_job.py:154} INFO - Started process (PID=59959) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:08,894] {logging_mixin.py:112} INFO - [2020-08-01 14:56:08,894] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:08,895] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:08,895] {logging_mixin.py:112} INFO - [2020-08-01 14:56:08,895] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:08,897] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:08,911] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:08,918] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:08,920] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:56:14,905] {scheduler_job.py:154} INFO - Started process (PID=59973) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:14,923] {logging_mixin.py:112} INFO - [2020-08-01 14:56:14,923] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:14,923] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:14,924] {logging_mixin.py:112} INFO - [2020-08-01 14:56:14,924] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:14,926] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:14,940] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:14,946] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:14,948] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:56:21,024] {scheduler_job.py:154} INFO - Started process (PID=59987) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:21,043] {logging_mixin.py:112} INFO - [2020-08-01 14:56:21,043] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:21,043] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:21,044] {logging_mixin.py:112} INFO - [2020-08-01 14:56:21,043] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:21,046] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:21,058] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:21,065] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:21,067] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:56:26,946] {scheduler_job.py:154} INFO - Started process (PID=60002) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:26,963] {logging_mixin.py:112} INFO - [2020-08-01 14:56:26,963] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:26,964] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:26,964] {logging_mixin.py:112} INFO - [2020-08-01 14:56:26,964] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:26,966] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:26,980] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:26,987] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:26,988] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:56:32,982] {scheduler_job.py:154} INFO - Started process (PID=60016) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:33,000] {logging_mixin.py:112} INFO - [2020-08-01 14:56:32,999] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:33,000] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:33,000] {logging_mixin.py:112} INFO - [2020-08-01 14:56:33,000] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:33,002] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:33,017] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:33,025] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:33,028] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:56:38,982] {scheduler_job.py:154} INFO - Started process (PID=60038) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:39,000] {logging_mixin.py:112} INFO - [2020-08-01 14:56:38,999] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:39,000] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:39,000] {logging_mixin.py:112} INFO - [2020-08-01 14:56:39,000] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:39,002] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:39,017] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:39,023] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:39,025] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:56:44,994] {scheduler_job.py:154} INFO - Started process (PID=60052) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:45,012] {logging_mixin.py:112} INFO - [2020-08-01 14:56:45,012] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:45,013] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:45,013] {logging_mixin.py:112} INFO - [2020-08-01 14:56:45,013] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:45,015] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:45,031] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:45,038] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:45,040] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:56:51,013] {scheduler_job.py:154} INFO - Started process (PID=60066) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:51,032] {logging_mixin.py:112} INFO - [2020-08-01 14:56:51,032] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:51,033] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:51,033] {logging_mixin.py:112} INFO - [2020-08-01 14:56:51,033] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:51,035] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:51,050] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:51,058] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:51,059] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:56:57,039] {scheduler_job.py:154} INFO - Started process (PID=60081) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:57,058] {logging_mixin.py:112} INFO - [2020-08-01 14:56:57,058] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:57,059] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:56:57,059] {logging_mixin.py:112} INFO - [2020-08-01 14:56:57,059] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:57,061] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:56:57,076] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:56:57,083] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:57,084] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:57:03,062] {scheduler_job.py:154} INFO - Started process (PID=60095) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:03,079] {logging_mixin.py:112} INFO - [2020-08-01 14:57:03,079] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:03,080] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:03,080] {logging_mixin.py:112} INFO - [2020-08-01 14:57:03,080] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:03,082] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:03,096] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:03,103] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:03,104] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:57:09,115] {scheduler_job.py:154} INFO - Started process (PID=60109) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:09,132] {logging_mixin.py:112} INFO - [2020-08-01 14:57:09,132] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:09,133] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:09,133] {logging_mixin.py:112} INFO - [2020-08-01 14:57:09,133] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:09,135] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:09,148] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:09,155] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:09,157] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 14:57:15,128] {scheduler_job.py:154} INFO - Started process (PID=60131) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:15,145] {logging_mixin.py:112} INFO - [2020-08-01 14:57:15,145] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:15,146] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:15,146] {logging_mixin.py:112} INFO - [2020-08-01 14:57:15,146] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:15,148] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:15,163] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:15,170] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:15,171] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:57:21,148] {scheduler_job.py:154} INFO - Started process (PID=60145) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:21,166] {logging_mixin.py:112} INFO - [2020-08-01 14:57:21,166] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:21,166] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:21,167] {logging_mixin.py:112} INFO - [2020-08-01 14:57:21,167] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:21,169] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:21,183] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:21,189] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:21,191] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:57:27,171] {scheduler_job.py:154} INFO - Started process (PID=60160) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:27,189] {logging_mixin.py:112} INFO - [2020-08-01 14:57:27,188] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:27,189] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:27,189] {logging_mixin.py:112} INFO - [2020-08-01 14:57:27,189] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:27,191] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:27,205] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:27,212] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:27,213] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 14:57:33,189] {scheduler_job.py:154} INFO - Started process (PID=60174) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:33,207] {logging_mixin.py:112} INFO - [2020-08-01 14:57:33,206] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:33,207] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:33,207] {logging_mixin.py:112} INFO - [2020-08-01 14:57:33,207] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:33,209] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:33,224] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:33,231] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:33,232] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:57:39,237] {scheduler_job.py:154} INFO - Started process (PID=60188) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:39,255] {logging_mixin.py:112} INFO - [2020-08-01 14:57:39,254] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:39,255] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:39,255] {logging_mixin.py:112} INFO - [2020-08-01 14:57:39,255] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:39,257] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:39,272] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:39,278] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:39,280] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:57:45,250] {scheduler_job.py:154} INFO - Started process (PID=60210) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:45,268] {logging_mixin.py:112} INFO - [2020-08-01 14:57:45,268] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:45,269] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:45,269] {logging_mixin.py:112} INFO - [2020-08-01 14:57:45,269] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:45,271] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:45,285] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:45,292] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:45,293] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:57:51,368] {scheduler_job.py:154} INFO - Started process (PID=60224) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:51,387] {logging_mixin.py:112} INFO - [2020-08-01 14:57:51,387] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:51,388] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:51,388] {logging_mixin.py:112} INFO - [2020-08-01 14:57:51,388] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:51,390] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:51,404] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:51,411] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:51,412] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:57:57,290] {scheduler_job.py:154} INFO - Started process (PID=60234) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:57,307] {logging_mixin.py:112} INFO - [2020-08-01 14:57:57,307] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:57,307] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:57:57,308] {logging_mixin.py:112} INFO - [2020-08-01 14:57:57,308] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:57,310] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:57:57,327] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:57:57,335] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:57,338] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 14:58:03,386] {scheduler_job.py:154} INFO - Started process (PID=60244) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:03,404] {logging_mixin.py:112} INFO - [2020-08-01 14:58:03,404] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:03,405] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:03,405] {logging_mixin.py:112} INFO - [2020-08-01 14:58:03,405] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:03,407] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:03,421] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:03,428] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:03,429] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:58:09,379] {scheduler_job.py:154} INFO - Started process (PID=60251) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:09,397] {logging_mixin.py:112} INFO - [2020-08-01 14:58:09,397] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:09,398] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:09,398] {logging_mixin.py:112} INFO - [2020-08-01 14:58:09,398] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:09,400] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:09,413] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:09,420] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:09,421] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 14:58:15,464] {scheduler_job.py:154} INFO - Started process (PID=60259) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:15,482] {logging_mixin.py:112} INFO - [2020-08-01 14:58:15,482] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:15,483] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:15,483] {logging_mixin.py:112} INFO - [2020-08-01 14:58:15,483] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:15,485] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:15,501] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:15,507] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:15,509] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:58:21,441] {scheduler_job.py:154} INFO - Started process (PID=60266) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:21,461] {logging_mixin.py:112} INFO - [2020-08-01 14:58:21,461] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:21,462] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:21,462] {logging_mixin.py:112} INFO - [2020-08-01 14:58:21,462] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:21,464] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:21,480] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:21,486] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:21,488] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:58:27,393] {scheduler_job.py:154} INFO - Started process (PID=60273) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:27,413] {logging_mixin.py:112} INFO - [2020-08-01 14:58:27,413] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:27,414] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:27,414] {logging_mixin.py:112} INFO - [2020-08-01 14:58:27,414] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:27,416] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:27,431] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:27,439] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:27,440] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 14:58:33,390] {scheduler_job.py:154} INFO - Started process (PID=60282) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:33,413] {logging_mixin.py:112} INFO - [2020-08-01 14:58:33,413] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:33,413] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:33,414] {logging_mixin.py:112} INFO - [2020-08-01 14:58:33,413] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:33,416] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:33,435] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:33,443] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:33,446] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.056 seconds
[2020-08-01 14:58:39,468] {scheduler_job.py:154} INFO - Started process (PID=60288) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:39,486] {logging_mixin.py:112} INFO - [2020-08-01 14:58:39,486] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:39,486] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:39,487] {logging_mixin.py:112} INFO - [2020-08-01 14:58:39,487] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:39,489] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:39,503] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:39,511] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:39,512] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:58:45,447] {scheduler_job.py:154} INFO - Started process (PID=60294) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:45,466] {logging_mixin.py:112} INFO - [2020-08-01 14:58:45,466] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:45,467] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:45,467] {logging_mixin.py:112} INFO - [2020-08-01 14:58:45,467] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:45,469] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:45,484] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:45,491] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:45,493] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:58:51,509] {scheduler_job.py:154} INFO - Started process (PID=60300) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:51,526] {logging_mixin.py:112} INFO - [2020-08-01 14:58:51,526] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:51,527] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:51,527] {logging_mixin.py:112} INFO - [2020-08-01 14:58:51,527] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:51,529] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:51,543] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:51,553] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:51,555] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:58:57,474] {scheduler_job.py:154} INFO - Started process (PID=60309) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:57,492] {logging_mixin.py:112} INFO - [2020-08-01 14:58:57,492] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:57,493] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:58:57,493] {logging_mixin.py:112} INFO - [2020-08-01 14:58:57,493] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:57,495] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:58:57,510] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:58:57,517] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:57,519] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:59:03,521] {scheduler_job.py:154} INFO - Started process (PID=60315) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:03,539] {logging_mixin.py:112} INFO - [2020-08-01 14:59:03,539] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:03,540] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:03,540] {logging_mixin.py:112} INFO - [2020-08-01 14:59:03,540] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:03,542] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:03,556] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:03,563] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:03,565] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:59:09,480] {scheduler_job.py:154} INFO - Started process (PID=60321) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:09,498] {logging_mixin.py:112} INFO - [2020-08-01 14:59:09,498] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:09,499] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:09,499] {logging_mixin.py:112} INFO - [2020-08-01 14:59:09,499] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:09,501] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:09,516] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:09,524] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:09,526] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 14:59:15,461] {scheduler_job.py:154} INFO - Started process (PID=60327) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:15,478] {logging_mixin.py:112} INFO - [2020-08-01 14:59:15,478] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:15,479] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:15,479] {logging_mixin.py:112} INFO - [2020-08-01 14:59:15,479] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:15,481] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:15,498] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:15,506] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:15,508] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 14:59:21,481] {scheduler_job.py:154} INFO - Started process (PID=60333) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:21,499] {logging_mixin.py:112} INFO - [2020-08-01 14:59:21,498] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:21,499] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:21,499] {logging_mixin.py:112} INFO - [2020-08-01 14:59:21,499] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:21,501] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:21,516] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:21,522] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:21,524] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:59:27,554] {scheduler_job.py:154} INFO - Started process (PID=60340) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:27,571] {logging_mixin.py:112} INFO - [2020-08-01 14:59:27,571] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:27,572] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:27,572] {logging_mixin.py:112} INFO - [2020-08-01 14:59:27,572] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:27,574] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:27,590] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:27,597] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:27,599] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 14:59:33,608] {scheduler_job.py:154} INFO - Started process (PID=60346) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:33,626] {logging_mixin.py:112} INFO - [2020-08-01 14:59:33,626] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:33,627] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:33,627] {logging_mixin.py:112} INFO - [2020-08-01 14:59:33,627] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:33,629] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:33,643] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:33,651] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:33,652] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 14:59:39,524] {scheduler_job.py:154} INFO - Started process (PID=60352) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:39,541] {logging_mixin.py:112} INFO - [2020-08-01 14:59:39,541] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:39,542] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:39,542] {logging_mixin.py:112} INFO - [2020-08-01 14:59:39,542] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:39,544] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:39,558] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:39,565] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:39,566] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:59:45,558] {scheduler_job.py:154} INFO - Started process (PID=60358) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:45,576] {logging_mixin.py:112} INFO - [2020-08-01 14:59:45,576] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:45,577] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:45,577] {logging_mixin.py:112} INFO - [2020-08-01 14:59:45,577] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:45,579] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:45,593] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:45,600] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:45,601] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:59:51,591] {scheduler_job.py:154} INFO - Started process (PID=60364) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:51,609] {logging_mixin.py:112} INFO - [2020-08-01 14:59:51,608] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:51,609] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:51,609] {logging_mixin.py:112} INFO - [2020-08-01 14:59:51,609] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:51,611] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:51,626] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:51,633] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:51,634] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 14:59:57,616] {scheduler_job.py:154} INFO - Started process (PID=60371) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:57,633] {logging_mixin.py:112} INFO - [2020-08-01 14:59:57,633] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:57,634] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 14:59:57,634] {logging_mixin.py:112} INFO - [2020-08-01 14:59:57,634] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:57,636] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 14:59:57,650] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 14:59:57,657] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:57,659] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:00:03,628] {scheduler_job.py:154} INFO - Started process (PID=60377) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:03,645] {logging_mixin.py:112} INFO - [2020-08-01 15:00:03,645] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:03,646] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:03,646] {logging_mixin.py:112} INFO - [2020-08-01 15:00:03,646] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:03,648] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:03,662] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:03,670] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:03,672] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:00:09,655] {scheduler_job.py:154} INFO - Started process (PID=60383) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:09,673] {logging_mixin.py:112} INFO - [2020-08-01 15:00:09,673] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:09,674] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:09,674] {logging_mixin.py:112} INFO - [2020-08-01 15:00:09,674] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:09,676] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:09,690] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:09,698] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:09,700] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:00:15,685] {scheduler_job.py:154} INFO - Started process (PID=60389) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:15,703] {logging_mixin.py:112} INFO - [2020-08-01 15:00:15,703] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:15,703] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:15,704] {logging_mixin.py:112} INFO - [2020-08-01 15:00:15,703] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:15,706] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:15,720] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:15,727] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:15,728] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:00:21,702] {scheduler_job.py:154} INFO - Started process (PID=60395) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:21,721] {logging_mixin.py:112} INFO - [2020-08-01 15:00:21,720] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:21,721] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:21,721] {logging_mixin.py:112} INFO - [2020-08-01 15:00:21,721] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:21,723] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:21,737] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:21,744] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:21,746] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:00:27,783] {scheduler_job.py:154} INFO - Started process (PID=60402) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:27,802] {logging_mixin.py:112} INFO - [2020-08-01 15:00:27,802] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:27,803] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:27,803] {logging_mixin.py:112} INFO - [2020-08-01 15:00:27,803] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:27,805] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:27,821] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:27,836] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:27,838] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.055 seconds
[2020-08-01 15:00:33,880] {scheduler_job.py:154} INFO - Started process (PID=60408) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:33,898] {logging_mixin.py:112} INFO - [2020-08-01 15:00:33,898] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:33,899] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:33,899] {logging_mixin.py:112} INFO - [2020-08-01 15:00:33,899] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:33,901] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:33,917] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:33,924] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:33,926] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:00:39,761] {scheduler_job.py:154} INFO - Started process (PID=60414) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:39,779] {logging_mixin.py:112} INFO - [2020-08-01 15:00:39,779] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:39,780] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:39,780] {logging_mixin.py:112} INFO - [2020-08-01 15:00:39,780] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:39,782] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:39,796] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:39,804] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:39,806] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:00:45,778] {scheduler_job.py:154} INFO - Started process (PID=60420) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:45,797] {logging_mixin.py:112} INFO - [2020-08-01 15:00:45,797] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:45,798] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:45,798] {logging_mixin.py:112} INFO - [2020-08-01 15:00:45,798] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:45,800] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:45,814] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:45,822] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:45,823] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:00:51,862] {scheduler_job.py:154} INFO - Started process (PID=60426) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:51,883] {logging_mixin.py:112} INFO - [2020-08-01 15:00:51,883] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:51,883] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:51,884] {logging_mixin.py:112} INFO - [2020-08-01 15:00:51,884] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:51,886] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:51,902] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:51,909] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:51,911] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:00:57,859] {scheduler_job.py:154} INFO - Started process (PID=60435) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:57,877] {logging_mixin.py:112} INFO - [2020-08-01 15:00:57,877] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:57,878] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:00:57,878] {logging_mixin.py:112} INFO - [2020-08-01 15:00:57,878] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:57,880] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:00:57,896] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:00:57,903] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:57,905] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:01:03,873] {scheduler_job.py:154} INFO - Started process (PID=60447) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:03,894] {logging_mixin.py:112} INFO - [2020-08-01 15:01:03,894] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:03,895] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:03,895] {logging_mixin.py:112} INFO - [2020-08-01 15:01:03,895] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:03,897] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:03,911] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:03,920] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:03,921] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:01:10,021] {scheduler_job.py:154} INFO - Started process (PID=60454) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:10,038] {logging_mixin.py:112} INFO - [2020-08-01 15:01:10,038] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:10,039] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:10,039] {logging_mixin.py:112} INFO - [2020-08-01 15:01:10,039] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:10,041] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:10,056] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:10,063] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:10,064] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:01:15,952] {scheduler_job.py:154} INFO - Started process (PID=60461) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:15,970] {logging_mixin.py:112} INFO - [2020-08-01 15:01:15,970] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:15,971] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:15,971] {logging_mixin.py:112} INFO - [2020-08-01 15:01:15,971] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:15,973] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:15,988] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:15,998] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:16,001] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:01:21,915] {scheduler_job.py:154} INFO - Started process (PID=60469) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:21,934] {logging_mixin.py:112} INFO - [2020-08-01 15:01:21,934] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:21,935] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:21,935] {logging_mixin.py:112} INFO - [2020-08-01 15:01:21,935] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:21,937] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:21,953] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:21,961] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:21,962] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:01:28,048] {scheduler_job.py:154} INFO - Started process (PID=60483) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:28,067] {logging_mixin.py:112} INFO - [2020-08-01 15:01:28,066] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:28,067] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:28,067] {logging_mixin.py:112} INFO - [2020-08-01 15:01:28,067] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:28,069] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:28,085] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:28,091] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:28,093] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:01:34,132] {scheduler_job.py:154} INFO - Started process (PID=60501) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:34,148] {logging_mixin.py:112} INFO - [2020-08-01 15:01:34,148] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:34,149] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:34,149] {logging_mixin.py:112} INFO - [2020-08-01 15:01:34,149] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:34,151] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:34,165] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:34,172] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:34,173] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:01:39,923] {scheduler_job.py:154} INFO - Started process (PID=60547) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:39,941] {logging_mixin.py:112} INFO - [2020-08-01 15:01:39,940] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:39,941] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:39,941] {logging_mixin.py:112} INFO - [2020-08-01 15:01:39,941] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:39,943] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:39,958] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:39,964] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:39,966] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:01:45,931] {scheduler_job.py:154} INFO - Started process (PID=60562) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:45,949] {logging_mixin.py:112} INFO - [2020-08-01 15:01:45,949] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:45,950] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:45,950] {logging_mixin.py:112} INFO - [2020-08-01 15:01:45,950] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:45,952] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:45,966] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:45,973] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:45,975] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:01:52,088] {scheduler_job.py:154} INFO - Started process (PID=60576) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:52,107] {logging_mixin.py:112} INFO - [2020-08-01 15:01:52,107] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:52,108] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:52,108] {logging_mixin.py:112} INFO - [2020-08-01 15:01:52,108] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:52,110] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:52,125] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:52,132] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:52,134] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:01:58,329] {scheduler_job.py:154} INFO - Started process (PID=60582) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:58,351] {logging_mixin.py:112} INFO - [2020-08-01 15:01:58,351] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:58,352] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:01:58,352] {logging_mixin.py:112} INFO - [2020-08-01 15:01:58,352] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:58,355] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:01:58,371] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:01:58,380] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:58,382] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.054 seconds
[2020-08-01 15:02:04,066] {scheduler_job.py:154} INFO - Started process (PID=60592) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:04,085] {logging_mixin.py:112} INFO - [2020-08-01 15:02:04,085] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:04,086] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:04,086] {logging_mixin.py:112} INFO - [2020-08-01 15:02:04,086] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:04,088] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:04,104] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:04,114] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:04,117] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.051 seconds
[2020-08-01 15:02:10,121] {scheduler_job.py:154} INFO - Started process (PID=60598) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:10,141] {logging_mixin.py:112} INFO - [2020-08-01 15:02:10,141] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:10,142] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:10,142] {logging_mixin.py:112} INFO - [2020-08-01 15:02:10,142] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:10,144] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:10,160] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:10,167] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:10,169] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:02:16,073] {scheduler_job.py:154} INFO - Started process (PID=60605) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:16,091] {logging_mixin.py:112} INFO - [2020-08-01 15:02:16,091] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:16,092] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:16,092] {logging_mixin.py:112} INFO - [2020-08-01 15:02:16,092] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:16,094] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:16,106] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:16,114] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:16,116] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:02:22,035] {scheduler_job.py:154} INFO - Started process (PID=60612) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:22,053] {logging_mixin.py:112} INFO - [2020-08-01 15:02:22,052] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:22,053] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:22,053] {logging_mixin.py:112} INFO - [2020-08-01 15:02:22,053] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:22,055] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:22,070] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:22,077] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:22,079] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:02:28,042] {scheduler_job.py:154} INFO - Started process (PID=60618) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:28,060] {logging_mixin.py:112} INFO - [2020-08-01 15:02:28,060] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:28,060] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:28,061] {logging_mixin.py:112} INFO - [2020-08-01 15:02:28,061] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:28,063] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:28,077] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:28,084] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:28,085] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:02:34,056] {scheduler_job.py:154} INFO - Started process (PID=60625) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:34,073] {logging_mixin.py:112} INFO - [2020-08-01 15:02:34,073] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:34,074] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:34,074] {logging_mixin.py:112} INFO - [2020-08-01 15:02:34,074] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:34,076] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:34,091] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:34,098] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:34,100] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:02:40,119] {scheduler_job.py:154} INFO - Started process (PID=60631) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:40,136] {logging_mixin.py:112} INFO - [2020-08-01 15:02:40,136] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:40,136] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:40,137] {logging_mixin.py:112} INFO - [2020-08-01 15:02:40,137] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:40,139] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:40,152] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:40,159] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:40,160] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:02:46,149] {scheduler_job.py:154} INFO - Started process (PID=60637) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:46,167] {logging_mixin.py:112} INFO - [2020-08-01 15:02:46,167] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:46,168] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:46,168] {logging_mixin.py:112} INFO - [2020-08-01 15:02:46,168] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:46,170] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:46,184] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:46,191] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:46,193] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:02:52,126] {scheduler_job.py:154} INFO - Started process (PID=60643) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:52,144] {logging_mixin.py:112} INFO - [2020-08-01 15:02:52,143] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:52,144] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:52,144] {logging_mixin.py:112} INFO - [2020-08-01 15:02:52,144] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:52,146] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:52,161] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:52,168] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:52,169] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:02:58,187] {scheduler_job.py:154} INFO - Started process (PID=60652) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:58,205] {logging_mixin.py:112} INFO - [2020-08-01 15:02:58,205] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:58,205] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:02:58,206] {logging_mixin.py:112} INFO - [2020-08-01 15:02:58,206] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:58,208] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:02:58,223] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:02:58,231] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:58,232] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:03:04,217] {scheduler_job.py:154} INFO - Started process (PID=60659) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:04,236] {logging_mixin.py:112} INFO - [2020-08-01 15:03:04,236] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:04,237] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:04,238] {logging_mixin.py:112} INFO - [2020-08-01 15:03:04,237] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:04,240] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:04,254] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:04,261] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:04,263] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:03:10,205] {scheduler_job.py:154} INFO - Started process (PID=60665) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:10,226] {logging_mixin.py:112} INFO - [2020-08-01 15:03:10,225] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:10,226] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:10,226] {logging_mixin.py:112} INFO - [2020-08-01 15:03:10,226] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:10,228] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:10,244] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:10,251] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:10,252] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:03:16,200] {scheduler_job.py:154} INFO - Started process (PID=60671) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:16,219] {logging_mixin.py:112} INFO - [2020-08-01 15:03:16,219] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:16,220] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:16,220] {logging_mixin.py:112} INFO - [2020-08-01 15:03:16,220] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:16,222] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:16,236] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:16,246] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:16,248] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:03:22,256] {scheduler_job.py:154} INFO - Started process (PID=60677) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:22,273] {logging_mixin.py:112} INFO - [2020-08-01 15:03:22,273] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:22,274] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:22,274] {logging_mixin.py:112} INFO - [2020-08-01 15:03:22,274] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:22,276] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:22,290] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:22,296] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:22,298] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:03:28,344] {scheduler_job.py:154} INFO - Started process (PID=60683) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:28,361] {logging_mixin.py:112} INFO - [2020-08-01 15:03:28,361] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:28,362] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:28,362] {logging_mixin.py:112} INFO - [2020-08-01 15:03:28,362] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:28,364] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:28,379] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:28,386] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:28,388] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:03:34,305] {scheduler_job.py:154} INFO - Started process (PID=60690) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:34,322] {logging_mixin.py:112} INFO - [2020-08-01 15:03:34,322] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:34,323] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:34,323] {logging_mixin.py:112} INFO - [2020-08-01 15:03:34,323] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:34,325] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:34,339] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:34,346] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:34,348] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:03:40,525] {scheduler_job.py:154} INFO - Started process (PID=60696) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:40,545] {logging_mixin.py:112} INFO - [2020-08-01 15:03:40,545] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:40,546] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:40,546] {logging_mixin.py:112} INFO - [2020-08-01 15:03:40,546] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:40,548] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:40,563] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:40,571] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:40,573] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:03:46,271] {scheduler_job.py:154} INFO - Started process (PID=60702) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:46,289] {logging_mixin.py:112} INFO - [2020-08-01 15:03:46,289] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:46,290] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:46,290] {logging_mixin.py:112} INFO - [2020-08-01 15:03:46,290] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:46,292] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:46,306] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:46,314] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:46,315] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:03:52,321] {scheduler_job.py:154} INFO - Started process (PID=60708) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:52,340] {logging_mixin.py:112} INFO - [2020-08-01 15:03:52,340] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:52,340] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:52,341] {logging_mixin.py:112} INFO - [2020-08-01 15:03:52,341] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:52,343] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:52,359] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:52,367] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:52,368] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:03:58,322] {scheduler_job.py:154} INFO - Started process (PID=60714) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:58,339] {logging_mixin.py:112} INFO - [2020-08-01 15:03:58,339] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:58,340] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:03:58,340] {logging_mixin.py:112} INFO - [2020-08-01 15:03:58,340] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:58,342] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:03:58,355] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:03:58,362] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:58,363] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:04:04,350] {scheduler_job.py:154} INFO - Started process (PID=60721) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:04,368] {logging_mixin.py:112} INFO - [2020-08-01 15:04:04,368] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:04,369] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:04,369] {logging_mixin.py:112} INFO - [2020-08-01 15:04:04,369] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:04,371] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:04,385] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:04,394] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:04,395] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:04:10,372] {scheduler_job.py:154} INFO - Started process (PID=60727) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:10,389] {logging_mixin.py:112} INFO - [2020-08-01 15:04:10,389] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:10,390] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:10,390] {logging_mixin.py:112} INFO - [2020-08-01 15:04:10,390] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:10,392] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:10,406] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:10,413] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:10,415] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:04:16,395] {scheduler_job.py:154} INFO - Started process (PID=60733) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:16,413] {logging_mixin.py:112} INFO - [2020-08-01 15:04:16,413] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:16,414] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:16,414] {logging_mixin.py:112} INFO - [2020-08-01 15:04:16,414] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:16,416] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:16,430] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:16,437] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:16,438] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:04:22,426] {scheduler_job.py:154} INFO - Started process (PID=60739) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:22,444] {logging_mixin.py:112} INFO - [2020-08-01 15:04:22,444] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:22,445] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:22,445] {logging_mixin.py:112} INFO - [2020-08-01 15:04:22,445] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:22,447] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:22,461] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:22,467] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:22,469] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:04:28,457] {scheduler_job.py:154} INFO - Started process (PID=60745) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:28,475] {logging_mixin.py:112} INFO - [2020-08-01 15:04:28,475] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:28,475] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:28,476] {logging_mixin.py:112} INFO - [2020-08-01 15:04:28,476] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:28,478] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:28,492] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:28,499] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:28,501] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:04:34,468] {scheduler_job.py:154} INFO - Started process (PID=60752) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:34,485] {logging_mixin.py:112} INFO - [2020-08-01 15:04:34,485] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:34,486] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:34,486] {logging_mixin.py:112} INFO - [2020-08-01 15:04:34,486] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:34,488] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:34,504] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:34,512] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:34,514] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:04:40,497] {scheduler_job.py:154} INFO - Started process (PID=60758) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:40,514] {logging_mixin.py:112} INFO - [2020-08-01 15:04:40,514] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:40,515] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:40,515] {logging_mixin.py:112} INFO - [2020-08-01 15:04:40,515] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:40,517] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:40,531] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:40,539] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:40,540] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:04:46,512] {scheduler_job.py:154} INFO - Started process (PID=60764) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:46,530] {logging_mixin.py:112} INFO - [2020-08-01 15:04:46,530] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:46,531] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:46,531] {logging_mixin.py:112} INFO - [2020-08-01 15:04:46,531] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:46,533] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:46,547] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:46,555] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:46,556] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:04:52,551] {scheduler_job.py:154} INFO - Started process (PID=60770) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:52,569] {logging_mixin.py:112} INFO - [2020-08-01 15:04:52,569] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:52,569] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:52,570] {logging_mixin.py:112} INFO - [2020-08-01 15:04:52,570] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:52,572] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:52,586] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:52,592] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:52,594] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:04:58,584] {scheduler_job.py:154} INFO - Started process (PID=60785) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:58,601] {logging_mixin.py:112} INFO - [2020-08-01 15:04:58,601] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:58,602] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:04:58,602] {logging_mixin.py:112} INFO - [2020-08-01 15:04:58,602] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:58,604] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:04:58,618] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:04:58,629] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:58,631] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:05:04,713] {scheduler_job.py:154} INFO - Started process (PID=60808) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:04,735] {logging_mixin.py:112} INFO - [2020-08-01 15:05:04,735] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:04,735] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:04,736] {logging_mixin.py:112} INFO - [2020-08-01 15:05:04,736] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:04,738] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:04,755] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:04,765] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:04,767] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.054 seconds
[2020-08-01 15:05:10,768] {scheduler_job.py:154} INFO - Started process (PID=60817) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:10,789] {logging_mixin.py:112} INFO - [2020-08-01 15:05:10,789] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:10,789] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:10,789] {logging_mixin.py:112} INFO - [2020-08-01 15:05:10,789] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:10,792] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:10,807] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:10,815] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:10,816] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:05:16,688] {scheduler_job.py:154} INFO - Started process (PID=60824) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:16,706] {logging_mixin.py:112} INFO - [2020-08-01 15:05:16,706] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:16,707] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:16,707] {logging_mixin.py:112} INFO - [2020-08-01 15:05:16,707] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:16,709] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:16,723] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:16,730] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:16,732] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:05:22,677] {scheduler_job.py:154} INFO - Started process (PID=60830) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:22,696] {logging_mixin.py:112} INFO - [2020-08-01 15:05:22,696] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:22,696] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:22,696] {logging_mixin.py:112} INFO - [2020-08-01 15:05:22,696] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:22,699] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:22,714] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:22,721] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:22,722] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:05:28,691] {scheduler_job.py:154} INFO - Started process (PID=60837) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:28,710] {logging_mixin.py:112} INFO - [2020-08-01 15:05:28,709] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:28,710] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:28,710] {logging_mixin.py:112} INFO - [2020-08-01 15:05:28,710] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:28,712] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:28,727] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:28,734] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:28,735] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:05:35,299] {scheduler_job.py:154} INFO - Started process (PID=60846) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:35,319] {logging_mixin.py:112} INFO - [2020-08-01 15:05:35,319] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:35,320] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:35,320] {logging_mixin.py:112} INFO - [2020-08-01 15:05:35,320] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:35,322] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:35,338] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:35,346] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:35,348] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:05:40,744] {scheduler_job.py:154} INFO - Started process (PID=60853) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:40,763] {logging_mixin.py:112} INFO - [2020-08-01 15:05:40,762] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:40,763] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:40,763] {logging_mixin.py:112} INFO - [2020-08-01 15:05:40,763] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:40,765] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:40,780] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:40,788] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:40,789] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:05:46,844] {scheduler_job.py:154} INFO - Started process (PID=60861) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:46,865] {logging_mixin.py:112} INFO - [2020-08-01 15:05:46,865] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:46,866] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:46,866] {logging_mixin.py:112} INFO - [2020-08-01 15:05:46,866] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:46,868] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:46,882] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:46,890] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:46,892] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:05:52,827] {scheduler_job.py:154} INFO - Started process (PID=60875) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:52,845] {logging_mixin.py:112} INFO - [2020-08-01 15:05:52,845] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:52,846] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:52,846] {logging_mixin.py:112} INFO - [2020-08-01 15:05:52,846] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:52,848] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:52,862] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:52,869] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:52,871] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:05:58,804] {scheduler_job.py:154} INFO - Started process (PID=60883) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:58,821] {logging_mixin.py:112} INFO - [2020-08-01 15:05:58,821] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:58,822] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:05:58,822] {logging_mixin.py:112} INFO - [2020-08-01 15:05:58,822] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:58,824] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:05:58,838] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:05:58,844] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:58,846] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:06:04,828] {scheduler_job.py:154} INFO - Started process (PID=60890) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:04,847] {logging_mixin.py:112} INFO - [2020-08-01 15:06:04,847] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:04,848] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:04,848] {logging_mixin.py:112} INFO - [2020-08-01 15:06:04,848] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:04,850] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:04,864] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:04,872] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:04,873] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:06:10,759] {scheduler_job.py:154} INFO - Started process (PID=60896) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:10,777] {logging_mixin.py:112} INFO - [2020-08-01 15:06:10,777] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:10,778] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:10,778] {logging_mixin.py:112} INFO - [2020-08-01 15:06:10,778] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:10,780] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:10,794] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:10,801] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:10,802] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:06:17,227] {scheduler_job.py:154} INFO - Started process (PID=60907) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:17,245] {logging_mixin.py:112} INFO - [2020-08-01 15:06:17,245] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:17,246] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:17,246] {logging_mixin.py:112} INFO - [2020-08-01 15:06:17,246] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:17,248] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:17,261] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:17,269] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:17,271] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:06:22,838] {scheduler_job.py:154} INFO - Started process (PID=60916) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:22,855] {logging_mixin.py:112} INFO - [2020-08-01 15:06:22,855] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:22,856] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:22,856] {logging_mixin.py:112} INFO - [2020-08-01 15:06:22,856] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:22,858] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:22,873] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:22,880] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:22,881] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:06:28,890] {scheduler_job.py:154} INFO - Started process (PID=60922) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:28,908] {logging_mixin.py:112} INFO - [2020-08-01 15:06:28,908] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:28,909] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:28,909] {logging_mixin.py:112} INFO - [2020-08-01 15:06:28,909] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:28,911] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:28,926] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:28,933] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:28,935] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:06:34,937] {scheduler_job.py:154} INFO - Started process (PID=60928) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:34,954] {logging_mixin.py:112} INFO - [2020-08-01 15:06:34,954] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:34,955] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:34,955] {logging_mixin.py:112} INFO - [2020-08-01 15:06:34,955] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:34,957] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:34,972] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:34,978] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:34,980] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:06:40,871] {scheduler_job.py:154} INFO - Started process (PID=60935) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:40,889] {logging_mixin.py:112} INFO - [2020-08-01 15:06:40,888] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:40,889] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:40,889] {logging_mixin.py:112} INFO - [2020-08-01 15:06:40,889] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:40,891] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:40,905] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:40,912] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:40,914] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:06:46,883] {scheduler_job.py:154} INFO - Started process (PID=60941) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:46,900] {logging_mixin.py:112} INFO - [2020-08-01 15:06:46,900] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:46,901] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:46,901] {logging_mixin.py:112} INFO - [2020-08-01 15:06:46,901] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:46,903] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:46,917] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:46,924] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:46,926] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:06:52,923] {scheduler_job.py:154} INFO - Started process (PID=60947) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:52,940] {logging_mixin.py:112} INFO - [2020-08-01 15:06:52,940] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:52,941] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:52,941] {logging_mixin.py:112} INFO - [2020-08-01 15:06:52,941] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:52,943] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:52,957] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:52,965] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:52,966] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:06:58,940] {scheduler_job.py:154} INFO - Started process (PID=60953) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:58,959] {logging_mixin.py:112} INFO - [2020-08-01 15:06:58,959] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:58,960] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:06:58,960] {logging_mixin.py:112} INFO - [2020-08-01 15:06:58,960] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:58,962] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:06:58,976] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:06:58,982] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:58,984] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:07:05,036] {scheduler_job.py:154} INFO - Started process (PID=60959) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:05,055] {logging_mixin.py:112} INFO - [2020-08-01 15:07:05,055] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:05,056] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:05,056] {logging_mixin.py:112} INFO - [2020-08-01 15:07:05,056] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:05,058] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:05,072] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:05,079] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:05,080] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:07:11,026] {scheduler_job.py:154} INFO - Started process (PID=60966) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:11,044] {logging_mixin.py:112} INFO - [2020-08-01 15:07:11,043] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:11,044] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:11,045] {logging_mixin.py:112} INFO - [2020-08-01 15:07:11,045] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:11,047] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:11,061] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:11,069] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:11,070] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:07:17,058] {scheduler_job.py:154} INFO - Started process (PID=60972) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:17,075] {logging_mixin.py:112} INFO - [2020-08-01 15:07:17,075] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:17,075] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:17,076] {logging_mixin.py:112} INFO - [2020-08-01 15:07:17,076] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:17,078] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:17,092] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:17,099] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:17,101] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:07:23,081] {scheduler_job.py:154} INFO - Started process (PID=60979) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:23,098] {logging_mixin.py:112} INFO - [2020-08-01 15:07:23,098] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:23,099] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:23,099] {logging_mixin.py:112} INFO - [2020-08-01 15:07:23,099] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:23,101] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:23,114] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:23,122] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:23,123] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:07:29,107] {scheduler_job.py:154} INFO - Started process (PID=60985) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:29,126] {logging_mixin.py:112} INFO - [2020-08-01 15:07:29,126] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:29,126] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:29,127] {logging_mixin.py:112} INFO - [2020-08-01 15:07:29,127] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:29,129] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:29,142] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:29,149] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:29,150] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:07:35,122] {scheduler_job.py:154} INFO - Started process (PID=60991) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:35,140] {logging_mixin.py:112} INFO - [2020-08-01 15:07:35,140] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:35,141] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:35,141] {logging_mixin.py:112} INFO - [2020-08-01 15:07:35,141] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:35,143] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:35,156] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:35,163] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:35,164] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:07:41,175] {scheduler_job.py:154} INFO - Started process (PID=60998) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:41,223] {logging_mixin.py:112} INFO - [2020-08-01 15:07:41,223] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:41,224] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:41,224] {logging_mixin.py:112} INFO - [2020-08-01 15:07:41,224] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:41,227] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:41,287] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:41,296] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:41,297] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.122 seconds
[2020-08-01 15:07:47,169] {scheduler_job.py:154} INFO - Started process (PID=61015) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:47,191] {logging_mixin.py:112} INFO - [2020-08-01 15:07:47,191] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:47,191] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:47,192] {logging_mixin.py:112} INFO - [2020-08-01 15:07:47,191] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:47,194] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:47,207] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:47,214] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:47,216] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:07:53,217] {scheduler_job.py:154} INFO - Started process (PID=61025) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:53,235] {logging_mixin.py:112} INFO - [2020-08-01 15:07:53,235] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:53,236] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:53,236] {logging_mixin.py:112} INFO - [2020-08-01 15:07:53,236] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:53,238] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:53,253] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:53,260] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:53,261] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:07:59,443] {scheduler_job.py:154} INFO - Started process (PID=61031) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:59,464] {logging_mixin.py:112} INFO - [2020-08-01 15:07:59,464] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:59,465] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:07:59,466] {logging_mixin.py:112} INFO - [2020-08-01 15:07:59,466] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:59,468] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:07:59,482] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:07:59,489] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:59,491] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:08:05,290] {scheduler_job.py:154} INFO - Started process (PID=61039) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:05,309] {logging_mixin.py:112} INFO - [2020-08-01 15:08:05,309] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:05,310] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:05,310] {logging_mixin.py:112} INFO - [2020-08-01 15:08:05,310] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:05,312] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:05,327] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:05,336] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:05,337] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:08:11,248] {scheduler_job.py:154} INFO - Started process (PID=61047) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:11,269] {logging_mixin.py:112} INFO - [2020-08-01 15:08:11,269] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:11,270] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:11,270] {logging_mixin.py:112} INFO - [2020-08-01 15:08:11,270] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:11,272] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:11,285] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:11,292] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:11,294] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:08:17,270] {scheduler_job.py:154} INFO - Started process (PID=61055) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:17,293] {logging_mixin.py:112} INFO - [2020-08-01 15:08:17,293] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:17,294] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:17,294] {logging_mixin.py:112} INFO - [2020-08-01 15:08:17,294] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:17,296] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:17,309] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:17,316] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:17,318] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:08:23,290] {scheduler_job.py:154} INFO - Started process (PID=61061) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:23,311] {logging_mixin.py:112} INFO - [2020-08-01 15:08:23,311] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:23,312] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:23,312] {logging_mixin.py:112} INFO - [2020-08-01 15:08:23,312] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:23,314] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:23,328] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:23,336] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:23,338] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:08:29,309] {scheduler_job.py:154} INFO - Started process (PID=61067) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:29,327] {logging_mixin.py:112} INFO - [2020-08-01 15:08:29,326] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:29,327] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:29,327] {logging_mixin.py:112} INFO - [2020-08-01 15:08:29,327] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:29,329] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:29,343] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:29,352] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:29,353] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:08:35,330] {scheduler_job.py:154} INFO - Started process (PID=61073) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:35,348] {logging_mixin.py:112} INFO - [2020-08-01 15:08:35,347] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:35,348] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:35,348] {logging_mixin.py:112} INFO - [2020-08-01 15:08:35,348] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:35,350] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:35,365] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:35,373] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:35,375] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:08:41,343] {scheduler_job.py:154} INFO - Started process (PID=61080) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:41,361] {logging_mixin.py:112} INFO - [2020-08-01 15:08:41,361] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:41,362] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:41,362] {logging_mixin.py:112} INFO - [2020-08-01 15:08:41,362] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:41,364] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:41,377] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:41,384] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:41,385] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:08:47,375] {scheduler_job.py:154} INFO - Started process (PID=61087) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:47,393] {logging_mixin.py:112} INFO - [2020-08-01 15:08:47,393] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:47,394] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:47,394] {logging_mixin.py:112} INFO - [2020-08-01 15:08:47,394] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:47,396] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:47,409] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:47,415] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:47,417] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:08:53,373] {scheduler_job.py:154} INFO - Started process (PID=61093) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:53,391] {logging_mixin.py:112} INFO - [2020-08-01 15:08:53,391] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:53,392] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:53,392] {logging_mixin.py:112} INFO - [2020-08-01 15:08:53,392] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:53,394] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:53,407] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:53,435] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:53,437] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.064 seconds
[2020-08-01 15:08:59,379] {scheduler_job.py:154} INFO - Started process (PID=61099) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:59,396] {logging_mixin.py:112} INFO - [2020-08-01 15:08:59,396] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:59,397] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:08:59,397] {logging_mixin.py:112} INFO - [2020-08-01 15:08:59,397] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:59,399] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:08:59,412] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:08:59,419] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:59,420] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:09:05,424] {scheduler_job.py:154} INFO - Started process (PID=61105) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:05,441] {logging_mixin.py:112} INFO - [2020-08-01 15:09:05,441] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:05,442] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:05,442] {logging_mixin.py:112} INFO - [2020-08-01 15:09:05,442] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:05,444] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:05,458] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:05,465] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:05,466] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:09:11,434] {scheduler_job.py:154} INFO - Started process (PID=61112) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:11,453] {logging_mixin.py:112} INFO - [2020-08-01 15:09:11,452] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:11,453] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:11,453] {logging_mixin.py:112} INFO - [2020-08-01 15:09:11,453] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:11,455] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:11,469] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:11,476] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:11,477] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:09:17,438] {scheduler_job.py:154} INFO - Started process (PID=61118) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:17,456] {logging_mixin.py:112} INFO - [2020-08-01 15:09:17,456] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:17,457] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:17,457] {logging_mixin.py:112} INFO - [2020-08-01 15:09:17,457] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:17,459] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:17,473] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:17,480] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:17,482] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:09:23,457] {scheduler_job.py:154} INFO - Started process (PID=61124) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:23,476] {logging_mixin.py:112} INFO - [2020-08-01 15:09:23,475] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:23,476] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:23,476] {logging_mixin.py:112} INFO - [2020-08-01 15:09:23,476] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:23,478] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:23,491] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:23,498] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:23,500] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:09:29,467] {scheduler_job.py:154} INFO - Started process (PID=61130) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:29,485] {logging_mixin.py:112} INFO - [2020-08-01 15:09:29,485] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:29,486] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:29,486] {logging_mixin.py:112} INFO - [2020-08-01 15:09:29,486] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:29,488] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:29,501] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:29,508] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:29,509] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:09:35,518] {scheduler_job.py:154} INFO - Started process (PID=61136) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:35,535] {logging_mixin.py:112} INFO - [2020-08-01 15:09:35,535] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:35,536] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:35,536] {logging_mixin.py:112} INFO - [2020-08-01 15:09:35,536] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:35,538] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:35,550] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:35,557] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:35,558] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.040 seconds
[2020-08-01 15:09:41,551] {scheduler_job.py:154} INFO - Started process (PID=61143) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:41,569] {logging_mixin.py:112} INFO - [2020-08-01 15:09:41,569] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:41,570] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:41,570] {logging_mixin.py:112} INFO - [2020-08-01 15:09:41,570] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:41,572] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:41,585] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:41,592] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:41,594] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:09:47,557] {scheduler_job.py:154} INFO - Started process (PID=61149) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:47,575] {logging_mixin.py:112} INFO - [2020-08-01 15:09:47,575] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:47,576] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:47,576] {logging_mixin.py:112} INFO - [2020-08-01 15:09:47,576] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:47,579] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:47,592] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:47,600] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:47,606] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:09:53,560] {scheduler_job.py:154} INFO - Started process (PID=61155) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:53,577] {logging_mixin.py:112} INFO - [2020-08-01 15:09:53,577] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:53,578] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:53,578] {logging_mixin.py:112} INFO - [2020-08-01 15:09:53,578] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:53,580] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:53,592] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:53,599] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:53,601] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.040 seconds
[2020-08-01 15:09:59,596] {scheduler_job.py:154} INFO - Started process (PID=61161) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:59,614] {logging_mixin.py:112} INFO - [2020-08-01 15:09:59,614] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:59,615] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:09:59,615] {logging_mixin.py:112} INFO - [2020-08-01 15:09:59,615] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:59,617] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:09:59,630] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:09:59,637] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:59,638] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:10:05,588] {scheduler_job.py:154} INFO - Started process (PID=61167) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:05,606] {logging_mixin.py:112} INFO - [2020-08-01 15:10:05,606] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:05,607] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:05,607] {logging_mixin.py:112} INFO - [2020-08-01 15:10:05,607] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:05,609] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:05,623] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:05,630] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:05,632] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:10:11,593] {scheduler_job.py:154} INFO - Started process (PID=61174) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:11,611] {logging_mixin.py:112} INFO - [2020-08-01 15:10:11,611] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:11,612] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:11,612] {logging_mixin.py:112} INFO - [2020-08-01 15:10:11,612] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:11,614] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:11,627] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:11,635] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:11,636] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:10:17,639] {scheduler_job.py:154} INFO - Started process (PID=61180) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:17,658] {logging_mixin.py:112} INFO - [2020-08-01 15:10:17,658] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:17,659] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:17,659] {logging_mixin.py:112} INFO - [2020-08-01 15:10:17,659] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:17,661] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:17,673] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:17,679] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:17,681] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:10:23,638] {scheduler_job.py:154} INFO - Started process (PID=61186) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:23,656] {logging_mixin.py:112} INFO - [2020-08-01 15:10:23,656] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:23,657] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:23,657] {logging_mixin.py:112} INFO - [2020-08-01 15:10:23,657] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:23,659] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:23,672] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:23,680] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:23,681] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:10:29,642] {scheduler_job.py:154} INFO - Started process (PID=61192) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:29,660] {logging_mixin.py:112} INFO - [2020-08-01 15:10:29,660] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:29,661] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:29,661] {logging_mixin.py:112} INFO - [2020-08-01 15:10:29,661] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:29,663] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:29,678] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:29,685] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:29,687] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:10:35,666] {scheduler_job.py:154} INFO - Started process (PID=61198) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:35,684] {logging_mixin.py:112} INFO - [2020-08-01 15:10:35,684] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:35,685] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:35,685] {logging_mixin.py:112} INFO - [2020-08-01 15:10:35,685] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:35,688] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:35,702] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:35,710] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:35,712] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:10:41,703] {scheduler_job.py:154} INFO - Started process (PID=61205) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:41,720] {logging_mixin.py:112} INFO - [2020-08-01 15:10:41,720] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:41,721] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:41,721] {logging_mixin.py:112} INFO - [2020-08-01 15:10:41,721] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:41,723] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:41,735] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:41,742] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:41,744] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:10:47,703] {scheduler_job.py:154} INFO - Started process (PID=61211) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:47,726] {logging_mixin.py:112} INFO - [2020-08-01 15:10:47,726] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:47,727] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:47,727] {logging_mixin.py:112} INFO - [2020-08-01 15:10:47,727] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:47,730] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:47,745] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:47,754] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:47,756] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 15:10:53,749] {scheduler_job.py:154} INFO - Started process (PID=61217) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:53,767] {logging_mixin.py:112} INFO - [2020-08-01 15:10:53,767] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:53,768] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:53,768] {logging_mixin.py:112} INFO - [2020-08-01 15:10:53,768] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:53,770] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:53,783] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:53,790] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:53,792] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:10:59,728] {scheduler_job.py:154} INFO - Started process (PID=61223) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:59,745] {logging_mixin.py:112} INFO - [2020-08-01 15:10:59,745] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:59,746] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:10:59,746] {logging_mixin.py:112} INFO - [2020-08-01 15:10:59,746] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:59,748] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:10:59,764] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:10:59,774] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:59,777] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:11:05,777] {scheduler_job.py:154} INFO - Started process (PID=61229) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:05,798] {logging_mixin.py:112} INFO - [2020-08-01 15:11:05,798] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:05,799] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:05,799] {logging_mixin.py:112} INFO - [2020-08-01 15:11:05,799] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:05,801] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:05,815] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:11:05,821] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:05,823] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:11:11,981] {scheduler_job.py:154} INFO - Started process (PID=61236) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:11,998] {logging_mixin.py:112} INFO - [2020-08-01 15:11:11,998] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:11,999] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:11,999] {logging_mixin.py:112} INFO - [2020-08-01 15:11:11,999] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:12,001] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:12,013] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:11:12,020] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:12,022] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.040 seconds
[2020-08-01 15:11:17,830] {scheduler_job.py:154} INFO - Started process (PID=61242) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:17,850] {logging_mixin.py:112} INFO - [2020-08-01 15:11:17,850] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:17,851] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:17,851] {logging_mixin.py:112} INFO - [2020-08-01 15:11:17,851] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:17,853] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:17,868] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:11:17,874] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:17,876] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:11:23,823] {scheduler_job.py:154} INFO - Started process (PID=61248) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:23,840] {logging_mixin.py:112} INFO - [2020-08-01 15:11:23,840] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:23,841] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:23,841] {logging_mixin.py:112} INFO - [2020-08-01 15:11:23,841] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:23,843] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:23,856] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:11:23,863] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:23,865] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:11:29,845] {scheduler_job.py:154} INFO - Started process (PID=61254) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:29,863] {logging_mixin.py:112} INFO - [2020-08-01 15:11:29,863] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:29,864] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:29,864] {logging_mixin.py:112} INFO - [2020-08-01 15:11:29,864] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:29,866] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:29,878] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:11:29,884] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:29,886] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:11:35,873] {scheduler_job.py:154} INFO - Started process (PID=61260) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:35,892] {logging_mixin.py:112} INFO - [2020-08-01 15:11:35,892] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:35,892] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:35,893] {logging_mixin.py:112} INFO - [2020-08-01 15:11:35,893] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:35,895] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:35,908] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:11:35,915] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:35,916] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:11:42,116] {scheduler_job.py:154} INFO - Started process (PID=61266) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:42,133] {logging_mixin.py:112} INFO - [2020-08-01 15:11:42,133] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:42,134] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:42,134] {logging_mixin.py:112} INFO - [2020-08-01 15:11:42,134] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:42,136] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:42,149] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:11:42,155] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:42,156] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.040 seconds
[2020-08-01 15:11:47,924] {scheduler_job.py:154} INFO - Started process (PID=61273) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:47,941] {logging_mixin.py:112} INFO - [2020-08-01 15:11:47,941] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:47,942] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:47,942] {logging_mixin.py:112} INFO - [2020-08-01 15:11:47,942] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:47,944] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:47,955] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:11:47,962] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:47,963] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.039 seconds
[2020-08-01 15:11:53,991] {scheduler_job.py:154} INFO - Started process (PID=61279) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:54,010] {logging_mixin.py:112} INFO - [2020-08-01 15:11:54,010] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:54,010] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:54,011] {logging_mixin.py:112} INFO - [2020-08-01 15:11:54,010] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:54,013] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:54,026] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:11:54,033] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:54,036] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:11:59,965] {scheduler_job.py:154} INFO - Started process (PID=61285) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:59,983] {logging_mixin.py:112} INFO - [2020-08-01 15:11:59,983] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:59,983] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:11:59,984] {logging_mixin.py:112} INFO - [2020-08-01 15:11:59,984] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:59,986] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:11:59,999] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:00,006] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:00,008] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:12:05,982] {scheduler_job.py:154} INFO - Started process (PID=61291) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:06,000] {logging_mixin.py:112} INFO - [2020-08-01 15:12:05,999] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:06,000] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:12:06,000] {logging_mixin.py:112} INFO - [2020-08-01 15:12:06,000] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:06,002] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:06,016] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:06,023] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:06,024] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:12:12,037] {scheduler_job.py:154} INFO - Started process (PID=61297) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:12,063] {logging_mixin.py:112} INFO - [2020-08-01 15:12:12,063] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:12,064] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:12:12,064] {logging_mixin.py:112} INFO - [2020-08-01 15:12:12,064] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:12,067] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:12,084] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:12,094] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:12,097] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.060 seconds
[2020-08-01 15:12:18,026] {scheduler_job.py:154} INFO - Started process (PID=61304) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:18,044] {logging_mixin.py:112} INFO - [2020-08-01 15:12:18,044] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:18,045] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:12:18,045] {logging_mixin.py:112} INFO - [2020-08-01 15:12:18,045] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:18,047] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:18,058] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:18,065] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:18,066] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.040 seconds
[2020-08-01 15:12:24,233] {scheduler_job.py:154} INFO - Started process (PID=61310) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:24,253] {logging_mixin.py:112} INFO - [2020-08-01 15:12:24,253] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:24,254] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:12:24,254] {logging_mixin.py:112} INFO - [2020-08-01 15:12:24,254] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:24,256] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:24,272] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:24,279] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:24,281] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:12:30,076] {scheduler_job.py:154} INFO - Started process (PID=61317) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:30,094] {logging_mixin.py:112} INFO - [2020-08-01 15:12:30,094] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:30,095] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:12:30,095] {logging_mixin.py:112} INFO - [2020-08-01 15:12:30,095] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:30,097] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:30,110] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:30,117] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:30,119] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:12:36,188] {scheduler_job.py:154} INFO - Started process (PID=61324) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:36,206] {logging_mixin.py:112} INFO - [2020-08-01 15:12:36,206] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:36,207] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:12:36,207] {logging_mixin.py:112} INFO - [2020-08-01 15:12:36,207] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:36,209] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:36,222] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:36,229] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:36,230] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:12:42,045] {scheduler_job.py:154} INFO - Started process (PID=61330) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:42,063] {logging_mixin.py:112} INFO - [2020-08-01 15:12:42,063] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:42,063] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:12:42,063] {logging_mixin.py:112} INFO - [2020-08-01 15:12:42,063] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:42,066] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:42,080] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:42,087] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:42,089] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:12:48,071] {scheduler_job.py:154} INFO - Started process (PID=61337) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:48,088] {logging_mixin.py:112} INFO - [2020-08-01 15:12:48,088] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:48,089] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:12:48,089] {logging_mixin.py:112} INFO - [2020-08-01 15:12:48,089] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:48,091] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:48,104] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:48,111] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:48,112] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:12:54,104] {scheduler_job.py:154} INFO - Started process (PID=61343) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:54,121] {logging_mixin.py:112} INFO - [2020-08-01 15:12:54,121] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:54,122] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:12:54,122] {logging_mixin.py:112} INFO - [2020-08-01 15:12:54,122] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:54,124] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:12:54,139] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:12:54,146] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:54,147] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:13:00,113] {scheduler_job.py:154} INFO - Started process (PID=61349) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:00,130] {logging_mixin.py:112} INFO - [2020-08-01 15:13:00,130] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:00,131] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:00,131] {logging_mixin.py:112} INFO - [2020-08-01 15:13:00,131] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:00,133] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:00,148] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:00,155] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:00,157] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:13:06,128] {scheduler_job.py:154} INFO - Started process (PID=61355) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:06,147] {logging_mixin.py:112} INFO - [2020-08-01 15:13:06,146] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:06,147] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:06,147] {logging_mixin.py:112} INFO - [2020-08-01 15:13:06,147] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:06,150] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:06,164] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:06,171] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:06,173] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:13:12,149] {scheduler_job.py:154} INFO - Started process (PID=61361) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:12,167] {logging_mixin.py:112} INFO - [2020-08-01 15:13:12,167] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:12,168] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:12,168] {logging_mixin.py:112} INFO - [2020-08-01 15:13:12,168] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:12,170] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:12,184] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:12,191] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:12,193] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:13:18,178] {scheduler_job.py:154} INFO - Started process (PID=61368) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:18,195] {logging_mixin.py:112} INFO - [2020-08-01 15:13:18,195] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:18,196] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:18,196] {logging_mixin.py:112} INFO - [2020-08-01 15:13:18,196] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:18,198] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:18,211] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:18,218] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:18,220] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:13:24,222] {scheduler_job.py:154} INFO - Started process (PID=61374) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:24,240] {logging_mixin.py:112} INFO - [2020-08-01 15:13:24,240] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:24,240] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:24,240] {logging_mixin.py:112} INFO - [2020-08-01 15:13:24,240] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:24,243] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:24,257] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:24,264] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:24,265] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:13:30,227] {scheduler_job.py:154} INFO - Started process (PID=61380) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:30,245] {logging_mixin.py:112} INFO - [2020-08-01 15:13:30,245] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:30,246] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:30,246] {logging_mixin.py:112} INFO - [2020-08-01 15:13:30,246] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:30,248] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:30,262] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:30,269] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:30,271] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:13:36,242] {scheduler_job.py:154} INFO - Started process (PID=61386) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:36,259] {logging_mixin.py:112} INFO - [2020-08-01 15:13:36,259] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:36,260] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:36,260] {logging_mixin.py:112} INFO - [2020-08-01 15:13:36,260] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:36,262] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:36,275] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:36,282] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:36,284] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:13:42,274] {scheduler_job.py:154} INFO - Started process (PID=61392) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:42,291] {logging_mixin.py:112} INFO - [2020-08-01 15:13:42,291] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:42,292] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:42,292] {logging_mixin.py:112} INFO - [2020-08-01 15:13:42,292] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:42,294] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:42,309] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:42,316] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:42,317] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:13:48,308] {scheduler_job.py:154} INFO - Started process (PID=61399) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:48,326] {logging_mixin.py:112} INFO - [2020-08-01 15:13:48,326] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:48,327] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:48,327] {logging_mixin.py:112} INFO - [2020-08-01 15:13:48,327] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:48,329] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:48,342] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:48,349] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:48,351] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:13:54,334] {scheduler_job.py:154} INFO - Started process (PID=61405) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:54,351] {logging_mixin.py:112} INFO - [2020-08-01 15:13:54,351] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:54,352] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:13:54,352] {logging_mixin.py:112} INFO - [2020-08-01 15:13:54,352] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:54,354] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:13:54,368] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:13:54,376] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:54,377] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:14:00,339] {scheduler_job.py:154} INFO - Started process (PID=61411) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:00,359] {logging_mixin.py:112} INFO - [2020-08-01 15:14:00,358] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:00,359] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:00,359] {logging_mixin.py:112} INFO - [2020-08-01 15:14:00,359] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:00,362] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:00,376] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:00,384] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:00,386] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:14:06,363] {scheduler_job.py:154} INFO - Started process (PID=61417) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:06,380] {logging_mixin.py:112} INFO - [2020-08-01 15:14:06,380] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:06,381] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:06,381] {logging_mixin.py:112} INFO - [2020-08-01 15:14:06,381] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:06,383] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:06,399] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:06,406] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:06,407] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:14:12,371] {scheduler_job.py:154} INFO - Started process (PID=61423) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:12,389] {logging_mixin.py:112} INFO - [2020-08-01 15:14:12,389] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:12,389] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:12,390] {logging_mixin.py:112} INFO - [2020-08-01 15:14:12,390] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:12,392] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:12,406] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:12,413] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:12,414] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:14:18,399] {scheduler_job.py:154} INFO - Started process (PID=61430) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:18,416] {logging_mixin.py:112} INFO - [2020-08-01 15:14:18,416] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:18,417] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:18,417] {logging_mixin.py:112} INFO - [2020-08-01 15:14:18,417] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:18,419] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:18,432] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:18,439] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:18,440] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:14:24,449] {scheduler_job.py:154} INFO - Started process (PID=61436) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:24,466] {logging_mixin.py:112} INFO - [2020-08-01 15:14:24,466] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:24,467] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:24,467] {logging_mixin.py:112} INFO - [2020-08-01 15:14:24,467] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:24,469] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:24,483] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:24,492] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:24,494] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:14:30,434] {scheduler_job.py:154} INFO - Started process (PID=61442) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:30,452] {logging_mixin.py:112} INFO - [2020-08-01 15:14:30,452] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:30,453] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:30,453] {logging_mixin.py:112} INFO - [2020-08-01 15:14:30,453] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:30,455] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:30,469] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:30,476] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:30,477] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:14:36,466] {scheduler_job.py:154} INFO - Started process (PID=61448) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:36,484] {logging_mixin.py:112} INFO - [2020-08-01 15:14:36,483] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:36,484] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:36,484] {logging_mixin.py:112} INFO - [2020-08-01 15:14:36,484] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:36,486] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:36,501] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:36,508] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:36,509] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:14:42,490] {scheduler_job.py:154} INFO - Started process (PID=61454) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:42,508] {logging_mixin.py:112} INFO - [2020-08-01 15:14:42,508] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:42,508] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:42,509] {logging_mixin.py:112} INFO - [2020-08-01 15:14:42,509] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:42,511] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:42,525] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:42,532] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:42,534] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:14:48,545] {scheduler_job.py:154} INFO - Started process (PID=61461) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:48,562] {logging_mixin.py:112} INFO - [2020-08-01 15:14:48,562] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:48,563] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:48,563] {logging_mixin.py:112} INFO - [2020-08-01 15:14:48,563] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:48,565] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:48,579] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:48,587] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:48,588] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:14:54,610] {scheduler_job.py:154} INFO - Started process (PID=61467) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:54,628] {logging_mixin.py:112} INFO - [2020-08-01 15:14:54,628] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:54,629] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:14:54,629] {logging_mixin.py:112} INFO - [2020-08-01 15:14:54,629] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:54,631] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:14:54,648] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:14:54,656] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:54,658] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:15:00,563] {scheduler_job.py:154} INFO - Started process (PID=61473) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:00,582] {logging_mixin.py:112} INFO - [2020-08-01 15:15:00,581] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:00,582] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:00,582] {logging_mixin.py:112} INFO - [2020-08-01 15:15:00,582] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:00,585] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:00,600] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:00,607] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:00,609] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:15:06,573] {scheduler_job.py:154} INFO - Started process (PID=61479) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:06,591] {logging_mixin.py:112} INFO - [2020-08-01 15:15:06,590] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:06,591] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:06,591] {logging_mixin.py:112} INFO - [2020-08-01 15:15:06,591] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:06,593] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:06,608] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:06,615] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:06,617] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:15:13,039] {scheduler_job.py:154} INFO - Started process (PID=61487) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:13,057] {logging_mixin.py:112} INFO - [2020-08-01 15:15:13,057] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:13,058] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:13,058] {logging_mixin.py:112} INFO - [2020-08-01 15:15:13,058] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:13,060] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:13,075] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:13,082] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:13,084] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:15:18,732] {scheduler_job.py:154} INFO - Started process (PID=61497) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:18,750] {logging_mixin.py:112} INFO - [2020-08-01 15:15:18,750] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:18,751] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:18,751] {logging_mixin.py:112} INFO - [2020-08-01 15:15:18,751] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:18,753] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:18,767] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:18,775] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:18,776] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:15:24,634] {scheduler_job.py:154} INFO - Started process (PID=61503) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:24,652] {logging_mixin.py:112} INFO - [2020-08-01 15:15:24,652] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:24,653] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:24,653] {logging_mixin.py:112} INFO - [2020-08-01 15:15:24,653] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:24,655] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:24,671] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:24,679] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:24,680] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:15:30,696] {scheduler_job.py:154} INFO - Started process (PID=61509) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:30,713] {logging_mixin.py:112} INFO - [2020-08-01 15:15:30,713] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:30,714] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:30,714] {logging_mixin.py:112} INFO - [2020-08-01 15:15:30,714] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:30,716] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:30,730] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:30,737] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:30,739] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:15:37,190] {scheduler_job.py:154} INFO - Started process (PID=61516) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:37,218] {logging_mixin.py:112} INFO - [2020-08-01 15:15:37,218] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:37,219] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:37,219] {logging_mixin.py:112} INFO - [2020-08-01 15:15:37,219] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:37,222] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:37,240] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:37,250] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:37,252] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.063 seconds
[2020-08-01 15:15:43,197] {scheduler_job.py:154} INFO - Started process (PID=61522) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:43,226] {logging_mixin.py:112} INFO - [2020-08-01 15:15:43,226] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:43,227] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:43,228] {logging_mixin.py:112} INFO - [2020-08-01 15:15:43,227] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:43,231] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:43,249] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:43,259] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:43,261] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.064 seconds
[2020-08-01 15:15:49,223] {scheduler_job.py:154} INFO - Started process (PID=61529) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:49,252] {logging_mixin.py:112} INFO - [2020-08-01 15:15:49,252] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:49,253] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:49,253] {logging_mixin.py:112} INFO - [2020-08-01 15:15:49,253] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:49,256] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:49,274] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:49,284] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:49,286] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.063 seconds
[2020-08-01 15:15:55,298] {scheduler_job.py:154} INFO - Started process (PID=61535) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:55,324] {logging_mixin.py:112} INFO - [2020-08-01 15:15:55,324] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:55,325] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:15:55,325] {logging_mixin.py:112} INFO - [2020-08-01 15:15:55,325] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:55,329] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:15:55,349] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:15:55,360] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:55,363] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.065 seconds
[2020-08-01 15:16:01,073] {scheduler_job.py:154} INFO - Started process (PID=61541) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:01,091] {logging_mixin.py:112} INFO - [2020-08-01 15:16:01,091] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:01,092] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:01,092] {logging_mixin.py:112} INFO - [2020-08-01 15:16:01,092] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:01,094] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:01,109] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:01,117] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:01,119] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:16:06,784] {scheduler_job.py:154} INFO - Started process (PID=61547) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:06,803] {logging_mixin.py:112} INFO - [2020-08-01 15:16:06,803] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:06,804] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:06,804] {logging_mixin.py:112} INFO - [2020-08-01 15:16:06,804] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:06,806] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:06,821] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:06,828] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:06,830] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:16:12,851] {scheduler_job.py:154} INFO - Started process (PID=61553) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:12,871] {logging_mixin.py:112} INFO - [2020-08-01 15:16:12,871] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:12,871] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:12,872] {logging_mixin.py:112} INFO - [2020-08-01 15:16:12,872] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:12,874] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:12,889] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:12,896] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:12,898] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:16:19,067] {scheduler_job.py:154} INFO - Started process (PID=61568) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:19,084] {logging_mixin.py:112} INFO - [2020-08-01 15:16:19,084] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:19,085] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:19,085] {logging_mixin.py:112} INFO - [2020-08-01 15:16:19,085] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:19,087] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:19,101] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:19,107] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:19,109] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:16:24,853] {scheduler_job.py:154} INFO - Started process (PID=61582) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:24,870] {logging_mixin.py:112} INFO - [2020-08-01 15:16:24,870] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:24,871] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:24,871] {logging_mixin.py:112} INFO - [2020-08-01 15:16:24,871] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:24,873] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:24,886] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:24,893] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:24,895] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:16:30,862] {scheduler_job.py:154} INFO - Started process (PID=61588) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:30,879] {logging_mixin.py:112} INFO - [2020-08-01 15:16:30,879] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:30,880] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:30,880] {logging_mixin.py:112} INFO - [2020-08-01 15:16:30,880] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:30,882] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:30,898] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:30,906] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:30,907] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:16:36,843] {scheduler_job.py:154} INFO - Started process (PID=61594) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:36,861] {logging_mixin.py:112} INFO - [2020-08-01 15:16:36,861] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:36,862] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:36,862] {logging_mixin.py:112} INFO - [2020-08-01 15:16:36,862] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:36,864] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:36,878] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:36,885] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:36,887] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:16:42,873] {scheduler_job.py:154} INFO - Started process (PID=61600) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:42,891] {logging_mixin.py:112} INFO - [2020-08-01 15:16:42,891] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:42,892] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:42,892] {logging_mixin.py:112} INFO - [2020-08-01 15:16:42,892] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:42,894] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:42,908] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:42,915] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:42,917] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:16:48,995] {scheduler_job.py:154} INFO - Started process (PID=61606) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:49,012] {logging_mixin.py:112} INFO - [2020-08-01 15:16:49,011] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:49,012] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:49,012] {logging_mixin.py:112} INFO - [2020-08-01 15:16:49,012] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:49,014] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:49,028] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:49,035] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:49,036] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:16:54,934] {scheduler_job.py:154} INFO - Started process (PID=61613) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:54,952] {logging_mixin.py:112} INFO - [2020-08-01 15:16:54,951] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:54,952] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:16:54,952] {logging_mixin.py:112} INFO - [2020-08-01 15:16:54,952] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:54,954] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:16:54,969] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:16:54,976] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:54,978] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:17:00,950] {scheduler_job.py:154} INFO - Started process (PID=61619) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:00,968] {logging_mixin.py:112} INFO - [2020-08-01 15:17:00,968] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:00,968] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:00,969] {logging_mixin.py:112} INFO - [2020-08-01 15:17:00,969] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:00,971] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:00,985] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:00,992] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:00,994] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:17:06,965] {scheduler_job.py:154} INFO - Started process (PID=61625) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:06,984] {logging_mixin.py:112} INFO - [2020-08-01 15:17:06,984] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:06,984] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:06,985] {logging_mixin.py:112} INFO - [2020-08-01 15:17:06,985] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:06,987] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:07,001] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:07,008] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:07,010] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:17:12,972] {scheduler_job.py:154} INFO - Started process (PID=61631) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:12,991] {logging_mixin.py:112} INFO - [2020-08-01 15:17:12,991] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:12,992] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:12,992] {logging_mixin.py:112} INFO - [2020-08-01 15:17:12,992] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:12,994] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:13,008] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:13,015] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:13,017] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:17:18,998] {scheduler_job.py:154} INFO - Started process (PID=61637) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:19,017] {logging_mixin.py:112} INFO - [2020-08-01 15:17:19,017] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:19,017] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:19,018] {logging_mixin.py:112} INFO - [2020-08-01 15:17:19,018] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:19,020] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:19,033] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:19,040] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:19,042] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:17:25,022] {scheduler_job.py:154} INFO - Started process (PID=61644) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:25,040] {logging_mixin.py:112} INFO - [2020-08-01 15:17:25,040] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:25,041] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:25,041] {logging_mixin.py:112} INFO - [2020-08-01 15:17:25,041] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:25,043] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:25,057] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:25,064] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:25,065] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:17:31,033] {scheduler_job.py:154} INFO - Started process (PID=61650) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:31,051] {logging_mixin.py:112} INFO - [2020-08-01 15:17:31,051] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:31,052] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:31,052] {logging_mixin.py:112} INFO - [2020-08-01 15:17:31,052] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:31,054] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:31,068] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:31,076] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:31,077] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:17:37,058] {scheduler_job.py:154} INFO - Started process (PID=61656) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:37,076] {logging_mixin.py:112} INFO - [2020-08-01 15:17:37,076] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:37,076] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:37,076] {logging_mixin.py:112} INFO - [2020-08-01 15:17:37,076] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:37,078] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:37,093] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:37,100] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:37,102] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:17:43,074] {scheduler_job.py:154} INFO - Started process (PID=61662) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:43,092] {logging_mixin.py:112} INFO - [2020-08-01 15:17:43,092] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:43,093] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:43,093] {logging_mixin.py:112} INFO - [2020-08-01 15:17:43,093] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:43,095] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:43,109] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:43,116] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:43,118] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:17:49,090] {scheduler_job.py:154} INFO - Started process (PID=61668) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:49,108] {logging_mixin.py:112} INFO - [2020-08-01 15:17:49,108] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:49,109] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:49,109] {logging_mixin.py:112} INFO - [2020-08-01 15:17:49,109] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:49,111] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:49,125] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:49,133] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:49,134] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:17:55,104] {scheduler_job.py:154} INFO - Started process (PID=61675) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:55,121] {logging_mixin.py:112} INFO - [2020-08-01 15:17:55,121] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:55,122] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:17:55,122] {logging_mixin.py:112} INFO - [2020-08-01 15:17:55,122] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:55,124] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:17:55,138] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:17:55,146] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:55,147] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:18:01,160] {scheduler_job.py:154} INFO - Started process (PID=61681) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:01,177] {logging_mixin.py:112} INFO - [2020-08-01 15:18:01,177] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:01,178] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:01,178] {logging_mixin.py:112} INFO - [2020-08-01 15:18:01,178] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:01,180] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:01,194] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:01,202] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:01,203] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:18:07,145] {scheduler_job.py:154} INFO - Started process (PID=61687) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:07,162] {logging_mixin.py:112} INFO - [2020-08-01 15:18:07,162] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:07,163] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:07,163] {logging_mixin.py:112} INFO - [2020-08-01 15:18:07,163] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:07,165] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:07,178] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:07,185] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:07,186] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:18:13,170] {scheduler_job.py:154} INFO - Started process (PID=61693) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:13,188] {logging_mixin.py:112} INFO - [2020-08-01 15:18:13,188] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:13,189] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:13,189] {logging_mixin.py:112} INFO - [2020-08-01 15:18:13,189] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:13,191] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:13,205] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:13,212] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:13,213] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:18:19,196] {scheduler_job.py:154} INFO - Started process (PID=61699) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:19,214] {logging_mixin.py:112} INFO - [2020-08-01 15:18:19,214] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:19,214] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:19,214] {logging_mixin.py:112} INFO - [2020-08-01 15:18:19,214] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:19,217] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:19,231] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:19,238] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:19,239] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:18:25,220] {scheduler_job.py:154} INFO - Started process (PID=61706) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:25,238] {logging_mixin.py:112} INFO - [2020-08-01 15:18:25,237] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:25,238] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:25,238] {logging_mixin.py:112} INFO - [2020-08-01 15:18:25,238] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:25,240] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:25,255] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:25,261] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:25,263] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:18:31,240] {scheduler_job.py:154} INFO - Started process (PID=61712) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:31,258] {logging_mixin.py:112} INFO - [2020-08-01 15:18:31,258] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:31,258] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:31,259] {logging_mixin.py:112} INFO - [2020-08-01 15:18:31,259] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:31,261] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:31,275] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:31,283] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:31,284] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:18:37,269] {scheduler_job.py:154} INFO - Started process (PID=61718) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:37,287] {logging_mixin.py:112} INFO - [2020-08-01 15:18:37,287] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:37,287] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:37,288] {logging_mixin.py:112} INFO - [2020-08-01 15:18:37,288] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:37,290] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:37,304] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:37,311] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:37,313] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:18:43,306] {scheduler_job.py:154} INFO - Started process (PID=61724) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:43,325] {logging_mixin.py:112} INFO - [2020-08-01 15:18:43,325] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:43,326] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:43,326] {logging_mixin.py:112} INFO - [2020-08-01 15:18:43,326] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:43,328] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:43,344] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:43,351] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:43,353] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:18:49,415] {scheduler_job.py:154} INFO - Started process (PID=61730) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:49,433] {logging_mixin.py:112} INFO - [2020-08-01 15:18:49,433] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:49,434] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:49,434] {logging_mixin.py:112} INFO - [2020-08-01 15:18:49,434] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:49,436] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:49,452] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:49,459] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:49,461] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:18:55,380] {scheduler_job.py:154} INFO - Started process (PID=61738) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:55,398] {logging_mixin.py:112} INFO - [2020-08-01 15:18:55,398] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:55,399] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:18:55,399] {logging_mixin.py:112} INFO - [2020-08-01 15:18:55,399] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:55,401] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:18:55,415] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:18:55,424] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:55,426] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:19:01,403] {scheduler_job.py:154} INFO - Started process (PID=61744) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:01,420] {logging_mixin.py:112} INFO - [2020-08-01 15:19:01,420] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:01,420] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:01,420] {logging_mixin.py:112} INFO - [2020-08-01 15:19:01,420] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:01,423] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:01,439] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:01,447] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:01,449] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:19:07,357] {scheduler_job.py:154} INFO - Started process (PID=61750) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:07,374] {logging_mixin.py:112} INFO - [2020-08-01 15:19:07,374] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:07,375] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:07,375] {logging_mixin.py:112} INFO - [2020-08-01 15:19:07,375] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:07,377] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:07,391] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:07,399] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:07,400] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:19:13,382] {scheduler_job.py:154} INFO - Started process (PID=61756) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:13,400] {logging_mixin.py:112} INFO - [2020-08-01 15:19:13,400] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:13,401] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:13,401] {logging_mixin.py:112} INFO - [2020-08-01 15:19:13,401] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:13,403] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:13,417] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:13,424] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:13,426] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:19:19,413] {scheduler_job.py:154} INFO - Started process (PID=61762) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:19,431] {logging_mixin.py:112} INFO - [2020-08-01 15:19:19,431] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:19,431] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:19,431] {logging_mixin.py:112} INFO - [2020-08-01 15:19:19,431] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:19,433] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:19,447] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:19,453] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:19,455] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:19:25,435] {scheduler_job.py:154} INFO - Started process (PID=61769) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:25,453] {logging_mixin.py:112} INFO - [2020-08-01 15:19:25,452] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:25,453] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:25,453] {logging_mixin.py:112} INFO - [2020-08-01 15:19:25,453] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:25,455] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:25,470] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:25,477] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:25,478] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:19:31,459] {scheduler_job.py:154} INFO - Started process (PID=61775) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:31,476] {logging_mixin.py:112} INFO - [2020-08-01 15:19:31,476] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:31,477] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:31,477] {logging_mixin.py:112} INFO - [2020-08-01 15:19:31,477] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:31,479] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:31,493] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:31,500] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:31,502] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:19:37,490] {scheduler_job.py:154} INFO - Started process (PID=61781) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:37,508] {logging_mixin.py:112} INFO - [2020-08-01 15:19:37,508] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:37,509] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:37,509] {logging_mixin.py:112} INFO - [2020-08-01 15:19:37,509] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:37,511] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:37,524] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:37,531] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:37,532] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:19:43,514] {scheduler_job.py:154} INFO - Started process (PID=61787) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:43,533] {logging_mixin.py:112} INFO - [2020-08-01 15:19:43,533] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:43,534] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:43,534] {logging_mixin.py:112} INFO - [2020-08-01 15:19:43,534] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:43,536] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:43,550] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:43,558] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:43,559] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:19:49,539] {scheduler_job.py:154} INFO - Started process (PID=61793) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:49,557] {logging_mixin.py:112} INFO - [2020-08-01 15:19:49,557] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:49,558] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:49,558] {logging_mixin.py:112} INFO - [2020-08-01 15:19:49,558] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:49,560] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:49,572] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:49,579] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:49,581] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:19:55,567] {scheduler_job.py:154} INFO - Started process (PID=61800) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:55,585] {logging_mixin.py:112} INFO - [2020-08-01 15:19:55,585] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:55,585] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:19:55,585] {logging_mixin.py:112} INFO - [2020-08-01 15:19:55,585] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:55,588] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:19:55,601] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:19:55,608] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:55,610] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:20:01,580] {scheduler_job.py:154} INFO - Started process (PID=61806) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:01,597] {logging_mixin.py:112} INFO - [2020-08-01 15:20:01,597] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:01,598] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:01,598] {logging_mixin.py:112} INFO - [2020-08-01 15:20:01,598] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:01,600] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:01,614] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:01,621] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:01,623] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:20:07,614] {scheduler_job.py:154} INFO - Started process (PID=61812) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:07,632] {logging_mixin.py:112} INFO - [2020-08-01 15:20:07,632] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:07,634] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:07,634] {logging_mixin.py:112} INFO - [2020-08-01 15:20:07,634] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:07,636] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:07,651] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:07,658] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:07,659] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:20:13,632] {scheduler_job.py:154} INFO - Started process (PID=61818) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:13,649] {logging_mixin.py:112} INFO - [2020-08-01 15:20:13,649] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:13,650] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:13,650] {logging_mixin.py:112} INFO - [2020-08-01 15:20:13,650] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:13,652] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:13,666] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:13,673] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:13,675] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:20:19,662] {scheduler_job.py:154} INFO - Started process (PID=61824) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:19,680] {logging_mixin.py:112} INFO - [2020-08-01 15:20:19,680] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:19,681] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:19,681] {logging_mixin.py:112} INFO - [2020-08-01 15:20:19,681] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:19,683] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:19,696] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:19,703] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:19,705] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:20:25,687] {scheduler_job.py:154} INFO - Started process (PID=61831) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:25,705] {logging_mixin.py:112} INFO - [2020-08-01 15:20:25,705] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:25,706] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:25,706] {logging_mixin.py:112} INFO - [2020-08-01 15:20:25,706] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:25,708] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:25,722] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:25,729] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:25,731] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:20:31,695] {scheduler_job.py:154} INFO - Started process (PID=61837) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:31,713] {logging_mixin.py:112} INFO - [2020-08-01 15:20:31,713] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:31,714] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:31,714] {logging_mixin.py:112} INFO - [2020-08-01 15:20:31,714] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:31,716] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:31,733] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:31,740] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:31,741] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:20:37,743] {scheduler_job.py:154} INFO - Started process (PID=61843) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:37,763] {logging_mixin.py:112} INFO - [2020-08-01 15:20:37,762] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:37,763] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:37,763] {logging_mixin.py:112} INFO - [2020-08-01 15:20:37,763] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:37,766] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:37,781] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:37,791] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:37,793] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.050 seconds
[2020-08-01 15:20:43,733] {scheduler_job.py:154} INFO - Started process (PID=61849) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:43,751] {logging_mixin.py:112} INFO - [2020-08-01 15:20:43,750] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:43,751] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:43,751] {logging_mixin.py:112} INFO - [2020-08-01 15:20:43,751] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:43,753] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:43,766] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:43,773] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:43,774] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:20:49,773] {scheduler_job.py:154} INFO - Started process (PID=61855) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:49,791] {logging_mixin.py:112} INFO - [2020-08-01 15:20:49,791] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:49,791] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:49,792] {logging_mixin.py:112} INFO - [2020-08-01 15:20:49,792] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:49,794] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:49,808] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:49,815] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:49,816] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:20:55,881] {scheduler_job.py:154} INFO - Started process (PID=61862) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:55,901] {logging_mixin.py:112} INFO - [2020-08-01 15:20:55,900] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:55,902] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:20:55,903] {logging_mixin.py:112} INFO - [2020-08-01 15:20:55,903] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:55,906] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:20:55,923] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:20:55,931] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:55,932] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 15:21:01,848] {scheduler_job.py:154} INFO - Started process (PID=61868) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:01,865] {logging_mixin.py:112} INFO - [2020-08-01 15:21:01,865] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:01,866] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:01,866] {logging_mixin.py:112} INFO - [2020-08-01 15:21:01,866] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:01,868] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:01,882] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:01,889] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:01,891] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:21:07,824] {scheduler_job.py:154} INFO - Started process (PID=61874) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:07,848] {logging_mixin.py:112} INFO - [2020-08-01 15:21:07,848] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:07,849] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:07,849] {logging_mixin.py:112} INFO - [2020-08-01 15:21:07,849] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:07,851] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:07,866] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:07,874] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:07,875] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 15:21:13,876] {scheduler_job.py:154} INFO - Started process (PID=61880) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:13,893] {logging_mixin.py:112} INFO - [2020-08-01 15:21:13,893] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:13,894] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:13,894] {logging_mixin.py:112} INFO - [2020-08-01 15:21:13,894] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:13,896] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:13,909] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:13,916] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:13,918] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:21:19,859] {scheduler_job.py:154} INFO - Started process (PID=61886) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:19,877] {logging_mixin.py:112} INFO - [2020-08-01 15:21:19,876] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:19,877] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:19,877] {logging_mixin.py:112} INFO - [2020-08-01 15:21:19,877] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:19,879] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:19,894] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:19,901] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:19,902] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:21:25,899] {scheduler_job.py:154} INFO - Started process (PID=61893) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:25,915] {logging_mixin.py:112} INFO - [2020-08-01 15:21:25,915] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:25,916] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:25,916] {logging_mixin.py:112} INFO - [2020-08-01 15:21:25,916] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:25,918] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:25,932] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:25,938] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:25,940] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:21:31,937] {scheduler_job.py:154} INFO - Started process (PID=61899) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:31,956] {logging_mixin.py:112} INFO - [2020-08-01 15:21:31,956] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:31,957] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:31,957] {logging_mixin.py:112} INFO - [2020-08-01 15:21:31,957] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:31,959] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:31,975] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:31,984] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:31,986] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:21:37,931] {scheduler_job.py:154} INFO - Started process (PID=61905) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:37,949] {logging_mixin.py:112} INFO - [2020-08-01 15:21:37,949] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:37,949] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:37,950] {logging_mixin.py:112} INFO - [2020-08-01 15:21:37,949] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:37,952] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:37,966] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:37,975] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:37,978] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:21:43,903] {scheduler_job.py:154} INFO - Started process (PID=61911) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:43,921] {logging_mixin.py:112} INFO - [2020-08-01 15:21:43,921] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:43,921] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:43,922] {logging_mixin.py:112} INFO - [2020-08-01 15:21:43,921] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:43,924] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:43,938] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:43,944] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:43,946] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:21:49,917] {scheduler_job.py:154} INFO - Started process (PID=61917) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:49,935] {logging_mixin.py:112} INFO - [2020-08-01 15:21:49,935] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:49,936] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:49,936] {logging_mixin.py:112} INFO - [2020-08-01 15:21:49,936] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:49,938] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:49,952] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:49,960] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:49,962] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:21:56,019] {scheduler_job.py:154} INFO - Started process (PID=61923) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:56,036] {logging_mixin.py:112} INFO - [2020-08-01 15:21:56,036] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:56,037] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:21:56,037] {logging_mixin.py:112} INFO - [2020-08-01 15:21:56,037] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:56,039] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:21:56,052] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:21:56,059] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:56,060] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:22:01,996] {scheduler_job.py:154} INFO - Started process (PID=61930) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:02,014] {logging_mixin.py:112} INFO - [2020-08-01 15:22:02,014] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:02,015] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:02,015] {logging_mixin.py:112} INFO - [2020-08-01 15:22:02,015] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:02,017] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:02,033] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:02,040] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:02,042] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:22:08,027] {scheduler_job.py:154} INFO - Started process (PID=61936) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:08,045] {logging_mixin.py:112} INFO - [2020-08-01 15:22:08,044] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:08,045] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:08,045] {logging_mixin.py:112} INFO - [2020-08-01 15:22:08,045] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:08,048] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:08,062] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:08,069] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:08,071] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:22:14,008] {scheduler_job.py:154} INFO - Started process (PID=61942) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:14,025] {logging_mixin.py:112} INFO - [2020-08-01 15:22:14,025] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:14,026] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:14,026] {logging_mixin.py:112} INFO - [2020-08-01 15:22:14,026] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:14,028] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:14,233] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:14,254] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:14,303] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.295 seconds
[2020-08-01 15:22:20,917] {scheduler_job.py:154} INFO - Started process (PID=61948) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:20,946] {logging_mixin.py:112} INFO - [2020-08-01 15:22:20,946] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:20,947] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:20,947] {logging_mixin.py:112} INFO - [2020-08-01 15:22:20,947] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:20,950] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:20,969] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:20,993] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:21,010] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.093 seconds
[2020-08-01 15:22:26,971] {scheduler_job.py:154} INFO - Started process (PID=61954) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:27,123] {logging_mixin.py:112} INFO - [2020-08-01 15:22:27,123] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:27,124] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:27,124] {logging_mixin.py:112} INFO - [2020-08-01 15:22:27,124] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:27,128] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:27,154] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:27,164] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:27,167] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.196 seconds
[2020-08-01 15:22:33,671] {scheduler_job.py:154} INFO - Started process (PID=61961) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:33,702] {logging_mixin.py:112} INFO - [2020-08-01 15:22:33,702] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:33,703] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:33,703] {logging_mixin.py:112} INFO - [2020-08-01 15:22:33,703] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:33,706] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:33,726] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:33,736] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:33,738] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.067 seconds
[2020-08-01 15:22:39,242] {scheduler_job.py:154} INFO - Started process (PID=61967) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:39,273] {logging_mixin.py:112} INFO - [2020-08-01 15:22:39,273] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:39,274] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:39,274] {logging_mixin.py:112} INFO - [2020-08-01 15:22:39,274] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:39,278] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:39,297] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:39,307] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:39,309] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.067 seconds
[2020-08-01 15:22:45,008] {scheduler_job.py:154} INFO - Started process (PID=61973) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:45,040] {logging_mixin.py:112} INFO - [2020-08-01 15:22:45,039] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:45,041] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:45,041] {logging_mixin.py:112} INFO - [2020-08-01 15:22:45,041] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:45,044] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:45,064] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:45,074] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:45,077] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.069 seconds
[2020-08-01 15:22:51,184] {scheduler_job.py:154} INFO - Started process (PID=61979) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:51,215] {logging_mixin.py:112} INFO - [2020-08-01 15:22:51,215] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:51,216] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:51,217] {logging_mixin.py:112} INFO - [2020-08-01 15:22:51,217] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:51,220] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:51,237] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:51,248] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:51,250] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.066 seconds
[2020-08-01 15:22:57,240] {scheduler_job.py:154} INFO - Started process (PID=61985) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:57,272] {logging_mixin.py:112} INFO - [2020-08-01 15:22:57,271] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:57,273] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:22:57,273] {logging_mixin.py:112} INFO - [2020-08-01 15:22:57,273] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:57,276] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:22:57,546] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:22:57,557] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:57,559] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.319 seconds
[2020-08-01 15:23:03,844] {scheduler_job.py:154} INFO - Started process (PID=61992) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:03,878] {logging_mixin.py:112} INFO - [2020-08-01 15:23:03,878] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:03,879] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:23:03,879] {logging_mixin.py:112} INFO - [2020-08-01 15:23:03,879] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:03,882] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:03,903] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:23:03,914] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:03,917] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.073 seconds
[2020-08-01 15:23:10,049] {scheduler_job.py:154} INFO - Started process (PID=61998) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:10,080] {logging_mixin.py:112} INFO - [2020-08-01 15:23:10,080] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:10,081] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:23:10,081] {logging_mixin.py:112} INFO - [2020-08-01 15:23:10,081] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:10,085] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:10,104] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:23:10,115] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:10,118] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.069 seconds
[2020-08-01 15:23:16,830] {scheduler_job.py:154} INFO - Started process (PID=62004) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:16,860] {logging_mixin.py:112} INFO - [2020-08-01 15:23:16,860] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:16,861] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:23:16,861] {logging_mixin.py:112} INFO - [2020-08-01 15:23:16,861] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:16,865] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:16,884] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:23:16,894] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:16,897] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.067 seconds
[2020-08-01 15:23:22,736] {scheduler_job.py:154} INFO - Started process (PID=62010) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:22,768] {logging_mixin.py:112} INFO - [2020-08-01 15:23:22,768] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:22,769] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:23:22,769] {logging_mixin.py:112} INFO - [2020-08-01 15:23:22,769] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:22,772] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:22,791] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:23:22,802] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:22,804] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.068 seconds
[2020-08-01 15:23:29,182] {scheduler_job.py:154} INFO - Started process (PID=62016) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:29,244] {logging_mixin.py:112} INFO - [2020-08-01 15:23:29,243] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:29,245] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:23:29,245] {logging_mixin.py:112} INFO - [2020-08-01 15:23:29,245] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:29,249] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:29,270] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:23:29,280] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:29,283] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.101 seconds
[2020-08-01 15:23:35,469] {scheduler_job.py:154} INFO - Started process (PID=62023) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:35,499] {logging_mixin.py:112} INFO - [2020-08-01 15:23:35,499] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:35,500] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:23:35,500] {logging_mixin.py:112} INFO - [2020-08-01 15:23:35,500] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:35,504] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:35,523] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:23:35,532] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:35,534] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.066 seconds
[2020-08-01 15:23:42,699] {scheduler_job.py:154} INFO - Started process (PID=62029) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:42,730] {logging_mixin.py:112} INFO - [2020-08-01 15:23:42,729] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:42,731] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:23:42,731] {logging_mixin.py:112} INFO - [2020-08-01 15:23:42,731] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:42,735] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:42,755] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:23:42,766] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:42,768] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.070 seconds
[2020-08-01 15:23:48,793] {scheduler_job.py:154} INFO - Started process (PID=62035) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:48,829] {logging_mixin.py:112} INFO - [2020-08-01 15:23:48,828] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:48,830] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:23:48,830] {logging_mixin.py:112} INFO - [2020-08-01 15:23:48,830] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:48,834] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:48,856] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:23:48,867] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:48,870] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.077 seconds
[2020-08-01 15:23:54,597] {scheduler_job.py:154} INFO - Started process (PID=62041) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:54,629] {logging_mixin.py:112} INFO - [2020-08-01 15:23:54,628] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:54,630] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:23:54,630] {logging_mixin.py:112} INFO - [2020-08-01 15:23:54,630] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:54,633] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:23:54,656] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:23:54,667] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:54,670] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.073 seconds
[2020-08-01 15:24:01,584] {scheduler_job.py:154} INFO - Started process (PID=62048) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:01,614] {logging_mixin.py:112} INFO - [2020-08-01 15:24:01,614] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:01,615] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:01,615] {logging_mixin.py:112} INFO - [2020-08-01 15:24:01,615] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:01,618] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:01,637] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:01,648] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:01,650] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.066 seconds
[2020-08-01 15:24:07,745] {scheduler_job.py:154} INFO - Started process (PID=62054) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:07,796] {logging_mixin.py:112} INFO - [2020-08-01 15:24:07,796] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:07,797] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:07,798] {logging_mixin.py:112} INFO - [2020-08-01 15:24:07,798] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:07,802] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:07,821] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:07,832] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:07,834] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.089 seconds
[2020-08-01 15:24:13,557] {scheduler_job.py:154} INFO - Started process (PID=62060) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:13,587] {logging_mixin.py:112} INFO - [2020-08-01 15:24:13,587] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:13,588] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:13,589] {logging_mixin.py:112} INFO - [2020-08-01 15:24:13,589] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:13,592] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:13,611] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:13,621] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:13,623] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.066 seconds
[2020-08-01 15:24:19,600] {scheduler_job.py:154} INFO - Started process (PID=62066) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:19,628] {logging_mixin.py:112} INFO - [2020-08-01 15:24:19,628] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:19,629] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:19,630] {logging_mixin.py:112} INFO - [2020-08-01 15:24:19,629] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:19,633] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:19,652] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:19,664] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:19,667] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.067 seconds
[2020-08-01 15:24:25,213] {scheduler_job.py:154} INFO - Started process (PID=62072) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:25,241] {logging_mixin.py:112} INFO - [2020-08-01 15:24:25,240] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:25,242] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:25,242] {logging_mixin.py:112} INFO - [2020-08-01 15:24:25,242] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:25,245] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:25,265] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:25,276] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:25,278] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.065 seconds
[2020-08-01 15:24:30,836] {scheduler_job.py:154} INFO - Started process (PID=62078) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:30,869] {logging_mixin.py:112} INFO - [2020-08-01 15:24:30,869] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:30,870] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:30,870] {logging_mixin.py:112} INFO - [2020-08-01 15:24:30,870] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:30,873] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:30,893] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:30,906] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:30,909] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.073 seconds
[2020-08-01 15:24:36,309] {scheduler_job.py:154} INFO - Started process (PID=62085) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:36,349] {logging_mixin.py:112} INFO - [2020-08-01 15:24:36,349] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:36,350] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:36,350] {logging_mixin.py:112} INFO - [2020-08-01 15:24:36,350] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:36,354] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:36,382] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:36,397] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:36,400] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.091 seconds
[2020-08-01 15:24:42,502] {scheduler_job.py:154} INFO - Started process (PID=62091) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:42,541] {logging_mixin.py:112} INFO - [2020-08-01 15:24:42,541] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:42,542] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:42,542] {logging_mixin.py:112} INFO - [2020-08-01 15:24:42,542] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:42,545] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:42,575] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:42,589] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:42,592] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.091 seconds
[2020-08-01 15:24:48,653] {scheduler_job.py:154} INFO - Started process (PID=62097) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:48,686] {logging_mixin.py:112} INFO - [2020-08-01 15:24:48,686] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:48,687] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:48,687] {logging_mixin.py:112} INFO - [2020-08-01 15:24:48,687] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:48,691] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:48,712] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:48,723] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:48,726] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.073 seconds
[2020-08-01 15:24:54,235] {scheduler_job.py:154} INFO - Started process (PID=62103) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:54,267] {logging_mixin.py:112} INFO - [2020-08-01 15:24:54,267] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:54,268] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:54,268] {logging_mixin.py:112} INFO - [2020-08-01 15:24:54,268] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:54,271] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:54,288] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:54,298] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:54,300] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.066 seconds
[2020-08-01 15:24:59,633] {scheduler_job.py:154} INFO - Started process (PID=62109) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:59,668] {logging_mixin.py:112} INFO - [2020-08-01 15:24:59,668] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:59,669] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:24:59,669] {logging_mixin.py:112} INFO - [2020-08-01 15:24:59,669] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:59,672] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:24:59,693] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:24:59,706] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:59,708] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.075 seconds
[2020-08-01 15:25:05,232] {scheduler_job.py:154} INFO - Started process (PID=62116) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:05,261] {logging_mixin.py:112} INFO - [2020-08-01 15:25:05,261] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:05,262] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:05,263] {logging_mixin.py:112} INFO - [2020-08-01 15:25:05,263] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:05,266] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:05,287] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:05,295] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:05,296] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.065 seconds
[2020-08-01 15:25:10,658] {scheduler_job.py:154} INFO - Started process (PID=62122) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:10,695] {logging_mixin.py:112} INFO - [2020-08-01 15:25:10,695] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:10,696] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:10,696] {logging_mixin.py:112} INFO - [2020-08-01 15:25:10,696] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:10,700] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:10,722] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:10,733] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:10,736] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.077 seconds
[2020-08-01 15:25:16,170] {scheduler_job.py:154} INFO - Started process (PID=62128) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:16,203] {logging_mixin.py:112} INFO - [2020-08-01 15:25:16,203] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:16,204] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:16,204] {logging_mixin.py:112} INFO - [2020-08-01 15:25:16,204] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:16,207] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:16,234] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:16,245] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:16,251] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.081 seconds
[2020-08-01 15:25:21,653] {scheduler_job.py:154} INFO - Started process (PID=62134) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:21,691] {logging_mixin.py:112} INFO - [2020-08-01 15:25:21,691] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:21,692] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:21,692] {logging_mixin.py:112} INFO - [2020-08-01 15:25:21,692] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:21,695] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:21,714] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:21,724] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:21,727] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.073 seconds
[2020-08-01 15:25:27,114] {scheduler_job.py:154} INFO - Started process (PID=62140) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:27,148] {logging_mixin.py:112} INFO - [2020-08-01 15:25:27,148] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:27,149] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:27,149] {logging_mixin.py:112} INFO - [2020-08-01 15:25:27,149] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:27,152] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:27,172] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:27,183] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:27,186] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.072 seconds
[2020-08-01 15:25:32,612] {scheduler_job.py:154} INFO - Started process (PID=62147) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:32,630] {logging_mixin.py:112} INFO - [2020-08-01 15:25:32,630] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:32,631] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:32,631] {logging_mixin.py:112} INFO - [2020-08-01 15:25:32,631] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:32,633] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:32,647] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:32,654] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:32,656] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:25:38,593] {scheduler_job.py:154} INFO - Started process (PID=62153) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:38,610] {logging_mixin.py:112} INFO - [2020-08-01 15:25:38,610] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:38,611] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:38,611] {logging_mixin.py:112} INFO - [2020-08-01 15:25:38,611] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:38,613] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:38,627] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:38,634] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:38,636] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:25:44,630] {scheduler_job.py:154} INFO - Started process (PID=62159) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:44,647] {logging_mixin.py:112} INFO - [2020-08-01 15:25:44,647] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:44,648] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:44,648] {logging_mixin.py:112} INFO - [2020-08-01 15:25:44,648] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:44,650] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:44,662] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:44,669] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:44,671] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:25:50,645] {scheduler_job.py:154} INFO - Started process (PID=62170) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:50,663] {logging_mixin.py:112} INFO - [2020-08-01 15:25:50,662] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:50,663] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:50,663] {logging_mixin.py:112} INFO - [2020-08-01 15:25:50,663] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:50,665] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:50,680] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:50,686] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:50,688] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:25:56,663] {scheduler_job.py:154} INFO - Started process (PID=62176) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:56,681] {logging_mixin.py:112} INFO - [2020-08-01 15:25:56,681] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:56,682] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:25:56,682] {logging_mixin.py:112} INFO - [2020-08-01 15:25:56,682] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:56,684] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:25:56,698] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:25:56,705] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:56,707] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:26:02,729] {scheduler_job.py:154} INFO - Started process (PID=62183) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:02,747] {logging_mixin.py:112} INFO - [2020-08-01 15:26:02,747] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:02,747] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:02,748] {logging_mixin.py:112} INFO - [2020-08-01 15:26:02,748] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:02,750] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:02,764] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:02,771] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:02,773] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:26:08,705] {scheduler_job.py:154} INFO - Started process (PID=62190) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:08,723] {logging_mixin.py:112} INFO - [2020-08-01 15:26:08,723] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:08,723] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:08,724] {logging_mixin.py:112} INFO - [2020-08-01 15:26:08,724] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:08,726] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:08,739] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:08,746] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:08,747] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:26:14,741] {scheduler_job.py:154} INFO - Started process (PID=62196) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:14,759] {logging_mixin.py:112} INFO - [2020-08-01 15:26:14,759] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:14,759] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:14,760] {logging_mixin.py:112} INFO - [2020-08-01 15:26:14,760] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:14,762] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:14,776] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:14,783] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:14,785] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:26:20,744] {scheduler_job.py:154} INFO - Started process (PID=62202) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:20,762] {logging_mixin.py:112} INFO - [2020-08-01 15:26:20,762] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:20,763] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:20,763] {logging_mixin.py:112} INFO - [2020-08-01 15:26:20,763] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:20,765] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:20,779] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:20,786] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:20,788] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:26:26,767] {scheduler_job.py:154} INFO - Started process (PID=62208) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:26,785] {logging_mixin.py:112} INFO - [2020-08-01 15:26:26,785] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:26,786] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:26,786] {logging_mixin.py:112} INFO - [2020-08-01 15:26:26,786] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:26,788] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:26,802] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:26,809] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:26,811] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:26:32,890] {scheduler_job.py:154} INFO - Started process (PID=62214) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:32,907] {logging_mixin.py:112} INFO - [2020-08-01 15:26:32,907] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:32,908] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:32,908] {logging_mixin.py:112} INFO - [2020-08-01 15:26:32,908] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:32,910] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:32,924] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:32,932] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:32,933] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:26:38,869] {scheduler_job.py:154} INFO - Started process (PID=62221) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:38,888] {logging_mixin.py:112} INFO - [2020-08-01 15:26:38,888] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:38,889] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:38,889] {logging_mixin.py:112} INFO - [2020-08-01 15:26:38,889] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:38,891] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:38,906] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:38,914] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:38,915] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:26:44,865] {scheduler_job.py:154} INFO - Started process (PID=62227) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:44,883] {logging_mixin.py:112} INFO - [2020-08-01 15:26:44,883] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:44,884] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:44,884] {logging_mixin.py:112} INFO - [2020-08-01 15:26:44,884] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:44,886] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:44,901] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:44,909] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:44,911] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:26:50,855] {scheduler_job.py:154} INFO - Started process (PID=62233) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:50,872] {logging_mixin.py:112} INFO - [2020-08-01 15:26:50,872] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:50,873] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:50,873] {logging_mixin.py:112} INFO - [2020-08-01 15:26:50,873] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:50,875] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:50,889] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:50,896] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:50,898] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:26:56,901] {scheduler_job.py:154} INFO - Started process (PID=62241) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:56,926] {logging_mixin.py:112} INFO - [2020-08-01 15:26:56,926] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:56,927] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:26:56,927] {logging_mixin.py:112} INFO - [2020-08-01 15:26:56,927] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:56,930] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:26:56,948] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:26:56,957] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:56,959] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.058 seconds
[2020-08-01 15:27:02,912] {scheduler_job.py:154} INFO - Started process (PID=62247) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:02,930] {logging_mixin.py:112} INFO - [2020-08-01 15:27:02,929] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:02,930] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:02,930] {logging_mixin.py:112} INFO - [2020-08-01 15:27:02,930] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:02,932] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:02,946] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:02,953] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:02,955] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:27:08,922] {scheduler_job.py:154} INFO - Started process (PID=62254) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:08,940] {logging_mixin.py:112} INFO - [2020-08-01 15:27:08,940] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:08,941] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:08,941] {logging_mixin.py:112} INFO - [2020-08-01 15:27:08,941] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:08,943] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:08,957] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:08,964] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:08,966] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:27:14,951] {scheduler_job.py:154} INFO - Started process (PID=62260) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:14,969] {logging_mixin.py:112} INFO - [2020-08-01 15:27:14,969] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:14,969] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:14,970] {logging_mixin.py:112} INFO - [2020-08-01 15:27:14,970] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:14,972] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:14,986] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:14,993] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:14,994] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:27:20,972] {scheduler_job.py:154} INFO - Started process (PID=62266) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:20,990] {logging_mixin.py:112} INFO - [2020-08-01 15:27:20,990] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:20,990] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:20,991] {logging_mixin.py:112} INFO - [2020-08-01 15:27:20,991] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:20,993] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:21,007] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:21,014] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:21,016] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:27:26,993] {scheduler_job.py:154} INFO - Started process (PID=62272) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:27,011] {logging_mixin.py:112} INFO - [2020-08-01 15:27:27,011] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:27,011] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:27,012] {logging_mixin.py:112} INFO - [2020-08-01 15:27:27,011] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:27,014] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:27,028] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:27,035] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:27,036] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:27:33,020] {scheduler_job.py:154} INFO - Started process (PID=62278) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:33,037] {logging_mixin.py:112} INFO - [2020-08-01 15:27:33,037] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:33,038] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:33,038] {logging_mixin.py:112} INFO - [2020-08-01 15:27:33,038] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:33,040] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:33,054] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:33,061] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:33,063] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:27:39,042] {scheduler_job.py:154} INFO - Started process (PID=62285) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:39,060] {logging_mixin.py:112} INFO - [2020-08-01 15:27:39,060] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:39,061] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:39,061] {logging_mixin.py:112} INFO - [2020-08-01 15:27:39,061] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:39,063] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:39,077] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:39,084] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:39,086] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:27:45,066] {scheduler_job.py:154} INFO - Started process (PID=62291) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:45,085] {logging_mixin.py:112} INFO - [2020-08-01 15:27:45,084] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:45,085] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:45,085] {logging_mixin.py:112} INFO - [2020-08-01 15:27:45,085] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:45,087] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:45,102] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:45,109] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:45,111] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:27:51,092] {scheduler_job.py:154} INFO - Started process (PID=62297) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:51,111] {logging_mixin.py:112} INFO - [2020-08-01 15:27:51,111] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:51,112] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:51,112] {logging_mixin.py:112} INFO - [2020-08-01 15:27:51,112] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:51,114] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:51,129] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:51,136] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:51,138] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:27:57,097] {scheduler_job.py:154} INFO - Started process (PID=62303) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:57,115] {logging_mixin.py:112} INFO - [2020-08-01 15:27:57,115] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:57,115] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:27:57,116] {logging_mixin.py:112} INFO - [2020-08-01 15:27:57,115] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:57,118] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:27:57,132] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:27:57,140] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:57,142] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:28:03,124] {scheduler_job.py:154} INFO - Started process (PID=62309) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:03,142] {logging_mixin.py:112} INFO - [2020-08-01 15:28:03,142] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:03,143] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:03,143] {logging_mixin.py:112} INFO - [2020-08-01 15:28:03,143] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:03,145] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:03,159] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:03,166] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:03,168] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:28:09,139] {scheduler_job.py:154} INFO - Started process (PID=62316) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:09,156] {logging_mixin.py:112} INFO - [2020-08-01 15:28:09,156] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:09,157] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:09,157] {logging_mixin.py:112} INFO - [2020-08-01 15:28:09,157] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:09,159] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:09,173] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:09,180] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:09,182] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:28:15,163] {scheduler_job.py:154} INFO - Started process (PID=62322) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:15,181] {logging_mixin.py:112} INFO - [2020-08-01 15:28:15,180] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:15,181] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:15,181] {logging_mixin.py:112} INFO - [2020-08-01 15:28:15,181] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:15,183] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:15,198] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:15,205] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:15,207] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:28:21,188] {scheduler_job.py:154} INFO - Started process (PID=62328) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:21,206] {logging_mixin.py:112} INFO - [2020-08-01 15:28:21,205] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:21,206] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:21,206] {logging_mixin.py:112} INFO - [2020-08-01 15:28:21,206] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:21,208] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:21,222] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:21,229] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:21,231] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:28:27,209] {scheduler_job.py:154} INFO - Started process (PID=62334) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:27,227] {logging_mixin.py:112} INFO - [2020-08-01 15:28:27,226] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:27,227] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:27,227] {logging_mixin.py:112} INFO - [2020-08-01 15:28:27,227] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:27,229] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:27,244] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:27,251] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:27,252] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:28:33,246] {scheduler_job.py:154} INFO - Started process (PID=62340) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:33,264] {logging_mixin.py:112} INFO - [2020-08-01 15:28:33,264] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:33,264] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:33,264] {logging_mixin.py:112} INFO - [2020-08-01 15:28:33,264] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:33,266] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:33,280] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:33,288] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:33,290] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:28:39,269] {scheduler_job.py:154} INFO - Started process (PID=62347) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:39,287] {logging_mixin.py:112} INFO - [2020-08-01 15:28:39,287] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:39,287] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:39,288] {logging_mixin.py:112} INFO - [2020-08-01 15:28:39,288] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:39,290] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:39,304] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:39,311] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:39,313] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:28:45,291] {scheduler_job.py:154} INFO - Started process (PID=62353) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:45,309] {logging_mixin.py:112} INFO - [2020-08-01 15:28:45,309] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:45,309] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:45,309] {logging_mixin.py:112} INFO - [2020-08-01 15:28:45,309] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:45,312] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:45,326] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:45,333] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:45,335] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:28:51,305] {scheduler_job.py:154} INFO - Started process (PID=62359) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:51,323] {logging_mixin.py:112} INFO - [2020-08-01 15:28:51,322] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:51,323] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:51,323] {logging_mixin.py:112} INFO - [2020-08-01 15:28:51,323] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:51,325] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:51,339] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:51,347] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:51,348] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:28:57,333] {scheduler_job.py:154} INFO - Started process (PID=62365) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:57,352] {logging_mixin.py:112} INFO - [2020-08-01 15:28:57,352] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:57,352] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:28:57,353] {logging_mixin.py:112} INFO - [2020-08-01 15:28:57,352] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:57,355] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:28:57,369] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:28:57,376] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:57,377] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:29:03,422] {scheduler_job.py:154} INFO - Started process (PID=62371) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:03,445] {logging_mixin.py:112} INFO - [2020-08-01 15:29:03,445] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:03,446] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:03,446] {logging_mixin.py:112} INFO - [2020-08-01 15:29:03,446] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:03,449] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:03,467] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:03,474] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:03,476] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.054 seconds
[2020-08-01 15:29:09,408] {scheduler_job.py:154} INFO - Started process (PID=62378) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:09,426] {logging_mixin.py:112} INFO - [2020-08-01 15:29:09,426] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:09,426] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:09,427] {logging_mixin.py:112} INFO - [2020-08-01 15:29:09,427] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:09,429] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:09,443] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:09,450] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:09,451] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:29:15,451] {scheduler_job.py:154} INFO - Started process (PID=62384) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:15,469] {logging_mixin.py:112} INFO - [2020-08-01 15:29:15,469] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:15,470] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:15,470] {logging_mixin.py:112} INFO - [2020-08-01 15:29:15,470] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:15,472] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:15,486] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:15,494] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:15,495] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:29:21,428] {scheduler_job.py:154} INFO - Started process (PID=62390) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:21,446] {logging_mixin.py:112} INFO - [2020-08-01 15:29:21,446] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:21,446] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:21,447] {logging_mixin.py:112} INFO - [2020-08-01 15:29:21,447] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:21,449] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:21,463] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:21,470] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:21,471] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:29:27,577] {scheduler_job.py:154} INFO - Started process (PID=62396) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:27,598] {logging_mixin.py:112} INFO - [2020-08-01 15:29:27,598] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:27,599] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:27,599] {logging_mixin.py:112} INFO - [2020-08-01 15:29:27,599] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:27,602] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:27,619] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:27,626] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:27,628] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.051 seconds
[2020-08-01 15:29:33,473] {scheduler_job.py:154} INFO - Started process (PID=62402) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:33,491] {logging_mixin.py:112} INFO - [2020-08-01 15:29:33,491] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:33,491] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:33,492] {logging_mixin.py:112} INFO - [2020-08-01 15:29:33,492] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:33,494] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:33,508] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:33,515] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:33,517] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:29:39,486] {scheduler_job.py:154} INFO - Started process (PID=62409) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:39,503] {logging_mixin.py:112} INFO - [2020-08-01 15:29:39,503] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:39,504] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:39,504] {logging_mixin.py:112} INFO - [2020-08-01 15:29:39,504] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:39,506] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:39,520] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:39,527] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:39,529] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:29:45,607] {scheduler_job.py:154} INFO - Started process (PID=62415) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:45,632] {logging_mixin.py:112} INFO - [2020-08-01 15:29:45,632] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:45,633] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:45,633] {logging_mixin.py:112} INFO - [2020-08-01 15:29:45,633] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:45,636] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:45,655] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:45,666] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:45,669] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.062 seconds
[2020-08-01 15:29:51,634] {scheduler_job.py:154} INFO - Started process (PID=62429) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:51,657] {logging_mixin.py:112} INFO - [2020-08-01 15:29:51,656] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:51,657] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:51,657] {logging_mixin.py:112} INFO - [2020-08-01 15:29:51,657] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:51,662] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:51,683] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:51,690] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:51,692] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.058 seconds
[2020-08-01 15:29:57,527] {scheduler_job.py:154} INFO - Started process (PID=62446) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:57,545] {logging_mixin.py:112} INFO - [2020-08-01 15:29:57,545] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:57,546] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:29:57,546] {logging_mixin.py:112} INFO - [2020-08-01 15:29:57,546] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:57,548] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:29:57,562] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:29:57,569] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:57,571] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:30:03,552] {scheduler_job.py:154} INFO - Started process (PID=62462) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:03,570] {logging_mixin.py:112} INFO - [2020-08-01 15:30:03,569] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:03,570] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:03,570] {logging_mixin.py:112} INFO - [2020-08-01 15:30:03,570] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:03,572] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:03,587] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:03,594] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:03,595] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:30:09,630] {scheduler_job.py:154} INFO - Started process (PID=62477) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:09,647] {logging_mixin.py:112} INFO - [2020-08-01 15:30:09,647] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:09,648] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:09,648] {logging_mixin.py:112} INFO - [2020-08-01 15:30:09,648] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:09,650] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:09,664] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:09,672] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:09,673] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:30:15,870] {scheduler_job.py:154} INFO - Started process (PID=62499) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:15,889] {logging_mixin.py:112} INFO - [2020-08-01 15:30:15,889] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:15,890] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:15,890] {logging_mixin.py:112} INFO - [2020-08-01 15:30:15,890] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:15,892] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:15,907] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:15,915] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:15,917] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:30:21,617] {scheduler_job.py:154} INFO - Started process (PID=62550) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:21,635] {logging_mixin.py:112} INFO - [2020-08-01 15:30:21,635] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:21,636] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:21,636] {logging_mixin.py:112} INFO - [2020-08-01 15:30:21,636] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:21,638] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:21,652] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:21,659] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:21,661] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:30:27,667] {scheduler_job.py:154} INFO - Started process (PID=62596) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:27,684] {logging_mixin.py:112} INFO - [2020-08-01 15:30:27,684] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:27,685] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:27,685] {logging_mixin.py:112} INFO - [2020-08-01 15:30:27,685] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:27,687] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:27,701] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:27,709] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:27,710] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:30:33,655] {scheduler_job.py:154} INFO - Started process (PID=62659) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:33,672] {logging_mixin.py:112} INFO - [2020-08-01 15:30:33,672] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:33,673] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:33,673] {logging_mixin.py:112} INFO - [2020-08-01 15:30:33,673] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:33,675] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:33,689] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:33,696] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:33,698] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:30:39,702] {scheduler_job.py:154} INFO - Started process (PID=62674) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:39,719] {logging_mixin.py:112} INFO - [2020-08-01 15:30:39,719] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:39,720] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:39,720] {logging_mixin.py:112} INFO - [2020-08-01 15:30:39,720] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:39,723] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:39,737] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:39,744] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:39,746] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:30:45,697] {scheduler_job.py:154} INFO - Started process (PID=62697) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:45,715] {logging_mixin.py:112} INFO - [2020-08-01 15:30:45,715] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:45,716] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:45,716] {logging_mixin.py:112} INFO - [2020-08-01 15:30:45,716] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:45,718] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:45,732] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:45,739] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:45,741] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:30:51,712] {scheduler_job.py:154} INFO - Started process (PID=62711) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:51,729] {logging_mixin.py:112} INFO - [2020-08-01 15:30:51,729] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:51,730] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:51,730] {logging_mixin.py:112} INFO - [2020-08-01 15:30:51,730] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:51,732] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:51,747] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:51,754] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:51,755] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:30:57,734] {scheduler_job.py:154} INFO - Started process (PID=62725) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:57,752] {logging_mixin.py:112} INFO - [2020-08-01 15:30:57,752] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:57,753] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:30:57,753] {logging_mixin.py:112} INFO - [2020-08-01 15:30:57,753] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:57,755] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:30:57,769] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:30:57,776] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:57,777] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:31:03,757] {scheduler_job.py:154} INFO - Started process (PID=62739) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:03,774] {logging_mixin.py:112} INFO - [2020-08-01 15:31:03,774] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:03,775] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:03,775] {logging_mixin.py:112} INFO - [2020-08-01 15:31:03,775] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:03,777] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:03,791] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:03,799] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:03,801] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:31:09,814] {scheduler_job.py:154} INFO - Started process (PID=62754) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:09,831] {logging_mixin.py:112} INFO - [2020-08-01 15:31:09,831] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:09,831] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:09,831] {logging_mixin.py:112} INFO - [2020-08-01 15:31:09,831] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:09,834] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:09,847] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:09,854] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:09,855] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:31:15,838] {scheduler_job.py:154} INFO - Started process (PID=62768) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:15,856] {logging_mixin.py:112} INFO - [2020-08-01 15:31:15,856] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:15,856] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:15,856] {logging_mixin.py:112} INFO - [2020-08-01 15:31:15,856] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:15,858] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:15,873] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:15,880] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:15,881] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:31:21,827] {scheduler_job.py:154} INFO - Started process (PID=62790) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:21,844] {logging_mixin.py:112} INFO - [2020-08-01 15:31:21,844] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:21,845] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:21,845] {logging_mixin.py:112} INFO - [2020-08-01 15:31:21,845] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:21,847] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:21,861] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:21,869] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:21,871] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:31:27,854] {scheduler_job.py:154} INFO - Started process (PID=62804) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:27,872] {logging_mixin.py:112} INFO - [2020-08-01 15:31:27,872] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:27,873] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:27,873] {logging_mixin.py:112} INFO - [2020-08-01 15:31:27,873] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:27,875] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:27,889] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:27,896] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:27,897] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:31:33,888] {scheduler_job.py:154} INFO - Started process (PID=62818) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:33,906] {logging_mixin.py:112} INFO - [2020-08-01 15:31:33,906] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:33,906] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:33,907] {logging_mixin.py:112} INFO - [2020-08-01 15:31:33,907] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:33,909] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:33,923] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:33,930] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:33,932] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:31:39,961] {scheduler_job.py:154} INFO - Started process (PID=62832) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:39,978] {logging_mixin.py:112} INFO - [2020-08-01 15:31:39,978] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:39,979] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:39,979] {logging_mixin.py:112} INFO - [2020-08-01 15:31:39,979] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:39,981] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:39,996] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:40,003] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:40,005] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:31:45,964] {scheduler_job.py:154} INFO - Started process (PID=62847) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:45,982] {logging_mixin.py:112} INFO - [2020-08-01 15:31:45,982] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:45,983] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:45,983] {logging_mixin.py:112} INFO - [2020-08-01 15:31:45,983] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:45,985] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:45,999] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:46,006] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:46,008] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:31:51,961] {scheduler_job.py:154} INFO - Started process (PID=62869) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:51,979] {logging_mixin.py:112} INFO - [2020-08-01 15:31:51,979] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:51,979] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:51,979] {logging_mixin.py:112} INFO - [2020-08-01 15:31:51,979] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:51,982] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:51,996] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:52,003] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:52,005] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:31:57,990] {scheduler_job.py:154} INFO - Started process (PID=62883) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:58,007] {logging_mixin.py:112} INFO - [2020-08-01 15:31:58,007] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:58,008] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:31:58,008] {logging_mixin.py:112} INFO - [2020-08-01 15:31:58,008] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:58,010] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:31:58,024] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:31:58,031] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:58,033] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:32:04,019] {scheduler_job.py:154} INFO - Started process (PID=62897) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:04,036] {logging_mixin.py:112} INFO - [2020-08-01 15:32:04,036] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:04,037] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:04,037] {logging_mixin.py:112} INFO - [2020-08-01 15:32:04,037] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:04,039] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:04,053] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:04,060] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:04,062] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:32:10,091] {scheduler_job.py:154} INFO - Started process (PID=62911) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:10,114] {logging_mixin.py:112} INFO - [2020-08-01 15:32:10,114] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:10,115] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:10,115] {logging_mixin.py:112} INFO - [2020-08-01 15:32:10,115] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:10,118] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:10,134] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:10,142] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:10,143] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 15:32:16,056] {scheduler_job.py:154} INFO - Started process (PID=62926) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:16,074] {logging_mixin.py:112} INFO - [2020-08-01 15:32:16,073] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:16,074] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:16,074] {logging_mixin.py:112} INFO - [2020-08-01 15:32:16,074] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:16,076] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:16,091] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:16,098] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:16,100] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:32:22,118] {scheduler_job.py:154} INFO - Started process (PID=62940) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:22,136] {logging_mixin.py:112} INFO - [2020-08-01 15:32:22,136] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:22,137] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:22,137] {logging_mixin.py:112} INFO - [2020-08-01 15:32:22,137] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:22,139] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:22,153] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:22,160] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:22,162] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:32:28,103] {scheduler_job.py:154} INFO - Started process (PID=62962) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:28,121] {logging_mixin.py:112} INFO - [2020-08-01 15:32:28,120] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:28,121] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:28,121] {logging_mixin.py:112} INFO - [2020-08-01 15:32:28,121] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:28,123] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:28,138] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:28,145] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:28,146] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:32:34,130] {scheduler_job.py:154} INFO - Started process (PID=62976) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:34,147] {logging_mixin.py:112} INFO - [2020-08-01 15:32:34,147] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:34,148] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:34,148] {logging_mixin.py:112} INFO - [2020-08-01 15:32:34,148] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:34,150] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:34,164] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:34,171] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:34,172] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:32:40,145] {scheduler_job.py:154} INFO - Started process (PID=62990) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:40,163] {logging_mixin.py:112} INFO - [2020-08-01 15:32:40,163] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:40,164] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:40,164] {logging_mixin.py:112} INFO - [2020-08-01 15:32:40,164] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:40,166] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:40,180] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:40,187] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:40,188] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:32:46,166] {scheduler_job.py:154} INFO - Started process (PID=63005) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:46,183] {logging_mixin.py:112} INFO - [2020-08-01 15:32:46,183] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:46,184] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:46,184] {logging_mixin.py:112} INFO - [2020-08-01 15:32:46,184] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:46,186] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:46,200] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:46,208] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:46,209] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:32:52,201] {scheduler_job.py:154} INFO - Started process (PID=63019) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:52,218] {logging_mixin.py:112} INFO - [2020-08-01 15:32:52,218] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:52,219] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:52,219] {logging_mixin.py:112} INFO - [2020-08-01 15:32:52,219] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:52,221] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:52,235] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:52,242] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:52,244] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:32:58,209] {scheduler_job.py:154} INFO - Started process (PID=63041) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:58,227] {logging_mixin.py:112} INFO - [2020-08-01 15:32:58,227] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:58,227] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:32:58,227] {logging_mixin.py:112} INFO - [2020-08-01 15:32:58,227] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:58,230] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:32:58,244] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:32:58,253] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:58,255] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:33:04,229] {scheduler_job.py:154} INFO - Started process (PID=63055) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:04,246] {logging_mixin.py:112} INFO - [2020-08-01 15:33:04,246] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:04,247] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:04,247] {logging_mixin.py:112} INFO - [2020-08-01 15:33:04,247] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:04,249] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:04,264] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:04,271] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:04,273] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:33:10,231] {scheduler_job.py:154} INFO - Started process (PID=63069) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:10,248] {logging_mixin.py:112} INFO - [2020-08-01 15:33:10,248] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:10,249] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:10,249] {logging_mixin.py:112} INFO - [2020-08-01 15:33:10,249] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:10,251] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:10,265] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:10,272] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:10,274] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:33:16,296] {scheduler_job.py:154} INFO - Started process (PID=63084) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:16,316] {logging_mixin.py:112} INFO - [2020-08-01 15:33:16,315] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:16,316] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:16,316] {logging_mixin.py:112} INFO - [2020-08-01 15:33:16,316] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:16,318] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:16,333] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:16,340] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:16,341] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:33:22,254] {scheduler_job.py:154} INFO - Started process (PID=63114) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:22,271] {logging_mixin.py:112} INFO - [2020-08-01 15:33:22,271] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:22,272] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:22,272] {logging_mixin.py:112} INFO - [2020-08-01 15:33:22,272] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:22,274] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:22,289] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:22,296] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:22,297] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:33:28,355] {scheduler_job.py:154} INFO - Started process (PID=63128) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:28,376] {logging_mixin.py:112} INFO - [2020-08-01 15:33:28,375] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:28,376] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:28,376] {logging_mixin.py:112} INFO - [2020-08-01 15:33:28,376] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:28,380] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:28,397] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:28,405] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:28,407] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 15:33:34,330] {scheduler_job.py:154} INFO - Started process (PID=63167) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:34,352] {logging_mixin.py:112} INFO - [2020-08-01 15:33:34,352] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:34,353] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:34,354] {logging_mixin.py:112} INFO - [2020-08-01 15:33:34,353] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:34,356] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:34,371] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:34,378] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:34,380] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:33:40,362] {scheduler_job.py:154} INFO - Started process (PID=63181) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:40,380] {logging_mixin.py:112} INFO - [2020-08-01 15:33:40,379] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:40,381] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:40,381] {logging_mixin.py:112} INFO - [2020-08-01 15:33:40,381] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:40,383] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:40,397] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:40,404] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:40,405] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:33:46,319] {scheduler_job.py:154} INFO - Started process (PID=63197) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:46,337] {logging_mixin.py:112} INFO - [2020-08-01 15:33:46,337] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:46,337] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:46,338] {logging_mixin.py:112} INFO - [2020-08-01 15:33:46,338] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:46,340] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:46,354] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:46,361] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:46,362] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:33:52,342] {scheduler_job.py:154} INFO - Started process (PID=63211) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:52,360] {logging_mixin.py:112} INFO - [2020-08-01 15:33:52,360] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:52,361] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:52,361] {logging_mixin.py:112} INFO - [2020-08-01 15:33:52,361] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:52,363] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:52,379] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:52,386] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:52,388] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:33:58,391] {scheduler_job.py:154} INFO - Started process (PID=63225) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:58,409] {logging_mixin.py:112} INFO - [2020-08-01 15:33:58,408] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:58,410] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:33:58,410] {logging_mixin.py:112} INFO - [2020-08-01 15:33:58,410] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:58,412] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:33:58,426] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:33:58,434] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:58,436] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:34:04,455] {scheduler_job.py:154} INFO - Started process (PID=63248) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:04,474] {logging_mixin.py:112} INFO - [2020-08-01 15:34:04,473] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:04,474] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:04,474] {logging_mixin.py:112} INFO - [2020-08-01 15:34:04,474] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:04,477] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:04,491] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:04,498] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:04,499] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:34:10,390] {scheduler_job.py:154} INFO - Started process (PID=63262) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:10,412] {logging_mixin.py:112} INFO - [2020-08-01 15:34:10,412] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:10,412] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:10,413] {logging_mixin.py:112} INFO - [2020-08-01 15:34:10,413] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:10,415] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:10,428] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:10,435] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:10,436] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:34:16,415] {scheduler_job.py:154} INFO - Started process (PID=63278) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:16,433] {logging_mixin.py:112} INFO - [2020-08-01 15:34:16,432] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:16,433] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:16,433] {logging_mixin.py:112} INFO - [2020-08-01 15:34:16,433] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:16,435] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:16,450] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:16,458] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:16,459] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:34:22,455] {scheduler_job.py:154} INFO - Started process (PID=63292) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:22,473] {logging_mixin.py:112} INFO - [2020-08-01 15:34:22,473] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:22,474] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:22,474] {logging_mixin.py:112} INFO - [2020-08-01 15:34:22,474] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:22,476] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:22,490] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:22,498] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:22,500] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:34:28,533] {scheduler_job.py:154} INFO - Started process (PID=63306) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:28,551] {logging_mixin.py:112} INFO - [2020-08-01 15:34:28,551] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:28,552] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:28,552] {logging_mixin.py:112} INFO - [2020-08-01 15:34:28,552] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:28,554] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:28,566] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:28,573] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:28,575] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:34:34,573] {scheduler_job.py:154} INFO - Started process (PID=63321) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:34,592] {logging_mixin.py:112} INFO - [2020-08-01 15:34:34,592] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:34,593] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:34,593] {logging_mixin.py:112} INFO - [2020-08-01 15:34:34,593] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:34,595] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:34,611] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:34,619] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:34,620] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:34:40,610] {scheduler_job.py:154} INFO - Started process (PID=63343) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:40,631] {logging_mixin.py:112} INFO - [2020-08-01 15:34:40,630] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:40,631] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:40,632] {logging_mixin.py:112} INFO - [2020-08-01 15:34:40,632] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:40,635] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:40,650] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:40,657] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:40,659] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:34:46,556] {scheduler_job.py:154} INFO - Started process (PID=63359) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:46,575] {logging_mixin.py:112} INFO - [2020-08-01 15:34:46,575] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:46,575] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:46,576] {logging_mixin.py:112} INFO - [2020-08-01 15:34:46,576] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:46,578] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:46,603] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:46,613] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:46,616] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.061 seconds
[2020-08-01 15:34:52,565] {scheduler_job.py:154} INFO - Started process (PID=63373) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:52,583] {logging_mixin.py:112} INFO - [2020-08-01 15:34:52,583] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:52,584] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:52,584] {logging_mixin.py:112} INFO - [2020-08-01 15:34:52,584] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:52,586] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:52,601] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:52,608] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:52,610] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:34:58,564] {scheduler_job.py:154} INFO - Started process (PID=63387) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:58,582] {logging_mixin.py:112} INFO - [2020-08-01 15:34:58,581] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:58,582] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:34:58,582] {logging_mixin.py:112} INFO - [2020-08-01 15:34:58,582] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:58,584] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:34:58,599] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:34:58,606] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:58,607] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:35:04,575] {scheduler_job.py:154} INFO - Started process (PID=63419) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:04,592] {logging_mixin.py:112} INFO - [2020-08-01 15:35:04,592] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:04,593] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:35:04,593] {logging_mixin.py:112} INFO - [2020-08-01 15:35:04,593] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:04,595] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:04,609] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:35:04,615] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:04,617] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:35:06,562] {scheduler_job.py:154} INFO - Started process (PID=63429) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:06,580] {logging_mixin.py:112} INFO - [2020-08-01 15:35:06,580] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:06,580] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:35:06,581] {logging_mixin.py:112} INFO - [2020-08-01 15:35:06,581] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:06,583] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:06,597] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:35:06,604] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:06,605] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:35:14,840] {scheduler_job.py:154} INFO - Started process (PID=63463) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:14,858] {logging_mixin.py:112} INFO - [2020-08-01 15:35:14,858] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:14,859] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:35:14,860] {logging_mixin.py:112} INFO - [2020-08-01 15:35:14,859] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:14,862] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:14,877] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:35:14,884] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:14,886] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:35:22,605] {scheduler_job.py:154} INFO - Started process (PID=63480) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:22,623] {logging_mixin.py:112} INFO - [2020-08-01 15:35:22,623] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:22,624] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:35:22,624] {logging_mixin.py:112} INFO - [2020-08-01 15:35:22,624] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:22,626] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:22,640] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:35:22,649] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:22,651] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:35:30,727] {scheduler_job.py:154} INFO - Started process (PID=63504) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:30,747] {logging_mixin.py:112} INFO - [2020-08-01 15:35:30,747] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:30,748] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:35:30,748] {logging_mixin.py:112} INFO - [2020-08-01 15:35:30,748] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:30,750] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:30,764] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:35:30,770] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:30,772] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:35:38,704] {scheduler_job.py:154} INFO - Started process (PID=63536) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:38,722] {logging_mixin.py:112} INFO - [2020-08-01 15:35:38,721] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:38,722] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:35:38,722] {logging_mixin.py:112} INFO - [2020-08-01 15:35:38,722] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:38,724] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:38,741] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:35:38,749] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:38,751] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:35:46,704] {scheduler_job.py:154} INFO - Started process (PID=63578) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:46,722] {logging_mixin.py:112} INFO - [2020-08-01 15:35:46,722] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:46,722] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:35:46,723] {logging_mixin.py:112} INFO - [2020-08-01 15:35:46,723] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:46,725] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:46,739] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:35:46,747] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:46,749] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:35:54,772] {scheduler_job.py:154} INFO - Started process (PID=63594) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:54,791] {logging_mixin.py:112} INFO - [2020-08-01 15:35:54,791] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:54,792] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:35:54,792] {logging_mixin.py:112} INFO - [2020-08-01 15:35:54,792] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:54,794] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:35:54,810] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:35:54,819] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:54,821] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:36:02,750] {scheduler_job.py:154} INFO - Started process (PID=63619) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:02,769] {logging_mixin.py:112} INFO - [2020-08-01 15:36:02,769] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:02,769] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:36:02,770] {logging_mixin.py:112} INFO - [2020-08-01 15:36:02,769] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:02,772] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:02,786] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:36:02,794] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:02,795] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:36:10,792] {scheduler_job.py:154} INFO - Started process (PID=63635) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:10,810] {logging_mixin.py:112} INFO - [2020-08-01 15:36:10,810] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:10,811] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:36:10,811] {logging_mixin.py:112} INFO - [2020-08-01 15:36:10,811] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:10,813] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:10,827] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:36:10,834] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:10,835] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:36:18,802] {scheduler_job.py:154} INFO - Started process (PID=63660) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:18,819] {logging_mixin.py:112} INFO - [2020-08-01 15:36:18,819] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:18,820] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:36:18,820] {logging_mixin.py:112} INFO - [2020-08-01 15:36:18,820] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:18,822] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:18,836] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:36:18,843] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:18,845] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:36:26,833] {scheduler_job.py:154} INFO - Started process (PID=63684) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:26,850] {logging_mixin.py:112} INFO - [2020-08-01 15:36:26,850] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:26,851] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:36:26,851] {logging_mixin.py:112} INFO - [2020-08-01 15:36:26,851] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:26,853] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:26,867] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:36:26,875] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:26,876] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:36:34,864] {scheduler_job.py:154} INFO - Started process (PID=63700) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:34,882] {logging_mixin.py:112} INFO - [2020-08-01 15:36:34,881] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:34,882] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:36:34,882] {logging_mixin.py:112} INFO - [2020-08-01 15:36:34,882] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:34,884] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:34,899] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:36:34,906] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:34,908] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:36:42,903] {scheduler_job.py:154} INFO - Started process (PID=63724) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:42,920] {logging_mixin.py:112} INFO - [2020-08-01 15:36:42,920] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:42,921] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:36:42,921] {logging_mixin.py:112} INFO - [2020-08-01 15:36:42,921] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:42,923] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:42,937] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:36:42,944] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:42,946] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:36:50,927] {scheduler_job.py:154} INFO - Started process (PID=63742) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:50,945] {logging_mixin.py:112} INFO - [2020-08-01 15:36:50,944] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:50,945] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:36:50,945] {logging_mixin.py:112} INFO - [2020-08-01 15:36:50,945] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:50,948] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:50,962] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:36:50,969] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:50,970] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:36:58,964] {scheduler_job.py:154} INFO - Started process (PID=63766) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:58,982] {logging_mixin.py:112} INFO - [2020-08-01 15:36:58,981] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:58,982] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:36:58,982] {logging_mixin.py:112} INFO - [2020-08-01 15:36:58,982] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:58,984] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:36:58,999] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:36:59,006] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:59,008] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:37:07,016] {scheduler_job.py:154} INFO - Started process (PID=63782) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:07,033] {logging_mixin.py:112} INFO - [2020-08-01 15:37:07,033] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:07,034] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:37:07,034] {logging_mixin.py:112} INFO - [2020-08-01 15:37:07,034] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:07,036] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:07,050] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:37:07,058] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:07,059] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:37:15,022] {scheduler_job.py:154} INFO - Started process (PID=63806) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:15,040] {logging_mixin.py:112} INFO - [2020-08-01 15:37:15,039] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:15,040] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:37:15,040] {logging_mixin.py:112} INFO - [2020-08-01 15:37:15,040] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:15,042] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:15,057] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:37:15,064] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:15,065] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:37:23,046] {scheduler_job.py:154} INFO - Started process (PID=63831) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:23,063] {logging_mixin.py:112} INFO - [2020-08-01 15:37:23,063] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:23,064] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:37:23,064] {logging_mixin.py:112} INFO - [2020-08-01 15:37:23,064] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:23,066] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:23,080] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:37:23,087] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:23,089] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:37:31,076] {scheduler_job.py:154} INFO - Started process (PID=63847) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:31,094] {logging_mixin.py:112} INFO - [2020-08-01 15:37:31,094] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:31,094] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:37:31,094] {logging_mixin.py:112} INFO - [2020-08-01 15:37:31,094] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:31,097] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:31,111] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:37:31,118] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:31,120] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:37:39,101] {scheduler_job.py:154} INFO - Started process (PID=63871) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:39,119] {logging_mixin.py:112} INFO - [2020-08-01 15:37:39,119] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:39,120] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:37:39,120] {logging_mixin.py:112} INFO - [2020-08-01 15:37:39,120] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:39,122] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:39,136] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:37:39,145] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:39,147] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:37:47,169] {scheduler_job.py:154} INFO - Started process (PID=63888) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:47,190] {logging_mixin.py:112} INFO - [2020-08-01 15:37:47,190] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:47,191] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:37:47,192] {logging_mixin.py:112} INFO - [2020-08-01 15:37:47,192] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:47,194] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:47,209] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:37:47,216] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:47,217] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:37:55,151] {scheduler_job.py:154} INFO - Started process (PID=63913) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:55,168] {logging_mixin.py:112} INFO - [2020-08-01 15:37:55,168] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:55,169] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:37:55,169] {logging_mixin.py:112} INFO - [2020-08-01 15:37:55,169] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:55,171] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:37:55,185] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:37:55,193] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:55,194] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:38:03,231] {scheduler_job.py:154} INFO - Started process (PID=63930) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:03,250] {logging_mixin.py:112} INFO - [2020-08-01 15:38:03,250] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:03,250] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:38:03,250] {logging_mixin.py:112} INFO - [2020-08-01 15:38:03,250] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:03,252] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:03,266] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:38:03,273] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:03,274] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:38:11,241] {scheduler_job.py:154} INFO - Started process (PID=63954) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:11,261] {logging_mixin.py:112} INFO - [2020-08-01 15:38:11,261] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:11,262] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:38:11,262] {logging_mixin.py:112} INFO - [2020-08-01 15:38:11,262] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:11,264] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:11,277] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:38:11,283] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:11,285] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:38:19,346] {scheduler_job.py:154} INFO - Started process (PID=63980) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:19,364] {logging_mixin.py:112} INFO - [2020-08-01 15:38:19,364] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:19,365] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:38:19,365] {logging_mixin.py:112} INFO - [2020-08-01 15:38:19,365] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:19,367] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:19,381] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:38:19,388] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:19,389] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:38:27,336] {scheduler_job.py:154} INFO - Started process (PID=63996) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:27,355] {logging_mixin.py:112} INFO - [2020-08-01 15:38:27,355] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:27,355] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:38:27,356] {logging_mixin.py:112} INFO - [2020-08-01 15:38:27,355] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:27,358] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:27,372] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:38:27,379] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:27,381] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:38:35,365] {scheduler_job.py:154} INFO - Started process (PID=64021) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:35,382] {logging_mixin.py:112} INFO - [2020-08-01 15:38:35,382] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:35,383] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:38:35,383] {logging_mixin.py:112} INFO - [2020-08-01 15:38:35,383] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:35,385] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:35,400] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:38:35,407] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:35,408] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:38:43,455] {scheduler_job.py:154} INFO - Started process (PID=64037) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:43,479] {logging_mixin.py:112} INFO - [2020-08-01 15:38:43,478] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:43,479] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:38:43,479] {logging_mixin.py:112} INFO - [2020-08-01 15:38:43,479] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:43,481] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:43,496] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:38:43,503] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:43,505] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.050 seconds
[2020-08-01 15:38:51,368] {scheduler_job.py:154} INFO - Started process (PID=64063) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:51,385] {logging_mixin.py:112} INFO - [2020-08-01 15:38:51,385] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:51,386] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:38:51,386] {logging_mixin.py:112} INFO - [2020-08-01 15:38:51,386] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:51,388] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:51,401] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:38:51,408] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:51,410] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:38:59,401] {scheduler_job.py:154} INFO - Started process (PID=64080) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:59,419] {logging_mixin.py:112} INFO - [2020-08-01 15:38:59,419] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:59,420] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:38:59,420] {logging_mixin.py:112} INFO - [2020-08-01 15:38:59,420] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:59,422] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:38:59,437] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:38:59,445] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:59,446] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:39:07,426] {scheduler_job.py:154} INFO - Started process (PID=64104) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:07,442] {logging_mixin.py:112} INFO - [2020-08-01 15:39:07,442] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:07,443] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:39:07,443] {logging_mixin.py:112} INFO - [2020-08-01 15:39:07,443] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:07,445] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:07,462] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:39:07,468] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:07,469] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:39:15,438] {scheduler_job.py:154} INFO - Started process (PID=64146) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:15,456] {logging_mixin.py:112} INFO - [2020-08-01 15:39:15,456] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:15,457] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:39:15,457] {logging_mixin.py:112} INFO - [2020-08-01 15:39:15,457] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:15,459] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:15,475] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:39:15,482] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:15,483] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:39:23,457] {scheduler_job.py:154} INFO - Started process (PID=64163) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:23,475] {logging_mixin.py:112} INFO - [2020-08-01 15:39:23,475] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:23,476] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:39:23,476] {logging_mixin.py:112} INFO - [2020-08-01 15:39:23,476] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:23,478] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:23,492] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:39:23,499] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:23,501] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:39:31,429] {scheduler_job.py:154} INFO - Started process (PID=64188) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:31,446] {logging_mixin.py:112} INFO - [2020-08-01 15:39:31,446] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:31,447] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:39:31,447] {logging_mixin.py:112} INFO - [2020-08-01 15:39:31,447] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:31,449] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:31,463] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:39:31,470] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:31,472] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:39:39,536] {scheduler_job.py:154} INFO - Started process (PID=64204) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:39,555] {logging_mixin.py:112} INFO - [2020-08-01 15:39:39,555] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:39,555] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:39:39,556] {logging_mixin.py:112} INFO - [2020-08-01 15:39:39,555] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:39,558] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:39,573] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:39:39,579] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:39,581] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:39:47,496] {scheduler_job.py:154} INFO - Started process (PID=64229) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:47,513] {logging_mixin.py:112} INFO - [2020-08-01 15:39:47,513] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:47,514] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:39:47,514] {logging_mixin.py:112} INFO - [2020-08-01 15:39:47,514] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:47,516] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:47,530] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:39:47,537] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:47,539] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:39:55,552] {scheduler_job.py:154} INFO - Started process (PID=64246) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:55,570] {logging_mixin.py:112} INFO - [2020-08-01 15:39:55,569] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:55,570] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:39:55,570] {logging_mixin.py:112} INFO - [2020-08-01 15:39:55,570] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:55,572] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:39:55,586] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:39:55,593] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:55,595] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:40:03,572] {scheduler_job.py:154} INFO - Started process (PID=64274) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:03,590] {logging_mixin.py:112} INFO - [2020-08-01 15:40:03,589] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:03,590] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:40:03,590] {logging_mixin.py:112} INFO - [2020-08-01 15:40:03,590] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:03,592] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:03,606] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:40:03,612] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:03,614] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:40:11,574] {scheduler_job.py:154} INFO - Started process (PID=64298) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:11,592] {logging_mixin.py:112} INFO - [2020-08-01 15:40:11,591] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:11,592] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:40:11,592] {logging_mixin.py:112} INFO - [2020-08-01 15:40:11,592] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:11,594] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:11,609] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:40:11,616] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:11,617] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:40:19,617] {scheduler_job.py:154} INFO - Started process (PID=64315) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:19,636] {logging_mixin.py:112} INFO - [2020-08-01 15:40:19,636] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:19,637] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:40:19,637] {logging_mixin.py:112} INFO - [2020-08-01 15:40:19,637] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:19,639] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:19,652] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:40:19,659] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:19,660] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:40:27,636] {scheduler_job.py:154} INFO - Started process (PID=64340) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:27,653] {logging_mixin.py:112} INFO - [2020-08-01 15:40:27,653] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:27,654] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:40:27,654] {logging_mixin.py:112} INFO - [2020-08-01 15:40:27,654] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:27,656] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:27,671] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:40:27,678] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:27,680] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:40:35,688] {scheduler_job.py:154} INFO - Started process (PID=64356) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:35,706] {logging_mixin.py:112} INFO - [2020-08-01 15:40:35,705] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:35,706] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:40:35,706] {logging_mixin.py:112} INFO - [2020-08-01 15:40:35,706] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:35,709] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:35,723] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:40:35,730] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:35,731] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:40:43,678] {scheduler_job.py:154} INFO - Started process (PID=64380) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:43,696] {logging_mixin.py:112} INFO - [2020-08-01 15:40:43,696] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:43,696] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:40:43,696] {logging_mixin.py:112} INFO - [2020-08-01 15:40:43,696] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:43,699] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:43,713] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:40:43,720] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:43,721] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:40:51,786] {scheduler_job.py:154} INFO - Started process (PID=64396) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:51,804] {logging_mixin.py:112} INFO - [2020-08-01 15:40:51,804] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:51,805] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:40:51,805] {logging_mixin.py:112} INFO - [2020-08-01 15:40:51,805] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:51,807] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:51,820] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:40:51,827] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:51,828] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:40:59,723] {scheduler_job.py:154} INFO - Started process (PID=64421) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:59,744] {logging_mixin.py:112} INFO - [2020-08-01 15:40:59,744] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:59,744] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:40:59,745] {logging_mixin.py:112} INFO - [2020-08-01 15:40:59,744] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:59,747] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:40:59,762] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:40:59,769] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:59,770] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:41:07,771] {scheduler_job.py:154} INFO - Started process (PID=64437) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:07,789] {logging_mixin.py:112} INFO - [2020-08-01 15:41:07,789] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:07,790] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:41:07,790] {logging_mixin.py:112} INFO - [2020-08-01 15:41:07,790] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:07,792] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:07,806] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:41:07,813] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:07,815] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:41:15,846] {scheduler_job.py:154} INFO - Started process (PID=64445) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:15,865] {logging_mixin.py:112} INFO - [2020-08-01 15:41:15,864] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:15,865] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:41:15,865] {logging_mixin.py:112} INFO - [2020-08-01 15:41:15,865] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:15,867] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:15,882] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:41:15,889] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:15,890] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:41:23,837] {scheduler_job.py:154} INFO - Started process (PID=64454) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:23,856] {logging_mixin.py:112} INFO - [2020-08-01 15:41:23,856] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:23,856] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:41:23,857] {logging_mixin.py:112} INFO - [2020-08-01 15:41:23,857] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:23,859] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:23,874] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:41:23,882] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:23,884] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:41:31,885] {scheduler_job.py:154} INFO - Started process (PID=64463) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:31,902] {logging_mixin.py:112} INFO - [2020-08-01 15:41:31,902] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:31,903] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:41:31,903] {logging_mixin.py:112} INFO - [2020-08-01 15:41:31,903] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:31,905] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:31,918] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:41:31,925] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:31,926] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:41:39,871] {scheduler_job.py:154} INFO - Started process (PID=64482) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:39,889] {logging_mixin.py:112} INFO - [2020-08-01 15:41:39,889] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:39,889] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:41:39,890] {logging_mixin.py:112} INFO - [2020-08-01 15:41:39,889] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:39,892] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:39,906] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:41:39,914] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:39,916] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:41:48,245] {scheduler_job.py:154} INFO - Started process (PID=64498) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:48,264] {logging_mixin.py:112} INFO - [2020-08-01 15:41:48,264] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:48,265] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:41:48,265] {logging_mixin.py:112} INFO - [2020-08-01 15:41:48,265] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:48,267] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:48,279] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:41:48,285] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:48,287] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:41:56,128] {scheduler_job.py:154} INFO - Started process (PID=64544) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:56,151] {logging_mixin.py:112} INFO - [2020-08-01 15:41:56,151] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:56,151] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:41:56,152] {logging_mixin.py:112} INFO - [2020-08-01 15:41:56,152] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:56,154] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:41:56,176] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:41:56,186] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:56,189] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.062 seconds
[2020-08-01 15:42:03,936] {scheduler_job.py:154} INFO - Started process (PID=64585) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:03,953] {logging_mixin.py:112} INFO - [2020-08-01 15:42:03,953] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:03,954] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:42:03,954] {logging_mixin.py:112} INFO - [2020-08-01 15:42:03,954] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:03,956] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:03,970] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:42:03,978] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:03,979] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:42:12,066] {scheduler_job.py:154} INFO - Started process (PID=64601) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:12,083] {logging_mixin.py:112} INFO - [2020-08-01 15:42:12,083] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:12,084] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:42:12,084] {logging_mixin.py:112} INFO - [2020-08-01 15:42:12,084] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:12,086] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:12,099] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:42:12,107] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:12,108] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:42:19,976] {scheduler_job.py:154} INFO - Started process (PID=64626) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:19,994] {logging_mixin.py:112} INFO - [2020-08-01 15:42:19,994] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:19,995] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:42:19,995] {logging_mixin.py:112} INFO - [2020-08-01 15:42:19,995] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:19,997] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:20,011] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:42:20,018] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:20,019] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:42:28,079] {scheduler_job.py:154} INFO - Started process (PID=64677) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:28,097] {logging_mixin.py:112} INFO - [2020-08-01 15:42:28,097] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:28,098] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:42:28,098] {logging_mixin.py:112} INFO - [2020-08-01 15:42:28,098] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:28,100] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:28,114] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:42:28,121] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:28,123] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:42:36,099] {scheduler_job.py:154} INFO - Started process (PID=64719) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:36,116] {logging_mixin.py:112} INFO - [2020-08-01 15:42:36,116] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:36,116] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:42:36,116] {logging_mixin.py:112} INFO - [2020-08-01 15:42:36,116] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:36,118] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:36,132] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:42:36,139] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:36,141] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:42:44,094] {scheduler_job.py:154} INFO - Started process (PID=64727) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:44,113] {logging_mixin.py:112} INFO - [2020-08-01 15:42:44,113] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:44,114] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:42:44,114] {logging_mixin.py:112} INFO - [2020-08-01 15:42:44,114] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:44,116] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:44,130] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:42:44,139] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:44,142] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:42:52,129] {scheduler_job.py:154} INFO - Started process (PID=64735) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:52,147] {logging_mixin.py:112} INFO - [2020-08-01 15:42:52,147] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:52,148] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:42:52,148] {logging_mixin.py:112} INFO - [2020-08-01 15:42:52,148] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:52,151] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:42:52,167] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:42:52,174] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:52,175] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:43:00,130] {scheduler_job.py:154} INFO - Started process (PID=64744) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:00,148] {logging_mixin.py:112} INFO - [2020-08-01 15:43:00,147] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:00,148] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:43:00,148] {logging_mixin.py:112} INFO - [2020-08-01 15:43:00,148] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:00,150] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:00,164] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:43:00,171] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:00,172] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:43:08,123] {scheduler_job.py:154} INFO - Started process (PID=64768) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:08,142] {logging_mixin.py:112} INFO - [2020-08-01 15:43:08,142] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:08,142] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:43:08,143] {logging_mixin.py:112} INFO - [2020-08-01 15:43:08,142] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:08,145] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:08,160] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:43:08,166] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:08,168] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:43:16,235] {scheduler_job.py:154} INFO - Started process (PID=64785) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:16,252] {logging_mixin.py:112} INFO - [2020-08-01 15:43:16,252] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:16,253] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:43:16,253] {logging_mixin.py:112} INFO - [2020-08-01 15:43:16,253] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:16,255] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:16,269] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:43:16,276] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:16,277] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:43:24,160] {scheduler_job.py:154} INFO - Started process (PID=64803) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:24,178] {logging_mixin.py:112} INFO - [2020-08-01 15:43:24,178] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:24,178] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:43:24,179] {logging_mixin.py:112} INFO - [2020-08-01 15:43:24,179] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:24,181] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:24,195] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:43:24,202] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:24,204] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:43:32,163] {scheduler_job.py:154} INFO - Started process (PID=64813) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:32,181] {logging_mixin.py:112} INFO - [2020-08-01 15:43:32,181] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:32,182] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:43:32,182] {logging_mixin.py:112} INFO - [2020-08-01 15:43:32,182] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:32,184] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:32,198] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:43:32,205] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:32,207] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:43:40,196] {scheduler_job.py:154} INFO - Started process (PID=64822) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:40,214] {logging_mixin.py:112} INFO - [2020-08-01 15:43:40,214] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:40,214] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:43:40,215] {logging_mixin.py:112} INFO - [2020-08-01 15:43:40,215] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:40,217] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:40,231] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:43:40,239] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:40,240] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:43:48,254] {scheduler_job.py:154} INFO - Started process (PID=64830) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:48,272] {logging_mixin.py:112} INFO - [2020-08-01 15:43:48,272] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:48,273] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:43:48,273] {logging_mixin.py:112} INFO - [2020-08-01 15:43:48,273] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:48,275] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:48,288] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:43:48,296] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:48,297] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:43:56,352] {scheduler_job.py:154} INFO - Started process (PID=64840) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:56,370] {logging_mixin.py:112} INFO - [2020-08-01 15:43:56,370] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:56,371] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:43:56,371] {logging_mixin.py:112} INFO - [2020-08-01 15:43:56,371] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:56,374] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:43:56,389] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:43:56,397] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:56,400] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:44:04,271] {scheduler_job.py:154} INFO - Started process (PID=64851) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:04,289] {logging_mixin.py:112} INFO - [2020-08-01 15:44:04,289] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:04,290] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:44:04,290] {logging_mixin.py:112} INFO - [2020-08-01 15:44:04,290] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:04,292] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:04,306] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:44:04,314] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:04,316] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:44:12,313] {scheduler_job.py:154} INFO - Started process (PID=64859) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:12,330] {logging_mixin.py:112} INFO - [2020-08-01 15:44:12,330] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:12,331] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:44:12,331] {logging_mixin.py:112} INFO - [2020-08-01 15:44:12,331] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:12,333] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:12,347] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:44:12,353] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:12,355] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:44:20,434] {scheduler_job.py:154} INFO - Started process (PID=64868) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:20,453] {logging_mixin.py:112} INFO - [2020-08-01 15:44:20,453] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:20,454] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:44:20,454] {logging_mixin.py:112} INFO - [2020-08-01 15:44:20,454] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:20,456] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:20,472] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:44:20,480] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:20,482] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:44:28,396] {scheduler_job.py:154} INFO - Started process (PID=64894) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:28,415] {logging_mixin.py:112} INFO - [2020-08-01 15:44:28,415] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:28,415] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:44:28,416] {logging_mixin.py:112} INFO - [2020-08-01 15:44:28,416] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:28,418] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:28,433] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:44:28,441] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:28,442] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:44:36,431] {scheduler_job.py:154} INFO - Started process (PID=64962) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:36,449] {logging_mixin.py:112} INFO - [2020-08-01 15:44:36,449] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:36,449] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:44:36,449] {logging_mixin.py:112} INFO - [2020-08-01 15:44:36,449] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:36,451] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:36,466] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:44:36,473] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:36,475] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:44:44,458] {scheduler_job.py:154} INFO - Started process (PID=64979) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:44,477] {logging_mixin.py:112} INFO - [2020-08-01 15:44:44,477] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:44,478] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:44:44,478] {logging_mixin.py:112} INFO - [2020-08-01 15:44:44,478] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:44,480] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:44,495] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:44:44,502] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:44,503] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:44:52,403] {scheduler_job.py:154} INFO - Started process (PID=64987) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:52,421] {logging_mixin.py:112} INFO - [2020-08-01 15:44:52,421] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:52,422] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:44:52,422] {logging_mixin.py:112} INFO - [2020-08-01 15:44:52,422] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:52,424] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:44:52,438] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:44:52,446] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:52,447] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:45:00,436] {scheduler_job.py:154} INFO - Started process (PID=64996) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:00,455] {logging_mixin.py:112} INFO - [2020-08-01 15:45:00,454] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:00,455] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:45:00,455] {logging_mixin.py:112} INFO - [2020-08-01 15:45:00,455] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:00,458] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:00,473] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:45:00,483] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:00,485] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:45:08,477] {scheduler_job.py:154} INFO - Started process (PID=65020) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:08,495] {logging_mixin.py:112} INFO - [2020-08-01 15:45:08,495] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:08,496] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:45:08,496] {logging_mixin.py:112} INFO - [2020-08-01 15:45:08,496] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:08,498] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:08,512] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:45:08,521] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:08,523] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:45:16,551] {scheduler_job.py:154} INFO - Started process (PID=65055) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:16,572] {logging_mixin.py:112} INFO - [2020-08-01 15:45:16,571] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:16,572] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:45:16,572] {logging_mixin.py:112} INFO - [2020-08-01 15:45:16,572] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:16,574] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:16,589] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:45:16,596] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:16,598] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:45:24,517] {scheduler_job.py:154} INFO - Started process (PID=65063) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:24,535] {logging_mixin.py:112} INFO - [2020-08-01 15:45:24,535] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:24,536] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:45:24,536] {logging_mixin.py:112} INFO - [2020-08-01 15:45:24,536] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:24,538] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:24,552] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:45:24,560] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:24,561] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:45:32,514] {scheduler_job.py:154} INFO - Started process (PID=65076) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:32,533] {logging_mixin.py:112} INFO - [2020-08-01 15:45:32,532] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:32,533] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:45:32,533] {logging_mixin.py:112} INFO - [2020-08-01 15:45:32,533] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:32,535] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:32,549] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:45:32,557] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:32,558] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:45:40,589] {scheduler_job.py:154} INFO - Started process (PID=65085) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:40,616] {logging_mixin.py:112} INFO - [2020-08-01 15:45:40,616] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:40,616] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:45:40,616] {logging_mixin.py:112} INFO - [2020-08-01 15:45:40,616] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:40,619] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:40,631] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:45:40,638] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:40,640] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.051 seconds
[2020-08-01 15:45:48,603] {scheduler_job.py:154} INFO - Started process (PID=65128) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:48,623] {logging_mixin.py:112} INFO - [2020-08-01 15:45:48,623] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:48,623] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:45:48,623] {logging_mixin.py:112} INFO - [2020-08-01 15:45:48,623] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:48,625] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:48,639] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:45:48,646] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:48,648] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:45:56,583] {scheduler_job.py:154} INFO - Started process (PID=65161) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:56,603] {logging_mixin.py:112} INFO - [2020-08-01 15:45:56,603] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:56,604] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:45:56,604] {logging_mixin.py:112} INFO - [2020-08-01 15:45:56,604] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:56,606] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:45:56,622] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:45:56,630] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:56,632] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:46:04,646] {scheduler_job.py:154} INFO - Started process (PID=65204) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:04,665] {logging_mixin.py:112} INFO - [2020-08-01 15:46:04,665] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:04,666] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:46:04,666] {logging_mixin.py:112} INFO - [2020-08-01 15:46:04,666] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:04,668] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:04,684] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:46:04,691] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:04,693] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:46:12,865] {scheduler_job.py:154} INFO - Started process (PID=65257) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:12,884] {logging_mixin.py:112} INFO - [2020-08-01 15:46:12,884] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:12,885] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:46:12,885] {logging_mixin.py:112} INFO - [2020-08-01 15:46:12,885] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:12,887] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:12,903] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:46:12,911] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:12,912] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:46:20,683] {scheduler_job.py:154} INFO - Started process (PID=65298) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:20,701] {logging_mixin.py:112} INFO - [2020-08-01 15:46:20,701] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:20,702] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:46:20,702] {logging_mixin.py:112} INFO - [2020-08-01 15:46:20,702] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:20,705] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:20,723] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:46:20,730] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:20,731] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:46:28,736] {scheduler_job.py:154} INFO - Started process (PID=65314) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:28,754] {logging_mixin.py:112} INFO - [2020-08-01 15:46:28,754] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:28,754] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:46:28,754] {logging_mixin.py:112} INFO - [2020-08-01 15:46:28,754] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:28,756] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:28,770] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:46:28,778] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:28,779] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:46:36,772] {scheduler_job.py:154} INFO - Started process (PID=65357) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:36,793] {logging_mixin.py:112} INFO - [2020-08-01 15:46:36,793] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:36,794] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:46:36,794] {logging_mixin.py:112} INFO - [2020-08-01 15:46:36,794] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:36,797] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:36,814] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:46:36,821] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:36,823] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.051 seconds
[2020-08-01 15:46:44,745] {scheduler_job.py:154} INFO - Started process (PID=65410) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:44,763] {logging_mixin.py:112} INFO - [2020-08-01 15:46:44,763] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:44,764] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:46:44,764] {logging_mixin.py:112} INFO - [2020-08-01 15:46:44,764] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:44,766] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:44,780] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:46:44,786] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:44,788] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:46:52,864] {scheduler_job.py:154} INFO - Started process (PID=65420) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:52,881] {logging_mixin.py:112} INFO - [2020-08-01 15:46:52,881] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:52,882] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:46:52,882] {logging_mixin.py:112} INFO - [2020-08-01 15:46:52,882] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:52,884] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:46:52,898] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:46:52,905] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:52,907] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:47:00,848] {scheduler_job.py:154} INFO - Started process (PID=65429) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:00,871] {logging_mixin.py:112} INFO - [2020-08-01 15:47:00,870] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:00,872] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:47:00,872] {logging_mixin.py:112} INFO - [2020-08-01 15:47:00,872] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:00,875] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:00,898] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:47:00,910] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:00,912] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.064 seconds
[2020-08-01 15:47:08,792] {scheduler_job.py:154} INFO - Started process (PID=65437) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:08,810] {logging_mixin.py:112} INFO - [2020-08-01 15:47:08,810] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:08,810] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:47:08,811] {logging_mixin.py:112} INFO - [2020-08-01 15:47:08,811] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:08,813] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:08,828] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:47:08,835] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:08,837] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:47:16,821] {scheduler_job.py:154} INFO - Started process (PID=65445) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:16,839] {logging_mixin.py:112} INFO - [2020-08-01 15:47:16,838] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:16,839] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:47:16,839] {logging_mixin.py:112} INFO - [2020-08-01 15:47:16,839] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:16,841] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:16,855] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:47:16,861] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:16,863] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:47:25,159] {scheduler_job.py:154} INFO - Started process (PID=65461) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:25,182] {logging_mixin.py:112} INFO - [2020-08-01 15:47:25,182] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:25,183] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:47:25,183] {logging_mixin.py:112} INFO - [2020-08-01 15:47:25,183] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:25,185] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:25,202] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:47:25,211] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:25,214] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.055 seconds
[2020-08-01 15:47:32,848] {scheduler_job.py:154} INFO - Started process (PID=65473) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:32,869] {logging_mixin.py:112} INFO - [2020-08-01 15:47:32,869] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:32,870] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:47:32,870] {logging_mixin.py:112} INFO - [2020-08-01 15:47:32,870] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:32,873] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:32,890] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:47:32,899] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:32,901] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.053 seconds
[2020-08-01 15:47:41,031] {scheduler_job.py:154} INFO - Started process (PID=65483) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:41,049] {logging_mixin.py:112} INFO - [2020-08-01 15:47:41,048] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:41,049] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:47:41,049] {logging_mixin.py:112} INFO - [2020-08-01 15:47:41,049] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:41,051] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:41,065] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:47:41,073] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:41,074] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:47:48,888] {scheduler_job.py:154} INFO - Started process (PID=65491) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:48,906] {logging_mixin.py:112} INFO - [2020-08-01 15:47:48,906] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:48,907] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:47:48,907] {logging_mixin.py:112} INFO - [2020-08-01 15:47:48,907] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:48,909] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:48,924] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:47:48,932] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:48,933] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:47:56,994] {scheduler_job.py:154} INFO - Started process (PID=65499) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:57,012] {logging_mixin.py:112} INFO - [2020-08-01 15:47:57,012] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:57,012] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:47:57,012] {logging_mixin.py:112} INFO - [2020-08-01 15:47:57,012] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:57,014] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:47:57,031] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:47:57,041] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:57,044] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.050 seconds
[2020-08-01 15:48:04,991] {scheduler_job.py:154} INFO - Started process (PID=65508) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:05,009] {logging_mixin.py:112} INFO - [2020-08-01 15:48:05,009] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:05,009] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:48:05,009] {logging_mixin.py:112} INFO - [2020-08-01 15:48:05,009] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:05,011] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:05,025] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:48:05,032] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:05,034] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:48:12,992] {scheduler_job.py:154} INFO - Started process (PID=65516) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:13,010] {logging_mixin.py:112} INFO - [2020-08-01 15:48:13,010] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:13,010] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:48:13,011] {logging_mixin.py:112} INFO - [2020-08-01 15:48:13,011] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:13,013] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:13,028] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:48:13,036] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:13,037] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:48:21,093] {scheduler_job.py:154} INFO - Started process (PID=65524) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:21,114] {logging_mixin.py:112} INFO - [2020-08-01 15:48:21,114] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:21,115] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:48:21,115] {logging_mixin.py:112} INFO - [2020-08-01 15:48:21,115] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:21,117] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:21,136] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:48:21,144] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:21,148] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.055 seconds
[2020-08-01 15:48:29,089] {scheduler_job.py:154} INFO - Started process (PID=65532) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:29,106] {logging_mixin.py:112} INFO - [2020-08-01 15:48:29,106] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:29,107] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:48:29,107] {logging_mixin.py:112} INFO - [2020-08-01 15:48:29,107] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:29,109] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:29,122] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:48:29,129] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:29,130] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:48:37,091] {scheduler_job.py:154} INFO - Started process (PID=65541) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:37,108] {logging_mixin.py:112} INFO - [2020-08-01 15:48:37,108] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:37,109] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:48:37,109] {logging_mixin.py:112} INFO - [2020-08-01 15:48:37,109] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:37,111] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:37,125] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:48:37,131] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:37,133] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:48:45,128] {scheduler_job.py:154} INFO - Started process (PID=65549) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:45,146] {logging_mixin.py:112} INFO - [2020-08-01 15:48:45,146] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:45,146] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:48:45,146] {logging_mixin.py:112} INFO - [2020-08-01 15:48:45,146] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:45,148] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:45,164] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:48:45,172] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:45,174] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:48:53,166] {scheduler_job.py:154} INFO - Started process (PID=65557) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:53,183] {logging_mixin.py:112} INFO - [2020-08-01 15:48:53,183] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:53,183] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:48:53,184] {logging_mixin.py:112} INFO - [2020-08-01 15:48:53,184] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:53,186] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:48:53,199] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:48:53,207] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:53,208] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:49:01,080] {scheduler_job.py:154} INFO - Started process (PID=65565) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:01,098] {logging_mixin.py:112} INFO - [2020-08-01 15:49:01,097] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:01,098] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:49:01,098] {logging_mixin.py:112} INFO - [2020-08-01 15:49:01,098] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:01,100] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:01,115] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:49:01,123] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:01,124] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:49:09,117] {scheduler_job.py:154} INFO - Started process (PID=65574) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:09,135] {logging_mixin.py:112} INFO - [2020-08-01 15:49:09,135] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:09,136] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:49:09,136] {logging_mixin.py:112} INFO - [2020-08-01 15:49:09,136] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:09,138] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:09,152] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:49:09,160] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:09,161] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:49:17,382] {scheduler_job.py:154} INFO - Started process (PID=65582) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:17,399] {logging_mixin.py:112} INFO - [2020-08-01 15:49:17,399] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:17,399] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:49:17,400] {logging_mixin.py:112} INFO - [2020-08-01 15:49:17,399] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:17,401] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:17,415] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:49:17,422] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:17,424] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:49:25,200] {scheduler_job.py:154} INFO - Started process (PID=65590) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:25,219] {logging_mixin.py:112} INFO - [2020-08-01 15:49:25,219] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:25,220] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:49:25,220] {logging_mixin.py:112} INFO - [2020-08-01 15:49:25,220] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:25,222] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:25,237] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:49:25,246] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:25,248] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:49:33,246] {scheduler_job.py:154} INFO - Started process (PID=65607) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:33,264] {logging_mixin.py:112} INFO - [2020-08-01 15:49:33,264] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:33,265] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:49:33,265] {logging_mixin.py:112} INFO - [2020-08-01 15:49:33,265] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:33,268] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:33,283] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:49:33,292] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:33,295] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:49:41,290] {scheduler_job.py:154} INFO - Started process (PID=65624) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:41,308] {logging_mixin.py:112} INFO - [2020-08-01 15:49:41,308] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:41,309] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:49:41,309] {logging_mixin.py:112} INFO - [2020-08-01 15:49:41,309] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:41,311] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:41,326] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:49:41,334] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:41,336] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:49:49,345] {scheduler_job.py:154} INFO - Started process (PID=65648) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:49,364] {logging_mixin.py:112} INFO - [2020-08-01 15:49:49,364] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:49,365] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:49:49,365] {logging_mixin.py:112} INFO - [2020-08-01 15:49:49,365] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:49,367] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:49,382] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:49:49,390] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:49,391] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:49:57,253] {scheduler_job.py:154} INFO - Started process (PID=65672) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:57,271] {logging_mixin.py:112} INFO - [2020-08-01 15:49:57,271] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:57,271] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:49:57,272] {logging_mixin.py:112} INFO - [2020-08-01 15:49:57,272] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:57,274] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:49:57,288] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:49:57,295] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:57,297] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:50:05,278] {scheduler_job.py:154} INFO - Started process (PID=65689) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:05,296] {logging_mixin.py:112} INFO - [2020-08-01 15:50:05,296] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:05,297] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:50:05,297] {logging_mixin.py:112} INFO - [2020-08-01 15:50:05,297] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:05,299] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:05,313] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:50:05,321] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:05,323] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:50:13,281] {scheduler_job.py:154} INFO - Started process (PID=65713) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:13,298] {logging_mixin.py:112} INFO - [2020-08-01 15:50:13,298] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:13,299] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:50:13,299] {logging_mixin.py:112} INFO - [2020-08-01 15:50:13,299] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:13,301] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:13,316] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:50:13,323] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:13,324] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:50:21,319] {scheduler_job.py:154} INFO - Started process (PID=65729) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:21,339] {logging_mixin.py:112} INFO - [2020-08-01 15:50:21,339] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:21,340] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:50:21,340] {logging_mixin.py:112} INFO - [2020-08-01 15:50:21,340] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:21,342] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:21,358] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:50:21,365] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:21,366] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:50:29,353] {scheduler_job.py:154} INFO - Started process (PID=65753) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:29,372] {logging_mixin.py:112} INFO - [2020-08-01 15:50:29,372] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:29,372] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:50:29,372] {logging_mixin.py:112} INFO - [2020-08-01 15:50:29,372] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:29,375] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:29,389] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:50:29,396] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:29,397] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:50:37,405] {scheduler_job.py:154} INFO - Started process (PID=65770) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:37,423] {logging_mixin.py:112} INFO - [2020-08-01 15:50:37,423] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:37,424] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:50:37,424] {logging_mixin.py:112} INFO - [2020-08-01 15:50:37,424] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:37,426] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:37,440] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:50:37,448] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:37,450] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:50:45,406] {scheduler_job.py:154} INFO - Started process (PID=65794) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:45,423] {logging_mixin.py:112} INFO - [2020-08-01 15:50:45,423] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:45,424] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:50:45,424] {logging_mixin.py:112} INFO - [2020-08-01 15:50:45,424] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:45,426] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:45,440] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:50:45,447] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:45,449] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:50:53,433] {scheduler_job.py:154} INFO - Started process (PID=65818) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:53,451] {logging_mixin.py:112} INFO - [2020-08-01 15:50:53,450] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:53,451] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:50:53,451] {logging_mixin.py:112} INFO - [2020-08-01 15:50:53,451] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:53,453] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:50:53,468] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:50:53,475] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:53,476] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:51:01,462] {scheduler_job.py:154} INFO - Started process (PID=65834) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:01,481] {logging_mixin.py:112} INFO - [2020-08-01 15:51:01,481] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:01,482] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:51:01,482] {logging_mixin.py:112} INFO - [2020-08-01 15:51:01,482] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:01,484] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:01,498] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:51:01,506] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:01,507] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:51:09,503] {scheduler_job.py:154} INFO - Started process (PID=65859) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:09,521] {logging_mixin.py:112} INFO - [2020-08-01 15:51:09,521] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:09,522] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:51:09,522] {logging_mixin.py:112} INFO - [2020-08-01 15:51:09,522] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:09,524] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:09,538] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:51:09,546] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:09,548] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:51:17,535] {scheduler_job.py:154} INFO - Started process (PID=65875) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:17,553] {logging_mixin.py:112} INFO - [2020-08-01 15:51:17,553] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:17,554] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:51:17,554] {logging_mixin.py:112} INFO - [2020-08-01 15:51:17,554] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:17,556] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:17,570] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:51:17,577] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:17,579] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:51:25,557] {scheduler_job.py:154} INFO - Started process (PID=65899) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:25,575] {logging_mixin.py:112} INFO - [2020-08-01 15:51:25,574] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:25,575] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:51:25,575] {logging_mixin.py:112} INFO - [2020-08-01 15:51:25,575] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:25,577] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:25,591] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:51:25,599] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:25,601] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:51:33,612] {scheduler_job.py:154} INFO - Started process (PID=65915) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:33,630] {logging_mixin.py:112} INFO - [2020-08-01 15:51:33,629] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:33,630] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:51:33,630] {logging_mixin.py:112} INFO - [2020-08-01 15:51:33,630] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:33,632] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:33,646] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:51:33,654] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:33,655] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:51:41,634] {scheduler_job.py:154} INFO - Started process (PID=65940) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:41,652] {logging_mixin.py:112} INFO - [2020-08-01 15:51:41,652] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:41,653] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:51:41,653] {logging_mixin.py:112} INFO - [2020-08-01 15:51:41,653] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:41,655] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:41,669] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:51:41,677] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:41,679] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:51:49,826] {scheduler_job.py:154} INFO - Started process (PID=65948) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:49,849] {logging_mixin.py:112} INFO - [2020-08-01 15:51:49,849] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:49,850] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:51:49,850] {logging_mixin.py:112} INFO - [2020-08-01 15:51:49,850] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:49,852] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:49,868] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:51:49,878] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:49,880] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.054 seconds
[2020-08-01 15:51:57,959] {scheduler_job.py:154} INFO - Started process (PID=65959) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:57,978] {logging_mixin.py:112} INFO - [2020-08-01 15:51:57,978] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:57,979] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:51:57,979] {logging_mixin.py:112} INFO - [2020-08-01 15:51:57,979] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:57,981] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:51:57,995] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:51:58,005] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:58,007] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:52:11,193] {scheduler_job.py:154} INFO - Started process (PID=65972) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:11,212] {logging_mixin.py:112} INFO - [2020-08-01 15:52:11,212] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:11,212] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:52:11,213] {logging_mixin.py:112} INFO - [2020-08-01 15:52:11,212] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:11,215] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:11,229] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:52:11,236] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:11,238] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:52:19,226] {scheduler_job.py:154} INFO - Started process (PID=65980) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:19,246] {logging_mixin.py:112} INFO - [2020-08-01 15:52:19,246] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:19,247] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:52:19,247] {logging_mixin.py:112} INFO - [2020-08-01 15:52:19,247] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:19,249] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:19,264] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:52:19,272] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:19,274] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 15:52:27,254] {scheduler_job.py:154} INFO - Started process (PID=65988) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:27,271] {logging_mixin.py:112} INFO - [2020-08-01 15:52:27,271] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:27,272] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:52:27,272] {logging_mixin.py:112} INFO - [2020-08-01 15:52:27,272] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:27,274] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:27,288] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:52:27,296] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:27,297] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:52:35,295] {scheduler_job.py:154} INFO - Started process (PID=65996) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:35,313] {logging_mixin.py:112} INFO - [2020-08-01 15:52:35,312] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:35,313] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:52:35,313] {logging_mixin.py:112} INFO - [2020-08-01 15:52:35,313] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:35,315] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:35,329] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:52:35,337] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:35,339] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:52:43,316] {scheduler_job.py:154} INFO - Started process (PID=66005) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:43,334] {logging_mixin.py:112} INFO - [2020-08-01 15:52:43,333] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:43,334] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:52:43,334] {logging_mixin.py:112} INFO - [2020-08-01 15:52:43,334] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:43,336] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:43,351] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:52:43,360] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:43,362] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:52:51,336] {scheduler_job.py:154} INFO - Started process (PID=66013) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:51,353] {logging_mixin.py:112} INFO - [2020-08-01 15:52:51,353] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:51,354] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:52:51,354] {logging_mixin.py:112} INFO - [2020-08-01 15:52:51,354] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:51,356] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:51,371] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:52:51,378] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:51,380] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:52:59,365] {scheduler_job.py:154} INFO - Started process (PID=66021) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:59,383] {logging_mixin.py:112} INFO - [2020-08-01 15:52:59,383] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:59,384] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:52:59,384] {logging_mixin.py:112} INFO - [2020-08-01 15:52:59,384] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:59,386] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:52:59,400] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:52:59,407] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:59,409] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:53:07,416] {scheduler_job.py:154} INFO - Started process (PID=66037) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:07,434] {logging_mixin.py:112} INFO - [2020-08-01 15:53:07,433] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:07,434] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:53:07,434] {logging_mixin.py:112} INFO - [2020-08-01 15:53:07,434] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:07,436] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:07,451] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:53:07,458] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:07,459] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:53:15,470] {scheduler_job.py:154} INFO - Started process (PID=66054) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:15,488] {logging_mixin.py:112} INFO - [2020-08-01 15:53:15,488] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:15,488] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:53:15,489] {logging_mixin.py:112} INFO - [2020-08-01 15:53:15,489] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:15,491] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:15,505] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:53:15,513] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:15,515] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:53:23,464] {scheduler_job.py:154} INFO - Started process (PID=66079) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:23,482] {logging_mixin.py:112} INFO - [2020-08-01 15:53:23,482] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:23,483] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:53:23,483] {logging_mixin.py:112} INFO - [2020-08-01 15:53:23,483] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:23,485] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:23,499] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:53:23,505] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:23,507] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:53:31,478] {scheduler_job.py:154} INFO - Started process (PID=66103) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:31,497] {logging_mixin.py:112} INFO - [2020-08-01 15:53:31,497] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:31,497] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:53:31,498] {logging_mixin.py:112} INFO - [2020-08-01 15:53:31,498] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:31,500] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:31,514] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:53:31,521] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:31,523] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:53:39,548] {scheduler_job.py:154} INFO - Started process (PID=66120) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:39,571] {logging_mixin.py:112} INFO - [2020-08-01 15:53:39,570] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:39,572] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:53:39,572] {logging_mixin.py:112} INFO - [2020-08-01 15:53:39,572] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:39,574] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:39,588] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:53:39,595] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:39,597] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 15:53:47,539] {scheduler_job.py:154} INFO - Started process (PID=66144) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:47,563] {logging_mixin.py:112} INFO - [2020-08-01 15:53:47,562] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:47,564] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:53:47,564] {logging_mixin.py:112} INFO - [2020-08-01 15:53:47,564] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:47,567] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:47,584] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:53:47,593] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:47,595] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.057 seconds
[2020-08-01 15:53:55,646] {scheduler_job.py:154} INFO - Started process (PID=66197) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:55,667] {logging_mixin.py:112} INFO - [2020-08-01 15:53:55,667] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:55,668] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:53:55,668] {logging_mixin.py:112} INFO - [2020-08-01 15:53:55,668] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:55,671] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:53:55,688] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:53:55,695] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:55,697] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.051 seconds
[2020-08-01 15:54:03,605] {scheduler_job.py:154} INFO - Started process (PID=66216) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:03,623] {logging_mixin.py:112} INFO - [2020-08-01 15:54:03,623] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:03,624] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:54:03,624] {logging_mixin.py:112} INFO - [2020-08-01 15:54:03,624] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:03,626] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:03,642] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:54:03,651] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:03,652] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:54:11,601] {scheduler_job.py:154} INFO - Started process (PID=66233) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:11,619] {logging_mixin.py:112} INFO - [2020-08-01 15:54:11,619] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:11,619] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:54:11,620] {logging_mixin.py:112} INFO - [2020-08-01 15:54:11,619] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:11,622] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:11,636] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:54:11,644] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:11,646] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:54:19,772] {scheduler_job.py:154} INFO - Started process (PID=66302) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:19,789] {logging_mixin.py:112} INFO - [2020-08-01 15:54:19,789] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:19,790] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:54:19,790] {logging_mixin.py:112} INFO - [2020-08-01 15:54:19,790] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:19,792] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:19,806] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:54:19,814] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:19,816] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:54:27,638] {scheduler_job.py:154} INFO - Started process (PID=66310) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:27,656] {logging_mixin.py:112} INFO - [2020-08-01 15:54:27,656] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:27,657] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:54:27,657] {logging_mixin.py:112} INFO - [2020-08-01 15:54:27,657] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:27,659] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:27,673] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:54:27,680] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:27,682] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:54:35,862] {scheduler_job.py:154} INFO - Started process (PID=66318) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:35,892] {logging_mixin.py:112} INFO - [2020-08-01 15:54:35,891] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:35,892] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:54:35,893] {logging_mixin.py:112} INFO - [2020-08-01 15:54:35,893] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:35,895] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:35,913] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:54:35,921] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:35,924] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.061 seconds
[2020-08-01 15:54:43,787] {scheduler_job.py:154} INFO - Started process (PID=66327) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:43,806] {logging_mixin.py:112} INFO - [2020-08-01 15:54:43,806] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:43,807] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:54:43,807] {logging_mixin.py:112} INFO - [2020-08-01 15:54:43,807] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:43,809] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:43,823] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:54:43,830] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:43,832] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:54:51,942] {scheduler_job.py:154} INFO - Started process (PID=66335) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:51,960] {logging_mixin.py:112} INFO - [2020-08-01 15:54:51,960] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:51,960] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:54:51,961] {logging_mixin.py:112} INFO - [2020-08-01 15:54:51,961] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:51,963] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:54:51,976] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:54:51,985] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:51,987] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:55:05,243] {scheduler_job.py:154} INFO - Started process (PID=66346) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:05,261] {logging_mixin.py:112} INFO - [2020-08-01 15:55:05,261] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:05,262] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:55:05,262] {logging_mixin.py:112} INFO - [2020-08-01 15:55:05,262] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:05,264] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:05,279] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:55:05,286] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:05,288] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:55:13,191] {scheduler_job.py:154} INFO - Started process (PID=66355) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:13,210] {logging_mixin.py:112} INFO - [2020-08-01 15:55:13,210] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:13,210] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:55:13,210] {logging_mixin.py:112} INFO - [2020-08-01 15:55:13,210] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:13,212] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:13,227] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:55:13,234] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:13,235] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:55:21,212] {scheduler_job.py:154} INFO - Started process (PID=66363) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:21,230] {logging_mixin.py:112} INFO - [2020-08-01 15:55:21,230] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:21,231] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:55:21,231] {logging_mixin.py:112} INFO - [2020-08-01 15:55:21,231] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:21,233] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:21,247] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:55:21,254] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:21,255] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:55:29,237] {scheduler_job.py:154} INFO - Started process (PID=66371) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:29,255] {logging_mixin.py:112} INFO - [2020-08-01 15:55:29,255] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:29,255] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:55:29,256] {logging_mixin.py:112} INFO - [2020-08-01 15:55:29,255] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:29,258] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:29,272] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:55:29,279] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:29,281] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:55:37,260] {scheduler_job.py:154} INFO - Started process (PID=66387) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:37,278] {logging_mixin.py:112} INFO - [2020-08-01 15:55:37,277] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:37,278] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:55:37,278] {logging_mixin.py:112} INFO - [2020-08-01 15:55:37,278] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:37,280] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:37,295] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:55:37,303] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:37,305] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:55:45,282] {scheduler_job.py:154} INFO - Started process (PID=66404) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:45,300] {logging_mixin.py:112} INFO - [2020-08-01 15:55:45,300] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:45,300] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:55:45,300] {logging_mixin.py:112} INFO - [2020-08-01 15:55:45,300] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:45,302] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:45,319] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:55:45,327] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:45,329] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:55:53,296] {scheduler_job.py:154} INFO - Started process (PID=66428) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:53,314] {logging_mixin.py:112} INFO - [2020-08-01 15:55:53,314] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:53,315] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:55:53,315] {logging_mixin.py:112} INFO - [2020-08-01 15:55:53,315] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:53,318] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:55:53,333] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:55:53,341] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:53,343] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:56:01,331] {scheduler_job.py:154} INFO - Started process (PID=66444) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:01,352] {logging_mixin.py:112} INFO - [2020-08-01 15:56:01,351] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:01,352] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:56:01,353] {logging_mixin.py:112} INFO - [2020-08-01 15:56:01,353] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:01,355] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:01,371] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:56:01,380] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:01,381] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.050 seconds
[2020-08-01 15:56:09,364] {scheduler_job.py:154} INFO - Started process (PID=66468) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:09,382] {logging_mixin.py:112} INFO - [2020-08-01 15:56:09,382] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:09,383] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:56:09,383] {logging_mixin.py:112} INFO - [2020-08-01 15:56:09,383] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:09,385] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:09,400] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:56:09,407] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:09,409] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:56:17,425] {scheduler_job.py:154} INFO - Started process (PID=66485) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:17,442] {logging_mixin.py:112} INFO - [2020-08-01 15:56:17,442] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:17,443] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:56:17,443] {logging_mixin.py:112} INFO - [2020-08-01 15:56:17,443] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:17,445] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:17,459] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:56:17,467] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:17,469] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:56:25,416] {scheduler_job.py:154} INFO - Started process (PID=66509) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:25,434] {logging_mixin.py:112} INFO - [2020-08-01 15:56:25,433] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:25,434] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:56:25,434] {logging_mixin.py:112} INFO - [2020-08-01 15:56:25,434] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:25,436] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:25,450] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:56:25,459] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:25,460] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:56:33,509] {scheduler_job.py:154} INFO - Started process (PID=66533) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:33,528] {logging_mixin.py:112} INFO - [2020-08-01 15:56:33,527] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:33,528] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:56:33,528] {logging_mixin.py:112} INFO - [2020-08-01 15:56:33,528] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:33,531] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:33,546] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:56:33,552] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:33,554] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:56:41,524] {scheduler_job.py:154} INFO - Started process (PID=66549) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:41,543] {logging_mixin.py:112} INFO - [2020-08-01 15:56:41,543] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:41,544] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:56:41,544] {logging_mixin.py:112} INFO - [2020-08-01 15:56:41,544] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:41,546] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:41,559] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:56:41,565] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:41,567] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:56:49,496] {scheduler_job.py:154} INFO - Started process (PID=66575) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:49,513] {logging_mixin.py:112} INFO - [2020-08-01 15:56:49,513] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:49,514] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:56:49,514] {logging_mixin.py:112} INFO - [2020-08-01 15:56:49,514] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:49,516] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:49,530] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:56:49,538] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:49,540] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:56:57,605] {scheduler_job.py:154} INFO - Started process (PID=66659) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:57,624] {logging_mixin.py:112} INFO - [2020-08-01 15:56:57,624] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:57,624] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:56:57,624] {logging_mixin.py:112} INFO - [2020-08-01 15:56:57,624] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:57,626] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:56:57,641] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:56:57,649] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:57,650] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:57:05,690] {scheduler_job.py:154} INFO - Started process (PID=66684) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:05,707] {logging_mixin.py:112} INFO - [2020-08-01 15:57:05,707] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:05,708] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:57:05,708] {logging_mixin.py:112} INFO - [2020-08-01 15:57:05,708] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:05,710] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:05,723] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:57:05,729] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:05,731] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 15:57:16,645] {scheduler_job.py:154} INFO - Started process (PID=66697) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:16,662] {logging_mixin.py:112} INFO - [2020-08-01 15:57:16,662] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:16,662] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:57:16,662] {logging_mixin.py:112} INFO - [2020-08-01 15:57:16,662] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:16,664] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:16,678] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:57:16,685] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:16,687] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:57:24,626] {scheduler_job.py:154} INFO - Started process (PID=66713) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:24,644] {logging_mixin.py:112} INFO - [2020-08-01 15:57:24,643] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:24,644] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:57:24,644] {logging_mixin.py:112} INFO - [2020-08-01 15:57:24,644] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:24,647] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:24,661] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:57:24,668] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:24,669] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:57:32,664] {scheduler_job.py:154} INFO - Started process (PID=66721) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:32,682] {logging_mixin.py:112} INFO - [2020-08-01 15:57:32,682] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:32,682] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:57:32,683] {logging_mixin.py:112} INFO - [2020-08-01 15:57:32,682] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:32,685] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:32,699] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:57:32,708] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:32,710] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:57:40,946] {scheduler_job.py:154} INFO - Started process (PID=66729) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:40,965] {logging_mixin.py:112} INFO - [2020-08-01 15:57:40,965] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:40,966] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:57:40,966] {logging_mixin.py:112} INFO - [2020-08-01 15:57:40,966] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:40,968] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:40,983] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:57:40,991] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:40,992] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:57:48,758] {scheduler_job.py:154} INFO - Started process (PID=66754) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:48,776] {logging_mixin.py:112} INFO - [2020-08-01 15:57:48,776] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:48,777] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:57:48,777] {logging_mixin.py:112} INFO - [2020-08-01 15:57:48,777] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:48,779] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:48,793] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:57:48,800] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:48,802] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:57:56,846] {scheduler_job.py:154} INFO - Started process (PID=66778) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:56,863] {logging_mixin.py:112} INFO - [2020-08-01 15:57:56,863] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:56,864] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:57:56,864] {logging_mixin.py:112} INFO - [2020-08-01 15:57:56,864] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:56,866] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:57:56,880] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:57:56,886] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:56,888] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:58:04,774] {scheduler_job.py:154} INFO - Started process (PID=66795) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:04,794] {logging_mixin.py:112} INFO - [2020-08-01 15:58:04,794] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:04,794] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:58:04,794] {logging_mixin.py:112} INFO - [2020-08-01 15:58:04,794] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:04,796] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:04,811] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:58:04,819] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:04,820] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:58:12,833] {scheduler_job.py:154} INFO - Started process (PID=66819) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:12,851] {logging_mixin.py:112} INFO - [2020-08-01 15:58:12,851] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:12,851] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:58:12,851] {logging_mixin.py:112} INFO - [2020-08-01 15:58:12,851] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:12,853] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:12,868] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:58:12,875] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:12,876] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:58:20,925] {scheduler_job.py:154} INFO - Started process (PID=66839) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:20,942] {logging_mixin.py:112} INFO - [2020-08-01 15:58:20,942] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:20,943] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:58:20,943] {logging_mixin.py:112} INFO - [2020-08-01 15:58:20,943] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:20,945] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:20,957] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:58:20,966] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:20,968] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 15:58:28,971] {scheduler_job.py:154} INFO - Started process (PID=66931) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:28,989] {logging_mixin.py:112} INFO - [2020-08-01 15:58:28,989] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:28,990] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:58:28,990] {logging_mixin.py:112} INFO - [2020-08-01 15:58:28,990] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:28,992] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:29,006] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:58:29,014] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:29,016] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:58:36,890] {scheduler_job.py:154} INFO - Started process (PID=66940) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:36,908] {logging_mixin.py:112} INFO - [2020-08-01 15:58:36,908] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:36,909] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:58:36,909] {logging_mixin.py:112} INFO - [2020-08-01 15:58:36,909] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:36,911] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:36,927] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:58:36,934] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:36,936] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 15:58:44,930] {scheduler_job.py:154} INFO - Started process (PID=66956) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:44,949] {logging_mixin.py:112} INFO - [2020-08-01 15:58:44,949] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:44,950] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:58:44,950] {logging_mixin.py:112} INFO - [2020-08-01 15:58:44,950] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:44,952] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:44,968] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:58:44,975] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:44,977] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:58:52,941] {scheduler_job.py:154} INFO - Started process (PID=66965) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:52,960] {logging_mixin.py:112} INFO - [2020-08-01 15:58:52,959] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:52,960] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:58:52,960] {logging_mixin.py:112} INFO - [2020-08-01 15:58:52,960] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:52,962] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:58:52,978] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:58:52,986] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:52,988] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:59:01,000] {scheduler_job.py:154} INFO - Started process (PID=67045) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:01,017] {logging_mixin.py:112} INFO - [2020-08-01 15:59:01,017] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:01,018] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:59:01,018] {logging_mixin.py:112} INFO - [2020-08-01 15:59:01,018] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:01,020] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:01,033] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:59:01,040] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:01,042] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:59:08,991] {scheduler_job.py:154} INFO - Started process (PID=67055) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:09,008] {logging_mixin.py:112} INFO - [2020-08-01 15:59:09,008] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:09,008] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:59:09,008] {logging_mixin.py:112} INFO - [2020-08-01 15:59:09,008] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:09,010] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:09,024] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:59:09,032] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:09,033] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 15:59:17,083] {scheduler_job.py:154} INFO - Started process (PID=67070) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:17,101] {logging_mixin.py:112} INFO - [2020-08-01 15:59:17,101] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:17,102] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:59:17,102] {logging_mixin.py:112} INFO - [2020-08-01 15:59:17,102] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:17,104] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:17,118] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:59:17,126] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:17,128] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:59:25,056] {scheduler_job.py:154} INFO - Started process (PID=67078) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:25,076] {logging_mixin.py:112} INFO - [2020-08-01 15:59:25,075] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:25,076] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:59:25,076] {logging_mixin.py:112} INFO - [2020-08-01 15:59:25,076] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:25,079] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:25,094] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:59:25,102] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:25,104] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 15:59:33,053] {scheduler_job.py:154} INFO - Started process (PID=67087) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:33,072] {logging_mixin.py:112} INFO - [2020-08-01 15:59:33,072] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:33,073] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:59:33,073] {logging_mixin.py:112} INFO - [2020-08-01 15:59:33,073] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:33,075] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:33,089] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:59:33,096] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:33,097] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:59:41,609] {scheduler_job.py:154} INFO - Started process (PID=67095) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:41,627] {logging_mixin.py:112} INFO - [2020-08-01 15:59:41,627] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:41,628] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:59:41,628] {logging_mixin.py:112} INFO - [2020-08-01 15:59:41,628] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:41,630] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:41,644] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:59:41,652] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:41,654] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 15:59:49,036] {scheduler_job.py:154} INFO - Started process (PID=67185) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:49,054] {logging_mixin.py:112} INFO - [2020-08-01 15:59:49,053] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:49,054] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:59:49,054] {logging_mixin.py:112} INFO - [2020-08-01 15:59:49,054] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:49,056] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:49,071] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:59:49,079] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:49,080] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 15:59:57,135] {scheduler_job.py:154} INFO - Started process (PID=67209) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:57,153] {logging_mixin.py:112} INFO - [2020-08-01 15:59:57,153] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:57,154] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 15:59:57,154] {logging_mixin.py:112} INFO - [2020-08-01 15:59:57,154] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:57,156] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 15:59:57,170] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 15:59:57,178] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:57,180] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:00:05,115] {scheduler_job.py:154} INFO - Started process (PID=67225) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:05,133] {logging_mixin.py:112} INFO - [2020-08-01 16:00:05,133] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:05,134] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:00:05,134] {logging_mixin.py:112} INFO - [2020-08-01 16:00:05,134] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:05,136] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:05,150] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:00:05,158] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:05,160] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:00:13,194] {scheduler_job.py:154} INFO - Started process (PID=67249) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:13,212] {logging_mixin.py:112} INFO - [2020-08-01 16:00:13,211] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:13,213] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:00:13,213] {logging_mixin.py:112} INFO - [2020-08-01 16:00:13,213] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:13,215] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:13,229] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:00:13,236] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:13,238] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:00:21,168] {scheduler_job.py:154} INFO - Started process (PID=67266) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:21,187] {logging_mixin.py:112} INFO - [2020-08-01 16:00:21,187] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:21,188] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:00:21,188] {logging_mixin.py:112} INFO - [2020-08-01 16:00:21,188] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:21,190] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:21,205] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:00:21,215] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:21,216] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:00:29,190] {scheduler_job.py:154} INFO - Started process (PID=67290) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:29,207] {logging_mixin.py:112} INFO - [2020-08-01 16:00:29,207] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:29,208] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:00:29,208] {logging_mixin.py:112} INFO - [2020-08-01 16:00:29,208] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:29,210] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:29,224] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:00:29,232] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:29,234] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:00:37,254] {scheduler_job.py:154} INFO - Started process (PID=67307) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:37,272] {logging_mixin.py:112} INFO - [2020-08-01 16:00:37,271] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:37,272] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:00:37,272] {logging_mixin.py:112} INFO - [2020-08-01 16:00:37,272] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:37,274] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:37,289] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:00:37,298] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:37,299] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:00:45,285] {scheduler_job.py:154} INFO - Started process (PID=67331) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:45,304] {logging_mixin.py:112} INFO - [2020-08-01 16:00:45,303] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:45,304] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:00:45,304] {logging_mixin.py:112} INFO - [2020-08-01 16:00:45,304] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:45,306] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:45,321] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:00:45,329] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:45,330] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:00:53,422] {scheduler_job.py:154} INFO - Started process (PID=67356) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:53,442] {logging_mixin.py:112} INFO - [2020-08-01 16:00:53,442] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:53,442] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:00:53,443] {logging_mixin.py:112} INFO - [2020-08-01 16:00:53,442] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:53,445] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:00:53,459] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:00:53,467] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:53,469] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:01:01,294] {scheduler_job.py:154} INFO - Started process (PID=67409) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:01,312] {logging_mixin.py:112} INFO - [2020-08-01 16:01:01,312] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:01,312] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:01:01,312] {logging_mixin.py:112} INFO - [2020-08-01 16:01:01,312] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:01,314] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:01,329] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:01:01,336] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:01,337] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:01:09,389] {scheduler_job.py:154} INFO - Started process (PID=67450) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:09,408] {logging_mixin.py:112} INFO - [2020-08-01 16:01:09,408] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:09,408] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:01:09,409] {logging_mixin.py:112} INFO - [2020-08-01 16:01:09,409] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:09,411] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:09,426] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:01:09,433] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:09,435] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:01:17,365] {scheduler_job.py:154} INFO - Started process (PID=67468) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:17,384] {logging_mixin.py:112} INFO - [2020-08-01 16:01:17,383] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:17,384] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:01:17,384] {logging_mixin.py:112} INFO - [2020-08-01 16:01:17,384] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:17,386] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:17,401] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:01:17,408] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:17,410] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:01:25,352] {scheduler_job.py:154} INFO - Started process (PID=67493) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:25,370] {logging_mixin.py:112} INFO - [2020-08-01 16:01:25,369] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:25,370] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:01:25,370] {logging_mixin.py:112} INFO - [2020-08-01 16:01:25,370] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:25,372] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:25,386] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:01:25,393] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:25,395] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:01:33,458] {scheduler_job.py:154} INFO - Started process (PID=67509) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:33,476] {logging_mixin.py:112} INFO - [2020-08-01 16:01:33,476] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:33,477] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:01:33,477] {logging_mixin.py:112} INFO - [2020-08-01 16:01:33,477] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:33,479] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:33,493] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:01:33,504] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:33,507] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:01:41,411] {scheduler_job.py:154} INFO - Started process (PID=67534) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:41,429] {logging_mixin.py:112} INFO - [2020-08-01 16:01:41,429] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:41,429] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:01:41,430] {logging_mixin.py:112} INFO - [2020-08-01 16:01:41,430] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:41,432] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:41,446] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:01:41,454] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:41,456] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:01:49,455] {scheduler_job.py:154} INFO - Started process (PID=67559) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:49,473] {logging_mixin.py:112} INFO - [2020-08-01 16:01:49,473] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:49,474] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:01:49,474] {logging_mixin.py:112} INFO - [2020-08-01 16:01:49,474] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:49,476] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:49,490] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:01:49,497] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:49,499] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:01:57,462] {scheduler_job.py:154} INFO - Started process (PID=67576) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:57,480] {logging_mixin.py:112} INFO - [2020-08-01 16:01:57,480] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:57,481] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:01:57,481] {logging_mixin.py:112} INFO - [2020-08-01 16:01:57,481] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:57,483] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:01:57,498] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:01:57,506] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:57,507] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:02:05,466] {scheduler_job.py:154} INFO - Started process (PID=67600) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:05,484] {logging_mixin.py:112} INFO - [2020-08-01 16:02:05,484] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:05,484] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:02:05,485] {logging_mixin.py:112} INFO - [2020-08-01 16:02:05,485] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:05,487] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:05,501] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:02:05,509] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:05,511] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:02:13,577] {scheduler_job.py:154} INFO - Started process (PID=67616) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:13,596] {logging_mixin.py:112} INFO - [2020-08-01 16:02:13,596] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:13,596] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:02:13,597] {logging_mixin.py:112} INFO - [2020-08-01 16:02:13,596] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:13,599] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:13,614] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:02:13,624] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:13,626] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:02:21,538] {scheduler_job.py:154} INFO - Started process (PID=67642) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:21,555] {logging_mixin.py:112} INFO - [2020-08-01 16:02:21,555] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:21,556] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:02:21,556] {logging_mixin.py:112} INFO - [2020-08-01 16:02:21,556] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:21,558] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:21,575] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:02:21,581] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:21,582] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:02:29,561] {scheduler_job.py:154} INFO - Started process (PID=67659) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:29,578] {logging_mixin.py:112} INFO - [2020-08-01 16:02:29,578] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:29,579] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:02:29,579] {logging_mixin.py:112} INFO - [2020-08-01 16:02:29,579] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:29,581] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:29,595] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:02:29,603] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:29,605] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:02:37,594] {scheduler_job.py:154} INFO - Started process (PID=67683) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:37,614] {logging_mixin.py:112} INFO - [2020-08-01 16:02:37,614] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:37,615] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:02:37,615] {logging_mixin.py:112} INFO - [2020-08-01 16:02:37,615] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:37,617] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:37,631] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:02:37,638] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:37,640] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:02:45,690] {scheduler_job.py:154} INFO - Started process (PID=67708) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:45,707] {logging_mixin.py:112} INFO - [2020-08-01 16:02:45,707] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:45,708] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:02:45,708] {logging_mixin.py:112} INFO - [2020-08-01 16:02:45,708] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:45,710] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:45,724] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:02:45,731] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:45,732] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:02:53,701] {scheduler_job.py:154} INFO - Started process (PID=67717) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:53,720] {logging_mixin.py:112} INFO - [2020-08-01 16:02:53,719] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:53,720] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:02:53,720] {logging_mixin.py:112} INFO - [2020-08-01 16:02:53,720] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:53,722] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:02:53,736] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:02:53,744] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:53,746] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:03:01,692] {scheduler_job.py:154} INFO - Started process (PID=67726) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:01,710] {logging_mixin.py:112} INFO - [2020-08-01 16:03:01,710] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:01,711] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:03:01,711] {logging_mixin.py:112} INFO - [2020-08-01 16:03:01,711] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:01,713] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:01,726] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:03:01,734] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:01,736] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:03:09,760] {scheduler_job.py:154} INFO - Started process (PID=67734) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:09,778] {logging_mixin.py:112} INFO - [2020-08-01 16:03:09,778] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:09,779] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:03:09,779] {logging_mixin.py:112} INFO - [2020-08-01 16:03:09,779] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:09,782] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:09,795] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:03:09,804] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:09,806] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:03:17,804] {scheduler_job.py:154} INFO - Started process (PID=67743) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:17,827] {logging_mixin.py:112} INFO - [2020-08-01 16:03:17,827] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:17,828] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:03:17,828] {logging_mixin.py:112} INFO - [2020-08-01 16:03:17,828] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:17,830] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:17,844] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:03:17,851] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:17,852] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:03:25,706] {scheduler_job.py:154} INFO - Started process (PID=67764) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:25,723] {logging_mixin.py:112} INFO - [2020-08-01 16:03:25,723] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:25,724] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:03:25,724] {logging_mixin.py:112} INFO - [2020-08-01 16:03:25,724] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:25,726] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:25,740] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:03:25,747] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:25,748] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:03:33,731] {scheduler_job.py:154} INFO - Started process (PID=67772) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:33,749] {logging_mixin.py:112} INFO - [2020-08-01 16:03:33,749] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:33,750] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:03:33,750] {logging_mixin.py:112} INFO - [2020-08-01 16:03:33,750] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:33,752] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:33,766] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:03:33,774] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:33,776] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:03:41,752] {scheduler_job.py:154} INFO - Started process (PID=67780) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:41,770] {logging_mixin.py:112} INFO - [2020-08-01 16:03:41,769] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:41,770] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:03:41,770] {logging_mixin.py:112} INFO - [2020-08-01 16:03:41,770] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:41,772] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:41,787] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:03:41,794] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:41,796] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:03:49,777] {scheduler_job.py:154} INFO - Started process (PID=67788) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:49,794] {logging_mixin.py:112} INFO - [2020-08-01 16:03:49,794] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:49,795] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:03:49,795] {logging_mixin.py:112} INFO - [2020-08-01 16:03:49,795] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:49,797] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:49,811] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:03:49,819] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:49,820] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:03:57,811] {scheduler_job.py:154} INFO - Started process (PID=67797) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:57,829] {logging_mixin.py:112} INFO - [2020-08-01 16:03:57,828] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:57,829] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:03:57,829] {logging_mixin.py:112} INFO - [2020-08-01 16:03:57,829] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:57,831] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:03:57,846] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:03:57,854] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:57,856] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:04:05,842] {scheduler_job.py:154} INFO - Started process (PID=67805) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:05,860] {logging_mixin.py:112} INFO - [2020-08-01 16:04:05,859] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:05,860] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:04:05,860] {logging_mixin.py:112} INFO - [2020-08-01 16:04:05,860] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:05,862] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:05,877] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:04:05,884] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:05,886] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:04:13,891] {scheduler_job.py:154} INFO - Started process (PID=67813) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:13,910] {logging_mixin.py:112} INFO - [2020-08-01 16:04:13,910] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:13,911] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:04:13,911] {logging_mixin.py:112} INFO - [2020-08-01 16:04:13,911] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:13,913] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:13,928] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:04:13,935] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:13,937] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:04:21,964] {scheduler_job.py:154} INFO - Started process (PID=67822) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:21,982] {logging_mixin.py:112} INFO - [2020-08-01 16:04:21,982] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:21,983] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:04:21,983] {logging_mixin.py:112} INFO - [2020-08-01 16:04:21,983] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:21,986] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:22,000] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:04:22,007] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:22,009] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:04:29,918] {scheduler_job.py:154} INFO - Started process (PID=67831) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:29,935] {logging_mixin.py:112} INFO - [2020-08-01 16:04:29,935] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:29,936] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:04:29,936] {logging_mixin.py:112} INFO - [2020-08-01 16:04:29,936] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:29,938] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:29,952] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:04:29,959] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:29,961] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:04:37,947] {scheduler_job.py:154} INFO - Started process (PID=67839) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:37,965] {logging_mixin.py:112} INFO - [2020-08-01 16:04:37,965] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:37,966] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:04:37,966] {logging_mixin.py:112} INFO - [2020-08-01 16:04:37,966] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:37,968] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:37,982] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:04:37,990] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:37,991] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:04:45,983] {scheduler_job.py:154} INFO - Started process (PID=67847) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:46,000] {logging_mixin.py:112} INFO - [2020-08-01 16:04:46,000] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:46,001] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:04:46,001] {logging_mixin.py:112} INFO - [2020-08-01 16:04:46,001] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:46,003] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:46,017] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:04:46,025] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:46,027] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:04:54,143] {scheduler_job.py:154} INFO - Started process (PID=67855) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:54,160] {logging_mixin.py:112} INFO - [2020-08-01 16:04:54,160] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:54,161] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:04:54,161] {logging_mixin.py:112} INFO - [2020-08-01 16:04:54,161] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:54,163] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:04:54,176] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:04:54,183] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:54,184] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:05:02,050] {scheduler_job.py:154} INFO - Started process (PID=67864) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:02,067] {logging_mixin.py:112} INFO - [2020-08-01 16:05:02,067] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:02,068] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:05:02,068] {logging_mixin.py:112} INFO - [2020-08-01 16:05:02,068] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:02,070] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:02,084] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:05:02,092] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:02,093] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:05:10,084] {scheduler_job.py:154} INFO - Started process (PID=67872) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:10,102] {logging_mixin.py:112} INFO - [2020-08-01 16:05:10,102] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:10,102] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:05:10,102] {logging_mixin.py:112} INFO - [2020-08-01 16:05:10,102] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:10,105] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:10,119] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:05:10,128] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:10,129] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:05:18,106] {scheduler_job.py:154} INFO - Started process (PID=67880) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:18,123] {logging_mixin.py:112} INFO - [2020-08-01 16:05:18,123] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:18,124] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:05:18,124] {logging_mixin.py:112} INFO - [2020-08-01 16:05:18,124] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:18,126] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:18,139] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:05:18,146] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:18,148] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:05:26,154] {scheduler_job.py:154} INFO - Started process (PID=67889) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:26,171] {logging_mixin.py:112} INFO - [2020-08-01 16:05:26,171] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:26,172] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:05:26,172] {logging_mixin.py:112} INFO - [2020-08-01 16:05:26,172] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:26,174] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:26,188] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:05:26,195] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:26,197] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:05:34,171] {scheduler_job.py:154} INFO - Started process (PID=67897) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:34,188] {logging_mixin.py:112} INFO - [2020-08-01 16:05:34,188] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:34,189] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:05:34,189] {logging_mixin.py:112} INFO - [2020-08-01 16:05:34,189] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:34,191] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:34,205] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:05:34,213] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:34,215] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:05:42,207] {scheduler_job.py:154} INFO - Started process (PID=67905) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:42,224] {logging_mixin.py:112} INFO - [2020-08-01 16:05:42,224] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:42,225] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:05:42,225] {logging_mixin.py:112} INFO - [2020-08-01 16:05:42,225] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:42,227] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:42,241] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:05:42,249] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:42,251] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:05:50,238] {scheduler_job.py:154} INFO - Started process (PID=67913) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:50,256] {logging_mixin.py:112} INFO - [2020-08-01 16:05:50,255] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:50,256] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:05:50,256] {logging_mixin.py:112} INFO - [2020-08-01 16:05:50,256] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:50,258] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:50,272] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:05:50,279] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:50,280] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:05:58,385] {scheduler_job.py:154} INFO - Started process (PID=67922) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:58,402] {logging_mixin.py:112} INFO - [2020-08-01 16:05:58,402] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:58,402] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:05:58,402] {logging_mixin.py:112} INFO - [2020-08-01 16:05:58,402] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:58,404] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:05:58,419] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:05:58,427] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:58,428] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:06:06,354] {scheduler_job.py:154} INFO - Started process (PID=67949) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:06,371] {logging_mixin.py:112} INFO - [2020-08-01 16:06:06,371] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:06,372] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:06:06,372] {logging_mixin.py:112} INFO - [2020-08-01 16:06:06,372] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:06,374] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:06,388] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:06:06,395] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:06,397] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:06:14,367] {scheduler_job.py:154} INFO - Started process (PID=67972) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:14,384] {logging_mixin.py:112} INFO - [2020-08-01 16:06:14,384] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:14,385] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:06:14,385] {logging_mixin.py:112} INFO - [2020-08-01 16:06:14,385] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:14,387] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:14,402] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:06:14,409] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:14,410] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:06:22,418] {scheduler_job.py:154} INFO - Started process (PID=67990) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:22,436] {logging_mixin.py:112} INFO - [2020-08-01 16:06:22,436] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:22,437] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:06:22,437] {logging_mixin.py:112} INFO - [2020-08-01 16:06:22,437] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:22,439] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:22,453] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:06:22,460] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:22,461] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:06:30,411] {scheduler_job.py:154} INFO - Started process (PID=68016) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:30,429] {logging_mixin.py:112} INFO - [2020-08-01 16:06:30,429] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:30,430] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:06:30,430] {logging_mixin.py:112} INFO - [2020-08-01 16:06:30,430] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:30,432] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:30,446] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:06:30,453] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:30,455] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:06:38,438] {scheduler_job.py:154} INFO - Started process (PID=68032) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:38,457] {logging_mixin.py:112} INFO - [2020-08-01 16:06:38,456] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:38,457] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:06:38,457] {logging_mixin.py:112} INFO - [2020-08-01 16:06:38,457] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:38,459] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:38,474] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:06:38,482] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:38,483] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:06:46,418] {scheduler_job.py:154} INFO - Started process (PID=68057) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:46,435] {logging_mixin.py:112} INFO - [2020-08-01 16:06:46,435] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:46,436] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:06:46,436] {logging_mixin.py:112} INFO - [2020-08-01 16:06:46,436] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:46,438] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:46,452] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:06:46,459] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:46,460] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:06:54,554] {scheduler_job.py:154} INFO - Started process (PID=68074) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:54,573] {logging_mixin.py:112} INFO - [2020-08-01 16:06:54,573] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:54,574] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:06:54,574] {logging_mixin.py:112} INFO - [2020-08-01 16:06:54,574] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:54,577] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:06:54,589] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:06:54,596] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:54,597] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:07:02,613] {scheduler_job.py:154} INFO - Started process (PID=68100) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:02,631] {logging_mixin.py:112} INFO - [2020-08-01 16:07:02,631] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:02,631] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:07:02,631] {logging_mixin.py:112} INFO - [2020-08-01 16:07:02,631] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:02,634] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:02,647] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:07:02,654] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:02,655] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:07:10,725] {scheduler_job.py:154} INFO - Started process (PID=68116) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:10,743] {logging_mixin.py:112} INFO - [2020-08-01 16:07:10,743] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:10,743] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:07:10,744] {logging_mixin.py:112} INFO - [2020-08-01 16:07:10,743] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:10,745] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:10,758] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:07:10,765] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:10,767] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:07:18,663] {scheduler_job.py:154} INFO - Started process (PID=68141) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:18,684] {logging_mixin.py:112} INFO - [2020-08-01 16:07:18,683] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:18,684] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:07:18,684] {logging_mixin.py:112} INFO - [2020-08-01 16:07:18,684] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:18,687] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:18,700] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:07:18,706] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:18,708] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:07:26,593] {scheduler_job.py:154} INFO - Started process (PID=68158) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:26,611] {logging_mixin.py:112} INFO - [2020-08-01 16:07:26,610] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:26,611] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:07:26,612] {logging_mixin.py:112} INFO - [2020-08-01 16:07:26,611] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:26,614] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:26,628] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:07:26,636] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:26,637] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:07:34,605] {scheduler_job.py:154} INFO - Started process (PID=68183) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:34,623] {logging_mixin.py:112} INFO - [2020-08-01 16:07:34,622] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:34,623] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:07:34,623] {logging_mixin.py:112} INFO - [2020-08-01 16:07:34,623] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:34,625] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:34,638] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:07:34,644] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:34,646] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 16:07:42,577] {scheduler_job.py:154} INFO - Started process (PID=68207) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:42,594] {logging_mixin.py:112} INFO - [2020-08-01 16:07:42,594] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:42,595] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:07:42,595] {logging_mixin.py:112} INFO - [2020-08-01 16:07:42,595] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:42,597] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:42,611] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:07:42,617] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:42,619] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:07:50,628] {scheduler_job.py:154} INFO - Started process (PID=68224) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:50,646] {logging_mixin.py:112} INFO - [2020-08-01 16:07:50,646] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:50,646] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:07:50,646] {logging_mixin.py:112} INFO - [2020-08-01 16:07:50,646] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:50,648] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:50,663] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:07:50,669] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:50,671] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:07:58,712] {scheduler_job.py:154} INFO - Started process (PID=68249) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:58,735] {logging_mixin.py:112} INFO - [2020-08-01 16:07:58,735] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:58,735] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:07:58,735] {logging_mixin.py:112} INFO - [2020-08-01 16:07:58,735] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:58,738] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:07:58,752] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:07:58,763] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:58,765] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.053 seconds
[2020-08-01 16:08:06,709] {scheduler_job.py:154} INFO - Started process (PID=68266) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:06,726] {logging_mixin.py:112} INFO - [2020-08-01 16:08:06,726] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:06,727] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:08:06,727] {logging_mixin.py:112} INFO - [2020-08-01 16:08:06,727] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:06,729] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:06,742] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:08:06,749] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:06,750] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 16:08:14,773] {scheduler_job.py:154} INFO - Started process (PID=68290) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:14,799] {logging_mixin.py:112} INFO - [2020-08-01 16:08:14,799] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:14,800] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:08:14,800] {logging_mixin.py:112} INFO - [2020-08-01 16:08:14,800] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:14,802] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:14,817] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:08:14,825] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:14,826] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.053 seconds
[2020-08-01 16:08:22,798] {scheduler_job.py:154} INFO - Started process (PID=68315) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:22,817] {logging_mixin.py:112} INFO - [2020-08-01 16:08:22,817] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:22,817] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:08:22,818] {logging_mixin.py:112} INFO - [2020-08-01 16:08:22,818] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:22,821] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:22,836] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:08:22,845] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:22,846] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:08:30,766] {scheduler_job.py:154} INFO - Started process (PID=68333) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:30,790] {logging_mixin.py:112} INFO - [2020-08-01 16:08:30,789] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:30,790] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:08:30,790] {logging_mixin.py:112} INFO - [2020-08-01 16:08:30,790] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:30,793] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:30,810] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:08:30,817] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:30,818] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 16:08:38,777] {scheduler_job.py:154} INFO - Started process (PID=68357) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:38,796] {logging_mixin.py:112} INFO - [2020-08-01 16:08:38,796] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:38,797] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:08:38,797] {logging_mixin.py:112} INFO - [2020-08-01 16:08:38,797] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:38,799] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:38,813] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:08:38,820] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:38,821] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:08:46,848] {scheduler_job.py:154} INFO - Started process (PID=68375) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:46,866] {logging_mixin.py:112} INFO - [2020-08-01 16:08:46,866] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:46,867] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:08:46,867] {logging_mixin.py:112} INFO - [2020-08-01 16:08:46,867] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:46,869] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:46,884] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:08:46,892] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:46,894] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:08:54,788] {scheduler_job.py:154} INFO - Started process (PID=68399) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:54,805] {logging_mixin.py:112} INFO - [2020-08-01 16:08:54,805] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:54,806] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:08:54,806] {logging_mixin.py:112} INFO - [2020-08-01 16:08:54,806] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:54,808] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:08:54,822] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:08:54,830] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:54,832] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:09:02,910] {scheduler_job.py:154} INFO - Started process (PID=68417) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:02,928] {logging_mixin.py:112} INFO - [2020-08-01 16:09:02,928] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:02,928] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:09:02,929] {logging_mixin.py:112} INFO - [2020-08-01 16:09:02,929] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:02,931] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:02,945] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:09:02,951] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:02,953] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:09:10,890] {scheduler_job.py:154} INFO - Started process (PID=68441) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:10,908] {logging_mixin.py:112} INFO - [2020-08-01 16:09:10,908] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:10,909] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:09:10,909] {logging_mixin.py:112} INFO - [2020-08-01 16:09:10,909] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:10,911] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:10,925] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:09:10,934] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:10,935] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:09:18,942] {scheduler_job.py:154} INFO - Started process (PID=68466) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:18,961] {logging_mixin.py:112} INFO - [2020-08-01 16:09:18,960] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:18,961] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:09:18,961] {logging_mixin.py:112} INFO - [2020-08-01 16:09:18,961] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:18,963] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:18,979] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:09:18,988] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:18,989] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:09:26,948] {scheduler_job.py:154} INFO - Started process (PID=68482) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:26,969] {logging_mixin.py:112} INFO - [2020-08-01 16:09:26,968] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:26,969] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:09:26,969] {logging_mixin.py:112} INFO - [2020-08-01 16:09:26,969] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:26,971] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:26,985] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:09:26,991] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:26,993] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:09:35,007] {scheduler_job.py:154} INFO - Started process (PID=68508) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:35,026] {logging_mixin.py:112} INFO - [2020-08-01 16:09:35,026] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:35,027] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:09:35,027] {logging_mixin.py:112} INFO - [2020-08-01 16:09:35,027] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:35,029] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:35,045] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:09:35,053] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:35,055] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:09:43,002] {scheduler_job.py:154} INFO - Started process (PID=68626) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:43,021] {logging_mixin.py:112} INFO - [2020-08-01 16:09:43,021] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:43,021] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:09:43,022] {logging_mixin.py:112} INFO - [2020-08-01 16:09:43,021] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:43,024] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:43,040] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:09:43,048] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:43,050] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:09:51,026] {scheduler_job.py:154} INFO - Started process (PID=68668) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:51,044] {logging_mixin.py:112} INFO - [2020-08-01 16:09:51,044] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:51,044] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:09:51,044] {logging_mixin.py:112} INFO - [2020-08-01 16:09:51,044] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:51,046] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:51,061] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:09:51,068] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:51,070] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:09:59,006] {scheduler_job.py:154} INFO - Started process (PID=68684) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:59,023] {logging_mixin.py:112} INFO - [2020-08-01 16:09:59,023] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:59,024] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:09:59,024] {logging_mixin.py:112} INFO - [2020-08-01 16:09:59,024] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:59,026] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:09:59,040] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:09:59,047] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:59,049] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:10:07,024] {scheduler_job.py:154} INFO - Started process (PID=68710) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:07,041] {logging_mixin.py:112} INFO - [2020-08-01 16:10:07,041] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:07,042] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:10:07,042] {logging_mixin.py:112} INFO - [2020-08-01 16:10:07,042] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:07,044] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:07,058] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:10:07,066] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:07,067] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:10:15,053] {scheduler_job.py:154} INFO - Started process (PID=68734) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:15,071] {logging_mixin.py:112} INFO - [2020-08-01 16:10:15,071] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:15,071] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:10:15,072] {logging_mixin.py:112} INFO - [2020-08-01 16:10:15,072] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:15,074] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:15,087] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:10:15,094] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:15,096] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:10:23,123] {scheduler_job.py:154} INFO - Started process (PID=68750) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:23,143] {logging_mixin.py:112} INFO - [2020-08-01 16:10:23,143] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:23,143] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:10:23,143] {logging_mixin.py:112} INFO - [2020-08-01 16:10:23,143] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:23,145] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:23,161] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:10:23,169] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:23,172] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:10:31,170] {scheduler_job.py:154} INFO - Started process (PID=68775) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:31,191] {logging_mixin.py:112} INFO - [2020-08-01 16:10:31,191] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:31,192] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:10:31,193] {logging_mixin.py:112} INFO - [2020-08-01 16:10:31,193] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:31,197] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:31,215] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:10:31,224] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:31,226] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.056 seconds
[2020-08-01 16:10:39,150] {scheduler_job.py:154} INFO - Started process (PID=68828) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:39,168] {logging_mixin.py:112} INFO - [2020-08-01 16:10:39,168] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:39,169] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:10:39,169] {logging_mixin.py:112} INFO - [2020-08-01 16:10:39,169] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:39,171] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:39,185] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:10:39,192] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:39,193] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:10:47,167] {scheduler_job.py:154} INFO - Started process (PID=68837) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:47,187] {logging_mixin.py:112} INFO - [2020-08-01 16:10:47,186] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:47,187] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:10:47,187] {logging_mixin.py:112} INFO - [2020-08-01 16:10:47,187] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:47,189] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:47,206] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:10:47,214] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:47,215] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:10:55,177] {scheduler_job.py:154} INFO - Started process (PID=68846) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:55,195] {logging_mixin.py:112} INFO - [2020-08-01 16:10:55,195] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:55,195] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:10:55,195] {logging_mixin.py:112} INFO - [2020-08-01 16:10:55,195] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:55,198] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:10:55,212] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:10:55,220] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:55,222] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:11:03,182] {scheduler_job.py:154} INFO - Started process (PID=68872) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:03,199] {logging_mixin.py:112} INFO - [2020-08-01 16:11:03,199] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:03,199] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:11:03,199] {logging_mixin.py:112} INFO - [2020-08-01 16:11:03,199] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:03,201] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:03,215] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:11:03,222] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:03,224] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:11:11,269] {scheduler_job.py:154} INFO - Started process (PID=68888) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:11,289] {logging_mixin.py:112} INFO - [2020-08-01 16:11:11,289] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:11,290] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:11:11,290] {logging_mixin.py:112} INFO - [2020-08-01 16:11:11,290] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:11,293] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:11,311] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:11:11,319] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:11,321] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 16:11:19,353] {scheduler_job.py:154} INFO - Started process (PID=69015) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:19,373] {logging_mixin.py:112} INFO - [2020-08-01 16:11:19,373] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:19,375] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:11:19,375] {logging_mixin.py:112} INFO - [2020-08-01 16:11:19,375] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:19,377] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:19,391] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:11:19,398] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:19,399] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:11:27,285] {scheduler_job.py:154} INFO - Started process (PID=69025) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:27,303] {logging_mixin.py:112} INFO - [2020-08-01 16:11:27,303] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:27,304] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:11:27,304] {logging_mixin.py:112} INFO - [2020-08-01 16:11:27,304] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:27,306] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:27,321] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:11:27,333] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:27,335] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.050 seconds
[2020-08-01 16:11:35,331] {scheduler_job.py:154} INFO - Started process (PID=69034) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:35,349] {logging_mixin.py:112} INFO - [2020-08-01 16:11:35,348] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:35,349] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:11:35,349] {logging_mixin.py:112} INFO - [2020-08-01 16:11:35,349] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:35,351] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:35,366] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:11:35,373] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:35,375] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:11:43,413] {scheduler_job.py:154} INFO - Started process (PID=69052) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:43,431] {logging_mixin.py:112} INFO - [2020-08-01 16:11:43,431] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:43,432] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:11:43,432] {logging_mixin.py:112} INFO - [2020-08-01 16:11:43,432] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:43,434] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:43,447] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:11:43,455] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:43,457] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:11:51,341] {scheduler_job.py:154} INFO - Started process (PID=69061) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:51,359] {logging_mixin.py:112} INFO - [2020-08-01 16:11:51,359] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:51,359] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:11:51,360] {logging_mixin.py:112} INFO - [2020-08-01 16:11:51,359] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:51,362] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:51,377] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:11:51,385] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:51,386] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:11:59,431] {scheduler_job.py:154} INFO - Started process (PID=69069) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:59,449] {logging_mixin.py:112} INFO - [2020-08-01 16:11:59,449] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:59,450] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:11:59,450] {logging_mixin.py:112} INFO - [2020-08-01 16:11:59,450] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:59,452] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:11:59,467] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:11:59,475] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:59,477] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:12:07,411] {scheduler_job.py:154} INFO - Started process (PID=69086) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:07,430] {logging_mixin.py:112} INFO - [2020-08-01 16:12:07,430] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:07,431] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:12:07,431] {logging_mixin.py:112} INFO - [2020-08-01 16:12:07,431] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:07,433] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:07,449] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:12:07,456] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:07,458] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:12:15,358] {scheduler_job.py:154} INFO - Started process (PID=69095) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:15,375] {logging_mixin.py:112} INFO - [2020-08-01 16:12:15,375] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:15,376] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:12:15,376] {logging_mixin.py:112} INFO - [2020-08-01 16:12:15,376] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:15,378] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:15,392] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:12:15,400] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:15,401] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:12:23,396] {scheduler_job.py:154} INFO - Started process (PID=69111) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:23,414] {logging_mixin.py:112} INFO - [2020-08-01 16:12:23,414] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:23,415] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:12:23,415] {logging_mixin.py:112} INFO - [2020-08-01 16:12:23,415] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:23,417] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:23,431] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:12:23,439] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:23,440] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:12:31,396] {scheduler_job.py:154} INFO - Started process (PID=69119) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:31,414] {logging_mixin.py:112} INFO - [2020-08-01 16:12:31,414] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:31,414] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:12:31,415] {logging_mixin.py:112} INFO - [2020-08-01 16:12:31,415] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:31,417] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:31,431] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:12:31,439] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:31,440] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:12:39,528] {scheduler_job.py:154} INFO - Started process (PID=69136) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:39,547] {logging_mixin.py:112} INFO - [2020-08-01 16:12:39,547] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:39,548] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:12:39,548] {logging_mixin.py:112} INFO - [2020-08-01 16:12:39,548] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:39,550] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:39,566] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:12:39,576] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:39,579] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.051 seconds
[2020-08-01 16:12:47,642] {scheduler_job.py:154} INFO - Started process (PID=69212) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:47,661] {logging_mixin.py:112} INFO - [2020-08-01 16:12:47,661] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:47,662] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:12:47,662] {logging_mixin.py:112} INFO - [2020-08-01 16:12:47,662] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:47,664] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:47,676] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:12:47,683] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:47,685] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:12:55,603] {scheduler_job.py:154} INFO - Started process (PID=69222) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:55,620] {logging_mixin.py:112} INFO - [2020-08-01 16:12:55,620] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:55,621] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:12:55,621] {logging_mixin.py:112} INFO - [2020-08-01 16:12:55,621] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:55,623] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:12:55,636] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:12:55,644] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:55,646] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:13:03,550] {scheduler_job.py:154} INFO - Started process (PID=69233) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:03,568] {logging_mixin.py:112} INFO - [2020-08-01 16:13:03,568] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:03,569] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:13:03,569] {logging_mixin.py:112} INFO - [2020-08-01 16:13:03,569] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:03,571] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:03,585] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:13:03,591] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:03,593] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:13:11,742] {scheduler_job.py:154} INFO - Started process (PID=69252) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:11,776] {logging_mixin.py:112} INFO - [2020-08-01 16:13:11,776] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:11,777] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:13:11,777] {logging_mixin.py:112} INFO - [2020-08-01 16:13:11,777] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:11,779] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:11,806] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:13:11,814] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:11,818] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.076 seconds
[2020-08-01 16:13:19,546] {scheduler_job.py:154} INFO - Started process (PID=69277) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:19,563] {logging_mixin.py:112} INFO - [2020-08-01 16:13:19,563] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:19,564] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:13:19,564] {logging_mixin.py:112} INFO - [2020-08-01 16:13:19,564] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:19,566] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:19,581] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:13:19,588] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:19,590] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:13:27,579] {scheduler_job.py:154} INFO - Started process (PID=69293) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:27,597] {logging_mixin.py:112} INFO - [2020-08-01 16:13:27,597] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:27,598] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:13:27,598] {logging_mixin.py:112} INFO - [2020-08-01 16:13:27,598] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:27,600] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:27,614] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:13:27,622] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:27,623] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:13:35,701] {scheduler_job.py:154} INFO - Started process (PID=69318) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:35,721] {logging_mixin.py:112} INFO - [2020-08-01 16:13:35,720] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:35,721] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:13:35,721] {logging_mixin.py:112} INFO - [2020-08-01 16:13:35,721] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:35,723] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:35,737] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:13:35,744] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:35,745] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:13:43,722] {scheduler_job.py:154} INFO - Started process (PID=69335) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:43,740] {logging_mixin.py:112} INFO - [2020-08-01 16:13:43,740] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:43,740] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:13:43,740] {logging_mixin.py:112} INFO - [2020-08-01 16:13:43,740] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:43,743] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:43,758] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:13:43,766] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:43,767] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:13:51,713] {scheduler_job.py:154} INFO - Started process (PID=69360) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:51,732] {logging_mixin.py:112} INFO - [2020-08-01 16:13:51,732] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:51,732] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:13:51,733] {logging_mixin.py:112} INFO - [2020-08-01 16:13:51,733] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:51,735] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:51,748] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:13:51,758] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:51,760] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:13:59,824] {scheduler_job.py:154} INFO - Started process (PID=69384) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:59,860] {logging_mixin.py:112} INFO - [2020-08-01 16:13:59,859] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:59,861] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:13:59,861] {logging_mixin.py:112} INFO - [2020-08-01 16:13:59,861] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:59,864] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:13:59,878] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:13:59,886] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:59,887] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.063 seconds
[2020-08-01 16:14:07,784] {scheduler_job.py:154} INFO - Started process (PID=69402) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:07,803] {logging_mixin.py:112} INFO - [2020-08-01 16:14:07,803] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:07,804] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:14:07,804] {logging_mixin.py:112} INFO - [2020-08-01 16:14:07,804] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:07,806] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:07,821] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:14:07,829] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:07,831] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:14:15,763] {scheduler_job.py:154} INFO - Started process (PID=69427) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:15,779] {logging_mixin.py:112} INFO - [2020-08-01 16:14:15,779] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:15,780] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:14:15,780] {logging_mixin.py:112} INFO - [2020-08-01 16:14:15,780] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:15,782] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:15,796] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:14:15,804] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:15,807] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:14:23,743] {scheduler_job.py:154} INFO - Started process (PID=69443) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:23,762] {logging_mixin.py:112} INFO - [2020-08-01 16:14:23,761] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:23,762] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:14:23,762] {logging_mixin.py:112} INFO - [2020-08-01 16:14:23,762] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:23,764] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:23,781] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:14:23,790] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:23,793] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.050 seconds
[2020-08-01 16:14:31,823] {scheduler_job.py:154} INFO - Started process (PID=69468) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:31,840] {logging_mixin.py:112} INFO - [2020-08-01 16:14:31,840] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:31,841] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:14:31,841] {logging_mixin.py:112} INFO - [2020-08-01 16:14:31,841] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:31,843] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:31,857] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:14:31,864] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:31,865] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:14:39,785] {scheduler_job.py:154} INFO - Started process (PID=69485) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:39,804] {logging_mixin.py:112} INFO - [2020-08-01 16:14:39,804] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:39,805] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:14:39,805] {logging_mixin.py:112} INFO - [2020-08-01 16:14:39,805] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:39,808] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:39,822] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:14:39,830] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:39,832] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:14:47,914] {scheduler_job.py:154} INFO - Started process (PID=69510) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:47,932] {logging_mixin.py:112} INFO - [2020-08-01 16:14:47,932] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:47,933] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:14:47,933] {logging_mixin.py:112} INFO - [2020-08-01 16:14:47,933] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:47,935] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:47,947] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:14:47,954] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:47,956] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:14:55,910] {scheduler_job.py:154} INFO - Started process (PID=69535) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:55,927] {logging_mixin.py:112} INFO - [2020-08-01 16:14:55,927] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:55,928] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:14:55,928] {logging_mixin.py:112} INFO - [2020-08-01 16:14:55,928] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:55,930] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:14:55,944] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:14:55,951] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:55,952] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:15:03,894] {scheduler_job.py:154} INFO - Started process (PID=69552) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:03,912] {logging_mixin.py:112} INFO - [2020-08-01 16:15:03,912] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:03,912] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:15:03,913] {logging_mixin.py:112} INFO - [2020-08-01 16:15:03,912] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:03,915] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:03,928] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:15:03,934] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:03,936] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:15:11,932] {scheduler_job.py:154} INFO - Started process (PID=69577) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:11,952] {logging_mixin.py:112} INFO - [2020-08-01 16:15:11,952] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:11,953] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:15:11,953] {logging_mixin.py:112} INFO - [2020-08-01 16:15:11,953] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:11,957] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:11,971] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:15:11,979] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:11,981] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:15:19,880] {scheduler_job.py:154} INFO - Started process (PID=69594) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:19,902] {logging_mixin.py:112} INFO - [2020-08-01 16:15:19,902] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:19,902] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:15:19,903] {logging_mixin.py:112} INFO - [2020-08-01 16:15:19,903] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:19,905] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:19,929] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:15:19,945] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:19,950] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.070 seconds
[2020-08-01 16:15:27,895] {scheduler_job.py:154} INFO - Started process (PID=69618) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:27,912] {logging_mixin.py:112} INFO - [2020-08-01 16:15:27,912] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:27,913] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:15:27,913] {logging_mixin.py:112} INFO - [2020-08-01 16:15:27,913] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:27,915] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:27,929] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:15:27,936] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:27,938] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:15:35,924] {scheduler_job.py:154} INFO - Started process (PID=69635) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:35,942] {logging_mixin.py:112} INFO - [2020-08-01 16:15:35,942] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:35,943] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:15:35,943] {logging_mixin.py:112} INFO - [2020-08-01 16:15:35,943] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:35,945] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:35,959] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:15:35,966] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:35,968] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:15:43,942] {scheduler_job.py:154} INFO - Started process (PID=69660) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:43,959] {logging_mixin.py:112} INFO - [2020-08-01 16:15:43,959] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:43,960] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:15:43,960] {logging_mixin.py:112} INFO - [2020-08-01 16:15:43,960] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:43,962] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:43,977] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:15:43,985] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:43,987] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:15:52,000] {scheduler_job.py:154} INFO - Started process (PID=69685) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:52,017] {logging_mixin.py:112} INFO - [2020-08-01 16:15:52,017] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:52,018] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:15:52,018] {logging_mixin.py:112} INFO - [2020-08-01 16:15:52,018] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:52,020] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:15:52,034] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:15:52,040] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:52,042] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:15:59,998] {scheduler_job.py:154} INFO - Started process (PID=69701) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:00,019] {logging_mixin.py:112} INFO - [2020-08-01 16:16:00,018] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:00,019] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:16:00,019] {logging_mixin.py:112} INFO - [2020-08-01 16:16:00,019] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:00,022] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:00,035] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:16:00,043] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:00,045] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:16:08,043] {scheduler_job.py:154} INFO - Started process (PID=69729) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:08,060] {logging_mixin.py:112} INFO - [2020-08-01 16:16:08,060] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:08,061] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:16:08,061] {logging_mixin.py:112} INFO - [2020-08-01 16:16:08,061] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:08,063] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:08,077] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:16:08,083] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:08,085] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:16:16,059] {scheduler_job.py:154} INFO - Started process (PID=69747) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:16,079] {logging_mixin.py:112} INFO - [2020-08-01 16:16:16,079] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:16,080] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:16:16,080] {logging_mixin.py:112} INFO - [2020-08-01 16:16:16,080] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:16,083] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:16,099] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:16:16,114] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:16,116] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.057 seconds
[2020-08-01 16:16:24,122] {scheduler_job.py:154} INFO - Started process (PID=69771) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:24,140] {logging_mixin.py:112} INFO - [2020-08-01 16:16:24,139] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:24,140] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:16:24,140] {logging_mixin.py:112} INFO - [2020-08-01 16:16:24,140] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:24,142] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:24,157] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:16:24,165] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:24,167] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:16:32,110] {scheduler_job.py:154} INFO - Started process (PID=69822) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:32,129] {logging_mixin.py:112} INFO - [2020-08-01 16:16:32,129] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:32,130] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:16:32,130] {logging_mixin.py:112} INFO - [2020-08-01 16:16:32,130] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:32,132] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:32,148] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:16:32,159] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:32,162] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 16:16:40,308] {scheduler_job.py:154} INFO - Started process (PID=69853) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:40,325] {logging_mixin.py:112} INFO - [2020-08-01 16:16:40,325] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:40,325] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:16:40,326] {logging_mixin.py:112} INFO - [2020-08-01 16:16:40,326] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:40,328] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:40,340] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:16:40,347] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:40,350] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:16:48,188] {scheduler_job.py:154} INFO - Started process (PID=69906) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:48,206] {logging_mixin.py:112} INFO - [2020-08-01 16:16:48,206] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:48,207] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:16:48,207] {logging_mixin.py:112} INFO - [2020-08-01 16:16:48,207] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:48,209] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:48,222] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:16:48,230] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:48,231] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:16:56,190] {scheduler_job.py:154} INFO - Started process (PID=69931) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:56,206] {logging_mixin.py:112} INFO - [2020-08-01 16:16:56,206] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:56,207] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:16:56,207] {logging_mixin.py:112} INFO - [2020-08-01 16:16:56,207] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:56,209] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:16:56,223] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:16:56,231] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:56,233] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:17:04,179] {scheduler_job.py:154} INFO - Started process (PID=69941) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:04,197] {logging_mixin.py:112} INFO - [2020-08-01 16:17:04,197] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:04,198] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:17:04,198] {logging_mixin.py:112} INFO - [2020-08-01 16:17:04,198] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:04,200] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:04,215] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:17:04,222] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:04,224] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:17:12,349] {scheduler_job.py:154} INFO - Started process (PID=69954) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:12,367] {logging_mixin.py:112} INFO - [2020-08-01 16:17:12,367] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:12,368] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:17:12,368] {logging_mixin.py:112} INFO - [2020-08-01 16:17:12,368] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:12,370] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:12,385] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:17:12,392] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:12,394] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:17:20,458] {scheduler_job.py:154} INFO - Started process (PID=69975) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:20,477] {logging_mixin.py:112} INFO - [2020-08-01 16:17:20,477] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:20,478] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:17:20,478] {logging_mixin.py:112} INFO - [2020-08-01 16:17:20,478] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:20,480] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:20,493] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:17:20,499] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:20,500] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:17:28,254] {scheduler_job.py:154} INFO - Started process (PID=69999) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:28,272] {logging_mixin.py:112} INFO - [2020-08-01 16:17:28,272] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:28,272] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:17:28,272] {logging_mixin.py:112} INFO - [2020-08-01 16:17:28,272] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:28,275] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:28,289] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:17:28,298] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:28,300] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:17:36,298] {scheduler_job.py:154} INFO - Started process (PID=70018) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:36,317] {logging_mixin.py:112} INFO - [2020-08-01 16:17:36,317] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:36,318] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:17:36,318] {logging_mixin.py:112} INFO - [2020-08-01 16:17:36,318] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:36,320] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:36,336] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:17:36,345] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:36,347] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:17:44,339] {scheduler_job.py:154} INFO - Started process (PID=70111) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:44,357] {logging_mixin.py:112} INFO - [2020-08-01 16:17:44,357] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:44,358] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:17:44,358] {logging_mixin.py:112} INFO - [2020-08-01 16:17:44,358] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:44,360] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:44,374] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:17:44,384] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:44,386] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:17:52,356] {scheduler_job.py:154} INFO - Started process (PID=70122) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:52,374] {logging_mixin.py:112} INFO - [2020-08-01 16:17:52,374] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:52,375] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:17:52,375] {logging_mixin.py:112} INFO - [2020-08-01 16:17:52,375] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:52,377] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:17:52,393] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:17:52,400] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:52,402] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:18:00,346] {scheduler_job.py:154} INFO - Started process (PID=70138) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:00,363] {logging_mixin.py:112} INFO - [2020-08-01 16:18:00,363] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:00,364] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:18:00,364] {logging_mixin.py:112} INFO - [2020-08-01 16:18:00,364] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:00,366] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:00,380] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:18:00,387] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:00,389] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:18:08,344] {scheduler_job.py:154} INFO - Started process (PID=70147) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:08,362] {logging_mixin.py:112} INFO - [2020-08-01 16:18:08,361] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:08,362] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:18:08,362] {logging_mixin.py:112} INFO - [2020-08-01 16:18:08,362] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:08,364] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:08,379] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:18:08,387] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:08,388] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:18:16,342] {scheduler_job.py:154} INFO - Started process (PID=70156) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:16,359] {logging_mixin.py:112} INFO - [2020-08-01 16:18:16,359] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:16,360] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:18:16,360] {logging_mixin.py:112} INFO - [2020-08-01 16:18:16,360] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:16,362] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:16,376] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:18:16,384] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:16,386] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:18:24,368] {scheduler_job.py:154} INFO - Started process (PID=70164) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:24,386] {logging_mixin.py:112} INFO - [2020-08-01 16:18:24,386] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:24,386] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:18:24,387] {logging_mixin.py:112} INFO - [2020-08-01 16:18:24,387] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:24,389] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:24,403] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:18:24,410] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:24,412] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:18:32,398] {scheduler_job.py:154} INFO - Started process (PID=70180) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:32,416] {logging_mixin.py:112} INFO - [2020-08-01 16:18:32,416] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:32,417] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:18:32,417] {logging_mixin.py:112} INFO - [2020-08-01 16:18:32,417] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:32,419] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:32,432] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:18:32,440] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:32,441] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:18:40,412] {scheduler_job.py:154} INFO - Started process (PID=70204) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:40,430] {logging_mixin.py:112} INFO - [2020-08-01 16:18:40,429] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:40,430] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:18:40,431] {logging_mixin.py:112} INFO - [2020-08-01 16:18:40,431] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:40,433] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:40,447] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:18:40,454] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:40,456] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:18:48,447] {scheduler_job.py:154} INFO - Started process (PID=70222) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:48,465] {logging_mixin.py:112} INFO - [2020-08-01 16:18:48,465] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:48,466] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:18:48,466] {logging_mixin.py:112} INFO - [2020-08-01 16:18:48,466] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:48,468] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:48,480] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:18:48,487] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:48,489] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 16:18:56,458] {scheduler_job.py:154} INFO - Started process (PID=70246) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:56,475] {logging_mixin.py:112} INFO - [2020-08-01 16:18:56,475] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:56,476] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:18:56,476] {logging_mixin.py:112} INFO - [2020-08-01 16:18:56,476] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:56,478] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:18:56,492] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:18:56,500] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:56,501] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:19:04,513] {scheduler_job.py:154} INFO - Started process (PID=70262) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:04,531] {logging_mixin.py:112} INFO - [2020-08-01 16:19:04,530] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:04,531] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:19:04,531] {logging_mixin.py:112} INFO - [2020-08-01 16:19:04,531] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:04,533] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:04,548] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:19:04,555] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:04,557] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:19:12,534] {scheduler_job.py:154} INFO - Started process (PID=70286) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:12,552] {logging_mixin.py:112} INFO - [2020-08-01 16:19:12,552] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:12,552] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:19:12,552] {logging_mixin.py:112} INFO - [2020-08-01 16:19:12,552] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:12,555] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:12,569] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:19:12,576] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:12,577] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:19:20,563] {scheduler_job.py:154} INFO - Started process (PID=70312) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:20,581] {logging_mixin.py:112} INFO - [2020-08-01 16:19:20,580] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:20,581] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:19:20,581] {logging_mixin.py:112} INFO - [2020-08-01 16:19:20,581] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:20,583] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:20,597] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:19:20,604] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:20,606] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:19:28,660] {scheduler_job.py:154} INFO - Started process (PID=70328) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:28,677] {logging_mixin.py:112} INFO - [2020-08-01 16:19:28,677] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:28,678] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:19:28,678] {logging_mixin.py:112} INFO - [2020-08-01 16:19:28,678] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:28,680] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:28,694] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:19:28,702] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:28,704] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:19:36,652] {scheduler_job.py:154} INFO - Started process (PID=70364) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:36,669] {logging_mixin.py:112} INFO - [2020-08-01 16:19:36,669] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:36,670] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:19:36,670] {logging_mixin.py:112} INFO - [2020-08-01 16:19:36,670] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:36,672] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:36,686] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:19:36,692] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:36,693] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 16:19:44,941] {scheduler_job.py:154} INFO - Started process (PID=70397) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:44,963] {logging_mixin.py:112} INFO - [2020-08-01 16:19:44,963] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:44,963] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:19:44,963] {logging_mixin.py:112} INFO - [2020-08-01 16:19:44,963] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:44,968] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:44,983] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:19:44,993] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:44,994] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.054 seconds
[2020-08-01 16:19:52,909] {scheduler_job.py:154} INFO - Started process (PID=70415) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:52,933] {logging_mixin.py:112} INFO - [2020-08-01 16:19:52,933] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:52,934] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:19:52,934] {logging_mixin.py:112} INFO - [2020-08-01 16:19:52,934] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:52,937] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:19:52,959] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:19:52,969] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:52,970] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.061 seconds
[2020-08-01 16:20:00,687] {scheduler_job.py:154} INFO - Started process (PID=70423) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:00,706] {logging_mixin.py:112} INFO - [2020-08-01 16:20:00,705] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:00,706] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:20:00,706] {logging_mixin.py:112} INFO - [2020-08-01 16:20:00,706] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:00,709] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:00,722] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:20:00,729] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:00,730] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:20:08,712] {scheduler_job.py:154} INFO - Started process (PID=70431) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:08,730] {logging_mixin.py:112} INFO - [2020-08-01 16:20:08,730] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:08,730] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:20:08,731] {logging_mixin.py:112} INFO - [2020-08-01 16:20:08,731] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:08,733] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:08,747] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:20:08,755] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:08,756] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:20:16,779] {scheduler_job.py:154} INFO - Started process (PID=70440) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:16,797] {logging_mixin.py:112} INFO - [2020-08-01 16:20:16,797] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:16,797] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:20:16,798] {logging_mixin.py:112} INFO - [2020-08-01 16:20:16,798] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:16,800] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:16,814] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:20:16,821] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:16,822] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:20:24,770] {scheduler_job.py:154} INFO - Started process (PID=70448) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:24,788] {logging_mixin.py:112} INFO - [2020-08-01 16:20:24,788] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:24,789] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:20:24,789] {logging_mixin.py:112} INFO - [2020-08-01 16:20:24,789] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:24,791] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:24,804] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:20:24,811] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:24,812] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:20:32,808] {scheduler_job.py:154} INFO - Started process (PID=70456) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:32,826] {logging_mixin.py:112} INFO - [2020-08-01 16:20:32,826] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:32,827] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:20:32,827] {logging_mixin.py:112} INFO - [2020-08-01 16:20:32,827] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:32,829] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:32,843] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:20:32,851] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:32,853] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:20:40,839] {scheduler_job.py:154} INFO - Started process (PID=70464) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:40,857] {logging_mixin.py:112} INFO - [2020-08-01 16:20:40,856] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:40,857] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:20:40,857] {logging_mixin.py:112} INFO - [2020-08-01 16:20:40,857] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:40,859] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:40,873] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:20:40,881] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:40,883] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:20:48,895] {scheduler_job.py:154} INFO - Started process (PID=70473) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:48,912] {logging_mixin.py:112} INFO - [2020-08-01 16:20:48,912] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:48,913] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:20:48,913] {logging_mixin.py:112} INFO - [2020-08-01 16:20:48,913] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:48,915] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:48,929] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:20:48,937] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:48,939] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:20:56,965] {scheduler_job.py:154} INFO - Started process (PID=70489) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:56,984] {logging_mixin.py:112} INFO - [2020-08-01 16:20:56,983] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:56,984] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:20:56,984] {logging_mixin.py:112} INFO - [2020-08-01 16:20:56,984] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:56,986] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:20:57,000] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:20:57,007] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:57,008] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:21:04,932] {scheduler_job.py:154} INFO - Started process (PID=70513) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:04,949] {logging_mixin.py:112} INFO - [2020-08-01 16:21:04,949] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:04,950] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:21:04,950] {logging_mixin.py:112} INFO - [2020-08-01 16:21:04,950] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:04,952] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:04,967] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:21:04,974] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:04,976] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:21:12,992] {scheduler_job.py:154} INFO - Started process (PID=70529) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:13,010] {logging_mixin.py:112} INFO - [2020-08-01 16:21:13,010] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:13,010] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:21:13,010] {logging_mixin.py:112} INFO - [2020-08-01 16:21:13,010] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:13,013] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:13,027] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:21:13,036] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:13,037] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:21:21,008] {scheduler_job.py:154} INFO - Started process (PID=70554) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:21,025] {logging_mixin.py:112} INFO - [2020-08-01 16:21:21,025] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:21,026] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:21:21,026] {logging_mixin.py:112} INFO - [2020-08-01 16:21:21,026] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:21,028] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:21,042] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:21:21,050] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:21,051] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:21:29,031] {scheduler_job.py:154} INFO - Started process (PID=70578) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:29,048] {logging_mixin.py:112} INFO - [2020-08-01 16:21:29,048] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:29,049] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:21:29,049] {logging_mixin.py:112} INFO - [2020-08-01 16:21:29,049] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:29,051] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:29,066] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:21:29,072] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:29,074] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:21:37,049] {scheduler_job.py:154} INFO - Started process (PID=70594) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:37,068] {logging_mixin.py:112} INFO - [2020-08-01 16:21:37,067] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:37,068] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:21:37,068] {logging_mixin.py:112} INFO - [2020-08-01 16:21:37,068] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:37,070] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:37,085] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:21:37,093] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:37,095] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:21:45,061] {scheduler_job.py:154} INFO - Started process (PID=70618) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:45,078] {logging_mixin.py:112} INFO - [2020-08-01 16:21:45,078] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:45,079] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:21:45,079] {logging_mixin.py:112} INFO - [2020-08-01 16:21:45,079] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:45,081] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:45,096] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:21:45,105] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:45,106] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:21:53,087] {scheduler_job.py:154} INFO - Started process (PID=70635) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:53,106] {logging_mixin.py:112} INFO - [2020-08-01 16:21:53,106] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:53,107] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:21:53,108] {logging_mixin.py:112} INFO - [2020-08-01 16:21:53,108] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:53,110] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:21:53,126] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:21:53,133] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:53,135] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:22:01,137] {scheduler_job.py:154} INFO - Started process (PID=70659) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:01,155] {logging_mixin.py:112} INFO - [2020-08-01 16:22:01,155] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:01,156] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:22:01,156] {logging_mixin.py:112} INFO - [2020-08-01 16:22:01,156] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:01,158] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:01,173] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:22:01,180] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:01,182] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:22:09,130] {scheduler_job.py:154} INFO - Started process (PID=70680) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:09,147] {logging_mixin.py:112} INFO - [2020-08-01 16:22:09,147] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:09,148] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:22:09,148] {logging_mixin.py:112} INFO - [2020-08-01 16:22:09,148] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:09,150] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:09,164] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:22:09,172] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:09,174] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:22:17,174] {scheduler_job.py:154} INFO - Started process (PID=70700) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:17,195] {logging_mixin.py:112} INFO - [2020-08-01 16:22:17,195] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:17,196] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:22:17,196] {logging_mixin.py:112} INFO - [2020-08-01 16:22:17,196] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:17,198] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:17,211] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:22:17,218] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:17,220] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:22:25,180] {scheduler_job.py:154} INFO - Started process (PID=70725) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:25,198] {logging_mixin.py:112} INFO - [2020-08-01 16:22:25,198] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:25,199] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:22:25,199] {logging_mixin.py:112} INFO - [2020-08-01 16:22:25,199] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:25,201] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:25,215] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:22:25,222] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:25,224] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:22:33,287] {scheduler_job.py:154} INFO - Started process (PID=70742) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:33,305] {logging_mixin.py:112} INFO - [2020-08-01 16:22:33,305] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:33,306] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:22:33,306] {logging_mixin.py:112} INFO - [2020-08-01 16:22:33,306] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:33,308] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:33,323] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:22:33,331] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:33,332] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:22:41,270] {scheduler_job.py:154} INFO - Started process (PID=70766) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:41,287] {logging_mixin.py:112} INFO - [2020-08-01 16:22:41,287] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:41,288] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:22:41,288] {logging_mixin.py:112} INFO - [2020-08-01 16:22:41,288] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:41,290] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:41,304] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:22:41,311] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:41,313] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:22:49,460] {scheduler_job.py:154} INFO - Started process (PID=70784) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:49,478] {logging_mixin.py:112} INFO - [2020-08-01 16:22:49,477] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:49,478] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:22:49,478] {logging_mixin.py:112} INFO - [2020-08-01 16:22:49,478] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:49,480] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:49,496] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:22:49,505] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:49,507] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:22:57,294] {scheduler_job.py:154} INFO - Started process (PID=70808) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:57,313] {logging_mixin.py:112} INFO - [2020-08-01 16:22:57,313] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:57,314] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:22:57,314] {logging_mixin.py:112} INFO - [2020-08-01 16:22:57,314] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:57,317] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:22:57,335] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:22:57,342] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:57,344] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.050 seconds
[2020-08-01 16:23:05,313] {scheduler_job.py:154} INFO - Started process (PID=70884) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:05,331] {logging_mixin.py:112} INFO - [2020-08-01 16:23:05,330] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:05,331] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:23:05,331] {logging_mixin.py:112} INFO - [2020-08-01 16:23:05,331] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:05,333] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:05,347] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:23:05,355] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:05,357] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:23:13,287] {scheduler_job.py:154} INFO - Started process (PID=70911) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:13,304] {logging_mixin.py:112} INFO - [2020-08-01 16:23:13,304] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:13,305] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:23:13,305] {logging_mixin.py:112} INFO - [2020-08-01 16:23:13,305] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:13,307] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:13,321] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:23:13,329] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:13,330] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:23:21,391] {scheduler_job.py:154} INFO - Started process (PID=70936) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:21,409] {logging_mixin.py:112} INFO - [2020-08-01 16:23:21,409] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:21,409] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:23:21,410] {logging_mixin.py:112} INFO - [2020-08-01 16:23:21,410] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:21,412] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:21,427] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:23:21,435] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:21,436] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:23:29,446] {scheduler_job.py:154} INFO - Started process (PID=70980) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:29,464] {logging_mixin.py:112} INFO - [2020-08-01 16:23:29,464] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:29,465] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:23:29,465] {logging_mixin.py:112} INFO - [2020-08-01 16:23:29,465] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:29,467] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:29,482] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:23:29,489] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:29,490] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:23:37,422] {scheduler_job.py:154} INFO - Started process (PID=70991) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:37,439] {logging_mixin.py:112} INFO - [2020-08-01 16:23:37,439] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:37,440] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:23:37,440] {logging_mixin.py:112} INFO - [2020-08-01 16:23:37,440] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:37,442] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:37,455] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:23:37,463] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:37,465] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:23:45,432] {scheduler_job.py:154} INFO - Started process (PID=70999) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:45,450] {logging_mixin.py:112} INFO - [2020-08-01 16:23:45,449] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:45,450] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:23:45,450] {logging_mixin.py:112} INFO - [2020-08-01 16:23:45,450] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:45,452] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:45,465] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:23:45,473] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:45,475] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:23:53,580] {scheduler_job.py:154} INFO - Started process (PID=71016) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:53,598] {logging_mixin.py:112} INFO - [2020-08-01 16:23:53,598] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:53,599] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:23:53,599] {logging_mixin.py:112} INFO - [2020-08-01 16:23:53,599] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:53,602] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:23:53,615] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:23:53,623] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:53,625] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:24:01,443] {scheduler_job.py:154} INFO - Started process (PID=71043) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:01,461] {logging_mixin.py:112} INFO - [2020-08-01 16:24:01,461] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:01,461] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:24:01,462] {logging_mixin.py:112} INFO - [2020-08-01 16:24:01,462] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:01,464] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:01,478] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:24:01,485] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:01,487] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:24:09,467] {scheduler_job.py:154} INFO - Started process (PID=71059) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:09,485] {logging_mixin.py:112} INFO - [2020-08-01 16:24:09,484] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:09,485] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:24:09,485] {logging_mixin.py:112} INFO - [2020-08-01 16:24:09,485] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:09,487] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:09,503] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:24:09,509] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:09,511] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:24:17,501] {scheduler_job.py:154} INFO - Started process (PID=71083) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:17,519] {logging_mixin.py:112} INFO - [2020-08-01 16:24:17,518] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:17,519] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:24:17,519] {logging_mixin.py:112} INFO - [2020-08-01 16:24:17,519] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:17,521] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:17,536] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:24:17,543] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:17,545] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:24:25,543] {scheduler_job.py:154} INFO - Started process (PID=71100) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:25,560] {logging_mixin.py:112} INFO - [2020-08-01 16:24:25,560] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:25,561] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:24:25,561] {logging_mixin.py:112} INFO - [2020-08-01 16:24:25,561] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:25,563] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:25,578] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:24:25,586] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:25,587] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:24:33,543] {scheduler_job.py:154} INFO - Started process (PID=71108) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:33,561] {logging_mixin.py:112} INFO - [2020-08-01 16:24:33,561] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:33,561] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:24:33,562] {logging_mixin.py:112} INFO - [2020-08-01 16:24:33,562] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:33,564] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:33,578] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:24:33,585] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:33,587] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:24:41,718] {scheduler_job.py:154} INFO - Started process (PID=71116) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:41,741] {logging_mixin.py:112} INFO - [2020-08-01 16:24:41,740] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:41,741] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:24:41,741] {logging_mixin.py:112} INFO - [2020-08-01 16:24:41,741] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:41,743] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:41,758] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:24:41,765] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:41,767] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:24:49,617] {scheduler_job.py:154} INFO - Started process (PID=71141) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:49,635] {logging_mixin.py:112} INFO - [2020-08-01 16:24:49,635] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:49,636] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:24:49,636] {logging_mixin.py:112} INFO - [2020-08-01 16:24:49,636] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:49,638] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:49,653] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:24:49,663] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:49,665] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:24:57,667] {scheduler_job.py:154} INFO - Started process (PID=71158) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:57,685] {logging_mixin.py:112} INFO - [2020-08-01 16:24:57,684] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:57,685] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:24:57,685] {logging_mixin.py:112} INFO - [2020-08-01 16:24:57,685] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:57,687] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:24:57,702] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:24:57,711] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:57,714] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:25:05,789] {scheduler_job.py:154} INFO - Started process (PID=71183) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:05,807] {logging_mixin.py:112} INFO - [2020-08-01 16:25:05,807] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:05,808] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:25:05,808] {logging_mixin.py:112} INFO - [2020-08-01 16:25:05,808] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:05,810] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:05,823] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:25:05,829] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:05,831] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:25:13,775] {scheduler_job.py:154} INFO - Started process (PID=71207) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:13,793] {logging_mixin.py:112} INFO - [2020-08-01 16:25:13,793] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:13,793] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:25:13,794] {logging_mixin.py:112} INFO - [2020-08-01 16:25:13,793] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:13,795] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:13,809] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:25:13,816] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:13,818] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:25:21,923] {scheduler_job.py:154} INFO - Started process (PID=71269) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:21,946] {logging_mixin.py:112} INFO - [2020-08-01 16:25:21,946] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:21,947] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:25:21,947] {logging_mixin.py:112} INFO - [2020-08-01 16:25:21,947] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:21,950] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:21,966] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:25:21,979] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:21,982] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.059 seconds
[2020-08-01 16:25:29,744] {scheduler_job.py:154} INFO - Started process (PID=71280) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:29,762] {logging_mixin.py:112} INFO - [2020-08-01 16:25:29,762] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:29,762] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:25:29,762] {logging_mixin.py:112} INFO - [2020-08-01 16:25:29,762] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:29,765] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:29,780] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:25:29,788] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:29,790] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:25:37,817] {scheduler_job.py:154} INFO - Started process (PID=71289) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:37,834] {logging_mixin.py:112} INFO - [2020-08-01 16:25:37,833] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:37,834] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:25:37,834] {logging_mixin.py:112} INFO - [2020-08-01 16:25:37,834] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:37,836] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:37,849] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:25:37,856] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:37,858] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 16:25:45,828] {scheduler_job.py:154} INFO - Started process (PID=71297) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:45,845] {logging_mixin.py:112} INFO - [2020-08-01 16:25:45,845] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:45,846] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:25:45,846] {logging_mixin.py:112} INFO - [2020-08-01 16:25:45,846] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:45,848] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:45,862] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:25:45,869] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:45,871] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:25:53,834] {scheduler_job.py:154} INFO - Started process (PID=71307) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:53,852] {logging_mixin.py:112} INFO - [2020-08-01 16:25:53,851] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:53,852] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:25:53,852] {logging_mixin.py:112} INFO - [2020-08-01 16:25:53,852] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:53,854] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:25:53,869] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:25:53,876] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:53,877] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:26:01,862] {scheduler_job.py:154} INFO - Started process (PID=71315) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:01,880] {logging_mixin.py:112} INFO - [2020-08-01 16:26:01,880] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:01,880] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:26:01,880] {logging_mixin.py:112} INFO - [2020-08-01 16:26:01,880] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:01,882] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:01,898] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:26:01,906] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:01,907] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:26:09,948] {scheduler_job.py:154} INFO - Started process (PID=71342) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:09,975] {logging_mixin.py:112} INFO - [2020-08-01 16:26:09,975] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:09,976] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:26:09,976] {logging_mixin.py:112} INFO - [2020-08-01 16:26:09,976] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:09,981] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:09,995] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:26:10,001] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:10,003] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.055 seconds
[2020-08-01 16:26:18,222] {scheduler_job.py:154} INFO - Started process (PID=71404) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:18,245] {logging_mixin.py:112} INFO - [2020-08-01 16:26:18,244] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:18,245] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:26:18,246] {logging_mixin.py:112} INFO - [2020-08-01 16:26:18,246] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:18,248] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:18,259] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:26:18,268] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:18,271] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:26:25,966] {scheduler_job.py:154} INFO - Started process (PID=71415) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:25,983] {logging_mixin.py:112} INFO - [2020-08-01 16:26:25,983] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:25,984] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:26:25,984] {logging_mixin.py:112} INFO - [2020-08-01 16:26:25,984] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:25,986] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:25,999] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:26:26,006] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:26,008] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:26:33,976] {scheduler_job.py:154} INFO - Started process (PID=71423) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:33,993] {logging_mixin.py:112} INFO - [2020-08-01 16:26:33,993] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:33,994] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:26:33,994] {logging_mixin.py:112} INFO - [2020-08-01 16:26:33,994] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:33,996] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:34,010] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:26:34,016] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:34,018] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:26:42,485] {scheduler_job.py:154} INFO - Started process (PID=71435) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:42,507] {logging_mixin.py:112} INFO - [2020-08-01 16:26:42,507] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:42,508] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:26:42,508] {logging_mixin.py:112} INFO - [2020-08-01 16:26:42,508] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:42,511] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:42,529] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:26:42,537] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:42,539] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.054 seconds
[2020-08-01 16:26:50,536] {scheduler_job.py:154} INFO - Started process (PID=71444) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:50,566] {logging_mixin.py:112} INFO - [2020-08-01 16:26:50,566] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:50,567] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:26:50,567] {logging_mixin.py:112} INFO - [2020-08-01 16:26:50,567] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:50,570] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:50,587] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:26:50,597] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:50,600] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.063 seconds
[2020-08-01 16:26:58,558] {scheduler_job.py:154} INFO - Started process (PID=71453) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:58,586] {logging_mixin.py:112} INFO - [2020-08-01 16:26:58,586] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:58,587] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:26:58,587] {logging_mixin.py:112} INFO - [2020-08-01 16:26:58,587] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:58,590] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:26:58,609] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:26:58,620] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:58,622] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.064 seconds
[2020-08-01 16:27:06,642] {scheduler_job.py:154} INFO - Started process (PID=71461) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:06,672] {logging_mixin.py:112} INFO - [2020-08-01 16:27:06,672] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:06,673] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:27:06,673] {logging_mixin.py:112} INFO - [2020-08-01 16:27:06,673] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:06,676] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:06,694] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:27:06,706] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:06,709] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.067 seconds
[2020-08-01 16:27:14,652] {scheduler_job.py:154} INFO - Started process (PID=71469) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:14,680] {logging_mixin.py:112} INFO - [2020-08-01 16:27:14,680] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:14,681] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:27:14,681] {logging_mixin.py:112} INFO - [2020-08-01 16:27:14,681] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:14,684] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:14,702] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:27:14,712] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:14,715] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.062 seconds
[2020-08-01 16:27:22,680] {scheduler_job.py:154} INFO - Started process (PID=71477) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:22,708] {logging_mixin.py:112} INFO - [2020-08-01 16:27:22,708] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:22,709] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:27:22,709] {logging_mixin.py:112} INFO - [2020-08-01 16:27:22,709] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:22,712] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:22,730] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:27:22,738] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:22,740] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.060 seconds
[2020-08-01 16:27:30,257] {scheduler_job.py:154} INFO - Started process (PID=71487) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:30,284] {logging_mixin.py:112} INFO - [2020-08-01 16:27:30,284] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:30,284] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:27:30,285] {logging_mixin.py:112} INFO - [2020-08-01 16:27:30,285] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:30,288] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:30,300] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:27:30,308] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:30,309] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 16:27:39,020] {scheduler_job.py:154} INFO - Started process (PID=71497) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:39,049] {logging_mixin.py:112} INFO - [2020-08-01 16:27:39,049] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:39,050] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:27:39,050] {logging_mixin.py:112} INFO - [2020-08-01 16:27:39,050] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:39,053] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:39,071] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:27:39,081] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:39,083] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.063 seconds
[2020-08-01 16:27:46,394] {scheduler_job.py:154} INFO - Started process (PID=71505) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:46,411] {logging_mixin.py:112} INFO - [2020-08-01 16:27:46,411] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:46,411] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:27:46,412] {logging_mixin.py:112} INFO - [2020-08-01 16:27:46,412] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:46,414] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:46,429] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:27:46,435] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:46,437] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:27:54,309] {scheduler_job.py:154} INFO - Started process (PID=71513) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:54,329] {logging_mixin.py:112} INFO - [2020-08-01 16:27:54,329] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:54,329] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:27:54,329] {logging_mixin.py:112} INFO - [2020-08-01 16:27:54,329] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:54,332] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:27:54,346] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:27:54,353] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:54,355] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:28:02,418] {scheduler_job.py:154} INFO - Started process (PID=71539) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:02,436] {logging_mixin.py:112} INFO - [2020-08-01 16:28:02,436] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:02,437] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:28:02,437] {logging_mixin.py:112} INFO - [2020-08-01 16:28:02,437] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:02,439] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:02,453] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:28:02,460] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:02,462] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:28:10,547] {scheduler_job.py:154} INFO - Started process (PID=71600) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:10,574] {logging_mixin.py:112} INFO - [2020-08-01 16:28:10,574] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:10,575] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:28:10,575] {logging_mixin.py:112} INFO - [2020-08-01 16:28:10,575] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:10,577] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:10,600] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:28:10,610] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:10,612] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.065 seconds
[2020-08-01 16:28:18,399] {scheduler_job.py:154} INFO - Started process (PID=71609) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:18,417] {logging_mixin.py:112} INFO - [2020-08-01 16:28:18,417] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:18,418] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:28:18,418] {logging_mixin.py:112} INFO - [2020-08-01 16:28:18,418] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:18,420] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:18,431] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:28:18,438] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:18,440] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.040 seconds
[2020-08-01 16:28:26,569] {scheduler_job.py:154} INFO - Started process (PID=71626) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:26,591] {logging_mixin.py:112} INFO - [2020-08-01 16:28:26,590] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:26,592] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:28:26,592] {logging_mixin.py:112} INFO - [2020-08-01 16:28:26,592] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:26,595] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:26,612] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:28:26,630] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:26,634] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.065 seconds
[2020-08-01 16:28:34,377] {scheduler_job.py:154} INFO - Started process (PID=71653) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:34,395] {logging_mixin.py:112} INFO - [2020-08-01 16:28:34,394] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:34,395] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:28:34,395] {logging_mixin.py:112} INFO - [2020-08-01 16:28:34,395] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:34,397] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:34,412] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:28:34,419] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:34,421] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:28:42,478] {scheduler_job.py:154} INFO - Started process (PID=71669) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:42,496] {logging_mixin.py:112} INFO - [2020-08-01 16:28:42,496] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:42,497] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:28:42,497] {logging_mixin.py:112} INFO - [2020-08-01 16:28:42,497] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:42,499] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:42,513] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:28:42,520] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:42,521] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:28:50,450] {scheduler_job.py:154} INFO - Started process (PID=71693) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:50,468] {logging_mixin.py:112} INFO - [2020-08-01 16:28:50,468] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:50,469] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:28:50,469] {logging_mixin.py:112} INFO - [2020-08-01 16:28:50,469] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:50,471] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:50,485] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:28:50,492] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:50,494] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:28:58,475] {scheduler_job.py:154} INFO - Started process (PID=71720) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:58,492] {logging_mixin.py:112} INFO - [2020-08-01 16:28:58,492] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:58,493] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:28:58,493] {logging_mixin.py:112} INFO - [2020-08-01 16:28:58,493] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:58,495] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:28:58,509] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:28:58,516] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:58,517] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:29:06,488] {scheduler_job.py:154} INFO - Started process (PID=71736) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:06,506] {logging_mixin.py:112} INFO - [2020-08-01 16:29:06,506] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:06,507] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:29:06,507] {logging_mixin.py:112} INFO - [2020-08-01 16:29:06,507] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:06,509] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:06,523] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:29:06,531] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:06,532] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:29:14,533] {scheduler_job.py:154} INFO - Started process (PID=71760) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:14,550] {logging_mixin.py:112} INFO - [2020-08-01 16:29:14,550] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:14,551] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:29:14,551] {logging_mixin.py:112} INFO - [2020-08-01 16:29:14,551] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:14,553] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:14,567] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:29:14,575] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:14,577] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:29:22,590] {scheduler_job.py:154} INFO - Started process (PID=71778) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:22,608] {logging_mixin.py:112} INFO - [2020-08-01 16:29:22,608] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:22,609] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:29:22,609] {logging_mixin.py:112} INFO - [2020-08-01 16:29:22,609] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:22,611] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:22,626] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:29:22,633] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:22,635] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:29:30,591] {scheduler_job.py:154} INFO - Started process (PID=71803) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:30,608] {logging_mixin.py:112} INFO - [2020-08-01 16:29:30,608] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:30,609] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:29:30,609] {logging_mixin.py:112} INFO - [2020-08-01 16:29:30,609] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:30,611] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:30,625] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:29:30,632] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:30,634] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:29:38,636] {scheduler_job.py:154} INFO - Started process (PID=71819) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:38,655] {logging_mixin.py:112} INFO - [2020-08-01 16:29:38,654] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:38,655] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:29:38,656] {logging_mixin.py:112} INFO - [2020-08-01 16:29:38,656] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:38,658] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:38,674] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:29:38,681] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:38,683] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:29:46,627] {scheduler_job.py:154} INFO - Started process (PID=71843) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:46,645] {logging_mixin.py:112} INFO - [2020-08-01 16:29:46,645] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:46,645] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:29:46,646] {logging_mixin.py:112} INFO - [2020-08-01 16:29:46,645] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:46,648] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:46,662] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:29:46,669] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:46,670] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:29:54,661] {scheduler_job.py:154} INFO - Started process (PID=71867) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:54,679] {logging_mixin.py:112} INFO - [2020-08-01 16:29:54,679] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:54,680] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:29:54,680] {logging_mixin.py:112} INFO - [2020-08-01 16:29:54,680] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:54,682] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:29:54,696] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:29:54,703] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:54,705] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:30:02,694] {scheduler_job.py:154} INFO - Started process (PID=71885) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:02,711] {logging_mixin.py:112} INFO - [2020-08-01 16:30:02,711] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:02,712] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:30:02,712] {logging_mixin.py:112} INFO - [2020-08-01 16:30:02,712] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:02,714] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:02,728] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:30:02,736] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:02,738] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:30:10,721] {scheduler_job.py:154} INFO - Started process (PID=71909) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:10,739] {logging_mixin.py:112} INFO - [2020-08-01 16:30:10,739] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:10,740] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:30:10,740] {logging_mixin.py:112} INFO - [2020-08-01 16:30:10,740] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:10,742] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:10,756] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:30:10,764] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:10,765] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:30:18,772] {scheduler_job.py:154} INFO - Started process (PID=71925) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:18,790] {logging_mixin.py:112} INFO - [2020-08-01 16:30:18,789] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:18,790] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:30:18,790] {logging_mixin.py:112} INFO - [2020-08-01 16:30:18,790] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:18,792] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:18,807] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:30:18,815] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:18,817] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:30:26,795] {scheduler_job.py:154} INFO - Started process (PID=71941) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:26,813] {logging_mixin.py:112} INFO - [2020-08-01 16:30:26,813] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:26,813] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:30:26,814] {logging_mixin.py:112} INFO - [2020-08-01 16:30:26,814] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:26,816] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:26,830] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:30:26,838] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:26,840] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:30:35,104] {scheduler_job.py:154} INFO - Started process (PID=71951) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:35,131] {logging_mixin.py:112} INFO - [2020-08-01 16:30:35,131] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:35,132] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:30:35,132] {logging_mixin.py:112} INFO - [2020-08-01 16:30:35,132] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:35,135] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:35,151] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:30:35,160] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:35,162] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.058 seconds
[2020-08-01 16:30:43,414] {scheduler_job.py:154} INFO - Started process (PID=71961) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:43,443] {logging_mixin.py:112} INFO - [2020-08-01 16:30:43,442] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:43,444] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:30:43,444] {logging_mixin.py:112} INFO - [2020-08-01 16:30:43,444] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:43,447] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:43,466] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:30:43,475] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:43,478] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.064 seconds
[2020-08-01 16:30:51,415] {scheduler_job.py:154} INFO - Started process (PID=71969) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:51,448] {logging_mixin.py:112} INFO - [2020-08-01 16:30:51,448] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:51,449] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:30:51,449] {logging_mixin.py:112} INFO - [2020-08-01 16:30:51,449] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:51,452] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:51,470] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:30:51,481] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:51,483] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.068 seconds
[2020-08-01 16:30:59,608] {scheduler_job.py:154} INFO - Started process (PID=71977) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:59,644] {logging_mixin.py:112} INFO - [2020-08-01 16:30:59,643] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:59,645] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:30:59,645] {logging_mixin.py:112} INFO - [2020-08-01 16:30:59,645] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:59,648] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:30:59,674] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:30:59,684] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:59,686] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.078 seconds
[2020-08-01 16:31:07,469] {scheduler_job.py:154} INFO - Started process (PID=71987) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:07,543] {logging_mixin.py:112} INFO - [2020-08-01 16:31:07,543] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:07,544] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:31:07,544] {logging_mixin.py:112} INFO - [2020-08-01 16:31:07,544] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:07,547] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:07,572] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:31:07,582] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:07,584] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.115 seconds
[2020-08-01 16:31:15,174] {scheduler_job.py:154} INFO - Started process (PID=71996) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:15,196] {logging_mixin.py:112} INFO - [2020-08-01 16:31:15,196] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:15,197] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:31:15,197] {logging_mixin.py:112} INFO - [2020-08-01 16:31:15,197] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:15,199] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:15,213] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:31:15,222] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:15,224] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.050 seconds
[2020-08-01 16:31:23,463] {scheduler_job.py:154} INFO - Started process (PID=72004) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:23,492] {logging_mixin.py:112} INFO - [2020-08-01 16:31:23,492] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:23,493] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:31:23,494] {logging_mixin.py:112} INFO - [2020-08-01 16:31:23,494] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:23,497] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:23,516] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:31:23,527] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:23,529] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.067 seconds
[2020-08-01 16:31:31,689] {scheduler_job.py:154} INFO - Started process (PID=72012) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:31,721] {logging_mixin.py:112} INFO - [2020-08-01 16:31:31,721] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:31,722] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:31:31,722] {logging_mixin.py:112} INFO - [2020-08-01 16:31:31,722] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:31,725] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:31,745] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:31:31,773] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:31,789] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.101 seconds
[2020-08-01 16:31:39,412] {scheduler_job.py:154} INFO - Started process (PID=72021) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:39,430] {logging_mixin.py:112} INFO - [2020-08-01 16:31:39,430] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:39,430] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:31:39,430] {logging_mixin.py:112} INFO - [2020-08-01 16:31:39,430] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:39,433] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:39,445] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:31:39,452] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:39,454] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:31:47,018] {scheduler_job.py:154} INFO - Started process (PID=72030) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:47,037] {logging_mixin.py:112} INFO - [2020-08-01 16:31:47,036] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:47,037] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:31:47,038] {logging_mixin.py:112} INFO - [2020-08-01 16:31:47,037] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:47,040] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:47,056] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:31:47,066] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:47,067] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:31:55,043] {scheduler_job.py:154} INFO - Started process (PID=72038) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:55,061] {logging_mixin.py:112} INFO - [2020-08-01 16:31:55,061] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:55,061] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:31:55,062] {logging_mixin.py:112} INFO - [2020-08-01 16:31:55,062] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:55,064] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:31:55,078] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:31:55,086] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:55,087] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:32:03,789] {scheduler_job.py:154} INFO - Started process (PID=72059) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:03,813] {logging_mixin.py:112} INFO - [2020-08-01 16:32:03,812] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:03,815] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:32:03,815] {logging_mixin.py:112} INFO - [2020-08-01 16:32:03,815] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:03,819] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:03,845] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:32:03,871] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:03,874] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.084 seconds
[2020-08-01 16:32:13,209] {scheduler_job.py:154} INFO - Started process (PID=72124) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:13,236] {logging_mixin.py:112} INFO - [2020-08-01 16:32:13,236] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:13,237] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:32:13,237] {logging_mixin.py:112} INFO - [2020-08-01 16:32:13,237] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:13,240] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:13,254] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:32:13,264] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:13,267] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.057 seconds
[2020-08-01 16:32:19,154] {scheduler_job.py:154} INFO - Started process (PID=72155) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:19,172] {logging_mixin.py:112} INFO - [2020-08-01 16:32:19,171] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:19,172] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:32:19,173] {logging_mixin.py:112} INFO - [2020-08-01 16:32:19,172] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:19,174] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:19,189] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:32:19,196] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:19,197] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:32:27,173] {scheduler_job.py:154} INFO - Started process (PID=72187) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:27,190] {logging_mixin.py:112} INFO - [2020-08-01 16:32:27,190] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:27,191] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:32:27,191] {logging_mixin.py:112} INFO - [2020-08-01 16:32:27,191] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:27,193] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:27,207] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:32:27,215] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:27,217] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:32:35,144] {scheduler_job.py:154} INFO - Started process (PID=72206) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:35,162] {logging_mixin.py:112} INFO - [2020-08-01 16:32:35,162] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:35,163] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:32:35,163] {logging_mixin.py:112} INFO - [2020-08-01 16:32:35,163] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:35,165] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:35,178] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:32:35,185] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:35,186] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:32:43,209] {scheduler_job.py:154} INFO - Started process (PID=72231) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:43,229] {logging_mixin.py:112} INFO - [2020-08-01 16:32:43,229] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:43,230] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:32:43,230] {logging_mixin.py:112} INFO - [2020-08-01 16:32:43,230] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:43,233] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:43,248] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:32:43,256] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:43,258] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:32:51,294] {scheduler_job.py:154} INFO - Started process (PID=72257) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:51,320] {logging_mixin.py:112} INFO - [2020-08-01 16:32:51,320] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:51,321] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:32:51,321] {logging_mixin.py:112} INFO - [2020-08-01 16:32:51,321] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:51,324] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:51,340] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:32:51,348] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:51,350] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.056 seconds
[2020-08-01 16:32:59,556] {scheduler_job.py:154} INFO - Started process (PID=72295) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:59,574] {logging_mixin.py:112} INFO - [2020-08-01 16:32:59,574] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:59,575] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:32:59,575] {logging_mixin.py:112} INFO - [2020-08-01 16:32:59,575] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:59,577] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:32:59,592] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:32:59,600] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:59,602] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:33:10,036] {scheduler_job.py:154} INFO - Started process (PID=72569) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:10,087] {logging_mixin.py:112} INFO - [2020-08-01 16:33:10,087] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:10,088] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:33:10,088] {logging_mixin.py:112} INFO - [2020-08-01 16:33:10,088] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:10,091] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:10,110] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:33:10,118] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:10,119] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.083 seconds
[2020-08-01 16:33:15,518] {scheduler_job.py:154} INFO - Started process (PID=72635) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:15,536] {logging_mixin.py:112} INFO - [2020-08-01 16:33:15,536] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:15,537] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:33:15,537] {logging_mixin.py:112} INFO - [2020-08-01 16:33:15,537] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:15,539] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:15,556] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:33:15,564] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:15,566] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:33:23,259] {scheduler_job.py:154} INFO - Started process (PID=72659) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:23,277] {logging_mixin.py:112} INFO - [2020-08-01 16:33:23,277] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:23,278] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:33:23,278] {logging_mixin.py:112} INFO - [2020-08-01 16:33:23,278] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:23,280] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:23,296] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:33:23,305] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:23,306] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:33:31,428] {scheduler_job.py:154} INFO - Started process (PID=72692) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:31,447] {logging_mixin.py:112} INFO - [2020-08-01 16:33:31,447] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:31,447] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:33:31,448] {logging_mixin.py:112} INFO - [2020-08-01 16:33:31,448] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:31,450] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:31,465] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:33:31,472] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:31,474] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:33:39,589] {scheduler_job.py:154} INFO - Started process (PID=72763) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:39,610] {logging_mixin.py:112} INFO - [2020-08-01 16:33:39,610] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:39,611] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:33:39,611] {logging_mixin.py:112} INFO - [2020-08-01 16:33:39,611] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:39,614] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:39,629] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:33:39,639] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:39,641] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.052 seconds
[2020-08-01 16:33:47,312] {scheduler_job.py:154} INFO - Started process (PID=72775) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:47,330] {logging_mixin.py:112} INFO - [2020-08-01 16:33:47,330] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:47,330] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:33:47,331] {logging_mixin.py:112} INFO - [2020-08-01 16:33:47,331] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:47,333] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:47,349] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:33:47,358] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:47,360] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:33:56,082] {scheduler_job.py:154} INFO - Started process (PID=72824) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:56,100] {logging_mixin.py:112} INFO - [2020-08-01 16:33:56,100] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:56,101] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:33:56,101] {logging_mixin.py:112} INFO - [2020-08-01 16:33:56,101] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:56,103] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:33:56,117] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:33:56,126] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:56,127] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:34:03,348] {scheduler_job.py:154} INFO - Started process (PID=72865) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:03,366] {logging_mixin.py:112} INFO - [2020-08-01 16:34:03,366] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:03,366] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:34:03,367] {logging_mixin.py:112} INFO - [2020-08-01 16:34:03,367] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:03,369] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:03,384] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:34:03,392] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:03,394] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:34:11,437] {scheduler_job.py:154} INFO - Started process (PID=72883) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:11,454] {logging_mixin.py:112} INFO - [2020-08-01 16:34:11,454] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:11,455] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:34:11,455] {logging_mixin.py:112} INFO - [2020-08-01 16:34:11,455] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:11,457] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:11,470] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:34:11,477] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:11,478] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 16:34:19,419] {scheduler_job.py:154} INFO - Started process (PID=72907) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:19,437] {logging_mixin.py:112} INFO - [2020-08-01 16:34:19,437] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:19,438] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:34:19,438] {logging_mixin.py:112} INFO - [2020-08-01 16:34:19,438] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:19,440] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:19,454] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:34:19,461] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:19,462] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:34:27,452] {scheduler_job.py:154} INFO - Started process (PID=72931) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:27,470] {logging_mixin.py:112} INFO - [2020-08-01 16:34:27,470] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:27,470] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:34:27,471] {logging_mixin.py:112} INFO - [2020-08-01 16:34:27,471] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:27,473] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:27,486] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:34:27,493] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:27,495] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:34:35,539] {scheduler_job.py:154} INFO - Started process (PID=72947) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:35,569] {logging_mixin.py:112} INFO - [2020-08-01 16:34:35,569] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:35,570] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:34:35,570] {logging_mixin.py:112} INFO - [2020-08-01 16:34:35,570] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:35,573] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:35,591] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:34:35,601] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:35,604] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.064 seconds
[2020-08-01 16:34:43,526] {scheduler_job.py:154} INFO - Started process (PID=72973) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:43,544] {logging_mixin.py:112} INFO - [2020-08-01 16:34:43,544] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:43,545] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:34:43,545] {logging_mixin.py:112} INFO - [2020-08-01 16:34:43,545] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:43,547] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:43,561] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:34:43,569] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:43,570] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:34:51,651] {scheduler_job.py:154} INFO - Started process (PID=73005) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:51,669] {logging_mixin.py:112} INFO - [2020-08-01 16:34:51,669] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:51,670] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:34:51,670] {logging_mixin.py:112} INFO - [2020-08-01 16:34:51,670] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:51,672] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:51,686] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:34:51,694] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:51,696] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:34:59,537] {scheduler_job.py:154} INFO - Started process (PID=73046) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:59,555] {logging_mixin.py:112} INFO - [2020-08-01 16:34:59,555] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:59,556] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:34:59,556] {logging_mixin.py:112} INFO - [2020-08-01 16:34:59,556] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:59,558] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:34:59,574] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:34:59,583] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:59,585] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:35:07,596] {scheduler_job.py:154} INFO - Started process (PID=73063) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:07,616] {logging_mixin.py:112} INFO - [2020-08-01 16:35:07,616] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:07,617] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:35:07,617] {logging_mixin.py:112} INFO - [2020-08-01 16:35:07,617] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:07,619] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:07,632] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:35:07,639] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:07,640] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:35:15,576] {scheduler_job.py:154} INFO - Started process (PID=73087) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:15,593] {logging_mixin.py:112} INFO - [2020-08-01 16:35:15,593] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:15,594] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:35:15,594] {logging_mixin.py:112} INFO - [2020-08-01 16:35:15,594] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:15,596] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:15,611] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:35:15,619] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:15,621] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:35:23,611] {scheduler_job.py:154} INFO - Started process (PID=73111) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:23,628] {logging_mixin.py:112} INFO - [2020-08-01 16:35:23,628] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:23,629] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:35:23,629] {logging_mixin.py:112} INFO - [2020-08-01 16:35:23,629] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:23,631] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:23,645] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:35:23,653] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:23,654] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:35:31,641] {scheduler_job.py:154} INFO - Started process (PID=73127) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:31,659] {logging_mixin.py:112} INFO - [2020-08-01 16:35:31,659] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:31,660] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:35:31,660] {logging_mixin.py:112} INFO - [2020-08-01 16:35:31,660] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:31,662] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:31,675] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:35:31,681] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:31,683] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:35:39,720] {scheduler_job.py:154} INFO - Started process (PID=73156) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:39,739] {logging_mixin.py:112} INFO - [2020-08-01 16:35:39,739] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:39,740] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:35:39,740] {logging_mixin.py:112} INFO - [2020-08-01 16:35:39,740] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:39,742] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:39,757] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:35:39,765] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:39,766] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:35:47,757] {scheduler_job.py:154} INFO - Started process (PID=73172) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:47,774] {logging_mixin.py:112} INFO - [2020-08-01 16:35:47,774] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:47,775] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:35:47,775] {logging_mixin.py:112} INFO - [2020-08-01 16:35:47,775] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:47,777] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:47,789] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:35:47,796] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:47,798] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.041 seconds
[2020-08-01 16:35:55,747] {scheduler_job.py:154} INFO - Started process (PID=73196) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:55,765] {logging_mixin.py:112} INFO - [2020-08-01 16:35:55,764] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:55,765] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:35:55,765] {logging_mixin.py:112} INFO - [2020-08-01 16:35:55,765] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:55,767] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:35:55,783] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:35:55,791] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:55,793] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:36:03,817] {scheduler_job.py:154} INFO - Started process (PID=73212) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:03,836] {logging_mixin.py:112} INFO - [2020-08-01 16:36:03,836] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:03,837] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:36:03,837] {logging_mixin.py:112} INFO - [2020-08-01 16:36:03,837] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:03,839] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:03,853] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:36:03,861] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:03,862] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:36:11,800] {scheduler_job.py:154} INFO - Started process (PID=73237) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:11,818] {logging_mixin.py:112} INFO - [2020-08-01 16:36:11,818] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:11,819] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:36:11,819] {logging_mixin.py:112} INFO - [2020-08-01 16:36:11,819] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:11,821] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:11,837] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:36:11,846] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:11,848] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:36:19,840] {scheduler_job.py:154} INFO - Started process (PID=73261) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:19,858] {logging_mixin.py:112} INFO - [2020-08-01 16:36:19,858] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:19,859] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:36:19,859] {logging_mixin.py:112} INFO - [2020-08-01 16:36:19,859] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:19,861] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:19,877] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:36:19,886] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:19,888] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:36:27,857] {scheduler_job.py:154} INFO - Started process (PID=73277) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:27,874] {logging_mixin.py:112} INFO - [2020-08-01 16:36:27,874] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:27,875] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:36:27,875] {logging_mixin.py:112} INFO - [2020-08-01 16:36:27,875] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:27,877] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:27,892] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:36:27,899] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:27,901] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:36:35,883] {scheduler_job.py:154} INFO - Started process (PID=73301) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:35,901] {logging_mixin.py:112} INFO - [2020-08-01 16:36:35,900] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:35,901] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:36:35,901] {logging_mixin.py:112} INFO - [2020-08-01 16:36:35,901] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:35,903] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:35,920] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:36:35,929] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:35,930] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:36:43,940] {scheduler_job.py:154} INFO - Started process (PID=73318) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:43,959] {logging_mixin.py:112} INFO - [2020-08-01 16:36:43,959] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:43,960] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:36:43,960] {logging_mixin.py:112} INFO - [2020-08-01 16:36:43,960] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:43,962] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:43,977] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:36:43,984] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:43,985] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:36:51,931] {scheduler_job.py:154} INFO - Started process (PID=73342) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:51,948] {logging_mixin.py:112} INFO - [2020-08-01 16:36:51,948] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:51,949] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:36:51,949] {logging_mixin.py:112} INFO - [2020-08-01 16:36:51,949] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:51,951] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:36:51,966] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:36:51,973] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:51,975] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:36:59,998] {scheduler_job.py:154} INFO - Started process (PID=73358) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:00,016] {logging_mixin.py:112} INFO - [2020-08-01 16:37:00,016] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:00,017] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:37:00,017] {logging_mixin.py:112} INFO - [2020-08-01 16:37:00,017] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:00,020] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:00,038] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:37:00,045] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:00,047] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:37:08,002] {scheduler_job.py:154} INFO - Started process (PID=73382) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:08,022] {logging_mixin.py:112} INFO - [2020-08-01 16:37:08,022] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:08,023] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:37:08,024] {logging_mixin.py:112} INFO - [2020-08-01 16:37:08,023] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:08,026] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:08,039] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:37:08,048] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:08,050] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:37:16,002] {scheduler_job.py:154} INFO - Started process (PID=73407) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:16,021] {logging_mixin.py:112} INFO - [2020-08-01 16:37:16,020] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:16,021] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:37:16,021] {logging_mixin.py:112} INFO - [2020-08-01 16:37:16,021] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:16,023] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:16,037] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:37:16,045] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:16,047] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:37:24,025] {scheduler_job.py:154} INFO - Started process (PID=73423) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:24,046] {logging_mixin.py:112} INFO - [2020-08-01 16:37:24,046] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:24,046] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:37:24,047] {logging_mixin.py:112} INFO - [2020-08-01 16:37:24,046] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:24,049] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:24,063] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:37:24,070] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:24,072] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:37:32,047] {scheduler_job.py:154} INFO - Started process (PID=73447) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:32,064] {logging_mixin.py:112} INFO - [2020-08-01 16:37:32,064] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:32,065] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:37:32,065] {logging_mixin.py:112} INFO - [2020-08-01 16:37:32,065] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:32,067] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:32,083] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:37:32,091] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:32,092] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:37:40,219] {scheduler_job.py:154} INFO - Started process (PID=73463) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:40,239] {logging_mixin.py:112} INFO - [2020-08-01 16:37:40,239] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:40,240] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:37:40,240] {logging_mixin.py:112} INFO - [2020-08-01 16:37:40,240] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:40,242] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:40,255] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:37:40,262] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:40,263] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:37:48,121] {scheduler_job.py:154} INFO - Started process (PID=73488) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:48,140] {logging_mixin.py:112} INFO - [2020-08-01 16:37:48,139] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:48,140] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:37:48,140] {logging_mixin.py:112} INFO - [2020-08-01 16:37:48,140] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:48,142] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:48,155] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:37:48,163] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:48,165] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.043 seconds
[2020-08-01 16:37:56,236] {scheduler_job.py:154} INFO - Started process (PID=73521) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:56,256] {logging_mixin.py:112} INFO - [2020-08-01 16:37:56,256] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:56,257] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:37:56,257] {logging_mixin.py:112} INFO - [2020-08-01 16:37:56,257] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:56,259] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:37:56,274] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:37:56,281] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:56,283] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:38:04,163] {scheduler_job.py:154} INFO - Started process (PID=73545) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:04,181] {logging_mixin.py:112} INFO - [2020-08-01 16:38:04,181] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:04,182] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:38:04,182] {logging_mixin.py:112} INFO - [2020-08-01 16:38:04,182] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:04,185] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:04,201] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:38:04,210] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:04,211] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:38:12,200] {scheduler_job.py:154} INFO - Started process (PID=73571) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:12,220] {logging_mixin.py:112} INFO - [2020-08-01 16:38:12,219] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:12,220] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:38:12,220] {logging_mixin.py:112} INFO - [2020-08-01 16:38:12,220] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:12,222] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:12,239] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:38:12,248] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:12,249] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:38:20,307] {scheduler_job.py:154} INFO - Started process (PID=73587) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:20,325] {logging_mixin.py:112} INFO - [2020-08-01 16:38:20,325] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:20,325] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:38:20,326] {logging_mixin.py:112} INFO - [2020-08-01 16:38:20,326] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:20,328] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:20,344] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:38:20,352] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:20,354] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:38:28,257] {scheduler_job.py:154} INFO - Started process (PID=73612) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:28,274] {logging_mixin.py:112} INFO - [2020-08-01 16:38:28,274] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:28,275] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:38:28,275] {logging_mixin.py:112} INFO - [2020-08-01 16:38:28,275] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:28,277] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:28,294] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:38:28,302] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:28,304] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:38:36,344] {scheduler_job.py:154} INFO - Started process (PID=73628) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:36,364] {logging_mixin.py:112} INFO - [2020-08-01 16:38:36,364] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:36,364] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:38:36,365] {logging_mixin.py:112} INFO - [2020-08-01 16:38:36,365] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:36,367] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:36,386] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:38:36,396] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:36,399] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.055 seconds
[2020-08-01 16:38:44,358] {scheduler_job.py:154} INFO - Started process (PID=73670) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:44,376] {logging_mixin.py:112} INFO - [2020-08-01 16:38:44,376] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:44,377] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:38:44,377] {logging_mixin.py:112} INFO - [2020-08-01 16:38:44,377] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:44,380] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:44,393] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:38:44,400] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:44,401] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:38:52,376] {scheduler_job.py:154} INFO - Started process (PID=73702) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:52,395] {logging_mixin.py:112} INFO - [2020-08-01 16:38:52,395] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:52,396] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:38:52,396] {logging_mixin.py:112} INFO - [2020-08-01 16:38:52,396] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:52,398] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:38:52,413] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:38:52,421] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:52,423] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:39:00,475] {scheduler_job.py:154} INFO - Started process (PID=73738) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:00,493] {logging_mixin.py:112} INFO - [2020-08-01 16:39:00,493] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:00,494] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:39:00,494] {logging_mixin.py:112} INFO - [2020-08-01 16:39:00,494] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:00,496] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:00,509] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:39:00,516] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:00,517] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:39:08,679] {scheduler_job.py:154} INFO - Started process (PID=73748) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:08,706] {logging_mixin.py:112} INFO - [2020-08-01 16:39:08,706] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:08,707] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:39:08,707] {logging_mixin.py:112} INFO - [2020-08-01 16:39:08,707] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:08,710] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:08,728] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:39:08,736] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:08,737] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.058 seconds
[2020-08-01 16:39:16,602] {scheduler_job.py:154} INFO - Started process (PID=73759) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:16,619] {logging_mixin.py:112} INFO - [2020-08-01 16:39:16,619] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:16,620] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:39:16,620] {logging_mixin.py:112} INFO - [2020-08-01 16:39:16,620] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:16,622] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:16,637] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:39:16,645] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:16,647] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.045 seconds
[2020-08-01 16:39:24,446] {scheduler_job.py:154} INFO - Started process (PID=73767) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:24,477] {logging_mixin.py:112} INFO - [2020-08-01 16:39:24,477] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:24,478] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:39:24,478] {logging_mixin.py:112} INFO - [2020-08-01 16:39:24,478] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:24,481] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:24,495] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:39:24,506] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:24,512] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.066 seconds
[2020-08-01 16:39:32,769] {scheduler_job.py:154} INFO - Started process (PID=73775) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:32,787] {logging_mixin.py:112} INFO - [2020-08-01 16:39:32,787] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:32,788] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:39:32,788] {logging_mixin.py:112} INFO - [2020-08-01 16:39:32,788] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:32,790] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:32,804] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:39:32,812] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:32,815] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:39:53,066] {scheduler_job.py:154} INFO - Started process (PID=73863) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:53,085] {logging_mixin.py:112} INFO - [2020-08-01 16:39:53,085] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:53,085] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:39:53,086] {logging_mixin.py:112} INFO - [2020-08-01 16:39:53,086] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:53,088] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:39:53,105] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:39:53,113] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:53,115] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:40:06,549] {scheduler_job.py:154} INFO - Started process (PID=73892) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:06,567] {logging_mixin.py:112} INFO - [2020-08-01 16:40:06,567] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:06,568] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:40:06,568] {logging_mixin.py:112} INFO - [2020-08-01 16:40:06,568] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:06,570] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:06,586] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:40:06,593] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:06,595] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:40:14,555] {scheduler_job.py:154} INFO - Started process (PID=73909) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:14,575] {logging_mixin.py:112} INFO - [2020-08-01 16:40:14,575] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:14,575] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:40:14,576] {logging_mixin.py:112} INFO - [2020-08-01 16:40:14,575] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:14,578] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:14,591] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:40:14,598] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:14,599] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:40:22,533] {scheduler_job.py:154} INFO - Started process (PID=73933) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:22,552] {logging_mixin.py:112} INFO - [2020-08-01 16:40:22,551] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:22,552] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:40:22,552] {logging_mixin.py:112} INFO - [2020-08-01 16:40:22,552] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:22,554] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:22,570] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:40:22,577] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:22,578] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.046 seconds
[2020-08-01 16:40:30,559] {scheduler_job.py:154} INFO - Started process (PID=73957) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:30,578] {logging_mixin.py:112} INFO - [2020-08-01 16:40:30,578] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:30,579] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:40:30,579] {logging_mixin.py:112} INFO - [2020-08-01 16:40:30,579] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:30,581] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:30,594] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:40:30,601] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:30,603] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.044 seconds
[2020-08-01 16:40:38,571] {scheduler_job.py:154} INFO - Started process (PID=73973) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:38,589] {logging_mixin.py:112} INFO - [2020-08-01 16:40:38,589] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:38,590] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:40:38,590] {logging_mixin.py:112} INFO - [2020-08-01 16:40:38,590] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:38,592] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:38,608] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:40:38,617] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:38,619] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
[2020-08-01 16:40:46,825] {scheduler_job.py:154} INFO - Started process (PID=74044) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:46,844] {logging_mixin.py:112} INFO - [2020-08-01 16:40:46,844] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:46,845] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:40:46,845] {logging_mixin.py:112} INFO - [2020-08-01 16:40:46,845] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:46,847] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:46,862] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:40:46,872] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:46,874] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.049 seconds
[2020-08-01 16:40:54,765] {scheduler_job.py:154} INFO - Started process (PID=74062) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:54,792] {logging_mixin.py:112} INFO - [2020-08-01 16:40:54,792] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:54,793] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:40:54,793] {logging_mixin.py:112} INFO - [2020-08-01 16:40:54,793] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:54,795] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:40:54,817] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:40:54,825] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:54,827] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.062 seconds
[2020-08-01 16:41:02,654] {scheduler_job.py:154} INFO - Started process (PID=74086) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:41:02,672] {logging_mixin.py:112} INFO - [2020-08-01 16:41:02,672] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:41:02,673] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:41:02,673] {logging_mixin.py:112} INFO - [2020-08-01 16:41:02,673] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:41:02,675] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:41:02,692] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:41:02,700] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:41:02,702] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.048 seconds
[2020-08-01 16:41:10,745] {scheduler_job.py:154} INFO - Started process (PID=74102) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:41:10,761] {logging_mixin.py:112} INFO - [2020-08-01 16:41:10,761] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:41:10,762] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:41:10,762] {logging_mixin.py:112} INFO - [2020-08-01 16:41:10,762] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:41:10,764] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:41:10,778] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:41:10,785] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:41:10,786] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.042 seconds
[2020-08-01 16:41:18,739] {scheduler_job.py:154} INFO - Started process (PID=74127) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:41:18,757] {logging_mixin.py:112} INFO - [2020-08-01 16:41:18,757] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:41:18,757] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py for tasks to queue
[2020-08-01 16:41:18,758] {logging_mixin.py:112} INFO - [2020-08-01 16:41:18,758] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:41:18,760] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['python_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py
[2020-08-01 16:41:18,776] {scheduler_job.py:1287} INFO - Processing python_pipeline
[2020-08-01 16:41:18,784] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: python_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:41:18,787] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/python_pipeline.py took 0.047 seconds
