[2020-08-01 14:23:27,550] {scheduler_job.py:154} INFO - Started process (PID=56025) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:27,570] {logging_mixin.py:112} INFO - [2020-08-01 14:23:27,570] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:23:27,571] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:23:27,571] {logging_mixin.py:112} INFO - [2020-08-01 14:23:27,571] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:27,578] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:27,590] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:23:27,602] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:23:27,604] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.054 seconds
[2020-08-01 14:23:31,566] {scheduler_job.py:154} INFO - Started process (PID=56029) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:31,588] {logging_mixin.py:112} INFO - [2020-08-01 14:23:31,587] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:23:31,588] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:23:31,588] {logging_mixin.py:112} INFO - [2020-08-01 14:23:31,588] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:31,592] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:31,605] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:23:31,619] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:23:31,620] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.054 seconds
[2020-08-01 14:23:35,636] {scheduler_job.py:154} INFO - Started process (PID=56033) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:35,657] {logging_mixin.py:112} INFO - [2020-08-01 14:23:35,657] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:23:35,658] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:23:35,658] {logging_mixin.py:112} INFO - [2020-08-01 14:23:35,658] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:35,660] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:35,675] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:23:35,690] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:23:35,692] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.055 seconds
[2020-08-01 14:23:39,667] {scheduler_job.py:154} INFO - Started process (PID=56038) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:39,684] {logging_mixin.py:112} INFO - [2020-08-01 14:23:39,684] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:23:39,685] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:23:39,685] {logging_mixin.py:112} INFO - [2020-08-01 14:23:39,685] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:39,688] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:39,700] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:23:39,715] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:23:39,716] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 14:23:43,548] {scheduler_job.py:154} INFO - Started process (PID=56042) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:43,567] {logging_mixin.py:112} INFO - [2020-08-01 14:23:43,567] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:23:43,567] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:23:43,567] {logging_mixin.py:112} INFO - [2020-08-01 14:23:43,567] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:43,570] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:43,583] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:23:43,597] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:23:43,599] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 14:23:47,727] {scheduler_job.py:154} INFO - Started process (PID=56046) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:47,747] {logging_mixin.py:112} INFO - [2020-08-01 14:23:47,747] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:23:47,747] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:23:47,747] {logging_mixin.py:112} INFO - [2020-08-01 14:23:47,747] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:47,751] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:47,765] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:23:47,781] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:23:47,784] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.057 seconds
[2020-08-01 14:23:51,563] {scheduler_job.py:154} INFO - Started process (PID=56058) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:51,584] {logging_mixin.py:112} INFO - [2020-08-01 14:23:51,584] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:23:51,585] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:23:51,585] {logging_mixin.py:112} INFO - [2020-08-01 14:23:51,585] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:51,587] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:51,603] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:23:51,618] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:23:51,619] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.057 seconds
[2020-08-01 14:23:55,633] {scheduler_job.py:154} INFO - Started process (PID=56070) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:55,653] {logging_mixin.py:112} INFO - [2020-08-01 14:23:55,653] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:23:55,654] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:23:55,654] {logging_mixin.py:112} INFO - [2020-08-01 14:23:55,654] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:55,657] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:55,671] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:23:55,684] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:23:55,686] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 14:23:59,593] {scheduler_job.py:154} INFO - Started process (PID=56083) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:59,613] {logging_mixin.py:112} INFO - [2020-08-01 14:23:59,613] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:23:59,613] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:23:59,614] {logging_mixin.py:112} INFO - [2020-08-01 14:23:59,614] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:59,616] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:23:59,629] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:23:59,643] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:23:59,645] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 14:24:03,631] {scheduler_job.py:154} INFO - Started process (PID=56095) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:03,648] {logging_mixin.py:112} INFO - [2020-08-01 14:24:03,648] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:03,648] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:03,648] {logging_mixin.py:112} INFO - [2020-08-01 14:24:03,648] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:03,651] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:03,663] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:24:03,676] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:24:03,678] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:24:07,721] {scheduler_job.py:154} INFO - Started process (PID=56099) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:07,743] {logging_mixin.py:112} INFO - [2020-08-01 14:24:07,743] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:07,743] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:07,743] {logging_mixin.py:112} INFO - [2020-08-01 14:24:07,743] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:07,747] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:07,764] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:24:07,783] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:24:07,786] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 14:24:11,604] {scheduler_job.py:154} INFO - Started process (PID=56112) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:11,635] {logging_mixin.py:112} INFO - [2020-08-01 14:24:11,635] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:11,636] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:11,636] {logging_mixin.py:112} INFO - [2020-08-01 14:24:11,636] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:11,640] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:11,661] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:24:11,674] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:24:11,675] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.072 seconds
[2020-08-01 14:24:15,663] {scheduler_job.py:154} INFO - Started process (PID=56125) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:15,682] {logging_mixin.py:112} INFO - [2020-08-01 14:24:15,681] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:15,682] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:15,682] {logging_mixin.py:112} INFO - [2020-08-01 14:24:15,682] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:15,685] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:15,700] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:24:15,713] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:24:15,714] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 14:24:19,770] {scheduler_job.py:154} INFO - Started process (PID=56137) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:19,787] {logging_mixin.py:112} INFO - [2020-08-01 14:24:19,787] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:19,788] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:19,788] {logging_mixin.py:112} INFO - [2020-08-01 14:24:19,788] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:19,791] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:19,804] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:24:19,817] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:24:19,819] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:24:23,644] {scheduler_job.py:154} INFO - Started process (PID=56148) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:23,660] {logging_mixin.py:112} INFO - [2020-08-01 14:24:23,660] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:23,661] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:23,661] {logging_mixin.py:112} INFO - [2020-08-01 14:24:23,661] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:23,664] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:23,676] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:24:23,689] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:24:23,691] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:24:27,965] {scheduler_job.py:154} INFO - Started process (PID=56154) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:27,983] {logging_mixin.py:112} INFO - [2020-08-01 14:24:27,983] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:27,984] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:27,984] {logging_mixin.py:112} INFO - [2020-08-01 14:24:27,984] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:27,987] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:28,003] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:24:28,024] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:24:28,026] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.061 seconds
[2020-08-01 14:24:31,724] {scheduler_job.py:154} INFO - Started process (PID=56166) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:31,743] {logging_mixin.py:112} INFO - [2020-08-01 14:24:31,743] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:31,745] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:31,746] {logging_mixin.py:112} INFO - [2020-08-01 14:24:31,745] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:31,748] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:31,760] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:24:31,774] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:24:31,776] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 14:24:35,717] {scheduler_job.py:154} INFO - Started process (PID=56178) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:35,734] {logging_mixin.py:112} INFO - [2020-08-01 14:24:35,734] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:35,734] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:35,735] {logging_mixin.py:112} INFO - [2020-08-01 14:24:35,735] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:35,737] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['dummy_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:35,750] {scheduler_job.py:1287} INFO - Processing dummy_pipeline
[2020-08-01 14:24:35,765] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: dummy_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:24:35,767] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 14:24:40,346] {scheduler_job.py:154} INFO - Started process (PID=56258) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:40,365] {logging_mixin.py:112} INFO - [2020-08-01 14:24:40,365] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:40,365] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:40,365] {logging_mixin.py:112} INFO - [2020-08-01 14:24:40,365] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:40,368] {logging_mixin.py:112} INFO - [2020-08-01 14:24:40,367] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 17, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:24:40,368] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:40,374] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.028 seconds
[2020-08-01 14:24:43,756] {scheduler_job.py:154} INFO - Started process (PID=56280) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:43,773] {logging_mixin.py:112} INFO - [2020-08-01 14:24:43,773] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:43,774] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:43,774] {logging_mixin.py:112} INFO - [2020-08-01 14:24:43,774] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:43,776] {logging_mixin.py:112} INFO - [2020-08-01 14:24:43,775] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 17, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:24:43,776] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:43,782] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.026 seconds
[2020-08-01 14:24:47,789] {scheduler_job.py:154} INFO - Started process (PID=56284) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:47,808] {logging_mixin.py:112} INFO - [2020-08-01 14:24:47,808] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:47,808] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:47,808] {logging_mixin.py:112} INFO - [2020-08-01 14:24:47,808] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:47,811] {logging_mixin.py:112} INFO - [2020-08-01 14:24:47,810] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 17, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:24:47,811] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:47,815] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.027 seconds
[2020-08-01 14:24:51,682] {scheduler_job.py:154} INFO - Started process (PID=56288) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:51,705] {logging_mixin.py:112} INFO - [2020-08-01 14:24:51,705] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:51,706] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:51,706] {logging_mixin.py:112} INFO - [2020-08-01 14:24:51,706] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:51,708] {logging_mixin.py:112} INFO - [2020-08-01 14:24:51,708] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 17, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:24:51,708] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:51,714] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.032 seconds
[2020-08-01 14:24:55,788] {scheduler_job.py:154} INFO - Started process (PID=56292) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:55,805] {logging_mixin.py:112} INFO - [2020-08-01 14:24:55,805] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:24:55,806] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:24:55,806] {logging_mixin.py:112} INFO - [2020-08-01 14:24:55,806] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:55,808] {logging_mixin.py:112} INFO - [2020-08-01 14:24:55,807] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 17, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:24:55,808] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:24:55,814] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.026 seconds
[2020-08-01 14:25:00,041] {scheduler_job.py:154} INFO - Started process (PID=56318) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:00,088] {logging_mixin.py:112} INFO - [2020-08-01 14:25:00,088] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:00,088] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:00,089] {logging_mixin.py:112} INFO - [2020-08-01 14:25:00,089] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:00,091] {logging_mixin.py:112} INFO - [2020-08-01 14:25:00,090] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 17, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:00,092] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:00,100] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.064 seconds
[2020-08-01 14:25:03,797] {scheduler_job.py:154} INFO - Started process (PID=56348) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:03,815] {logging_mixin.py:112} INFO - [2020-08-01 14:25:03,814] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:03,815] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:03,815] {logging_mixin.py:112} INFO - [2020-08-01 14:25:03,815] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:03,817] {logging_mixin.py:112} INFO - [2020-08-01 14:25:03,817] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 17, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:03,817] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:03,822] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.025 seconds
[2020-08-01 14:25:08,202] {scheduler_job.py:154} INFO - Started process (PID=56386) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:08,234] {logging_mixin.py:112} INFO - [2020-08-01 14:25:08,233] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:08,235] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:08,235] {logging_mixin.py:112} INFO - [2020-08-01 14:25:08,235] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:08,240] {logging_mixin.py:112} INFO - [2020-08-01 14:25:08,239] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:08,241] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:08,249] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:25:11,846] {scheduler_job.py:154} INFO - Started process (PID=56501) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:11,863] {logging_mixin.py:112} INFO - [2020-08-01 14:25:11,863] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:11,864] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:11,864] {logging_mixin.py:112} INFO - [2020-08-01 14:25:11,864] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:11,866] {logging_mixin.py:112} INFO - [2020-08-01 14:25:11,865] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:11,866] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:11,871] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.025 seconds
[2020-08-01 14:25:15,922] {scheduler_job.py:154} INFO - Started process (PID=56531) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:15,941] {logging_mixin.py:112} INFO - [2020-08-01 14:25:15,941] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:15,942] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:15,942] {logging_mixin.py:112} INFO - [2020-08-01 14:25:15,942] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:15,946] {logging_mixin.py:112} INFO - [2020-08-01 14:25:15,944] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:15,946] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:15,956] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.034 seconds
[2020-08-01 14:25:19,799] {scheduler_job.py:154} INFO - Started process (PID=56543) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:19,819] {logging_mixin.py:112} INFO - [2020-08-01 14:25:19,818] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:19,819] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:19,819] {logging_mixin.py:112} INFO - [2020-08-01 14:25:19,819] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:19,821] {logging_mixin.py:112} INFO - [2020-08-01 14:25:19,821] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:19,821] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:19,828] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.029 seconds
[2020-08-01 14:25:24,080] {scheduler_job.py:154} INFO - Started process (PID=56547) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:24,097] {logging_mixin.py:112} INFO - [2020-08-01 14:25:24,096] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:24,097] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:24,097] {logging_mixin.py:112} INFO - [2020-08-01 14:25:24,097] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:24,099] {logging_mixin.py:112} INFO - [2020-08-01 14:25:24,099] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:24,099] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:24,105] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.026 seconds
[2020-08-01 14:25:28,175] {scheduler_job.py:154} INFO - Started process (PID=56551) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:28,196] {logging_mixin.py:112} INFO - [2020-08-01 14:25:28,196] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:28,197] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:28,197] {logging_mixin.py:112} INFO - [2020-08-01 14:25:28,197] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:28,199] {logging_mixin.py:112} INFO - [2020-08-01 14:25:28,198] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:28,199] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:28,205] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.030 seconds
[2020-08-01 14:25:31,934] {scheduler_job.py:154} INFO - Started process (PID=56555) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:31,958] {logging_mixin.py:112} INFO - [2020-08-01 14:25:31,958] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:31,959] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:31,959] {logging_mixin.py:112} INFO - [2020-08-01 14:25:31,959] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:31,961] {logging_mixin.py:112} INFO - [2020-08-01 14:25:31,961] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:31,961] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:31,968] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.034 seconds
[2020-08-01 14:25:35,999] {scheduler_job.py:154} INFO - Started process (PID=56559) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:36,022] {logging_mixin.py:112} INFO - [2020-08-01 14:25:36,022] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:36,023] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:36,023] {logging_mixin.py:112} INFO - [2020-08-01 14:25:36,023] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:36,025] {logging_mixin.py:112} INFO - [2020-08-01 14:25:36,024] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:36,025] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:36,031] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.032 seconds
[2020-08-01 14:25:39,843] {scheduler_job.py:154} INFO - Started process (PID=56571) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:39,860] {logging_mixin.py:112} INFO - [2020-08-01 14:25:39,860] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:39,861] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:39,861] {logging_mixin.py:112} INFO - [2020-08-01 14:25:39,861] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:39,863] {logging_mixin.py:112} INFO - [2020-08-01 14:25:39,862] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:39,863] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:39,869] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.026 seconds
[2020-08-01 14:25:43,899] {scheduler_job.py:154} INFO - Started process (PID=56577) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:43,919] {logging_mixin.py:112} INFO - [2020-08-01 14:25:43,919] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:43,920] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:43,920] {logging_mixin.py:112} INFO - [2020-08-01 14:25:43,920] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:43,923] {logging_mixin.py:112} INFO - [2020-08-01 14:25:43,922] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:43,923] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:43,930] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.031 seconds
[2020-08-01 14:25:47,912] {scheduler_job.py:154} INFO - Started process (PID=56589) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:47,932] {logging_mixin.py:112} INFO - [2020-08-01 14:25:47,932] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:47,932] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:47,932] {logging_mixin.py:112} INFO - [2020-08-01 14:25:47,932] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:47,935] {logging_mixin.py:112} INFO - [2020-08-01 14:25:47,934] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:47,935] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:47,940] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.027 seconds
[2020-08-01 14:25:51,885] {scheduler_job.py:154} INFO - Started process (PID=56601) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:51,919] {logging_mixin.py:112} INFO - [2020-08-01 14:25:51,919] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:51,920] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:51,920] {logging_mixin.py:112} INFO - [2020-08-01 14:25:51,920] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:51,923] {logging_mixin.py:112} INFO - [2020-08-01 14:25:51,922] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:51,923] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:51,930] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:25:55,878] {scheduler_job.py:154} INFO - Started process (PID=56664) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:55,896] {logging_mixin.py:112} INFO - [2020-08-01 14:25:55,896] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:25:55,896] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:25:55,897] {logging_mixin.py:112} INFO - [2020-08-01 14:25:55,897] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:55,899] {logging_mixin.py:112} INFO - [2020-08-01 14:25:55,899] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:25:55,899] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:25:55,904] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.026 seconds
[2020-08-01 14:26:00,095] {scheduler_job.py:154} INFO - Started process (PID=56677) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:00,116] {logging_mixin.py:112} INFO - [2020-08-01 14:26:00,116] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:00,117] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:00,117] {logging_mixin.py:112} INFO - [2020-08-01 14:26:00,117] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:00,119] {logging_mixin.py:112} INFO - [2020-08-01 14:26:00,118] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:26:00,119] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:00,125] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.030 seconds
[2020-08-01 14:26:03,903] {scheduler_job.py:154} INFO - Started process (PID=56681) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:03,922] {logging_mixin.py:112} INFO - [2020-08-01 14:26:03,922] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:03,923] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:03,923] {logging_mixin.py:112} INFO - [2020-08-01 14:26:03,923] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:03,925] {logging_mixin.py:112} INFO - [2020-08-01 14:26:03,924] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:26:03,925] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:03,931] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.028 seconds
[2020-08-01 14:26:07,911] {scheduler_job.py:154} INFO - Started process (PID=56685) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:07,930] {logging_mixin.py:112} INFO - [2020-08-01 14:26:07,930] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:07,930] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:07,930] {logging_mixin.py:112} INFO - [2020-08-01 14:26:07,930] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:07,932] {logging_mixin.py:112} INFO - [2020-08-01 14:26:07,932] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:26:07,933] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:07,939] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.028 seconds
[2020-08-01 14:26:12,245] {scheduler_job.py:154} INFO - Started process (PID=56689) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:12,273] {logging_mixin.py:112} INFO - [2020-08-01 14:26:12,273] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:12,274] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:12,275] {logging_mixin.py:112} INFO - [2020-08-01 14:26:12,275] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:12,278] {logging_mixin.py:112} INFO - [2020-08-01 14:26:12,277] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:26:12,278] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:12,286] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:26:15,930] {scheduler_job.py:154} INFO - Started process (PID=56694) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:15,954] {logging_mixin.py:112} INFO - [2020-08-01 14:26:15,954] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:15,955] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:15,955] {logging_mixin.py:112} INFO - [2020-08-01 14:26:15,955] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:15,958] {logging_mixin.py:112} INFO - [2020-08-01 14:26:15,957] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:26:15,958] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:15,964] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.034 seconds
[2020-08-01 14:26:19,985] {scheduler_job.py:154} INFO - Started process (PID=56706) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:20,009] {logging_mixin.py:112} INFO - [2020-08-01 14:26:20,009] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:20,010] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:20,010] {logging_mixin.py:112} INFO - [2020-08-01 14:26:20,010] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:20,014] {logging_mixin.py:112} INFO - [2020-08-01 14:26:20,013] {dagbag.py:239} ERROR - Failed to import: /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
Traceback (most recent call last):
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/thanamat/.pyenv/versions/3.8.4/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 783, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py", line 16, in <module>
    t2 = BashOperator(task_id='hello',
  File "/Users/thanamat/train/airflow/ENV/lib/python3.8/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['bash_command'] is required
[2020-08-01 14:26:20,014] {scheduler_job.py:1585} WARNING - No viable dags retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:20,020] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.036 seconds
[2020-08-01 14:26:24,336] {scheduler_job.py:154} INFO - Started process (PID=56710) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:24,357] {logging_mixin.py:112} INFO - [2020-08-01 14:26:24,356] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:24,357] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:24,357] {logging_mixin.py:112} INFO - [2020-08-01 14:26:24,357] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:24,360] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:24,366] {logging_mixin.py:112} INFO - [2020-08-01 14:26:24,366] {dag.py:1520} INFO - Creating ORM DAG for bash_pipeline
[2020-08-01 14:26:24,374] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.038 seconds
[2020-08-01 14:26:27,929] {scheduler_job.py:154} INFO - Started process (PID=56757) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:27,947] {logging_mixin.py:112} INFO - [2020-08-01 14:26:27,947] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:27,947] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:27,948] {logging_mixin.py:112} INFO - [2020-08-01 14:26:27,948] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:27,951] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:27,965] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.035 seconds
[2020-08-01 14:26:31,950] {scheduler_job.py:154} INFO - Started process (PID=56761) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:31,970] {logging_mixin.py:112} INFO - [2020-08-01 14:26:31,970] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:31,971] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:31,971] {logging_mixin.py:112} INFO - [2020-08-01 14:26:31,971] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:31,973] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:31,984] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.034 seconds
[2020-08-01 14:26:36,022] {scheduler_job.py:154} INFO - Started process (PID=56765) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:36,042] {logging_mixin.py:112} INFO - [2020-08-01 14:26:36,041] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:36,042] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:36,042] {logging_mixin.py:112} INFO - [2020-08-01 14:26:36,042] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:36,044] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:36,056] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.034 seconds
[2020-08-01 14:26:40,024] {scheduler_job.py:154} INFO - Started process (PID=56769) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:40,042] {logging_mixin.py:112} INFO - [2020-08-01 14:26:40,042] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:40,043] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:40,043] {logging_mixin.py:112} INFO - [2020-08-01 14:26:40,043] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:40,045] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:40,056] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.032 seconds
[2020-08-01 14:26:44,056] {scheduler_job.py:154} INFO - Started process (PID=56774) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:44,073] {logging_mixin.py:112} INFO - [2020-08-01 14:26:44,073] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:44,074] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:44,074] {logging_mixin.py:112} INFO - [2020-08-01 14:26:44,074] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:44,076] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:44,086] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.030 seconds
[2020-08-01 14:26:48,330] {scheduler_job.py:154} INFO - Started process (PID=56779) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:48,368] {logging_mixin.py:112} INFO - [2020-08-01 14:26:48,368] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:48,369] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:48,369] {logging_mixin.py:112} INFO - [2020-08-01 14:26:48,369] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:48,372] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:48,397] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.066 seconds
[2020-08-01 14:26:52,391] {scheduler_job.py:154} INFO - Started process (PID=56784) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:52,412] {logging_mixin.py:112} INFO - [2020-08-01 14:26:52,412] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:52,413] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:52,413] {logging_mixin.py:112} INFO - [2020-08-01 14:26:52,413] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:52,415] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:52,428] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.037 seconds
[2020-08-01 14:26:56,175] {scheduler_job.py:154} INFO - Started process (PID=56794) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:56,195] {logging_mixin.py:112} INFO - [2020-08-01 14:26:56,195] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:26:56,196] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:26:56,196] {logging_mixin.py:112} INFO - [2020-08-01 14:26:56,196] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:56,198] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:26:56,212] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.037 seconds
[2020-08-01 14:27:00,031] {scheduler_job.py:154} INFO - Started process (PID=56798) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:00,050] {logging_mixin.py:112} INFO - [2020-08-01 14:27:00,050] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:00,051] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:00,051] {logging_mixin.py:112} INFO - [2020-08-01 14:27:00,051] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:00,053] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:00,066] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.036 seconds
[2020-08-01 14:27:04,334] {scheduler_job.py:154} INFO - Started process (PID=56802) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:04,358] {logging_mixin.py:112} INFO - [2020-08-01 14:27:04,358] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:04,359] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:04,359] {logging_mixin.py:112} INFO - [2020-08-01 14:27:04,359] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:04,361] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:04,372] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.039 seconds
[2020-08-01 14:27:08,133] {scheduler_job.py:154} INFO - Started process (PID=56814) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:08,159] {logging_mixin.py:112} INFO - [2020-08-01 14:27:08,158] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:08,159] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:08,159] {logging_mixin.py:112} INFO - [2020-08-01 14:27:08,159] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:08,161] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:08,176] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:27:12,151] {scheduler_job.py:154} INFO - Started process (PID=56830) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:12,168] {logging_mixin.py:112} INFO - [2020-08-01 14:27:12,168] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:12,169] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:12,169] {logging_mixin.py:112} INFO - [2020-08-01 14:27:12,169] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:12,171] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:12,183] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.032 seconds
[2020-08-01 14:27:16,102] {scheduler_job.py:154} INFO - Started process (PID=56836) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:16,121] {logging_mixin.py:112} INFO - [2020-08-01 14:27:16,120] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:16,121] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:16,121] {logging_mixin.py:112} INFO - [2020-08-01 14:27:16,121] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:16,123] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:16,136] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.033 seconds
[2020-08-01 14:27:20,064] {scheduler_job.py:154} INFO - Started process (PID=56848) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:20,082] {logging_mixin.py:112} INFO - [2020-08-01 14:27:20,082] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:20,083] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:20,083] {logging_mixin.py:112} INFO - [2020-08-01 14:27:20,083] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:20,085] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:20,098] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.034 seconds
[2020-08-01 14:27:24,028] {scheduler_job.py:154} INFO - Started process (PID=56860) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:24,047] {logging_mixin.py:112} INFO - [2020-08-01 14:27:24,047] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:24,048] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:24,048] {logging_mixin.py:112} INFO - [2020-08-01 14:27:24,048] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:24,049] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:24,062] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.034 seconds
[2020-08-01 14:27:28,077] {scheduler_job.py:154} INFO - Started process (PID=56865) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:28,096] {logging_mixin.py:112} INFO - [2020-08-01 14:27:28,095] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:28,096] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:28,096] {logging_mixin.py:112} INFO - [2020-08-01 14:27:28,096] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:28,098] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:28,111] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.034 seconds
[2020-08-01 14:27:32,057] {scheduler_job.py:154} INFO - Started process (PID=56869) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:32,075] {logging_mixin.py:112} INFO - [2020-08-01 14:27:32,074] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:32,075] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:32,075] {logging_mixin.py:112} INFO - [2020-08-01 14:27:32,075] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:32,077] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:32,089] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.033 seconds
[2020-08-01 14:27:36,099] {scheduler_job.py:154} INFO - Started process (PID=56873) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:36,117] {logging_mixin.py:112} INFO - [2020-08-01 14:27:36,117] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:36,117] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:36,118] {logging_mixin.py:112} INFO - [2020-08-01 14:27:36,118] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:36,119] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:36,134] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:27:36,140] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:27:36,142] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:27:40,103] {scheduler_job.py:154} INFO - Started process (PID=56877) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:40,121] {logging_mixin.py:112} INFO - [2020-08-01 14:27:40,120] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:40,121] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:40,121] {logging_mixin.py:112} INFO - [2020-08-01 14:27:40,121] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:40,123] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:40,138] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:27:40,145] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:27:40,147] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:27:44,133] {scheduler_job.py:154} INFO - Started process (PID=56881) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:44,156] {logging_mixin.py:112} INFO - [2020-08-01 14:27:44,156] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:44,157] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:44,157] {logging_mixin.py:112} INFO - [2020-08-01 14:27:44,157] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:44,160] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:44,174] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:27:44,182] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:27:44,183] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 14:27:48,139] {scheduler_job.py:154} INFO - Started process (PID=56886) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:48,156] {logging_mixin.py:112} INFO - [2020-08-01 14:27:48,156] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:48,156] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:48,156] {logging_mixin.py:112} INFO - [2020-08-01 14:27:48,156] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:48,158] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:48,172] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:27:48,178] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:27:48,180] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:27:52,256] {scheduler_job.py:154} INFO - Started process (PID=56890) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:52,276] {logging_mixin.py:112} INFO - [2020-08-01 14:27:52,276] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:52,276] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:52,276] {logging_mixin.py:112} INFO - [2020-08-01 14:27:52,276] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:52,278] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:52,293] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:27:52,301] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:27:52,303] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:27:56,192] {scheduler_job.py:154} INFO - Started process (PID=56894) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:56,210] {logging_mixin.py:112} INFO - [2020-08-01 14:27:56,210] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:27:56,211] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:27:56,211] {logging_mixin.py:112} INFO - [2020-08-01 14:27:56,211] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:56,213] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:27:56,229] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:27:56,237] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:27:56,239] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:28:00,140] {scheduler_job.py:154} INFO - Started process (PID=56898) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:00,158] {logging_mixin.py:112} INFO - [2020-08-01 14:28:00,158] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:00,159] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:00,159] {logging_mixin.py:112} INFO - [2020-08-01 14:28:00,159] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:00,161] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:00,176] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:00,184] {scheduler_job.py:766} INFO - Examining DAG run <DagRun bash_pipeline @ 2020-08-01 07:27:58.256690+00:00: manual__2020-08-01T07:27:58.256690+00:00, externally triggered: True>
[2020-08-01 14:28:00,199] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:00,201] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: bash_pipeline.start 2020-08-01 07:27:58.256690+00:00 [success]> in ORM
[2020-08-01 14:28:00,208] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-01 14:28:04,214] {scheduler_job.py:154} INFO - Started process (PID=56902) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:04,234] {logging_mixin.py:112} INFO - [2020-08-01 14:28:04,233] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:04,234] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:04,234] {logging_mixin.py:112} INFO - [2020-08-01 14:28:04,234] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:04,236] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:04,254] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:04,263] {scheduler_job.py:766} INFO - Examining DAG run <DagRun bash_pipeline @ 2020-08-01 07:27:58.256690+00:00: manual__2020-08-01T07:27:58.256690+00:00, externally triggered: True>
[2020-08-01 14:28:04,280] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:04,283] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: bash_pipeline.hello 2020-08-01 07:27:58.256690+00:00 [scheduled]> in ORM
[2020-08-01 14:28:04,289] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.076 seconds
[2020-08-01 14:28:13,637] {scheduler_job.py:154} INFO - Started process (PID=56910) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:13,655] {logging_mixin.py:112} INFO - [2020-08-01 14:28:13,655] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:13,656] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:13,656] {logging_mixin.py:112} INFO - [2020-08-01 14:28:13,656] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:13,658] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:13,672] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:13,678] {scheduler_job.py:766} INFO - Examining DAG run <DagRun bash_pipeline @ 2020-08-01 07:27:58.256690+00:00: manual__2020-08-01T07:27:58.256690+00:00, externally triggered: True>
[2020-08-01 14:28:13,694] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:13,697] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: bash_pipeline.end 2020-08-01 07:27:58.256690+00:00 [success]> in ORM
[2020-08-01 14:28:13,703] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 14:28:17,538] {scheduler_job.py:154} INFO - Started process (PID=56915) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:17,557] {logging_mixin.py:112} INFO - [2020-08-01 14:28:17,557] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:17,557] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:17,558] {logging_mixin.py:112} INFO - [2020-08-01 14:28:17,558] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:17,559] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:17,574] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:17,582] {scheduler_job.py:766} INFO - Examining DAG run <DagRun bash_pipeline @ 2020-08-01 07:27:58.256690+00:00: manual__2020-08-01T07:27:58.256690+00:00, externally triggered: True>
[2020-08-01 14:28:17,591] {logging_mixin.py:112} INFO - [2020-08-01 14:28:17,591] {dagrun.py:319} INFO - Marking run <DagRun bash_pipeline @ 2020-08-01 07:27:58.256690+00:00: manual__2020-08-01T07:27:58.256690+00:00, externally triggered: True> successful
[2020-08-01 14:28:17,598] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:17,600] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.062 seconds
[2020-08-01 14:28:21,612] {scheduler_job.py:154} INFO - Started process (PID=56919) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:21,631] {logging_mixin.py:112} INFO - [2020-08-01 14:28:21,630] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:21,632] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:21,632] {logging_mixin.py:112} INFO - [2020-08-01 14:28:21,632] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:21,635] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:21,650] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:21,657] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:21,659] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:28:25,598] {scheduler_job.py:154} INFO - Started process (PID=56923) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:25,617] {logging_mixin.py:112} INFO - [2020-08-01 14:28:25,617] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:25,618] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:25,618] {logging_mixin.py:112} INFO - [2020-08-01 14:28:25,618] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:25,620] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:25,635] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:25,643] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:25,645] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:28:29,707] {scheduler_job.py:154} INFO - Started process (PID=56927) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:29,727] {logging_mixin.py:112} INFO - [2020-08-01 14:28:29,726] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:29,728] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:29,728] {logging_mixin.py:112} INFO - [2020-08-01 14:28:29,728] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:29,730] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:29,746] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:29,755] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:29,757] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 14:28:33,624] {scheduler_job.py:154} INFO - Started process (PID=56931) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:33,643] {logging_mixin.py:112} INFO - [2020-08-01 14:28:33,642] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:33,643] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:33,643] {logging_mixin.py:112} INFO - [2020-08-01 14:28:33,643] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:33,645] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:33,662] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:33,669] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:33,671] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:28:37,605] {scheduler_job.py:154} INFO - Started process (PID=56935) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:37,625] {logging_mixin.py:112} INFO - [2020-08-01 14:28:37,625] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:37,625] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:37,625] {logging_mixin.py:112} INFO - [2020-08-01 14:28:37,625] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:37,628] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:37,642] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:37,649] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:37,651] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:28:41,719] {scheduler_job.py:154} INFO - Started process (PID=56939) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:41,738] {logging_mixin.py:112} INFO - [2020-08-01 14:28:41,738] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:41,739] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:41,739] {logging_mixin.py:112} INFO - [2020-08-01 14:28:41,739] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:41,741] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:41,757] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:41,764] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:41,765] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:28:45,719] {scheduler_job.py:154} INFO - Started process (PID=56943) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:45,737] {logging_mixin.py:112} INFO - [2020-08-01 14:28:45,736] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:45,737] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:45,737] {logging_mixin.py:112} INFO - [2020-08-01 14:28:45,737] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:45,739] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:45,752] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:45,759] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:45,760] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:28:49,745] {scheduler_job.py:154} INFO - Started process (PID=56948) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:49,764] {logging_mixin.py:112} INFO - [2020-08-01 14:28:49,764] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:49,765] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:49,765] {logging_mixin.py:112} INFO - [2020-08-01 14:28:49,765] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:49,767] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:49,783] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:49,790] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:49,792] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:28:53,665] {scheduler_job.py:154} INFO - Started process (PID=56952) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:53,683] {logging_mixin.py:112} INFO - [2020-08-01 14:28:53,683] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:53,684] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:53,684] {logging_mixin.py:112} INFO - [2020-08-01 14:28:53,684] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:53,686] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:53,700] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:53,707] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:53,708] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:28:57,607] {scheduler_job.py:154} INFO - Started process (PID=56956) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:57,625] {logging_mixin.py:112} INFO - [2020-08-01 14:28:57,625] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:28:57,626] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:28:57,626] {logging_mixin.py:112} INFO - [2020-08-01 14:28:57,626] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:57,628] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:28:57,642] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:28:57,650] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:28:57,651] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:29:01,634] {scheduler_job.py:154} INFO - Started process (PID=56960) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:01,651] {logging_mixin.py:112} INFO - [2020-08-01 14:29:01,651] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:01,652] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:01,652] {logging_mixin.py:112} INFO - [2020-08-01 14:29:01,652] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:01,654] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:01,668] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:01,674] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:01,676] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:29:05,688] {scheduler_job.py:154} INFO - Started process (PID=56964) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:05,710] {logging_mixin.py:112} INFO - [2020-08-01 14:29:05,710] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:05,711] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:05,711] {logging_mixin.py:112} INFO - [2020-08-01 14:29:05,711] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:05,713] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:05,730] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:05,737] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:05,740] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 14:29:09,754] {scheduler_job.py:154} INFO - Started process (PID=56968) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:09,774] {logging_mixin.py:112} INFO - [2020-08-01 14:29:09,774] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:09,775] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:09,775] {logging_mixin.py:112} INFO - [2020-08-01 14:29:09,775] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:09,777] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:09,791] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:09,799] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:09,800] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:29:13,735] {scheduler_job.py:154} INFO - Started process (PID=56972) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:13,753] {logging_mixin.py:112} INFO - [2020-08-01 14:29:13,753] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:13,754] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:13,754] {logging_mixin.py:112} INFO - [2020-08-01 14:29:13,754] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:13,756] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:13,770] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:13,778] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:13,781] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:29:17,741] {scheduler_job.py:154} INFO - Started process (PID=56985) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:17,761] {logging_mixin.py:112} INFO - [2020-08-01 14:29:17,760] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:17,761] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:17,762] {logging_mixin.py:112} INFO - [2020-08-01 14:29:17,762] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:17,764] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:17,778] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:17,785] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:17,787] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:29:21,776] {scheduler_job.py:154} INFO - Started process (PID=56989) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:21,794] {logging_mixin.py:112} INFO - [2020-08-01 14:29:21,793] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:21,794] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:21,794] {logging_mixin.py:112} INFO - [2020-08-01 14:29:21,794] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:21,796] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:21,811] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:21,818] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:21,820] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:29:25,675] {scheduler_job.py:154} INFO - Started process (PID=56993) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:25,694] {logging_mixin.py:112} INFO - [2020-08-01 14:29:25,694] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:25,695] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:25,695] {logging_mixin.py:112} INFO - [2020-08-01 14:29:25,695] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:25,697] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:25,712] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:25,719] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:25,720] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:29:29,674] {scheduler_job.py:154} INFO - Started process (PID=56998) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:29,691] {logging_mixin.py:112} INFO - [2020-08-01 14:29:29,691] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:29,692] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:29,692] {logging_mixin.py:112} INFO - [2020-08-01 14:29:29,692] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:29,694] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:29,708] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:29,717] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:29,719] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:29:33,691] {scheduler_job.py:154} INFO - Started process (PID=57002) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:33,708] {logging_mixin.py:112} INFO - [2020-08-01 14:29:33,708] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:33,709] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:33,709] {logging_mixin.py:112} INFO - [2020-08-01 14:29:33,709] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:33,711] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:33,725] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:33,732] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:33,734] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:29:37,697] {scheduler_job.py:154} INFO - Started process (PID=57006) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:37,714] {logging_mixin.py:112} INFO - [2020-08-01 14:29:37,714] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:37,715] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:37,715] {logging_mixin.py:112} INFO - [2020-08-01 14:29:37,715] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:37,717] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:37,731] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:37,738] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:37,740] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:29:41,709] {scheduler_job.py:154} INFO - Started process (PID=57010) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:41,726] {logging_mixin.py:112} INFO - [2020-08-01 14:29:41,726] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:41,727] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:41,727] {logging_mixin.py:112} INFO - [2020-08-01 14:29:41,727] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:41,729] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:41,743] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:41,751] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:41,752] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:29:45,736] {scheduler_job.py:154} INFO - Started process (PID=57014) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:45,754] {logging_mixin.py:112} INFO - [2020-08-01 14:29:45,753] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:45,754] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:45,754] {logging_mixin.py:112} INFO - [2020-08-01 14:29:45,754] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:45,756] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:45,770] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:45,778] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:45,779] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:29:49,747] {scheduler_job.py:154} INFO - Started process (PID=57019) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:49,767] {logging_mixin.py:112} INFO - [2020-08-01 14:29:49,767] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:49,768] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:49,768] {logging_mixin.py:112} INFO - [2020-08-01 14:29:49,768] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:49,769] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:49,784] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:49,791] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:49,793] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:29:53,758] {scheduler_job.py:154} INFO - Started process (PID=57023) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:53,775] {logging_mixin.py:112} INFO - [2020-08-01 14:29:53,775] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:53,776] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:53,776] {logging_mixin.py:112} INFO - [2020-08-01 14:29:53,776] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:53,778] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:53,792] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:53,800] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:53,801] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:29:57,776] {scheduler_job.py:154} INFO - Started process (PID=57027) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:57,793] {logging_mixin.py:112} INFO - [2020-08-01 14:29:57,793] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:29:57,794] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:29:57,794] {logging_mixin.py:112} INFO - [2020-08-01 14:29:57,794] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:57,796] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:29:57,810] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:29:57,817] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:29:57,819] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:30:01,794] {scheduler_job.py:154} INFO - Started process (PID=57032) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:01,812] {logging_mixin.py:112} INFO - [2020-08-01 14:30:01,811] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:01,812] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:01,812] {logging_mixin.py:112} INFO - [2020-08-01 14:30:01,812] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:01,814] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:01,829] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:01,836] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:01,838] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:30:05,809] {scheduler_job.py:154} INFO - Started process (PID=57036) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:05,826] {logging_mixin.py:112} INFO - [2020-08-01 14:30:05,826] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:05,827] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:05,827] {logging_mixin.py:112} INFO - [2020-08-01 14:30:05,827] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:05,829] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:05,844] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:05,850] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:05,852] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:30:09,820] {scheduler_job.py:154} INFO - Started process (PID=57040) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:09,837] {logging_mixin.py:112} INFO - [2020-08-01 14:30:09,837] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:09,838] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:09,838] {logging_mixin.py:112} INFO - [2020-08-01 14:30:09,838] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:09,840] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:09,854] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:09,862] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:09,863] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:30:13,838] {scheduler_job.py:154} INFO - Started process (PID=57044) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:13,855] {logging_mixin.py:112} INFO - [2020-08-01 14:30:13,855] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:13,856] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:13,856] {logging_mixin.py:112} INFO - [2020-08-01 14:30:13,856] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:13,858] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:13,872] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:13,879] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:13,881] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:30:17,971] {scheduler_job.py:154} INFO - Started process (PID=57048) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:17,991] {logging_mixin.py:112} INFO - [2020-08-01 14:30:17,991] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:17,992] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:17,992] {logging_mixin.py:112} INFO - [2020-08-01 14:30:17,992] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:17,994] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:18,011] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:18,017] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:18,019] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:30:21,935] {scheduler_job.py:154} INFO - Started process (PID=57053) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:21,953] {logging_mixin.py:112} INFO - [2020-08-01 14:30:21,953] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:21,954] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:21,954] {logging_mixin.py:112} INFO - [2020-08-01 14:30:21,954] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:21,956] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:21,970] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:21,977] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:21,978] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:30:25,885] {scheduler_job.py:154} INFO - Started process (PID=57057) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:25,903] {logging_mixin.py:112} INFO - [2020-08-01 14:30:25,903] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:25,904] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:25,904] {logging_mixin.py:112} INFO - [2020-08-01 14:30:25,904] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:25,906] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:25,922] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:25,930] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:25,932] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:30:29,897] {scheduler_job.py:154} INFO - Started process (PID=57061) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:29,914] {logging_mixin.py:112} INFO - [2020-08-01 14:30:29,914] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:29,915] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:29,915] {logging_mixin.py:112} INFO - [2020-08-01 14:30:29,915] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:29,917] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:29,931] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:29,938] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:29,940] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:30:34,070] {scheduler_job.py:154} INFO - Started process (PID=57065) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:34,097] {logging_mixin.py:112} INFO - [2020-08-01 14:30:34,097] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:34,097] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:34,098] {logging_mixin.py:112} INFO - [2020-08-01 14:30:34,097] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:34,100] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:34,114] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:34,121] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:34,122] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 14:30:38,243] {scheduler_job.py:154} INFO - Started process (PID=57069) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:38,280] {logging_mixin.py:112} INFO - [2020-08-01 14:30:38,279] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:38,285] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:38,285] {logging_mixin.py:112} INFO - [2020-08-01 14:30:38,285] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:38,290] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:38,319] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:38,327] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:38,328] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.086 seconds
[2020-08-01 14:30:42,163] {scheduler_job.py:154} INFO - Started process (PID=57073) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:42,181] {logging_mixin.py:112} INFO - [2020-08-01 14:30:42,181] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:42,181] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:42,182] {logging_mixin.py:112} INFO - [2020-08-01 14:30:42,182] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:42,183] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:42,198] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:42,206] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:42,207] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:30:46,073] {scheduler_job.py:154} INFO - Started process (PID=57077) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:46,092] {logging_mixin.py:112} INFO - [2020-08-01 14:30:46,092] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:46,093] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:46,093] {logging_mixin.py:112} INFO - [2020-08-01 14:30:46,093] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:46,095] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:46,110] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:46,117] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:46,118] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:30:49,977] {scheduler_job.py:154} INFO - Started process (PID=57082) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:49,994] {logging_mixin.py:112} INFO - [2020-08-01 14:30:49,994] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:49,995] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:49,995] {logging_mixin.py:112} INFO - [2020-08-01 14:30:49,995] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:49,997] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:50,010] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:50,017] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:50,018] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:30:53,954] {scheduler_job.py:154} INFO - Started process (PID=57086) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:53,972] {logging_mixin.py:112} INFO - [2020-08-01 14:30:53,972] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:53,972] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:53,973] {logging_mixin.py:112} INFO - [2020-08-01 14:30:53,972] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:53,974] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:53,989] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:53,995] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:53,997] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:30:58,017] {scheduler_job.py:154} INFO - Started process (PID=57090) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:58,035] {logging_mixin.py:112} INFO - [2020-08-01 14:30:58,035] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:30:58,036] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:30:58,036] {logging_mixin.py:112} INFO - [2020-08-01 14:30:58,036] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:58,038] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:30:58,052] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:30:58,059] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:30:58,061] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:31:02,015] {scheduler_job.py:154} INFO - Started process (PID=57094) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:02,032] {logging_mixin.py:112} INFO - [2020-08-01 14:31:02,032] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:02,033] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:02,033] {logging_mixin.py:112} INFO - [2020-08-01 14:31:02,033] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:02,035] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:02,049] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:02,055] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:02,057] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:31:06,028] {scheduler_job.py:154} INFO - Started process (PID=57098) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:06,050] {logging_mixin.py:112} INFO - [2020-08-01 14:31:06,049] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:06,050] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:06,050] {logging_mixin.py:112} INFO - [2020-08-01 14:31:06,050] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:06,052] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:06,067] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:06,073] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:06,075] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:31:10,043] {scheduler_job.py:154} INFO - Started process (PID=57102) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:10,061] {logging_mixin.py:112} INFO - [2020-08-01 14:31:10,061] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:10,061] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:10,061] {logging_mixin.py:112} INFO - [2020-08-01 14:31:10,061] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:10,063] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:10,078] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:10,084] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:10,086] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:31:14,034] {scheduler_job.py:154} INFO - Started process (PID=57106) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:14,051] {logging_mixin.py:112} INFO - [2020-08-01 14:31:14,051] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:14,052] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:14,052] {logging_mixin.py:112} INFO - [2020-08-01 14:31:14,052] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:14,054] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:14,068] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:14,077] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:14,079] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:31:18,055] {scheduler_job.py:154} INFO - Started process (PID=57111) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:18,073] {logging_mixin.py:112} INFO - [2020-08-01 14:31:18,073] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:18,074] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:18,074] {logging_mixin.py:112} INFO - [2020-08-01 14:31:18,074] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:18,076] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:18,090] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:18,097] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:18,099] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:31:22,094] {scheduler_job.py:154} INFO - Started process (PID=57116) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:22,115] {logging_mixin.py:112} INFO - [2020-08-01 14:31:22,115] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:22,116] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:22,116] {logging_mixin.py:112} INFO - [2020-08-01 14:31:22,116] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:22,119] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:22,134] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:22,140] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:22,142] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:31:26,104] {scheduler_job.py:154} INFO - Started process (PID=57121) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:26,126] {logging_mixin.py:112} INFO - [2020-08-01 14:31:26,126] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:26,127] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:26,127] {logging_mixin.py:112} INFO - [2020-08-01 14:31:26,127] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:26,129] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:26,144] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:26,151] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:26,152] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:31:30,112] {scheduler_job.py:154} INFO - Started process (PID=57125) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:30,129] {logging_mixin.py:112} INFO - [2020-08-01 14:31:30,129] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:30,130] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:30,130] {logging_mixin.py:112} INFO - [2020-08-01 14:31:30,130] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:30,132] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:30,146] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:30,152] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:30,154] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:31:34,146] {scheduler_job.py:154} INFO - Started process (PID=57129) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:34,164] {logging_mixin.py:112} INFO - [2020-08-01 14:31:34,164] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:34,164] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:34,165] {logging_mixin.py:112} INFO - [2020-08-01 14:31:34,164] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:34,166] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:34,181] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:34,188] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:34,189] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:31:38,103] {scheduler_job.py:154} INFO - Started process (PID=57135) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:38,120] {logging_mixin.py:112} INFO - [2020-08-01 14:31:38,120] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:38,121] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:38,121] {logging_mixin.py:112} INFO - [2020-08-01 14:31:38,121] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:38,123] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:38,137] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:38,144] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:38,146] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:31:42,134] {scheduler_job.py:154} INFO - Started process (PID=57139) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:42,152] {logging_mixin.py:112} INFO - [2020-08-01 14:31:42,151] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:42,152] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:42,152] {logging_mixin.py:112} INFO - [2020-08-01 14:31:42,152] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:42,154] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:42,168] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:42,175] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:42,177] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:31:46,168] {scheduler_job.py:154} INFO - Started process (PID=57143) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:46,185] {logging_mixin.py:112} INFO - [2020-08-01 14:31:46,185] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:46,186] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:46,186] {logging_mixin.py:112} INFO - [2020-08-01 14:31:46,186] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:46,188] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:46,202] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:46,210] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:46,211] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:31:50,211] {scheduler_job.py:154} INFO - Started process (PID=57147) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:50,228] {logging_mixin.py:112} INFO - [2020-08-01 14:31:50,228] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:50,229] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:50,229] {logging_mixin.py:112} INFO - [2020-08-01 14:31:50,229] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:50,231] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:50,245] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:50,252] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:50,254] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:31:54,159] {scheduler_job.py:154} INFO - Started process (PID=57152) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:54,176] {logging_mixin.py:112} INFO - [2020-08-01 14:31:54,176] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:54,177] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:54,177] {logging_mixin.py:112} INFO - [2020-08-01 14:31:54,177] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:54,178] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:54,192] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:54,199] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:54,201] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:31:58,189] {scheduler_job.py:154} INFO - Started process (PID=57156) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:58,206] {logging_mixin.py:112} INFO - [2020-08-01 14:31:58,206] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:31:58,207] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:31:58,207] {logging_mixin.py:112} INFO - [2020-08-01 14:31:58,207] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:58,208] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:31:58,222] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:31:58,229] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:31:58,230] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:32:02,218] {scheduler_job.py:154} INFO - Started process (PID=57160) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:02,237] {logging_mixin.py:112} INFO - [2020-08-01 14:32:02,236] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:02,237] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:02,237] {logging_mixin.py:112} INFO - [2020-08-01 14:32:02,237] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:02,239] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:02,254] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:02,260] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:02,262] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:32:06,312] {scheduler_job.py:154} INFO - Started process (PID=57164) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:06,330] {logging_mixin.py:112} INFO - [2020-08-01 14:32:06,329] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:06,330] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:06,330] {logging_mixin.py:112} INFO - [2020-08-01 14:32:06,330] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:06,332] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:06,346] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:06,353] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:06,354] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:32:10,204] {scheduler_job.py:154} INFO - Started process (PID=57168) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:10,221] {logging_mixin.py:112} INFO - [2020-08-01 14:32:10,221] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:10,222] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:10,222] {logging_mixin.py:112} INFO - [2020-08-01 14:32:10,222] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:10,224] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:10,238] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:10,245] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:10,247] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:32:14,220] {scheduler_job.py:154} INFO - Started process (PID=57172) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:14,237] {logging_mixin.py:112} INFO - [2020-08-01 14:32:14,237] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:14,238] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:14,238] {logging_mixin.py:112} INFO - [2020-08-01 14:32:14,238] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:14,240] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:14,254] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:14,261] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:14,262] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:32:18,287] {scheduler_job.py:154} INFO - Started process (PID=57178) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:18,304] {logging_mixin.py:112} INFO - [2020-08-01 14:32:18,304] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:18,305] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:18,305] {logging_mixin.py:112} INFO - [2020-08-01 14:32:18,305] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:18,307] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:18,321] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:18,327] {scheduler_job.py:766} INFO - Examining DAG run <DagRun bash_pipeline @ 2020-08-01 07:32:15+00:00: manual__2020-08-01T07:32:15+00:00, externally triggered: True>
[2020-08-01 14:32:18,342] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:18,344] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: bash_pipeline.start 2020-08-01 07:32:15+00:00 [success]> in ORM
[2020-08-01 14:32:18,349] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.062 seconds
[2020-08-01 14:32:22,445] {scheduler_job.py:154} INFO - Started process (PID=57183) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:22,467] {logging_mixin.py:112} INFO - [2020-08-01 14:32:22,467] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:22,468] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:22,468] {logging_mixin.py:112} INFO - [2020-08-01 14:32:22,468] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:22,470] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:22,487] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:22,494] {scheduler_job.py:766} INFO - Examining DAG run <DagRun bash_pipeline @ 2020-08-01 07:32:15+00:00: manual__2020-08-01T07:32:15+00:00, externally triggered: True>
[2020-08-01 14:32:22,515] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:22,519] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: bash_pipeline.hello 2020-08-01 07:32:15+00:00 [scheduled]> in ORM
[2020-08-01 14:32:22,525] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.080 seconds
[2020-08-01 14:32:31,608] {scheduler_job.py:154} INFO - Started process (PID=57191) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:31,626] {logging_mixin.py:112} INFO - [2020-08-01 14:32:31,626] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:31,627] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:31,627] {logging_mixin.py:112} INFO - [2020-08-01 14:32:31,627] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:31,629] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:31,644] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:31,651] {scheduler_job.py:766} INFO - Examining DAG run <DagRun bash_pipeline @ 2020-08-01 07:32:15+00:00: manual__2020-08-01T07:32:15+00:00, externally triggered: True>
[2020-08-01 14:32:31,664] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:31,667] {scheduler_job.py:1650} INFO - Creating / updating <TaskInstance: bash_pipeline.end 2020-08-01 07:32:15+00:00 [success]> in ORM
[2020-08-01 14:32:31,673] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 14:32:35,658] {scheduler_job.py:154} INFO - Started process (PID=57196) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:35,675] {logging_mixin.py:112} INFO - [2020-08-01 14:32:35,675] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:35,676] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:35,676] {logging_mixin.py:112} INFO - [2020-08-01 14:32:35,676] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:35,678] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:35,693] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:35,700] {scheduler_job.py:766} INFO - Examining DAG run <DagRun bash_pipeline @ 2020-08-01 07:32:15+00:00: manual__2020-08-01T07:32:15+00:00, externally triggered: True>
[2020-08-01 14:32:35,707] {logging_mixin.py:112} INFO - [2020-08-01 14:32:35,706] {dagrun.py:319} INFO - Marking run <DagRun bash_pipeline @ 2020-08-01 07:32:15+00:00: manual__2020-08-01T07:32:15+00:00, externally triggered: True> successful
[2020-08-01 14:32:35,709] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:35,711] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 14:32:39,700] {scheduler_job.py:154} INFO - Started process (PID=57200) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:39,719] {logging_mixin.py:112} INFO - [2020-08-01 14:32:39,719] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:39,720] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:39,720] {logging_mixin.py:112} INFO - [2020-08-01 14:32:39,720] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:39,723] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:39,739] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:39,748] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:39,750] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 14:32:43,793] {scheduler_job.py:154} INFO - Started process (PID=57204) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:43,811] {logging_mixin.py:112} INFO - [2020-08-01 14:32:43,811] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:43,812] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:43,812] {logging_mixin.py:112} INFO - [2020-08-01 14:32:43,812] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:43,814] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:43,826] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:43,833] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:43,834] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:32:47,627] {scheduler_job.py:154} INFO - Started process (PID=57208) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:47,645] {logging_mixin.py:112} INFO - [2020-08-01 14:32:47,645] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:47,646] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:47,646] {logging_mixin.py:112} INFO - [2020-08-01 14:32:47,646] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:47,648] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:47,661] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:47,668] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:47,669] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:32:51,713] {scheduler_job.py:154} INFO - Started process (PID=57212) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:51,730] {logging_mixin.py:112} INFO - [2020-08-01 14:32:51,730] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:51,731] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:51,731] {logging_mixin.py:112} INFO - [2020-08-01 14:32:51,731] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:51,733] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:51,747] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:51,756] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:51,757] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:32:55,656] {scheduler_job.py:154} INFO - Started process (PID=57217) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:55,674] {logging_mixin.py:112} INFO - [2020-08-01 14:32:55,673] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:55,674] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:55,674] {logging_mixin.py:112} INFO - [2020-08-01 14:32:55,674] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:55,676] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:55,690] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:55,697] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:55,699] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:32:59,672] {scheduler_job.py:154} INFO - Started process (PID=57221) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:59,689] {logging_mixin.py:112} INFO - [2020-08-01 14:32:59,689] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:32:59,690] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:32:59,690] {logging_mixin.py:112} INFO - [2020-08-01 14:32:59,690] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:59,691] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:32:59,706] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:32:59,713] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:32:59,714] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:33:03,685] {scheduler_job.py:154} INFO - Started process (PID=57225) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:03,703] {logging_mixin.py:112} INFO - [2020-08-01 14:33:03,703] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:03,704] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:03,704] {logging_mixin.py:112} INFO - [2020-08-01 14:33:03,704] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:03,705] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:03,720] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:03,727] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:03,729] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:33:07,709] {scheduler_job.py:154} INFO - Started process (PID=57229) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:07,726] {logging_mixin.py:112} INFO - [2020-08-01 14:33:07,726] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:07,727] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:07,727] {logging_mixin.py:112} INFO - [2020-08-01 14:33:07,727] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:07,729] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:07,743] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:07,750] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:07,751] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:33:11,719] {scheduler_job.py:154} INFO - Started process (PID=57233) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:11,737] {logging_mixin.py:112} INFO - [2020-08-01 14:33:11,737] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:11,738] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:11,738] {logging_mixin.py:112} INFO - [2020-08-01 14:33:11,738] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:11,739] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:11,754] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:11,761] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:11,762] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:33:15,731] {scheduler_job.py:154} INFO - Started process (PID=57237) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:15,749] {logging_mixin.py:112} INFO - [2020-08-01 14:33:15,749] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:15,750] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:15,750] {logging_mixin.py:112} INFO - [2020-08-01 14:33:15,750] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:15,752] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:15,766] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:15,773] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:15,775] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:33:19,756] {scheduler_job.py:154} INFO - Started process (PID=57241) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:19,774] {logging_mixin.py:112} INFO - [2020-08-01 14:33:19,773] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:19,774] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:19,774] {logging_mixin.py:112} INFO - [2020-08-01 14:33:19,774] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:19,776] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:19,790] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:19,799] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:19,801] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:33:23,762] {scheduler_job.py:154} INFO - Started process (PID=57245) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:23,779] {logging_mixin.py:112} INFO - [2020-08-01 14:33:23,779] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:23,780] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:23,780] {logging_mixin.py:112} INFO - [2020-08-01 14:33:23,780] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:23,781] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:23,796] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:23,803] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:23,805] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:33:27,784] {scheduler_job.py:154} INFO - Started process (PID=57249) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:27,801] {logging_mixin.py:112} INFO - [2020-08-01 14:33:27,801] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:27,802] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:27,802] {logging_mixin.py:112} INFO - [2020-08-01 14:33:27,802] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:27,804] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:27,818] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:27,825] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:27,827] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:33:31,815] {scheduler_job.py:154} INFO - Started process (PID=57253) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:31,832] {logging_mixin.py:112} INFO - [2020-08-01 14:33:31,832] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:31,833] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:31,833] {logging_mixin.py:112} INFO - [2020-08-01 14:33:31,833] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:31,835] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:31,849] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:31,857] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:31,858] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:33:35,941] {scheduler_job.py:154} INFO - Started process (PID=57257) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:35,961] {logging_mixin.py:112} INFO - [2020-08-01 14:33:35,961] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:35,962] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:35,962] {logging_mixin.py:112} INFO - [2020-08-01 14:33:35,962] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:35,964] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:35,978] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:35,985] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:35,986] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:33:39,844] {scheduler_job.py:154} INFO - Started process (PID=57261) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:39,862] {logging_mixin.py:112} INFO - [2020-08-01 14:33:39,862] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:39,863] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:39,863] {logging_mixin.py:112} INFO - [2020-08-01 14:33:39,863] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:39,865] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:39,879] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:39,885] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:39,887] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:33:43,926] {scheduler_job.py:154} INFO - Started process (PID=57265) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:43,946] {logging_mixin.py:112} INFO - [2020-08-01 14:33:43,946] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:43,947] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:43,947] {logging_mixin.py:112} INFO - [2020-08-01 14:33:43,947] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:43,950] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:43,966] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:43,975] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:43,976] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 14:33:47,860] {scheduler_job.py:154} INFO - Started process (PID=57269) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:47,878] {logging_mixin.py:112} INFO - [2020-08-01 14:33:47,878] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:47,879] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:47,879] {logging_mixin.py:112} INFO - [2020-08-01 14:33:47,879] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:47,881] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:47,893] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:47,900] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:47,902] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:33:51,926] {scheduler_job.py:154} INFO - Started process (PID=57273) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:51,945] {logging_mixin.py:112} INFO - [2020-08-01 14:33:51,945] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:51,946] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:51,946] {logging_mixin.py:112} INFO - [2020-08-01 14:33:51,946] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:51,948] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:51,962] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:51,970] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:51,972] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:33:55,860] {scheduler_job.py:154} INFO - Started process (PID=57277) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:55,879] {logging_mixin.py:112} INFO - [2020-08-01 14:33:55,878] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:55,879] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:55,879] {logging_mixin.py:112} INFO - [2020-08-01 14:33:55,879] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:55,881] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:55,895] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:55,902] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:55,904] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:33:59,918] {scheduler_job.py:154} INFO - Started process (PID=57281) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:59,936] {logging_mixin.py:112} INFO - [2020-08-01 14:33:59,936] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:33:59,936] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:33:59,937] {logging_mixin.py:112} INFO - [2020-08-01 14:33:59,937] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:59,938] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:33:59,952] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:33:59,959] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:33:59,961] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:34:03,926] {scheduler_job.py:154} INFO - Started process (PID=57285) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:03,944] {logging_mixin.py:112} INFO - [2020-08-01 14:34:03,944] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:03,945] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:03,945] {logging_mixin.py:112} INFO - [2020-08-01 14:34:03,945] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:03,947] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:03,961] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:03,968] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:03,970] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:34:07,956] {scheduler_job.py:154} INFO - Started process (PID=57289) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:07,975] {logging_mixin.py:112} INFO - [2020-08-01 14:34:07,975] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:07,975] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:07,976] {logging_mixin.py:112} INFO - [2020-08-01 14:34:07,976] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:07,977] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:07,992] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:07,999] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:08,001] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:34:11,979] {scheduler_job.py:154} INFO - Started process (PID=57293) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:12,000] {logging_mixin.py:112} INFO - [2020-08-01 14:34:11,999] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:12,000] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:12,001] {logging_mixin.py:112} INFO - [2020-08-01 14:34:12,000] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:12,002] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:12,019] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:12,026] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:12,028] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 14:34:15,946] {scheduler_job.py:154} INFO - Started process (PID=57297) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:15,964] {logging_mixin.py:112} INFO - [2020-08-01 14:34:15,964] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:15,965] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:15,965] {logging_mixin.py:112} INFO - [2020-08-01 14:34:15,965] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:15,967] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:15,981] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:15,988] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:15,989] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:34:19,937] {scheduler_job.py:154} INFO - Started process (PID=57301) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:19,960] {logging_mixin.py:112} INFO - [2020-08-01 14:34:19,960] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:19,961] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:19,961] {logging_mixin.py:112} INFO - [2020-08-01 14:34:19,961] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:19,966] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:19,979] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:19,986] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:19,988] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 14:34:23,972] {scheduler_job.py:154} INFO - Started process (PID=57306) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:23,989] {logging_mixin.py:112} INFO - [2020-08-01 14:34:23,989] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:23,990] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:23,990] {logging_mixin.py:112} INFO - [2020-08-01 14:34:23,990] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:23,992] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:24,007] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:24,014] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:24,016] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:34:27,929] {scheduler_job.py:154} INFO - Started process (PID=57310) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:27,947] {logging_mixin.py:112} INFO - [2020-08-01 14:34:27,947] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:27,948] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:27,948] {logging_mixin.py:112} INFO - [2020-08-01 14:34:27,948] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:27,950] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:27,963] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:27,969] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:27,971] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:34:31,946] {scheduler_job.py:154} INFO - Started process (PID=57314) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:31,964] {logging_mixin.py:112} INFO - [2020-08-01 14:34:31,964] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:31,964] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:31,964] {logging_mixin.py:112} INFO - [2020-08-01 14:34:31,964] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:31,966] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:31,980] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:31,988] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:31,990] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:34:35,959] {scheduler_job.py:154} INFO - Started process (PID=57318) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:35,977] {logging_mixin.py:112} INFO - [2020-08-01 14:34:35,977] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:35,977] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:35,978] {logging_mixin.py:112} INFO - [2020-08-01 14:34:35,978] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:35,979] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:35,994] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:36,000] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:36,002] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:34:40,025] {scheduler_job.py:154} INFO - Started process (PID=57322) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:40,043] {logging_mixin.py:112} INFO - [2020-08-01 14:34:40,042] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:40,043] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:40,043] {logging_mixin.py:112} INFO - [2020-08-01 14:34:40,043] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:40,045] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:40,060] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:40,068] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:40,070] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:34:44,059] {scheduler_job.py:154} INFO - Started process (PID=57326) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:44,079] {logging_mixin.py:112} INFO - [2020-08-01 14:34:44,079] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:44,079] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:44,080] {logging_mixin.py:112} INFO - [2020-08-01 14:34:44,080] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:44,081] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:44,095] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:44,103] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:44,104] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:34:48,118] {scheduler_job.py:154} INFO - Started process (PID=57330) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:48,136] {logging_mixin.py:112} INFO - [2020-08-01 14:34:48,136] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:48,136] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:48,137] {logging_mixin.py:112} INFO - [2020-08-01 14:34:48,137] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:48,138] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:48,152] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:48,160] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:48,162] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:34:52,115] {scheduler_job.py:154} INFO - Started process (PID=57334) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:52,140] {logging_mixin.py:112} INFO - [2020-08-01 14:34:52,139] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:52,140] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:52,140] {logging_mixin.py:112} INFO - [2020-08-01 14:34:52,140] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:52,142] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:52,156] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:52,164] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:52,166] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 14:34:56,046] {scheduler_job.py:154} INFO - Started process (PID=57339) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:56,064] {logging_mixin.py:112} INFO - [2020-08-01 14:34:56,064] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:34:56,064] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:34:56,065] {logging_mixin.py:112} INFO - [2020-08-01 14:34:56,065] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:56,066] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:34:56,081] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:34:56,087] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:34:56,089] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:00,041] {scheduler_job.py:154} INFO - Started process (PID=57343) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:00,059] {logging_mixin.py:112} INFO - [2020-08-01 14:35:00,059] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:00,060] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:00,060] {logging_mixin.py:112} INFO - [2020-08-01 14:35:00,060] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:00,061] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:00,076] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:00,083] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:00,084] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:04,038] {scheduler_job.py:154} INFO - Started process (PID=57347) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:04,056] {logging_mixin.py:112} INFO - [2020-08-01 14:35:04,055] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:04,056] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:04,056] {logging_mixin.py:112} INFO - [2020-08-01 14:35:04,056] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:04,058] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:04,072] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:04,079] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:04,081] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:08,067] {scheduler_job.py:154} INFO - Started process (PID=57351) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:08,085] {logging_mixin.py:112} INFO - [2020-08-01 14:35:08,084] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:08,085] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:08,085] {logging_mixin.py:112} INFO - [2020-08-01 14:35:08,085] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:08,087] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:08,101] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:08,108] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:08,109] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:35:12,080] {scheduler_job.py:154} INFO - Started process (PID=57355) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:12,097] {logging_mixin.py:112} INFO - [2020-08-01 14:35:12,097] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:12,098] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:12,098] {logging_mixin.py:112} INFO - [2020-08-01 14:35:12,098] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:12,100] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:12,114] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:12,121] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:12,123] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:16,106] {scheduler_job.py:154} INFO - Started process (PID=57359) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:16,124] {logging_mixin.py:112} INFO - [2020-08-01 14:35:16,123] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:16,124] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:16,124] {logging_mixin.py:112} INFO - [2020-08-01 14:35:16,124] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:16,126] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:16,140] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:16,147] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:16,149] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:20,140] {scheduler_job.py:154} INFO - Started process (PID=57363) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:20,157] {logging_mixin.py:112} INFO - [2020-08-01 14:35:20,157] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:20,158] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:20,158] {logging_mixin.py:112} INFO - [2020-08-01 14:35:20,158] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:20,160] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:20,175] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:20,181] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:20,183] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:35:24,159] {scheduler_job.py:154} INFO - Started process (PID=57368) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:24,176] {logging_mixin.py:112} INFO - [2020-08-01 14:35:24,176] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:24,177] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:24,177] {logging_mixin.py:112} INFO - [2020-08-01 14:35:24,177] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:24,179] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:24,193] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:24,201] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:24,203] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:35:28,168] {scheduler_job.py:154} INFO - Started process (PID=57375) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:28,185] {logging_mixin.py:112} INFO - [2020-08-01 14:35:28,185] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:28,186] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:28,186] {logging_mixin.py:112} INFO - [2020-08-01 14:35:28,186] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:28,188] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:28,202] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:28,209] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:28,211] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:32,157] {scheduler_job.py:154} INFO - Started process (PID=57379) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:32,174] {logging_mixin.py:112} INFO - [2020-08-01 14:35:32,174] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:32,175] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:32,175] {logging_mixin.py:112} INFO - [2020-08-01 14:35:32,175] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:32,177] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:32,191] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:32,198] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:32,199] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:36,158] {scheduler_job.py:154} INFO - Started process (PID=57384) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:36,175] {logging_mixin.py:112} INFO - [2020-08-01 14:35:36,175] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:36,176] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:36,176] {logging_mixin.py:112} INFO - [2020-08-01 14:35:36,176] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:36,178] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:36,192] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:36,199] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:36,201] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:40,175] {scheduler_job.py:154} INFO - Started process (PID=57388) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:40,192] {logging_mixin.py:112} INFO - [2020-08-01 14:35:40,192] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:40,193] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:40,193] {logging_mixin.py:112} INFO - [2020-08-01 14:35:40,193] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:40,195] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:40,209] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:40,217] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:40,218] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:44,200] {scheduler_job.py:154} INFO - Started process (PID=57392) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:44,218] {logging_mixin.py:112} INFO - [2020-08-01 14:35:44,218] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:44,218] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:44,219] {logging_mixin.py:112} INFO - [2020-08-01 14:35:44,219] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:44,220] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:44,235] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:44,242] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:44,243] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:35:48,216] {scheduler_job.py:154} INFO - Started process (PID=57396) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:48,234] {logging_mixin.py:112} INFO - [2020-08-01 14:35:48,233] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:48,234] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:48,234] {logging_mixin.py:112} INFO - [2020-08-01 14:35:48,234] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:48,236] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:48,249] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:48,257] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:48,258] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:35:52,238] {scheduler_job.py:154} INFO - Started process (PID=57400) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:52,256] {logging_mixin.py:112} INFO - [2020-08-01 14:35:52,255] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:52,256] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:52,256] {logging_mixin.py:112} INFO - [2020-08-01 14:35:52,256] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:52,258] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:52,272] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:52,280] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:52,282] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:35:56,256] {scheduler_job.py:154} INFO - Started process (PID=57405) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:56,274] {logging_mixin.py:112} INFO - [2020-08-01 14:35:56,273] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:35:56,274] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:35:56,274] {logging_mixin.py:112} INFO - [2020-08-01 14:35:56,274] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:56,276] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:35:56,292] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:35:56,300] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:35:56,302] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:36:00,258] {scheduler_job.py:154} INFO - Started process (PID=57409) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:00,275] {logging_mixin.py:112} INFO - [2020-08-01 14:36:00,275] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:00,276] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:00,276] {logging_mixin.py:112} INFO - [2020-08-01 14:36:00,276] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:00,278] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:00,292] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:00,299] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:00,301] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:36:04,266] {scheduler_job.py:154} INFO - Started process (PID=57413) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:04,283] {logging_mixin.py:112} INFO - [2020-08-01 14:36:04,283] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:04,284] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:04,284] {logging_mixin.py:112} INFO - [2020-08-01 14:36:04,284] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:04,286] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:04,300] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:04,307] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:04,309] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:36:08,292] {scheduler_job.py:154} INFO - Started process (PID=57417) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:08,309] {logging_mixin.py:112} INFO - [2020-08-01 14:36:08,309] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:08,310] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:08,310] {logging_mixin.py:112} INFO - [2020-08-01 14:36:08,310] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:08,311] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:08,326] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:08,333] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:08,334] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:36:12,312] {scheduler_job.py:154} INFO - Started process (PID=57421) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:12,330] {logging_mixin.py:112} INFO - [2020-08-01 14:36:12,329] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:12,330] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:12,330] {logging_mixin.py:112} INFO - [2020-08-01 14:36:12,330] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:12,332] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:12,346] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:12,353] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:12,355] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:36:16,328] {scheduler_job.py:154} INFO - Started process (PID=57425) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:16,345] {logging_mixin.py:112} INFO - [2020-08-01 14:36:16,345] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:16,346] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:16,346] {logging_mixin.py:112} INFO - [2020-08-01 14:36:16,346] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:16,348] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:16,362] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:16,371] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:16,373] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:36:20,337] {scheduler_job.py:154} INFO - Started process (PID=57429) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:20,355] {logging_mixin.py:112} INFO - [2020-08-01 14:36:20,354] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:20,355] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:20,355] {logging_mixin.py:112} INFO - [2020-08-01 14:36:20,355] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:20,357] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:20,371] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:20,378] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:20,380] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:36:24,443] {scheduler_job.py:154} INFO - Started process (PID=57433) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:24,460] {logging_mixin.py:112} INFO - [2020-08-01 14:36:24,460] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:24,461] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:24,461] {logging_mixin.py:112} INFO - [2020-08-01 14:36:24,461] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:24,462] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:24,476] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:24,483] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:24,484] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:36:28,375] {scheduler_job.py:154} INFO - Started process (PID=57438) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:28,392] {logging_mixin.py:112} INFO - [2020-08-01 14:36:28,392] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:28,393] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:28,393] {logging_mixin.py:112} INFO - [2020-08-01 14:36:28,393] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:28,395] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:28,409] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:28,416] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:28,418] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:36:32,387] {scheduler_job.py:154} INFO - Started process (PID=57442) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:32,404] {logging_mixin.py:112} INFO - [2020-08-01 14:36:32,404] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:32,405] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:32,405] {logging_mixin.py:112} INFO - [2020-08-01 14:36:32,405] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:32,407] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:32,421] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:32,428] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:32,430] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:36:36,409] {scheduler_job.py:154} INFO - Started process (PID=57446) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:36,427] {logging_mixin.py:112} INFO - [2020-08-01 14:36:36,427] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:36,428] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:36,428] {logging_mixin.py:112} INFO - [2020-08-01 14:36:36,428] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:36,429] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:36,444] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:36,452] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:36,453] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:36:40,584] {scheduler_job.py:154} INFO - Started process (PID=57450) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:40,601] {logging_mixin.py:112} INFO - [2020-08-01 14:36:40,601] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:40,602] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:40,602] {logging_mixin.py:112} INFO - [2020-08-01 14:36:40,602] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:40,603] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:40,618] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:40,628] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:40,634] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 14:36:44,569] {scheduler_job.py:154} INFO - Started process (PID=57454) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:44,595] {logging_mixin.py:112} INFO - [2020-08-01 14:36:44,595] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:44,595] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:44,596] {logging_mixin.py:112} INFO - [2020-08-01 14:36:44,596] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:44,598] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:44,617] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:44,628] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:44,631] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.062 seconds
[2020-08-01 14:36:48,532] {scheduler_job.py:154} INFO - Started process (PID=57458) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:48,550] {logging_mixin.py:112} INFO - [2020-08-01 14:36:48,550] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:48,551] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:48,551] {logging_mixin.py:112} INFO - [2020-08-01 14:36:48,551] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:48,553] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:48,566] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:48,573] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:48,575] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:36:52,560] {scheduler_job.py:154} INFO - Started process (PID=57462) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:52,577] {logging_mixin.py:112} INFO - [2020-08-01 14:36:52,577] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:52,578] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:52,578] {logging_mixin.py:112} INFO - [2020-08-01 14:36:52,578] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:52,579] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:52,594] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:52,601] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:52,602] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:36:56,568] {scheduler_job.py:154} INFO - Started process (PID=57467) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:56,586] {logging_mixin.py:112} INFO - [2020-08-01 14:36:56,586] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:36:56,587] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:36:56,587] {logging_mixin.py:112} INFO - [2020-08-01 14:36:56,587] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:56,589] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:36:56,604] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:36:56,612] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:36:56,614] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:37:00,467] {scheduler_job.py:154} INFO - Started process (PID=57471) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:00,485] {logging_mixin.py:112} INFO - [2020-08-01 14:37:00,485] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:00,485] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:00,486] {logging_mixin.py:112} INFO - [2020-08-01 14:37:00,486] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:00,487] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:00,502] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:00,510] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:00,511] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:37:04,472] {scheduler_job.py:154} INFO - Started process (PID=57475) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:04,490] {logging_mixin.py:112} INFO - [2020-08-01 14:37:04,490] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:04,491] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:04,491] {logging_mixin.py:112} INFO - [2020-08-01 14:37:04,491] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:04,493] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:04,507] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:04,514] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:04,515] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:08,493] {scheduler_job.py:154} INFO - Started process (PID=57479) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:08,511] {logging_mixin.py:112} INFO - [2020-08-01 14:37:08,510] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:08,511] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:08,511] {logging_mixin.py:112} INFO - [2020-08-01 14:37:08,511] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:08,513] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:08,528] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:08,535] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:08,536] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:12,514] {scheduler_job.py:154} INFO - Started process (PID=57483) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:12,531] {logging_mixin.py:112} INFO - [2020-08-01 14:37:12,531] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:12,532] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:12,532] {logging_mixin.py:112} INFO - [2020-08-01 14:37:12,532] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:12,534] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:12,548] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:12,556] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:12,557] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:37:16,522] {scheduler_job.py:154} INFO - Started process (PID=57487) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:16,540] {logging_mixin.py:112} INFO - [2020-08-01 14:37:16,540] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:16,540] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:16,540] {logging_mixin.py:112} INFO - [2020-08-01 14:37:16,540] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:16,542] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:16,557] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:16,563] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:16,565] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:20,554] {scheduler_job.py:154} INFO - Started process (PID=57491) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:20,572] {logging_mixin.py:112} INFO - [2020-08-01 14:37:20,571] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:20,572] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:20,572] {logging_mixin.py:112} INFO - [2020-08-01 14:37:20,572] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:20,574] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:20,588] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:20,596] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:20,597] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:24,559] {scheduler_job.py:154} INFO - Started process (PID=57495) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:24,576] {logging_mixin.py:112} INFO - [2020-08-01 14:37:24,576] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:24,577] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:24,577] {logging_mixin.py:112} INFO - [2020-08-01 14:37:24,577] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:24,579] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:24,593] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:24,600] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:24,601] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:28,591] {scheduler_job.py:154} INFO - Started process (PID=57500) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:28,609] {logging_mixin.py:112} INFO - [2020-08-01 14:37:28,609] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:28,610] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:28,610] {logging_mixin.py:112} INFO - [2020-08-01 14:37:28,610] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:28,611] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:28,626] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:28,633] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:28,635] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:32,608] {scheduler_job.py:154} INFO - Started process (PID=57504) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:32,626] {logging_mixin.py:112} INFO - [2020-08-01 14:37:32,625] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:32,626] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:32,626] {logging_mixin.py:112} INFO - [2020-08-01 14:37:32,626] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:32,628] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:32,642] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:32,650] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:32,651] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:36,604] {scheduler_job.py:154} INFO - Started process (PID=57508) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:36,622] {logging_mixin.py:112} INFO - [2020-08-01 14:37:36,621] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:36,622] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:36,622] {logging_mixin.py:112} INFO - [2020-08-01 14:37:36,622] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:36,624] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:36,638] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:36,645] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:36,647] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:40,635] {scheduler_job.py:154} INFO - Started process (PID=57512) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:40,653] {logging_mixin.py:112} INFO - [2020-08-01 14:37:40,653] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:40,654] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:40,654] {logging_mixin.py:112} INFO - [2020-08-01 14:37:40,654] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:40,656] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:40,670] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:40,677] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:40,679] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:44,651] {scheduler_job.py:154} INFO - Started process (PID=57516) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:44,668] {logging_mixin.py:112} INFO - [2020-08-01 14:37:44,668] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:44,669] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:44,669] {logging_mixin.py:112} INFO - [2020-08-01 14:37:44,669] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:44,671] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:44,685] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:44,692] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:44,693] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:37:48,669] {scheduler_job.py:154} INFO - Started process (PID=57520) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:48,686] {logging_mixin.py:112} INFO - [2020-08-01 14:37:48,686] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:48,687] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:48,687] {logging_mixin.py:112} INFO - [2020-08-01 14:37:48,687] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:48,689] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:48,703] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:48,710] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:48,711] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:37:52,784] {scheduler_job.py:154} INFO - Started process (PID=57524) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:52,801] {logging_mixin.py:112} INFO - [2020-08-01 14:37:52,801] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:52,801] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:52,802] {logging_mixin.py:112} INFO - [2020-08-01 14:37:52,801] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:52,803] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:52,817] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:52,824] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:52,826] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:37:56,826] {scheduler_job.py:154} INFO - Started process (PID=57539) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:56,844] {logging_mixin.py:112} INFO - [2020-08-01 14:37:56,844] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:37:56,845] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:37:56,845] {logging_mixin.py:112} INFO - [2020-08-01 14:37:56,845] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:56,847] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:37:56,861] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:37:56,868] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:37:56,869] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:00,715] {scheduler_job.py:154} INFO - Started process (PID=57553) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:00,733] {logging_mixin.py:112} INFO - [2020-08-01 14:38:00,733] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:00,733] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:00,733] {logging_mixin.py:112} INFO - [2020-08-01 14:38:00,733] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:00,735] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:00,749] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:00,756] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:00,757] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:04,761] {scheduler_job.py:154} INFO - Started process (PID=57565) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:04,779] {logging_mixin.py:112} INFO - [2020-08-01 14:38:04,779] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:04,780] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:04,780] {logging_mixin.py:112} INFO - [2020-08-01 14:38:04,780] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:04,781] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:04,796] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:04,803] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:04,804] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:08,770] {scheduler_job.py:154} INFO - Started process (PID=57569) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:08,788] {logging_mixin.py:112} INFO - [2020-08-01 14:38:08,788] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:08,788] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:08,789] {logging_mixin.py:112} INFO - [2020-08-01 14:38:08,788] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:08,790] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:08,804] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:08,811] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:08,813] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:12,796] {scheduler_job.py:154} INFO - Started process (PID=57581) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:12,814] {logging_mixin.py:112} INFO - [2020-08-01 14:38:12,814] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:12,815] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:12,815] {logging_mixin.py:112} INFO - [2020-08-01 14:38:12,815] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:12,816] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:12,831] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:12,838] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:12,839] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:16,786] {scheduler_job.py:154} INFO - Started process (PID=57593) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:16,804] {logging_mixin.py:112} INFO - [2020-08-01 14:38:16,804] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:16,804] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:16,805] {logging_mixin.py:112} INFO - [2020-08-01 14:38:16,805] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:16,806] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:16,821] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:16,827] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:16,829] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:20,789] {scheduler_job.py:154} INFO - Started process (PID=57605) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:20,807] {logging_mixin.py:112} INFO - [2020-08-01 14:38:20,807] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:20,807] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:20,808] {logging_mixin.py:112} INFO - [2020-08-01 14:38:20,807] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:20,809] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:20,823] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:20,831] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:20,833] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:24,814] {scheduler_job.py:154} INFO - Started process (PID=57617) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:24,831] {logging_mixin.py:112} INFO - [2020-08-01 14:38:24,831] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:24,832] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:24,832] {logging_mixin.py:112} INFO - [2020-08-01 14:38:24,832] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:24,834] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:24,848] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:24,855] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:24,857] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:28,848] {scheduler_job.py:154} INFO - Started process (PID=57622) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:28,867] {logging_mixin.py:112} INFO - [2020-08-01 14:38:28,867] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:28,868] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:28,868] {logging_mixin.py:112} INFO - [2020-08-01 14:38:28,868] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:28,870] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:28,884] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:28,891] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:28,892] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:38:32,944] {scheduler_job.py:154} INFO - Started process (PID=57634) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:32,963] {logging_mixin.py:112} INFO - [2020-08-01 14:38:32,963] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:32,963] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:32,964] {logging_mixin.py:112} INFO - [2020-08-01 14:38:32,963] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:32,965] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:32,981] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:32,988] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:32,990] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:38:36,963] {scheduler_job.py:154} INFO - Started process (PID=57646) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:36,980] {logging_mixin.py:112} INFO - [2020-08-01 14:38:36,980] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:36,981] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:36,981] {logging_mixin.py:112} INFO - [2020-08-01 14:38:36,981] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:36,983] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:36,997] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:37,004] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:37,006] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:40,859] {scheduler_job.py:154} INFO - Started process (PID=57658) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:40,880] {logging_mixin.py:112} INFO - [2020-08-01 14:38:40,880] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:40,881] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:40,881] {logging_mixin.py:112} INFO - [2020-08-01 14:38:40,881] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:40,883] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:40,897] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:40,904] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:40,905] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:38:44,926] {scheduler_job.py:154} INFO - Started process (PID=57663) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:44,944] {logging_mixin.py:112} INFO - [2020-08-01 14:38:44,944] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:44,945] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:44,945] {logging_mixin.py:112} INFO - [2020-08-01 14:38:44,945] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:44,946] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:44,961] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:44,968] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:44,969] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:48,894] {scheduler_job.py:154} INFO - Started process (PID=57675) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:48,912] {logging_mixin.py:112} INFO - [2020-08-01 14:38:48,912] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:48,912] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:48,913] {logging_mixin.py:112} INFO - [2020-08-01 14:38:48,913] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:48,914] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:48,929] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:48,936] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:48,937] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:52,907] {scheduler_job.py:154} INFO - Started process (PID=57724) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:52,925] {logging_mixin.py:112} INFO - [2020-08-01 14:38:52,925] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:52,926] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:52,926] {logging_mixin.py:112} INFO - [2020-08-01 14:38:52,926] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:52,928] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:52,942] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:52,949] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:52,950] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:38:56,913] {scheduler_job.py:154} INFO - Started process (PID=57736) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:56,931] {logging_mixin.py:112} INFO - [2020-08-01 14:38:56,931] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:38:56,931] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:38:56,932] {logging_mixin.py:112} INFO - [2020-08-01 14:38:56,932] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:56,933] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:38:56,949] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:38:56,957] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:38:56,959] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:39:00,935] {scheduler_job.py:154} INFO - Started process (PID=57750) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:00,953] {logging_mixin.py:112} INFO - [2020-08-01 14:39:00,953] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:00,954] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:00,954] {logging_mixin.py:112} INFO - [2020-08-01 14:39:00,954] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:00,956] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:00,970] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:00,976] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:00,978] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:39:04,977] {scheduler_job.py:154} INFO - Started process (PID=57754) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:04,994] {logging_mixin.py:112} INFO - [2020-08-01 14:39:04,994] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:04,995] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:04,995] {logging_mixin.py:112} INFO - [2020-08-01 14:39:04,995] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:04,997] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:05,011] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:05,018] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:05,020] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:39:08,972] {scheduler_job.py:154} INFO - Started process (PID=57766) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:08,990] {logging_mixin.py:112} INFO - [2020-08-01 14:39:08,990] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:08,990] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:08,990] {logging_mixin.py:112} INFO - [2020-08-01 14:39:08,990] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:08,992] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:09,006] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:09,014] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:09,015] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:39:12,995] {scheduler_job.py:154} INFO - Started process (PID=57778) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:13,012] {logging_mixin.py:112} INFO - [2020-08-01 14:39:13,012] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:13,013] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:13,013] {logging_mixin.py:112} INFO - [2020-08-01 14:39:13,013] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:13,015] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:13,029] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:13,036] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:13,037] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:39:17,005] {scheduler_job.py:154} INFO - Started process (PID=57790) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:17,022] {logging_mixin.py:112} INFO - [2020-08-01 14:39:17,022] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:17,023] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:17,023] {logging_mixin.py:112} INFO - [2020-08-01 14:39:17,023] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:17,025] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:17,039] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:17,046] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:17,048] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:39:21,026] {scheduler_job.py:154} INFO - Started process (PID=57802) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:21,044] {logging_mixin.py:112} INFO - [2020-08-01 14:39:21,043] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:21,044] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:21,044] {logging_mixin.py:112} INFO - [2020-08-01 14:39:21,044] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:21,046] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:21,060] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:21,068] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:21,069] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:39:25,058] {scheduler_job.py:154} INFO - Started process (PID=57806) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:25,076] {logging_mixin.py:112} INFO - [2020-08-01 14:39:25,075] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:25,076] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:25,076] {logging_mixin.py:112} INFO - [2020-08-01 14:39:25,076] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:25,078] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:25,093] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:25,100] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:25,101] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:39:29,081] {scheduler_job.py:154} INFO - Started process (PID=57819) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:29,101] {logging_mixin.py:112} INFO - [2020-08-01 14:39:29,101] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:29,102] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:29,102] {logging_mixin.py:112} INFO - [2020-08-01 14:39:29,102] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:29,105] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:29,119] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:29,128] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:29,130] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 14:39:33,053] {scheduler_job.py:154} INFO - Started process (PID=57831) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:33,070] {logging_mixin.py:112} INFO - [2020-08-01 14:39:33,070] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:33,071] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:33,071] {logging_mixin.py:112} INFO - [2020-08-01 14:39:33,071] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:33,073] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:33,087] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:33,094] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:33,096] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:39:37,134] {scheduler_job.py:154} INFO - Started process (PID=57843) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:37,151] {logging_mixin.py:112} INFO - [2020-08-01 14:39:37,151] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:37,151] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:37,151] {logging_mixin.py:112} INFO - [2020-08-01 14:39:37,151] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:37,153] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:37,167] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:37,173] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:37,175] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:39:41,086] {scheduler_job.py:154} INFO - Started process (PID=57855) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:41,104] {logging_mixin.py:112} INFO - [2020-08-01 14:39:41,103] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:41,104] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:41,104] {logging_mixin.py:112} INFO - [2020-08-01 14:39:41,104] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:41,106] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:41,123] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:41,130] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:41,132] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:39:45,249] {scheduler_job.py:154} INFO - Started process (PID=57877) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:45,268] {logging_mixin.py:112} INFO - [2020-08-01 14:39:45,268] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:45,268] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:45,268] {logging_mixin.py:112} INFO - [2020-08-01 14:39:45,268] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:45,270] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:45,285] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:45,293] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:45,294] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:39:49,107] {scheduler_job.py:154} INFO - Started process (PID=57908) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:49,125] {logging_mixin.py:112} INFO - [2020-08-01 14:39:49,125] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:49,125] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:49,126] {logging_mixin.py:112} INFO - [2020-08-01 14:39:49,125] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:49,127] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:49,143] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:49,150] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:49,151] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:39:53,125] {scheduler_job.py:154} INFO - Started process (PID=57920) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:53,143] {logging_mixin.py:112} INFO - [2020-08-01 14:39:53,142] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:53,143] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:53,143] {logging_mixin.py:112} INFO - [2020-08-01 14:39:53,143] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:53,145] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:53,159] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:53,166] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:53,168] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:39:57,143] {scheduler_job.py:154} INFO - Started process (PID=57948) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:57,161] {logging_mixin.py:112} INFO - [2020-08-01 14:39:57,160] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:39:57,161] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:39:57,161] {logging_mixin.py:112} INFO - [2020-08-01 14:39:57,161] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:57,163] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:39:57,175] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:39:57,181] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:39:57,183] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 14:40:01,246] {scheduler_job.py:154} INFO - Started process (PID=57954) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:01,264] {logging_mixin.py:112} INFO - [2020-08-01 14:40:01,264] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:01,265] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:01,265] {logging_mixin.py:112} INFO - [2020-08-01 14:40:01,265] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:01,266] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:01,280] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:01,287] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:01,288] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:40:05,251] {scheduler_job.py:154} INFO - Started process (PID=57982) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:05,270] {logging_mixin.py:112} INFO - [2020-08-01 14:40:05,270] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:05,270] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:05,271] {logging_mixin.py:112} INFO - [2020-08-01 14:40:05,271] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:05,273] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:05,285] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:05,292] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:05,294] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:40:09,169] {scheduler_job.py:154} INFO - Started process (PID=57994) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:09,188] {logging_mixin.py:112} INFO - [2020-08-01 14:40:09,188] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:09,189] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:09,189] {logging_mixin.py:112} INFO - [2020-08-01 14:40:09,189] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:09,191] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:09,207] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:09,215] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:09,217] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:40:13,217] {scheduler_job.py:154} INFO - Started process (PID=58007) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:13,234] {logging_mixin.py:112} INFO - [2020-08-01 14:40:13,234] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:13,235] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:13,235] {logging_mixin.py:112} INFO - [2020-08-01 14:40:13,235] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:13,237] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:13,253] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:13,260] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:13,261] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:40:17,248] {scheduler_job.py:154} INFO - Started process (PID=58019) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:17,265] {logging_mixin.py:112} INFO - [2020-08-01 14:40:17,265] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:17,265] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:17,266] {logging_mixin.py:112} INFO - [2020-08-01 14:40:17,265] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:17,267] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:17,281] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:17,288] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:17,289] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:40:21,212] {scheduler_job.py:154} INFO - Started process (PID=58023) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:21,230] {logging_mixin.py:112} INFO - [2020-08-01 14:40:21,230] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:21,231] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:21,231] {logging_mixin.py:112} INFO - [2020-08-01 14:40:21,231] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:21,232] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:21,247] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:21,254] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:21,255] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:40:25,262] {scheduler_job.py:154} INFO - Started process (PID=58035) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:25,280] {logging_mixin.py:112} INFO - [2020-08-01 14:40:25,280] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:25,281] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:25,281] {logging_mixin.py:112} INFO - [2020-08-01 14:40:25,281] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:25,283] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:25,296] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:25,303] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:25,305] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:40:29,274] {scheduler_job.py:154} INFO - Started process (PID=58048) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:29,293] {logging_mixin.py:112} INFO - [2020-08-01 14:40:29,293] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:29,293] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:29,294] {logging_mixin.py:112} INFO - [2020-08-01 14:40:29,294] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:29,296] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:29,310] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:29,317] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:29,319] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:40:33,266] {scheduler_job.py:154} INFO - Started process (PID=58061) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:33,284] {logging_mixin.py:112} INFO - [2020-08-01 14:40:33,283] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:33,285] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:33,285] {logging_mixin.py:112} INFO - [2020-08-01 14:40:33,285] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:33,288] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:33,309] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:33,316] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:33,317] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 14:40:37,353] {scheduler_job.py:154} INFO - Started process (PID=58073) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:37,372] {logging_mixin.py:112} INFO - [2020-08-01 14:40:37,372] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:37,373] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:37,373] {logging_mixin.py:112} INFO - [2020-08-01 14:40:37,373] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:37,374] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:37,388] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:37,395] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:37,396] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:40:41,358] {scheduler_job.py:154} INFO - Started process (PID=58077) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:41,376] {logging_mixin.py:112} INFO - [2020-08-01 14:40:41,376] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:41,376] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:41,377] {logging_mixin.py:112} INFO - [2020-08-01 14:40:41,377] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:41,378] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:41,392] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:41,399] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:41,400] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:40:45,315] {scheduler_job.py:154} INFO - Started process (PID=58090) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:45,333] {logging_mixin.py:112} INFO - [2020-08-01 14:40:45,333] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:45,334] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:45,334] {logging_mixin.py:112} INFO - [2020-08-01 14:40:45,334] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:45,336] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:45,350] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:45,358] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:45,360] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:40:49,317] {scheduler_job.py:154} INFO - Started process (PID=58102) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:49,335] {logging_mixin.py:112} INFO - [2020-08-01 14:40:49,335] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:49,335] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:49,336] {logging_mixin.py:112} INFO - [2020-08-01 14:40:49,336] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:49,337] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:49,352] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:49,358] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:49,360] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:40:53,356] {scheduler_job.py:154} INFO - Started process (PID=58114) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:53,374] {logging_mixin.py:112} INFO - [2020-08-01 14:40:53,374] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:53,374] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:53,375] {logging_mixin.py:112} INFO - [2020-08-01 14:40:53,375] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:53,376] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:53,391] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:53,399] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:53,400] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:40:57,431] {scheduler_job.py:154} INFO - Started process (PID=58118) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:57,450] {logging_mixin.py:112} INFO - [2020-08-01 14:40:57,450] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:40:57,450] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:40:57,451] {logging_mixin.py:112} INFO - [2020-08-01 14:40:57,450] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:57,452] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:40:57,467] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:40:57,474] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:40:57,476] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:41:01,344] {scheduler_job.py:154} INFO - Started process (PID=58132) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:01,361] {logging_mixin.py:112} INFO - [2020-08-01 14:41:01,361] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:01,362] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:01,362] {logging_mixin.py:112} INFO - [2020-08-01 14:41:01,362] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:01,364] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:01,377] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:01,384] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:01,386] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:41:05,336] {scheduler_job.py:154} INFO - Started process (PID=58144) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:05,353] {logging_mixin.py:112} INFO - [2020-08-01 14:41:05,353] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:05,354] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:05,354] {logging_mixin.py:112} INFO - [2020-08-01 14:41:05,354] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:05,356] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:05,370] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:05,377] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:05,379] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:41:09,349] {scheduler_job.py:154} INFO - Started process (PID=58156) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:09,368] {logging_mixin.py:112} INFO - [2020-08-01 14:41:09,368] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:09,369] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:09,369] {logging_mixin.py:112} INFO - [2020-08-01 14:41:09,369] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:09,371] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:09,385] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:09,392] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:09,394] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:41:13,377] {scheduler_job.py:154} INFO - Started process (PID=58169) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:13,395] {logging_mixin.py:112} INFO - [2020-08-01 14:41:13,395] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:13,396] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:13,396] {logging_mixin.py:112} INFO - [2020-08-01 14:41:13,396] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:13,398] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:13,412] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:13,418] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:13,420] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:41:17,397] {scheduler_job.py:154} INFO - Started process (PID=58173) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:17,416] {logging_mixin.py:112} INFO - [2020-08-01 14:41:17,416] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:17,417] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:17,417] {logging_mixin.py:112} INFO - [2020-08-01 14:41:17,417] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:17,419] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:17,434] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:17,442] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:17,443] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:41:21,396] {scheduler_job.py:154} INFO - Started process (PID=58185) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:21,413] {logging_mixin.py:112} INFO - [2020-08-01 14:41:21,413] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:21,414] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:21,414] {logging_mixin.py:112} INFO - [2020-08-01 14:41:21,414] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:21,416] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:21,430] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:21,438] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:21,439] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:41:25,411] {scheduler_job.py:154} INFO - Started process (PID=58197) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:25,429] {logging_mixin.py:112} INFO - [2020-08-01 14:41:25,429] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:25,429] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:25,430] {logging_mixin.py:112} INFO - [2020-08-01 14:41:25,429] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:25,431] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:25,446] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:25,453] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:25,454] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:41:29,424] {scheduler_job.py:154} INFO - Started process (PID=58210) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:29,442] {logging_mixin.py:112} INFO - [2020-08-01 14:41:29,442] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:29,442] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:29,442] {logging_mixin.py:112} INFO - [2020-08-01 14:41:29,442] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:29,444] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:29,459] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:29,465] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:29,467] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:41:33,444] {scheduler_job.py:154} INFO - Started process (PID=58223) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:33,461] {logging_mixin.py:112} INFO - [2020-08-01 14:41:33,461] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:33,462] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:33,462] {logging_mixin.py:112} INFO - [2020-08-01 14:41:33,462] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:33,464] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:33,480] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:33,486] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:33,488] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:41:37,469] {scheduler_job.py:154} INFO - Started process (PID=58227) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:37,489] {logging_mixin.py:112} INFO - [2020-08-01 14:41:37,489] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:37,490] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:37,491] {logging_mixin.py:112} INFO - [2020-08-01 14:41:37,490] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:37,493] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:37,508] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:37,515] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:37,517] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:41:41,454] {scheduler_job.py:154} INFO - Started process (PID=58239) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:41,472] {logging_mixin.py:112} INFO - [2020-08-01 14:41:41,472] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:41,472] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:41,472] {logging_mixin.py:112} INFO - [2020-08-01 14:41:41,472] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:41,474] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:41,489] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:41,495] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:41,497] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:41:45,482] {scheduler_job.py:154} INFO - Started process (PID=58251) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:45,499] {logging_mixin.py:112} INFO - [2020-08-01 14:41:45,499] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:45,500] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:45,500] {logging_mixin.py:112} INFO - [2020-08-01 14:41:45,500] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:45,502] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:45,516] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:45,525] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:45,526] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:41:49,501] {scheduler_job.py:154} INFO - Started process (PID=58263) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:49,519] {logging_mixin.py:112} INFO - [2020-08-01 14:41:49,519] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:49,519] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:49,520] {logging_mixin.py:112} INFO - [2020-08-01 14:41:49,520] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:49,521] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:49,535] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:49,542] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:49,544] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:41:53,524] {scheduler_job.py:154} INFO - Started process (PID=58275) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:53,542] {logging_mixin.py:112} INFO - [2020-08-01 14:41:53,541] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:53,542] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:53,542] {logging_mixin.py:112} INFO - [2020-08-01 14:41:53,542] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:53,544] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:53,558] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:53,566] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:53,567] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:41:57,539] {scheduler_job.py:154} INFO - Started process (PID=58279) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:57,559] {logging_mixin.py:112} INFO - [2020-08-01 14:41:57,558] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:41:57,559] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:41:57,559] {logging_mixin.py:112} INFO - [2020-08-01 14:41:57,559] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:57,561] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:41:57,577] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:41:57,586] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:41:57,588] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 14:42:01,604] {scheduler_job.py:154} INFO - Started process (PID=58292) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:01,621] {logging_mixin.py:112} INFO - [2020-08-01 14:42:01,621] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:01,622] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:01,622] {logging_mixin.py:112} INFO - [2020-08-01 14:42:01,622] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:01,624] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:01,637] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:01,644] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:01,645] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:42:05,604] {scheduler_job.py:154} INFO - Started process (PID=58305) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:05,622] {logging_mixin.py:112} INFO - [2020-08-01 14:42:05,622] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:05,623] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:05,623] {logging_mixin.py:112} INFO - [2020-08-01 14:42:05,623] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:05,625] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:05,640] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:05,647] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:05,649] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:42:09,610] {scheduler_job.py:154} INFO - Started process (PID=58318) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:09,628] {logging_mixin.py:112} INFO - [2020-08-01 14:42:09,628] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:09,628] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:09,629] {logging_mixin.py:112} INFO - [2020-08-01 14:42:09,629] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:09,630] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:09,645] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:09,651] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:09,653] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:42:13,652] {scheduler_job.py:154} INFO - Started process (PID=58323) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:13,670] {logging_mixin.py:112} INFO - [2020-08-01 14:42:13,670] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:13,671] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:13,671] {logging_mixin.py:112} INFO - [2020-08-01 14:42:13,671] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:13,673] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:13,686] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:13,693] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:13,695] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:42:17,610] {scheduler_job.py:154} INFO - Started process (PID=58335) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:17,627] {logging_mixin.py:112} INFO - [2020-08-01 14:42:17,627] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:17,628] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:17,628] {logging_mixin.py:112} INFO - [2020-08-01 14:42:17,628] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:17,630] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:17,642] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:17,649] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:17,650] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 14:42:21,653] {scheduler_job.py:154} INFO - Started process (PID=58347) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:21,670] {logging_mixin.py:112} INFO - [2020-08-01 14:42:21,670] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:21,670] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:21,671] {logging_mixin.py:112} INFO - [2020-08-01 14:42:21,671] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:21,672] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:21,687] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:21,694] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:21,695] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:42:25,632] {scheduler_job.py:154} INFO - Started process (PID=58359) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:25,651] {logging_mixin.py:112} INFO - [2020-08-01 14:42:25,651] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:25,652] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:25,652] {logging_mixin.py:112} INFO - [2020-08-01 14:42:25,652] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:25,654] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:25,667] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:25,673] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:25,675] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:42:29,703] {scheduler_job.py:154} INFO - Started process (PID=58372) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:29,720] {logging_mixin.py:112} INFO - [2020-08-01 14:42:29,720] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:29,721] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:29,721] {logging_mixin.py:112} INFO - [2020-08-01 14:42:29,721] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:29,723] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:29,737] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:29,743] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:29,745] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:42:33,693] {scheduler_job.py:154} INFO - Started process (PID=58377) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:33,711] {logging_mixin.py:112} INFO - [2020-08-01 14:42:33,711] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:33,711] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:33,711] {logging_mixin.py:112} INFO - [2020-08-01 14:42:33,711] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:33,713] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:33,727] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:33,734] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:33,736] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:42:37,671] {scheduler_job.py:154} INFO - Started process (PID=58389) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:37,689] {logging_mixin.py:112} INFO - [2020-08-01 14:42:37,688] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:37,689] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:37,689] {logging_mixin.py:112} INFO - [2020-08-01 14:42:37,689] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:37,691] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:37,705] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:37,713] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:37,714] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:42:41,682] {scheduler_job.py:154} INFO - Started process (PID=58401) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:41,700] {logging_mixin.py:112} INFO - [2020-08-01 14:42:41,700] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:41,701] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:41,701] {logging_mixin.py:112} INFO - [2020-08-01 14:42:41,701] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:41,703] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:41,717] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:41,724] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:41,725] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:42:45,690] {scheduler_job.py:154} INFO - Started process (PID=58414) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:45,708] {logging_mixin.py:112} INFO - [2020-08-01 14:42:45,708] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:45,709] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:45,709] {logging_mixin.py:112} INFO - [2020-08-01 14:42:45,709] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:45,711] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:45,725] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:45,731] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:45,733] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:42:49,726] {scheduler_job.py:154} INFO - Started process (PID=58426) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:49,744] {logging_mixin.py:112} INFO - [2020-08-01 14:42:49,744] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:49,744] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:49,744] {logging_mixin.py:112} INFO - [2020-08-01 14:42:49,744] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:49,746] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:49,761] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:49,767] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:49,769] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:42:53,759] {scheduler_job.py:154} INFO - Started process (PID=58430) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:53,777] {logging_mixin.py:112} INFO - [2020-08-01 14:42:53,776] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:53,777] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:53,777] {logging_mixin.py:112} INFO - [2020-08-01 14:42:53,777] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:53,779] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:53,793] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:53,800] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:53,801] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:42:57,825] {scheduler_job.py:154} INFO - Started process (PID=58442) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:57,843] {logging_mixin.py:112} INFO - [2020-08-01 14:42:57,843] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:42:57,844] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:42:57,844] {logging_mixin.py:112} INFO - [2020-08-01 14:42:57,844] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:57,845] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:42:57,861] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:42:57,870] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:42:57,873] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:43:01,766] {scheduler_job.py:154} INFO - Started process (PID=58455) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:01,787] {logging_mixin.py:112} INFO - [2020-08-01 14:43:01,787] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:01,787] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:01,788] {logging_mixin.py:112} INFO - [2020-08-01 14:43:01,788] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:01,789] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:01,805] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:01,812] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:01,814] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:43:05,785] {scheduler_job.py:154} INFO - Started process (PID=58468) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:05,803] {logging_mixin.py:112} INFO - [2020-08-01 14:43:05,802] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:05,803] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:05,803] {logging_mixin.py:112} INFO - [2020-08-01 14:43:05,803] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:05,805] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:05,820] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:05,828] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:05,829] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:43:09,863] {scheduler_job.py:154} INFO - Started process (PID=58472) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:09,880] {logging_mixin.py:112} INFO - [2020-08-01 14:43:09,880] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:09,881] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:09,881] {logging_mixin.py:112} INFO - [2020-08-01 14:43:09,881] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:09,882] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:09,903] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:09,915] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:09,918] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.055 seconds
[2020-08-01 14:43:13,829] {scheduler_job.py:154} INFO - Started process (PID=58485) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:13,847] {logging_mixin.py:112} INFO - [2020-08-01 14:43:13,847] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:13,848] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:13,848] {logging_mixin.py:112} INFO - [2020-08-01 14:43:13,848] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:13,850] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:13,871] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:13,882] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:13,885] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.056 seconds
[2020-08-01 14:43:17,836] {scheduler_job.py:154} INFO - Started process (PID=58497) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:17,855] {logging_mixin.py:112} INFO - [2020-08-01 14:43:17,855] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:17,856] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:17,856] {logging_mixin.py:112} INFO - [2020-08-01 14:43:17,856] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:17,858] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:17,872] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:17,878] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:17,880] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:43:21,877] {scheduler_job.py:154} INFO - Started process (PID=58509) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:21,895] {logging_mixin.py:112} INFO - [2020-08-01 14:43:21,895] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:21,896] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:21,896] {logging_mixin.py:112} INFO - [2020-08-01 14:43:21,896] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:21,897] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:21,912] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:21,919] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:21,921] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:43:25,882] {scheduler_job.py:154} INFO - Started process (PID=58521) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:25,908] {logging_mixin.py:112} INFO - [2020-08-01 14:43:25,908] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:25,909] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:25,909] {logging_mixin.py:112} INFO - [2020-08-01 14:43:25,909] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:25,912] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:25,927] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:25,934] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:25,936] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.055 seconds
[2020-08-01 14:43:29,982] {scheduler_job.py:154} INFO - Started process (PID=58526) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:29,999] {logging_mixin.py:112} INFO - [2020-08-01 14:43:29,999] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:29,999] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:29,999] {logging_mixin.py:112} INFO - [2020-08-01 14:43:29,999] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:30,001] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:30,015] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:30,022] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:30,024] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:43:33,994] {scheduler_job.py:154} INFO - Started process (PID=58538) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:34,012] {logging_mixin.py:112} INFO - [2020-08-01 14:43:34,012] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:34,013] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:34,013] {logging_mixin.py:112} INFO - [2020-08-01 14:43:34,013] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:34,014] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:34,030] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:34,037] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:34,039] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:43:37,845] {scheduler_job.py:154} INFO - Started process (PID=58551) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:37,863] {logging_mixin.py:112} INFO - [2020-08-01 14:43:37,863] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:37,864] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:37,864] {logging_mixin.py:112} INFO - [2020-08-01 14:43:37,864] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:37,866] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:37,879] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:37,885] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:37,887] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:43:41,915] {scheduler_job.py:154} INFO - Started process (PID=58563) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:41,933] {logging_mixin.py:112} INFO - [2020-08-01 14:43:41,933] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:41,933] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:41,934] {logging_mixin.py:112} INFO - [2020-08-01 14:43:41,934] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:41,935] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:41,950] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:41,959] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:41,961] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:43:45,961] {scheduler_job.py:154} INFO - Started process (PID=58576) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:45,979] {logging_mixin.py:112} INFO - [2020-08-01 14:43:45,979] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:45,980] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:45,980] {logging_mixin.py:112} INFO - [2020-08-01 14:43:45,980] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:45,982] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:45,997] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:46,003] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:46,005] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:43:50,014] {scheduler_job.py:154} INFO - Started process (PID=58597) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:50,032] {logging_mixin.py:112} INFO - [2020-08-01 14:43:50,032] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:50,033] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:50,033] {logging_mixin.py:112} INFO - [2020-08-01 14:43:50,033] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:50,035] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:50,049] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:50,056] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:50,057] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:43:53,909] {scheduler_job.py:154} INFO - Started process (PID=58609) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:53,926] {logging_mixin.py:112} INFO - [2020-08-01 14:43:53,926] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:53,926] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:53,927] {logging_mixin.py:112} INFO - [2020-08-01 14:43:53,927] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:53,928] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:53,943] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:53,949] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:53,951] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:43:59,907] {scheduler_job.py:154} INFO - Started process (PID=58692) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:59,925] {logging_mixin.py:112} INFO - [2020-08-01 14:43:59,925] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:43:59,926] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:43:59,926] {logging_mixin.py:112} INFO - [2020-08-01 14:43:59,926] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:59,927] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:43:59,942] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:43:59,950] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:43:59,952] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:44:05,949] {scheduler_job.py:154} INFO - Started process (PID=58724) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:05,967] {logging_mixin.py:112} INFO - [2020-08-01 14:44:05,966] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:05,967] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:44:05,967] {logging_mixin.py:112} INFO - [2020-08-01 14:44:05,967] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:05,969] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:05,982] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:44:05,989] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:44:05,990] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:44:11,961] {scheduler_job.py:154} INFO - Started process (PID=58730) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:11,980] {logging_mixin.py:112} INFO - [2020-08-01 14:44:11,980] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:11,981] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:44:11,981] {logging_mixin.py:112} INFO - [2020-08-01 14:44:11,981] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:11,983] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:11,997] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:44:12,005] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:44:12,007] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:44:17,975] {scheduler_job.py:154} INFO - Started process (PID=58738) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:17,992] {logging_mixin.py:112} INFO - [2020-08-01 14:44:17,992] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:17,993] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:44:17,993] {logging_mixin.py:112} INFO - [2020-08-01 14:44:17,993] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:17,995] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:18,008] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:44:18,015] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:44:18,016] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:44:23,970] {scheduler_job.py:154} INFO - Started process (PID=58744) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:23,987] {logging_mixin.py:112} INFO - [2020-08-01 14:44:23,987] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:23,988] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:44:23,988] {logging_mixin.py:112} INFO - [2020-08-01 14:44:23,988] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:23,990] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:24,004] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:44:24,011] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:44:24,013] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:44:29,987] {scheduler_job.py:154} INFO - Started process (PID=58750) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:30,005] {logging_mixin.py:112} INFO - [2020-08-01 14:44:30,005] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:30,006] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:44:30,006] {logging_mixin.py:112} INFO - [2020-08-01 14:44:30,006] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:30,007] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:30,022] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:44:30,029] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:44:30,030] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:44:36,092] {scheduler_job.py:154} INFO - Started process (PID=58757) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:36,109] {logging_mixin.py:112} INFO - [2020-08-01 14:44:36,109] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:36,110] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:44:36,110] {logging_mixin.py:112} INFO - [2020-08-01 14:44:36,110] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:36,112] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:36,126] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:44:36,133] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:44:36,134] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:44:42,072] {scheduler_job.py:154} INFO - Started process (PID=58772) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:42,089] {logging_mixin.py:112} INFO - [2020-08-01 14:44:42,089] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:42,090] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:44:42,090] {logging_mixin.py:112} INFO - [2020-08-01 14:44:42,090] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:42,092] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:42,106] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:44:42,115] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:44:42,117] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:44:48,108] {scheduler_job.py:154} INFO - Started process (PID=58789) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:48,136] {logging_mixin.py:112} INFO - [2020-08-01 14:44:48,136] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:48,137] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:44:48,137] {logging_mixin.py:112} INFO - [2020-08-01 14:44:48,137] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:48,140] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:48,159] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:44:48,168] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:44:48,169] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.062 seconds
[2020-08-01 14:44:54,085] {scheduler_job.py:154} INFO - Started process (PID=58845) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:54,103] {logging_mixin.py:112} INFO - [2020-08-01 14:44:54,103] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:44:54,103] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:44:54,103] {logging_mixin.py:112} INFO - [2020-08-01 14:44:54,103] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:54,105] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:44:54,120] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:44:54,129] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:44:54,131] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:45:00,161] {scheduler_job.py:154} INFO - Started process (PID=58860) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:00,178] {logging_mixin.py:112} INFO - [2020-08-01 14:45:00,178] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:00,179] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:00,179] {logging_mixin.py:112} INFO - [2020-08-01 14:45:00,179] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:00,180] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:00,194] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:00,200] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:00,202] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:45:06,320] {scheduler_job.py:154} INFO - Started process (PID=58874) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:06,337] {logging_mixin.py:112} INFO - [2020-08-01 14:45:06,337] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:06,338] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:06,338] {logging_mixin.py:112} INFO - [2020-08-01 14:45:06,338] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:06,339] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:06,353] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:06,360] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:06,362] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:45:12,187] {scheduler_job.py:154} INFO - Started process (PID=58889) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:12,205] {logging_mixin.py:112} INFO - [2020-08-01 14:45:12,205] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:12,206] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:12,206] {logging_mixin.py:112} INFO - [2020-08-01 14:45:12,206] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:12,208] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:12,223] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:12,230] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:12,231] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:45:18,277] {scheduler_job.py:154} INFO - Started process (PID=58904) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:18,295] {logging_mixin.py:112} INFO - [2020-08-01 14:45:18,295] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:18,295] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:18,295] {logging_mixin.py:112} INFO - [2020-08-01 14:45:18,295] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:18,297] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:18,312] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:18,319] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:18,320] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:45:24,221] {scheduler_job.py:154} INFO - Started process (PID=58943) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:24,239] {logging_mixin.py:112} INFO - [2020-08-01 14:45:24,239] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:24,240] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:24,240] {logging_mixin.py:112} INFO - [2020-08-01 14:45:24,240] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:24,242] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:24,256] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:24,263] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:24,264] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:45:30,320] {scheduler_job.py:154} INFO - Started process (PID=58958) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:30,341] {logging_mixin.py:112} INFO - [2020-08-01 14:45:30,341] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:30,342] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:30,342] {logging_mixin.py:112} INFO - [2020-08-01 14:45:30,342] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:30,345] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:30,360] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:30,367] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:30,369] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 14:45:36,321] {scheduler_job.py:154} INFO - Started process (PID=58968) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:36,340] {logging_mixin.py:112} INFO - [2020-08-01 14:45:36,340] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:36,341] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:36,341] {logging_mixin.py:112} INFO - [2020-08-01 14:45:36,341] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:36,344] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:36,362] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:36,370] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:36,371] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 14:45:42,267] {scheduler_job.py:154} INFO - Started process (PID=58975) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:42,286] {logging_mixin.py:112} INFO - [2020-08-01 14:45:42,286] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:42,287] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:42,287] {logging_mixin.py:112} INFO - [2020-08-01 14:45:42,287] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:42,290] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:42,303] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:42,311] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:42,313] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:45:48,305] {scheduler_job.py:154} INFO - Started process (PID=58982) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:48,323] {logging_mixin.py:112} INFO - [2020-08-01 14:45:48,323] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:48,323] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:48,324] {logging_mixin.py:112} INFO - [2020-08-01 14:45:48,323] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:48,325] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:48,339] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:48,347] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:48,349] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:45:54,380] {scheduler_job.py:154} INFO - Started process (PID=58996) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:54,399] {logging_mixin.py:112} INFO - [2020-08-01 14:45:54,399] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:45:54,400] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:45:54,400] {logging_mixin.py:112} INFO - [2020-08-01 14:45:54,400] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:54,402] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:45:54,416] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:45:54,425] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:45:54,427] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:46:00,326] {scheduler_job.py:154} INFO - Started process (PID=59011) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:00,344] {logging_mixin.py:112} INFO - [2020-08-01 14:46:00,343] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:00,344] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:00,344] {logging_mixin.py:112} INFO - [2020-08-01 14:46:00,344] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:00,346] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:00,360] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:00,367] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:00,369] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:46:06,324] {scheduler_job.py:154} INFO - Started process (PID=59059) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:06,342] {logging_mixin.py:112} INFO - [2020-08-01 14:46:06,341] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:06,342] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:06,342] {logging_mixin.py:112} INFO - [2020-08-01 14:46:06,342] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:06,344] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:06,360] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:06,368] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:06,370] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:46:12,329] {scheduler_job.py:154} INFO - Started process (PID=59082) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:12,347] {logging_mixin.py:112} INFO - [2020-08-01 14:46:12,347] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:12,347] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:12,348] {logging_mixin.py:112} INFO - [2020-08-01 14:46:12,347] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:12,349] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:12,364] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:12,371] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:12,372] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:46:18,352] {scheduler_job.py:154} INFO - Started process (PID=59114) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:18,369] {logging_mixin.py:112} INFO - [2020-08-01 14:46:18,369] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:18,370] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:18,370] {logging_mixin.py:112} INFO - [2020-08-01 14:46:18,370] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:18,372] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:18,386] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:18,393] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:18,395] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:46:24,560] {scheduler_job.py:154} INFO - Started process (PID=59128) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:24,579] {logging_mixin.py:112} INFO - [2020-08-01 14:46:24,579] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:24,580] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:24,580] {logging_mixin.py:112} INFO - [2020-08-01 14:46:24,580] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:24,583] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:24,597] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:24,605] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:24,606] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:46:30,416] {scheduler_job.py:154} INFO - Started process (PID=59135) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:30,434] {logging_mixin.py:112} INFO - [2020-08-01 14:46:30,434] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:30,434] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:30,435] {logging_mixin.py:112} INFO - [2020-08-01 14:46:30,434] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:30,436] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:30,452] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:30,459] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:30,461] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:46:36,389] {scheduler_job.py:154} INFO - Started process (PID=59141) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:36,407] {logging_mixin.py:112} INFO - [2020-08-01 14:46:36,407] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:36,407] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:36,408] {logging_mixin.py:112} INFO - [2020-08-01 14:46:36,407] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:36,409] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:36,423] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:36,431] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:36,432] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:46:42,505] {scheduler_job.py:154} INFO - Started process (PID=59156) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:42,522] {logging_mixin.py:112} INFO - [2020-08-01 14:46:42,522] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:42,523] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:42,523] {logging_mixin.py:112} INFO - [2020-08-01 14:46:42,523] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:42,525] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:42,539] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:42,545] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:42,547] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:46:48,532] {scheduler_job.py:154} INFO - Started process (PID=59171) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:48,554] {logging_mixin.py:112} INFO - [2020-08-01 14:46:48,553] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:48,554] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:48,554] {logging_mixin.py:112} INFO - [2020-08-01 14:46:48,554] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:48,556] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:48,570] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:48,578] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:48,579] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:46:54,486] {scheduler_job.py:154} INFO - Started process (PID=59185) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:54,503] {logging_mixin.py:112} INFO - [2020-08-01 14:46:54,503] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:46:54,504] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:46:54,504] {logging_mixin.py:112} INFO - [2020-08-01 14:46:54,504] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:54,506] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:46:54,520] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:46:54,528] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:46:54,529] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:47:00,553] {scheduler_job.py:154} INFO - Started process (PID=59200) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:00,570] {logging_mixin.py:112} INFO - [2020-08-01 14:47:00,570] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:00,571] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:00,571] {logging_mixin.py:112} INFO - [2020-08-01 14:47:00,571] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:00,572] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:00,587] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:00,594] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:00,596] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:47:06,484] {scheduler_job.py:154} INFO - Started process (PID=59214) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:06,502] {logging_mixin.py:112} INFO - [2020-08-01 14:47:06,502] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:06,503] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:06,503] {logging_mixin.py:112} INFO - [2020-08-01 14:47:06,503] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:06,504] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:06,519] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:06,526] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:06,528] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:47:12,580] {scheduler_job.py:154} INFO - Started process (PID=59229) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:12,597] {logging_mixin.py:112} INFO - [2020-08-01 14:47:12,597] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:12,598] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:12,598] {logging_mixin.py:112} INFO - [2020-08-01 14:47:12,598] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:12,600] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:12,613] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:12,619] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:12,621] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:47:18,541] {scheduler_job.py:154} INFO - Started process (PID=59278) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:18,559] {logging_mixin.py:112} INFO - [2020-08-01 14:47:18,559] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:18,560] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:18,560] {logging_mixin.py:112} INFO - [2020-08-01 14:47:18,560] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:18,562] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:18,576] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:18,583] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:18,584] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:47:24,545] {scheduler_job.py:154} INFO - Started process (PID=59284) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:24,563] {logging_mixin.py:112} INFO - [2020-08-01 14:47:24,563] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:24,564] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:24,564] {logging_mixin.py:112} INFO - [2020-08-01 14:47:24,564] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:24,566] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:24,580] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:24,587] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:24,589] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:47:30,647] {scheduler_job.py:154} INFO - Started process (PID=59291) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:30,667] {logging_mixin.py:112} INFO - [2020-08-01 14:47:30,667] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:30,668] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:30,668] {logging_mixin.py:112} INFO - [2020-08-01 14:47:30,668] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:30,676] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:30,698] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:30,709] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:30,711] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.064 seconds
[2020-08-01 14:47:36,779] {scheduler_job.py:154} INFO - Started process (PID=59297) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:36,797] {logging_mixin.py:112} INFO - [2020-08-01 14:47:36,797] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:36,797] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:36,798] {logging_mixin.py:112} INFO - [2020-08-01 14:47:36,798] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:36,799] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:36,815] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:36,822] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:36,824] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:47:42,597] {scheduler_job.py:154} INFO - Started process (PID=59320) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:42,616] {logging_mixin.py:112} INFO - [2020-08-01 14:47:42,616] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:42,617] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:42,617] {logging_mixin.py:112} INFO - [2020-08-01 14:47:42,617] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:42,620] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:42,635] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:42,642] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:42,643] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:47:48,750] {scheduler_job.py:154} INFO - Started process (PID=59327) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:48,768] {logging_mixin.py:112} INFO - [2020-08-01 14:47:48,767] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:48,768] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:48,768] {logging_mixin.py:112} INFO - [2020-08-01 14:47:48,768] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:48,770] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:48,783] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:48,792] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:48,793] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:47:54,772] {scheduler_job.py:154} INFO - Started process (PID=59333) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:54,789] {logging_mixin.py:112} INFO - [2020-08-01 14:47:54,789] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:47:54,790] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:47:54,790] {logging_mixin.py:112} INFO - [2020-08-01 14:47:54,790] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:54,792] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:47:54,806] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:47:54,813] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:47:54,815] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:48:06,023] {scheduler_job.py:154} INFO - Started process (PID=59342) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:06,087] {logging_mixin.py:112} INFO - [2020-08-01 14:48:06,087] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:06,088] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:48:06,088] {logging_mixin.py:112} INFO - [2020-08-01 14:48:06,088] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:06,091] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:06,106] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:48:06,113] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:06,115] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.091 seconds
[2020-08-01 14:48:11,987] {scheduler_job.py:154} INFO - Started process (PID=59349) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:12,004] {logging_mixin.py:112} INFO - [2020-08-01 14:48:12,004] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:12,005] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:48:12,005] {logging_mixin.py:112} INFO - [2020-08-01 14:48:12,005] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:12,007] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:12,021] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:48:12,028] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:12,029] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:48:17,992] {scheduler_job.py:154} INFO - Started process (PID=59366) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:18,010] {logging_mixin.py:112} INFO - [2020-08-01 14:48:18,010] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:18,010] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:48:18,011] {logging_mixin.py:112} INFO - [2020-08-01 14:48:18,010] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:18,012] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:18,026] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:48:18,032] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:18,034] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:48:24,003] {scheduler_job.py:154} INFO - Started process (PID=59380) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:24,021] {logging_mixin.py:112} INFO - [2020-08-01 14:48:24,021] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:24,022] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:48:24,022] {logging_mixin.py:112} INFO - [2020-08-01 14:48:24,022] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:24,024] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:24,038] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:48:24,046] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:24,048] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:48:30,100] {scheduler_job.py:154} INFO - Started process (PID=59387) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:30,119] {logging_mixin.py:112} INFO - [2020-08-01 14:48:30,119] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:30,120] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:48:30,120] {logging_mixin.py:112} INFO - [2020-08-01 14:48:30,120] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:30,122] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:30,137] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:48:30,145] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:30,147] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:48:36,028] {scheduler_job.py:154} INFO - Started process (PID=59393) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:36,046] {logging_mixin.py:112} INFO - [2020-08-01 14:48:36,046] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:36,047] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:48:36,047] {logging_mixin.py:112} INFO - [2020-08-01 14:48:36,047] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:36,049] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:36,062] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:48:36,070] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:36,071] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:48:42,070] {scheduler_job.py:154} INFO - Started process (PID=59400) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:42,088] {logging_mixin.py:112} INFO - [2020-08-01 14:48:42,088] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:42,088] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:48:42,089] {logging_mixin.py:112} INFO - [2020-08-01 14:48:42,088] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:42,090] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:42,105] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:48:42,112] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:42,114] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:48:48,086] {scheduler_job.py:154} INFO - Started process (PID=59406) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:48,103] {logging_mixin.py:112} INFO - [2020-08-01 14:48:48,103] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:48,104] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:48:48,104] {logging_mixin.py:112} INFO - [2020-08-01 14:48:48,104] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:48,106] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:48,120] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:48:48,127] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:48,129] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:48:54,163] {scheduler_job.py:154} INFO - Started process (PID=59412) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:54,181] {logging_mixin.py:112} INFO - [2020-08-01 14:48:54,180] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:48:54,181] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:48:54,181] {logging_mixin.py:112} INFO - [2020-08-01 14:48:54,181] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:54,183] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:48:54,197] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:48:54,204] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:48:54,206] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:49:00,112] {scheduler_job.py:154} INFO - Started process (PID=59418) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:00,130] {logging_mixin.py:112} INFO - [2020-08-01 14:49:00,129] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:00,130] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:00,130] {logging_mixin.py:112} INFO - [2020-08-01 14:49:00,130] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:00,132] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:00,146] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:00,155] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:00,157] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:49:06,170] {scheduler_job.py:154} INFO - Started process (PID=59424) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:06,191] {logging_mixin.py:112} INFO - [2020-08-01 14:49:06,191] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:06,192] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:06,192] {logging_mixin.py:112} INFO - [2020-08-01 14:49:06,192] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:06,194] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:06,207] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:06,214] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:06,216] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:49:12,208] {scheduler_job.py:154} INFO - Started process (PID=59431) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:12,226] {logging_mixin.py:112} INFO - [2020-08-01 14:49:12,226] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:12,227] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:12,227] {logging_mixin.py:112} INFO - [2020-08-01 14:49:12,227] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:12,229] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:12,243] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:12,250] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:12,251] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:49:18,167] {scheduler_job.py:154} INFO - Started process (PID=59437) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:18,185] {logging_mixin.py:112} INFO - [2020-08-01 14:49:18,185] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:18,185] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:18,186] {logging_mixin.py:112} INFO - [2020-08-01 14:49:18,186] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:18,187] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:18,202] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:18,209] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:18,211] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:49:24,219] {scheduler_job.py:154} INFO - Started process (PID=59443) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:24,239] {logging_mixin.py:112} INFO - [2020-08-01 14:49:24,239] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:24,240] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:24,240] {logging_mixin.py:112} INFO - [2020-08-01 14:49:24,240] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:24,242] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:24,258] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:24,265] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:24,267] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 14:49:30,223] {scheduler_job.py:154} INFO - Started process (PID=59449) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:30,241] {logging_mixin.py:112} INFO - [2020-08-01 14:49:30,241] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:30,242] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:30,242] {logging_mixin.py:112} INFO - [2020-08-01 14:49:30,242] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:30,243] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:30,259] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:30,266] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:30,267] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:49:36,244] {scheduler_job.py:154} INFO - Started process (PID=59455) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:36,262] {logging_mixin.py:112} INFO - [2020-08-01 14:49:36,262] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:36,263] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:36,263] {logging_mixin.py:112} INFO - [2020-08-01 14:49:36,263] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:36,265] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:36,278] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:36,289] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:36,291] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:49:42,278] {scheduler_job.py:154} INFO - Started process (PID=59461) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:42,294] {logging_mixin.py:112} INFO - [2020-08-01 14:49:42,294] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:42,295] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:42,295] {logging_mixin.py:112} INFO - [2020-08-01 14:49:42,295] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:42,297] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:42,310] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:42,318] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:42,320] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:49:48,242] {scheduler_job.py:154} INFO - Started process (PID=59468) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:48,260] {logging_mixin.py:112} INFO - [2020-08-01 14:49:48,260] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:48,261] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:48,261] {logging_mixin.py:112} INFO - [2020-08-01 14:49:48,261] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:48,263] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:48,276] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:48,283] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:48,284] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:49:54,273] {scheduler_job.py:154} INFO - Started process (PID=59474) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:54,291] {logging_mixin.py:112} INFO - [2020-08-01 14:49:54,291] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:49:54,292] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:49:54,292] {logging_mixin.py:112} INFO - [2020-08-01 14:49:54,292] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:54,294] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:49:54,308] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:49:54,315] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:49:54,316] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:50:00,293] {scheduler_job.py:154} INFO - Started process (PID=59480) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:00,311] {logging_mixin.py:112} INFO - [2020-08-01 14:50:00,311] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:00,311] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:00,312] {logging_mixin.py:112} INFO - [2020-08-01 14:50:00,311] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:00,313] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:00,328] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:00,335] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:00,336] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:50:06,368] {scheduler_job.py:154} INFO - Started process (PID=59486) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:06,387] {logging_mixin.py:112} INFO - [2020-08-01 14:50:06,387] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:06,388] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:06,388] {logging_mixin.py:112} INFO - [2020-08-01 14:50:06,388] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:06,390] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:06,406] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:06,414] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:06,416] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:50:12,373] {scheduler_job.py:154} INFO - Started process (PID=59492) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:12,398] {logging_mixin.py:112} INFO - [2020-08-01 14:50:12,397] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:12,399] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:12,399] {logging_mixin.py:112} INFO - [2020-08-01 14:50:12,399] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:12,401] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:12,419] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:12,428] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:12,431] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.058 seconds
[2020-08-01 14:50:18,391] {scheduler_job.py:154} INFO - Started process (PID=59499) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:18,408] {logging_mixin.py:112} INFO - [2020-08-01 14:50:18,408] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:18,409] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:18,409] {logging_mixin.py:112} INFO - [2020-08-01 14:50:18,409] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:18,410] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:18,424] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:18,431] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:18,433] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:50:24,369] {scheduler_job.py:154} INFO - Started process (PID=59506) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:24,386] {logging_mixin.py:112} INFO - [2020-08-01 14:50:24,386] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:24,387] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:24,387] {logging_mixin.py:112} INFO - [2020-08-01 14:50:24,387] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:24,389] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:24,403] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:24,410] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:24,411] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:50:30,396] {scheduler_job.py:154} INFO - Started process (PID=59512) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:30,413] {logging_mixin.py:112} INFO - [2020-08-01 14:50:30,413] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:30,414] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:30,414] {logging_mixin.py:112} INFO - [2020-08-01 14:50:30,414] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:30,416] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:30,430] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:30,439] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:30,441] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:50:36,404] {scheduler_job.py:154} INFO - Started process (PID=59518) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:36,421] {logging_mixin.py:112} INFO - [2020-08-01 14:50:36,421] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:36,422] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:36,422] {logging_mixin.py:112} INFO - [2020-08-01 14:50:36,422] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:36,424] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:36,438] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:36,445] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:36,447] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:50:42,423] {scheduler_job.py:154} INFO - Started process (PID=59524) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:42,441] {logging_mixin.py:112} INFO - [2020-08-01 14:50:42,441] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:42,441] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:42,442] {logging_mixin.py:112} INFO - [2020-08-01 14:50:42,442] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:42,443] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:42,458] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:42,465] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:42,467] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:50:48,473] {scheduler_job.py:154} INFO - Started process (PID=59531) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:48,490] {logging_mixin.py:112} INFO - [2020-08-01 14:50:48,490] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:48,491] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:48,491] {logging_mixin.py:112} INFO - [2020-08-01 14:50:48,491] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:48,493] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:48,506] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:48,513] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:48,515] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:50:54,482] {scheduler_job.py:154} INFO - Started process (PID=59537) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:54,499] {logging_mixin.py:112} INFO - [2020-08-01 14:50:54,499] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:50:54,500] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:50:54,500] {logging_mixin.py:112} INFO - [2020-08-01 14:50:54,500] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:54,501] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:50:54,516] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:50:54,523] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:50:54,525] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:51:00,498] {scheduler_job.py:154} INFO - Started process (PID=59543) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:00,516] {logging_mixin.py:112} INFO - [2020-08-01 14:51:00,516] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:00,516] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:00,517] {logging_mixin.py:112} INFO - [2020-08-01 14:51:00,516] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:00,518] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:00,533] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:00,540] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:00,542] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:51:06,530] {scheduler_job.py:154} INFO - Started process (PID=59550) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:06,547] {logging_mixin.py:112} INFO - [2020-08-01 14:51:06,547] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:06,548] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:06,548] {logging_mixin.py:112} INFO - [2020-08-01 14:51:06,548] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:06,550] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:06,564] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:06,571] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:06,573] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:51:12,550] {scheduler_job.py:154} INFO - Started process (PID=59557) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:12,568] {logging_mixin.py:112} INFO - [2020-08-01 14:51:12,567] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:12,568] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:12,568] {logging_mixin.py:112} INFO - [2020-08-01 14:51:12,568] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:12,570] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:12,585] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:12,593] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:12,594] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:51:18,578] {scheduler_job.py:154} INFO - Started process (PID=59564) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:18,596] {logging_mixin.py:112} INFO - [2020-08-01 14:51:18,596] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:18,597] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:18,597] {logging_mixin.py:112} INFO - [2020-08-01 14:51:18,597] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:18,599] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:18,612] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:18,620] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:18,621] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:51:24,606] {scheduler_job.py:154} INFO - Started process (PID=59570) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:24,623] {logging_mixin.py:112} INFO - [2020-08-01 14:51:24,623] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:24,624] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:24,624] {logging_mixin.py:112} INFO - [2020-08-01 14:51:24,624] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:24,626] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:24,640] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:24,647] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:24,649] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:51:30,621] {scheduler_job.py:154} INFO - Started process (PID=59576) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:30,639] {logging_mixin.py:112} INFO - [2020-08-01 14:51:30,638] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:30,639] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:30,639] {logging_mixin.py:112} INFO - [2020-08-01 14:51:30,639] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:30,641] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:30,655] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:30,662] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:30,664] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:51:36,659] {scheduler_job.py:154} INFO - Started process (PID=59582) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:36,677] {logging_mixin.py:112} INFO - [2020-08-01 14:51:36,676] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:36,677] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:36,677] {logging_mixin.py:112} INFO - [2020-08-01 14:51:36,677] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:36,679] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:36,693] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:36,701] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:36,702] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:51:42,674] {scheduler_job.py:154} INFO - Started process (PID=59588) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:42,691] {logging_mixin.py:112} INFO - [2020-08-01 14:51:42,691] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:42,691] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:42,692] {logging_mixin.py:112} INFO - [2020-08-01 14:51:42,692] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:42,693] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:42,708] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:42,715] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:42,716] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:51:48,692] {scheduler_job.py:154} INFO - Started process (PID=59595) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:48,710] {logging_mixin.py:112} INFO - [2020-08-01 14:51:48,709] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:48,710] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:48,710] {logging_mixin.py:112} INFO - [2020-08-01 14:51:48,710] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:48,712] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:48,726] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:48,733] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:48,735] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:51:55,104] {scheduler_job.py:154} INFO - Started process (PID=59609) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:55,135] {logging_mixin.py:112} INFO - [2020-08-01 14:51:55,135] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:51:55,136] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:51:55,136] {logging_mixin.py:112} INFO - [2020-08-01 14:51:55,136] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:55,138] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:51:55,153] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:51:55,163] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:51:55,165] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.061 seconds
[2020-08-01 14:52:00,766] {scheduler_job.py:154} INFO - Started process (PID=59620) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:00,787] {logging_mixin.py:112} INFO - [2020-08-01 14:52:00,787] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:00,788] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:52:00,788] {logging_mixin.py:112} INFO - [2020-08-01 14:52:00,788] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:00,790] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:00,803] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:52:00,809] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:00,811] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:52:06,909] {scheduler_job.py:154} INFO - Started process (PID=59626) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:06,929] {logging_mixin.py:112} INFO - [2020-08-01 14:52:06,929] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:06,930] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:52:06,930] {logging_mixin.py:112} INFO - [2020-08-01 14:52:06,930] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:06,932] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:06,949] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:52:06,956] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:06,958] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 14:52:12,964] {scheduler_job.py:154} INFO - Started process (PID=59632) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:12,990] {logging_mixin.py:112} INFO - [2020-08-01 14:52:12,990] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:12,991] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:52:12,991] {logging_mixin.py:112} INFO - [2020-08-01 14:52:12,991] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:12,997] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:13,020] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:52:13,030] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:13,034] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.070 seconds
[2020-08-01 14:52:49,193] {scheduler_job.py:154} INFO - Started process (PID=59650) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:49,211] {logging_mixin.py:112} INFO - [2020-08-01 14:52:49,210] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:49,211] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:52:49,211] {logging_mixin.py:112} INFO - [2020-08-01 14:52:49,211] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:49,213] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:49,228] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:52:49,235] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:49,237] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:52:54,891] {scheduler_job.py:154} INFO - Started process (PID=59656) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:54,908] {logging_mixin.py:112} INFO - [2020-08-01 14:52:54,908] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:52:54,909] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:52:54,909] {logging_mixin.py:112} INFO - [2020-08-01 14:52:54,909] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:54,911] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:52:54,924] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:52:54,934] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:52:54,936] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:53:00,930] {scheduler_job.py:154} INFO - Started process (PID=59662) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:00,948] {logging_mixin.py:112} INFO - [2020-08-01 14:53:00,948] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:00,948] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:53:00,949] {logging_mixin.py:112} INFO - [2020-08-01 14:53:00,949] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:00,950] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:00,968] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:53:00,977] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:00,979] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 14:53:07,001] {scheduler_job.py:154} INFO - Started process (PID=59668) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:07,019] {logging_mixin.py:112} INFO - [2020-08-01 14:53:07,019] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:07,019] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:53:07,020] {logging_mixin.py:112} INFO - [2020-08-01 14:53:07,019] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:07,022] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:07,037] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:53:07,045] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:07,047] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:53:12,911] {scheduler_job.py:154} INFO - Started process (PID=59674) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:12,931] {logging_mixin.py:112} INFO - [2020-08-01 14:53:12,930] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:12,931] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:53:12,931] {logging_mixin.py:112} INFO - [2020-08-01 14:53:12,931] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:12,933] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:12,948] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:53:12,955] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:12,956] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:53:19,162] {scheduler_job.py:154} INFO - Started process (PID=59681) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:19,181] {logging_mixin.py:112} INFO - [2020-08-01 14:53:19,181] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:19,181] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:53:19,181] {logging_mixin.py:112} INFO - [2020-08-01 14:53:19,181] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:19,183] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:19,197] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:53:19,204] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:19,205] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:53:30,478] {scheduler_job.py:154} INFO - Started process (PID=59690) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:30,513] {logging_mixin.py:112} INFO - [2020-08-01 14:53:30,512] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:30,514] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:53:30,514] {logging_mixin.py:112} INFO - [2020-08-01 14:53:30,514] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:30,517] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:30,543] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:53:30,561] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:30,570] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.092 seconds
[2020-08-01 14:53:36,359] {scheduler_job.py:154} INFO - Started process (PID=59696) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:36,376] {logging_mixin.py:112} INFO - [2020-08-01 14:53:36,376] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:36,377] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:53:36,377] {logging_mixin.py:112} INFO - [2020-08-01 14:53:36,377] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:36,379] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:36,393] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:53:36,401] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:36,403] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:53:42,369] {scheduler_job.py:154} INFO - Started process (PID=59702) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:42,387] {logging_mixin.py:112} INFO - [2020-08-01 14:53:42,387] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:42,387] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:53:42,388] {logging_mixin.py:112} INFO - [2020-08-01 14:53:42,388] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:42,389] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:42,404] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:53:42,411] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:42,413] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:53:48,453] {scheduler_job.py:154} INFO - Started process (PID=59709) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:48,470] {logging_mixin.py:112} INFO - [2020-08-01 14:53:48,470] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:48,470] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:53:48,471] {logging_mixin.py:112} INFO - [2020-08-01 14:53:48,471] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:48,472] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:48,486] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:53:48,493] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:48,494] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:53:54,402] {scheduler_job.py:154} INFO - Started process (PID=59715) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:54,420] {logging_mixin.py:112} INFO - [2020-08-01 14:53:54,420] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:53:54,421] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:53:54,421] {logging_mixin.py:112} INFO - [2020-08-01 14:53:54,421] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:54,422] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:53:54,437] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:53:54,444] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:53:54,446] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:54:00,435] {scheduler_job.py:154} INFO - Started process (PID=59721) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:00,453] {logging_mixin.py:112} INFO - [2020-08-01 14:54:00,453] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:00,454] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:00,454] {logging_mixin.py:112} INFO - [2020-08-01 14:54:00,454] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:00,456] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:00,470] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:00,477] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:00,479] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:54:06,452] {scheduler_job.py:154} INFO - Started process (PID=59727) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:06,470] {logging_mixin.py:112} INFO - [2020-08-01 14:54:06,470] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:06,471] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:06,471] {logging_mixin.py:112} INFO - [2020-08-01 14:54:06,471] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:06,473] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:06,487] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:06,494] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:06,495] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:54:12,471] {scheduler_job.py:154} INFO - Started process (PID=59733) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:12,488] {logging_mixin.py:112} INFO - [2020-08-01 14:54:12,488] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:12,489] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:12,489] {logging_mixin.py:112} INFO - [2020-08-01 14:54:12,489] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:12,491] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:12,505] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:12,512] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:12,513] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:54:18,559] {scheduler_job.py:154} INFO - Started process (PID=59739) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:18,577] {logging_mixin.py:112} INFO - [2020-08-01 14:54:18,577] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:18,577] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:18,578] {logging_mixin.py:112} INFO - [2020-08-01 14:54:18,578] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:18,580] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:18,593] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:18,600] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:18,602] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:54:24,549] {scheduler_job.py:154} INFO - Started process (PID=59746) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:24,567] {logging_mixin.py:112} INFO - [2020-08-01 14:54:24,566] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:24,567] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:24,567] {logging_mixin.py:112} INFO - [2020-08-01 14:54:24,567] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:24,569] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:24,584] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:24,592] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:24,593] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:54:30,554] {scheduler_job.py:154} INFO - Started process (PID=59752) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:30,572] {logging_mixin.py:112} INFO - [2020-08-01 14:54:30,572] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:30,573] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:30,573] {logging_mixin.py:112} INFO - [2020-08-01 14:54:30,573] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:30,575] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:30,589] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:30,597] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:30,598] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:54:36,563] {scheduler_job.py:154} INFO - Started process (PID=59758) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:36,580] {logging_mixin.py:112} INFO - [2020-08-01 14:54:36,580] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:36,581] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:36,581] {logging_mixin.py:112} INFO - [2020-08-01 14:54:36,581] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:36,583] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:36,597] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:36,604] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:36,606] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:54:42,595] {scheduler_job.py:154} INFO - Started process (PID=59764) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:42,613] {logging_mixin.py:112} INFO - [2020-08-01 14:54:42,613] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:42,613] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:42,614] {logging_mixin.py:112} INFO - [2020-08-01 14:54:42,614] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:42,615] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:42,630] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:42,637] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:42,639] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:54:48,623] {scheduler_job.py:154} INFO - Started process (PID=59770) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:48,647] {logging_mixin.py:112} INFO - [2020-08-01 14:54:48,647] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:48,647] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:48,647] {logging_mixin.py:112} INFO - [2020-08-01 14:54:48,647] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:48,649] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:48,663] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:48,671] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:48,674] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 14:54:54,681] {scheduler_job.py:154} INFO - Started process (PID=59777) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:54,699] {logging_mixin.py:112} INFO - [2020-08-01 14:54:54,699] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:54:54,700] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:54:54,700] {logging_mixin.py:112} INFO - [2020-08-01 14:54:54,700] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:54,701] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:54:54,716] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:54:54,725] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:54:54,726] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:55:00,625] {scheduler_job.py:154} INFO - Started process (PID=59784) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:00,643] {logging_mixin.py:112} INFO - [2020-08-01 14:55:00,642] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:00,643] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:00,643] {logging_mixin.py:112} INFO - [2020-08-01 14:55:00,643] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:00,645] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:00,659] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:00,666] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:00,667] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:55:06,877] {scheduler_job.py:154} INFO - Started process (PID=59790) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:06,895] {logging_mixin.py:112} INFO - [2020-08-01 14:55:06,895] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:06,896] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:06,896] {logging_mixin.py:112} INFO - [2020-08-01 14:55:06,896] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:06,898] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:06,912] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:06,919] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:06,922] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:55:12,680] {scheduler_job.py:154} INFO - Started process (PID=59812) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:12,698] {logging_mixin.py:112} INFO - [2020-08-01 14:55:12,698] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:12,699] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:12,699] {logging_mixin.py:112} INFO - [2020-08-01 14:55:12,699] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:12,701] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:12,715] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:12,722] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:12,723] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:55:18,713] {scheduler_job.py:154} INFO - Started process (PID=59826) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:18,730] {logging_mixin.py:112} INFO - [2020-08-01 14:55:18,730] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:18,731] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:18,731] {logging_mixin.py:112} INFO - [2020-08-01 14:55:18,731] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:18,733] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:18,748] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:18,755] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:18,756] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:55:24,727] {scheduler_job.py:154} INFO - Started process (PID=59841) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:24,746] {logging_mixin.py:112} INFO - [2020-08-01 14:55:24,746] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:24,746] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:24,746] {logging_mixin.py:112} INFO - [2020-08-01 14:55:24,746] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:24,748] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:24,763] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:24,770] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:24,771] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:55:30,791] {scheduler_job.py:154} INFO - Started process (PID=59855) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:30,809] {logging_mixin.py:112} INFO - [2020-08-01 14:55:30,809] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:30,810] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:30,810] {logging_mixin.py:112} INFO - [2020-08-01 14:55:30,810] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:30,812] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:30,826] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:30,833] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:30,835] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:55:36,784] {scheduler_job.py:154} INFO - Started process (PID=59869) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:36,801] {logging_mixin.py:112} INFO - [2020-08-01 14:55:36,801] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:36,802] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:36,802] {logging_mixin.py:112} INFO - [2020-08-01 14:55:36,802] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:36,804] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:36,817] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:36,823] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:36,825] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:55:42,789] {scheduler_job.py:154} INFO - Started process (PID=59891) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:42,807] {logging_mixin.py:112} INFO - [2020-08-01 14:55:42,807] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:42,808] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:42,808] {logging_mixin.py:112} INFO - [2020-08-01 14:55:42,808] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:42,810] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:42,823] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:42,830] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:42,831] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:55:48,807] {scheduler_job.py:154} INFO - Started process (PID=59906) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:48,825] {logging_mixin.py:112} INFO - [2020-08-01 14:55:48,825] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:48,825] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:48,825] {logging_mixin.py:112} INFO - [2020-08-01 14:55:48,825] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:48,827] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:48,841] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:48,848] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:48,850] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:55:54,815] {scheduler_job.py:154} INFO - Started process (PID=59921) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:54,833] {logging_mixin.py:112} INFO - [2020-08-01 14:55:54,833] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:55:54,834] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:55:54,834] {logging_mixin.py:112} INFO - [2020-08-01 14:55:54,834] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:54,836] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:55:54,851] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:55:54,858] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:55:54,859] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:56:00,847] {scheduler_job.py:154} INFO - Started process (PID=59935) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:00,865] {logging_mixin.py:112} INFO - [2020-08-01 14:56:00,865] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:00,866] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:00,866] {logging_mixin.py:112} INFO - [2020-08-01 14:56:00,866] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:00,867] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:00,882] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:00,888] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:00,890] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:56:06,868] {scheduler_job.py:154} INFO - Started process (PID=59949) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:06,885] {logging_mixin.py:112} INFO - [2020-08-01 14:56:06,885] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:06,886] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:06,886] {logging_mixin.py:112} INFO - [2020-08-01 14:56:06,886] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:06,888] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:06,901] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:06,908] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:06,910] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:56:12,925] {scheduler_job.py:154} INFO - Started process (PID=59963) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:12,943] {logging_mixin.py:112} INFO - [2020-08-01 14:56:12,942] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:12,943] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:12,943] {logging_mixin.py:112} INFO - [2020-08-01 14:56:12,943] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:12,945] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:12,959] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:12,967] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:12,968] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:56:18,918] {scheduler_job.py:154} INFO - Started process (PID=59985) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:18,936] {logging_mixin.py:112} INFO - [2020-08-01 14:56:18,936] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:18,937] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:18,937] {logging_mixin.py:112} INFO - [2020-08-01 14:56:18,937] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:18,938] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:18,953] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:18,960] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:18,962] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:56:24,943] {scheduler_job.py:154} INFO - Started process (PID=60000) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:24,960] {logging_mixin.py:112} INFO - [2020-08-01 14:56:24,960] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:24,961] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:24,961] {logging_mixin.py:112} INFO - [2020-08-01 14:56:24,961] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:24,963] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:24,977] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:24,984] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:24,986] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:56:30,955] {scheduler_job.py:154} INFO - Started process (PID=60014) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:30,973] {logging_mixin.py:112} INFO - [2020-08-01 14:56:30,973] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:30,974] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:30,974] {logging_mixin.py:112} INFO - [2020-08-01 14:56:30,974] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:30,976] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:30,990] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:30,997] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:30,998] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:56:36,971] {scheduler_job.py:154} INFO - Started process (PID=60028) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:36,989] {logging_mixin.py:112} INFO - [2020-08-01 14:56:36,989] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:36,990] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:36,990] {logging_mixin.py:112} INFO - [2020-08-01 14:56:36,990] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:36,992] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:37,006] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:37,014] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:37,016] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:56:43,017] {scheduler_job.py:154} INFO - Started process (PID=60042) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:43,036] {logging_mixin.py:112} INFO - [2020-08-01 14:56:43,036] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:43,036] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:43,036] {logging_mixin.py:112} INFO - [2020-08-01 14:56:43,036] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:43,038] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:43,053] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:43,060] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:43,062] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:56:49,028] {scheduler_job.py:154} INFO - Started process (PID=60064) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:49,045] {logging_mixin.py:112} INFO - [2020-08-01 14:56:49,045] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:49,046] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:49,046] {logging_mixin.py:112} INFO - [2020-08-01 14:56:49,046] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:49,048] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:49,062] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:49,070] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:49,071] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:56:55,042] {scheduler_job.py:154} INFO - Started process (PID=60079) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:55,059] {logging_mixin.py:112} INFO - [2020-08-01 14:56:55,059] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:56:55,060] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:56:55,060] {logging_mixin.py:112} INFO - [2020-08-01 14:56:55,060] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:55,062] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:56:55,076] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:56:55,083] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:56:55,085] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:57:01,056] {scheduler_job.py:154} INFO - Started process (PID=60093) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:01,074] {logging_mixin.py:112} INFO - [2020-08-01 14:57:01,074] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:01,074] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:01,075] {logging_mixin.py:112} INFO - [2020-08-01 14:57:01,075] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:01,076] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:01,091] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:01,098] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:01,099] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:57:07,087] {scheduler_job.py:154} INFO - Started process (PID=60107) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:07,105] {logging_mixin.py:112} INFO - [2020-08-01 14:57:07,104] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:07,105] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:07,105] {logging_mixin.py:112} INFO - [2020-08-01 14:57:07,105] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:07,107] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:07,121] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:07,129] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:07,130] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:57:13,112] {scheduler_job.py:154} INFO - Started process (PID=60121) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:13,129] {logging_mixin.py:112} INFO - [2020-08-01 14:57:13,129] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:13,130] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:13,130] {logging_mixin.py:112} INFO - [2020-08-01 14:57:13,130] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:13,132] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:13,146] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:13,152] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:13,154] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:57:19,167] {scheduler_job.py:154} INFO - Started process (PID=60135) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:19,184] {logging_mixin.py:112} INFO - [2020-08-01 14:57:19,184] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:19,185] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:19,185] {logging_mixin.py:112} INFO - [2020-08-01 14:57:19,185] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:19,187] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:19,201] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:19,208] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:19,210] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:57:25,166] {scheduler_job.py:154} INFO - Started process (PID=60158) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:25,183] {logging_mixin.py:112} INFO - [2020-08-01 14:57:25,183] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:25,184] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:25,184] {logging_mixin.py:112} INFO - [2020-08-01 14:57:25,184] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:25,186] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:25,200] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:25,207] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:25,209] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:57:31,182] {scheduler_job.py:154} INFO - Started process (PID=60172) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:31,200] {logging_mixin.py:112} INFO - [2020-08-01 14:57:31,199] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:31,200] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:31,200] {logging_mixin.py:112} INFO - [2020-08-01 14:57:31,200] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:31,202] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:31,217] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:31,223] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:31,225] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:57:37,226] {scheduler_job.py:154} INFO - Started process (PID=60186) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:37,243] {logging_mixin.py:112} INFO - [2020-08-01 14:57:37,243] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:37,244] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:37,244] {logging_mixin.py:112} INFO - [2020-08-01 14:57:37,244] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:37,246] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:37,260] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:37,267] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:37,269] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:57:43,238] {scheduler_job.py:154} INFO - Started process (PID=60200) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:43,255] {logging_mixin.py:112} INFO - [2020-08-01 14:57:43,255] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:43,256] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:43,256] {logging_mixin.py:112} INFO - [2020-08-01 14:57:43,256] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:43,258] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:43,272] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:43,278] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:43,280] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:57:49,285] {scheduler_job.py:154} INFO - Started process (PID=60214) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:49,305] {logging_mixin.py:112} INFO - [2020-08-01 14:57:49,304] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:49,305] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:49,305] {logging_mixin.py:112} INFO - [2020-08-01 14:57:49,305] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:49,307] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:49,322] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:49,331] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:49,333] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:57:55,606] {scheduler_job.py:154} INFO - Started process (PID=60230) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:55,623] {logging_mixin.py:112} INFO - [2020-08-01 14:57:55,623] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:57:55,624] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:57:55,624] {logging_mixin.py:112} INFO - [2020-08-01 14:57:55,624] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:55,626] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:57:55,640] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:57:55,647] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:57:55,648] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:58:01,344] {scheduler_job.py:154} INFO - Started process (PID=60240) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:01,361] {logging_mixin.py:112} INFO - [2020-08-01 14:58:01,360] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:01,361] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:01,361] {logging_mixin.py:112} INFO - [2020-08-01 14:58:01,361] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:01,363] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:01,377] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:01,384] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:01,385] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:58:07,450] {scheduler_job.py:154} INFO - Started process (PID=60249) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:07,468] {logging_mixin.py:112} INFO - [2020-08-01 14:58:07,468] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:07,469] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:07,469] {logging_mixin.py:112} INFO - [2020-08-01 14:58:07,469] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:07,471] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:07,486] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:07,494] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:07,495] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:58:13,814] {scheduler_job.py:154} INFO - Started process (PID=60255) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:13,843] {logging_mixin.py:112} INFO - [2020-08-01 14:58:13,843] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:13,844] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:13,844] {logging_mixin.py:112} INFO - [2020-08-01 14:58:13,844] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:13,846] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:13,863] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:13,873] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:13,874] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.061 seconds
[2020-08-01 14:58:19,530] {scheduler_job.py:154} INFO - Started process (PID=60264) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:19,547] {logging_mixin.py:112} INFO - [2020-08-01 14:58:19,547] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:19,548] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:19,548] {logging_mixin.py:112} INFO - [2020-08-01 14:58:19,548] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:19,550] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:19,564] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:19,570] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:19,572] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:58:25,526] {scheduler_job.py:154} INFO - Started process (PID=60271) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:25,545] {logging_mixin.py:112} INFO - [2020-08-01 14:58:25,545] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:25,546] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:25,546] {logging_mixin.py:112} INFO - [2020-08-01 14:58:25,546] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:25,548] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:25,563] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:25,570] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:25,572] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 14:58:31,679] {scheduler_job.py:154} INFO - Started process (PID=60278) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:31,700] {logging_mixin.py:112} INFO - [2020-08-01 14:58:31,700] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:31,701] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:31,701] {logging_mixin.py:112} INFO - [2020-08-01 14:58:31,701] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:31,703] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:31,717] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:31,724] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:31,725] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:58:37,378] {scheduler_job.py:154} INFO - Started process (PID=60286) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:37,396] {logging_mixin.py:112} INFO - [2020-08-01 14:58:37,396] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:37,397] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:37,397] {logging_mixin.py:112} INFO - [2020-08-01 14:58:37,397] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:37,399] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:37,413] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:37,420] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:37,422] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:58:43,455] {scheduler_job.py:154} INFO - Started process (PID=60292) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:43,473] {logging_mixin.py:112} INFO - [2020-08-01 14:58:43,473] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:43,474] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:43,474] {logging_mixin.py:112} INFO - [2020-08-01 14:58:43,474] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:43,476] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:43,489] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:43,495] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:43,497] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:58:49,555] {scheduler_job.py:154} INFO - Started process (PID=60298) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:49,573] {logging_mixin.py:112} INFO - [2020-08-01 14:58:49,573] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:49,574] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:49,574] {logging_mixin.py:112} INFO - [2020-08-01 14:58:49,574] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:49,576] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:49,592] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:49,600] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:49,601] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:58:55,618] {scheduler_job.py:154} INFO - Started process (PID=60307) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:55,636] {logging_mixin.py:112} INFO - [2020-08-01 14:58:55,636] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:58:55,636] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:58:55,636] {logging_mixin.py:112} INFO - [2020-08-01 14:58:55,636] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:55,638] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:58:55,652] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:58:55,658] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:58:55,660] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 14:59:01,531] {scheduler_job.py:154} INFO - Started process (PID=60313) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:01,553] {logging_mixin.py:112} INFO - [2020-08-01 14:59:01,553] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:01,553] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:01,553] {logging_mixin.py:112} INFO - [2020-08-01 14:59:01,553] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:01,555] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:01,570] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:01,577] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:01,579] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 14:59:07,546] {scheduler_job.py:154} INFO - Started process (PID=60319) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:07,563] {logging_mixin.py:112} INFO - [2020-08-01 14:59:07,563] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:07,564] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:07,564] {logging_mixin.py:112} INFO - [2020-08-01 14:59:07,564] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:07,566] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:07,580] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:07,587] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:07,589] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:59:13,485] {scheduler_job.py:154} INFO - Started process (PID=60325) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:13,503] {logging_mixin.py:112} INFO - [2020-08-01 14:59:13,502] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:13,503] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:13,503] {logging_mixin.py:112} INFO - [2020-08-01 14:59:13,503] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:13,505] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:13,519] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:13,526] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:13,528] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:59:19,471] {scheduler_job.py:154} INFO - Started process (PID=60331) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:19,488] {logging_mixin.py:112} INFO - [2020-08-01 14:59:19,488] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:19,489] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:19,489] {logging_mixin.py:112} INFO - [2020-08-01 14:59:19,489] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:19,491] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:19,505] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:19,512] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:19,514] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:59:25,577] {scheduler_job.py:154} INFO - Started process (PID=60337) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:25,597] {logging_mixin.py:112} INFO - [2020-08-01 14:59:25,597] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:25,597] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:25,598] {logging_mixin.py:112} INFO - [2020-08-01 14:59:25,598] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:25,600] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:25,616] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:25,623] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:25,625] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 14:59:31,557] {scheduler_job.py:154} INFO - Started process (PID=60344) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:31,575] {logging_mixin.py:112} INFO - [2020-08-01 14:59:31,574] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:31,575] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:31,575] {logging_mixin.py:112} INFO - [2020-08-01 14:59:31,575] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:31,577] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:31,592] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:31,600] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:31,602] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 14:59:37,556] {scheduler_job.py:154} INFO - Started process (PID=60350) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:37,574] {logging_mixin.py:112} INFO - [2020-08-01 14:59:37,574] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:37,574] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:37,574] {logging_mixin.py:112} INFO - [2020-08-01 14:59:37,574] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:37,576] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:37,591] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:37,598] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:37,599] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 14:59:43,552] {scheduler_job.py:154} INFO - Started process (PID=60356) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:43,569] {logging_mixin.py:112} INFO - [2020-08-01 14:59:43,569] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:43,570] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:43,570] {logging_mixin.py:112} INFO - [2020-08-01 14:59:43,570] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:43,572] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:43,585] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:43,592] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:43,594] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 14:59:49,576] {scheduler_job.py:154} INFO - Started process (PID=60362) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:49,594] {logging_mixin.py:112} INFO - [2020-08-01 14:59:49,594] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:49,595] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:49,595] {logging_mixin.py:112} INFO - [2020-08-01 14:59:49,595] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:49,597] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:49,611] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:49,618] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:49,619] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 14:59:55,656] {scheduler_job.py:154} INFO - Started process (PID=60368) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:55,674] {logging_mixin.py:112} INFO - [2020-08-01 14:59:55,674] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 14:59:55,675] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 14:59:55,675] {logging_mixin.py:112} INFO - [2020-08-01 14:59:55,675] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:55,678] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 14:59:55,692] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 14:59:55,699] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 14:59:55,702] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:00:01,628] {scheduler_job.py:154} INFO - Started process (PID=60375) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:01,645] {logging_mixin.py:112} INFO - [2020-08-01 15:00:01,645] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:01,646] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:01,646] {logging_mixin.py:112} INFO - [2020-08-01 15:00:01,646] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:01,648] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:01,663] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:01,670] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:01,671] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:00:07,651] {scheduler_job.py:154} INFO - Started process (PID=60381) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:07,669] {logging_mixin.py:112} INFO - [2020-08-01 15:00:07,669] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:07,669] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:07,670] {logging_mixin.py:112} INFO - [2020-08-01 15:00:07,670] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:07,671] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:07,686] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:07,693] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:07,694] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:00:13,670] {scheduler_job.py:154} INFO - Started process (PID=60387) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:13,687] {logging_mixin.py:112} INFO - [2020-08-01 15:00:13,687] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:13,688] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:13,688] {logging_mixin.py:112} INFO - [2020-08-01 15:00:13,688] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:13,690] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:13,703] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:13,710] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:13,711] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:00:19,699] {scheduler_job.py:154} INFO - Started process (PID=60393) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:19,717] {logging_mixin.py:112} INFO - [2020-08-01 15:00:19,716] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:19,717] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:19,717] {logging_mixin.py:112} INFO - [2020-08-01 15:00:19,717] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:19,719] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:19,733] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:19,741] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:19,742] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:00:25,795] {scheduler_job.py:154} INFO - Started process (PID=60399) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:25,816] {logging_mixin.py:112} INFO - [2020-08-01 15:00:25,815] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:25,816] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:25,816] {logging_mixin.py:112} INFO - [2020-08-01 15:00:25,816] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:25,818] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:25,833] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:25,839] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:25,841] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:00:31,796] {scheduler_job.py:154} INFO - Started process (PID=60406) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:31,816] {logging_mixin.py:112} INFO - [2020-08-01 15:00:31,816] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:31,816] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:31,816] {logging_mixin.py:112} INFO - [2020-08-01 15:00:31,816] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:31,819] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:31,833] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:31,840] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:31,842] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:00:37,778] {scheduler_job.py:154} INFO - Started process (PID=60412) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:37,795] {logging_mixin.py:112} INFO - [2020-08-01 15:00:37,795] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:37,796] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:37,796] {logging_mixin.py:112} INFO - [2020-08-01 15:00:37,796] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:37,798] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:37,813] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:37,822] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:37,824] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:00:43,778] {scheduler_job.py:154} INFO - Started process (PID=60418) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:43,796] {logging_mixin.py:112} INFO - [2020-08-01 15:00:43,796] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:43,796] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:43,796] {logging_mixin.py:112} INFO - [2020-08-01 15:00:43,796] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:43,798] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:43,813] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:43,820] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:43,821] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:00:49,796] {scheduler_job.py:154} INFO - Started process (PID=60424) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:49,814] {logging_mixin.py:112} INFO - [2020-08-01 15:00:49,813] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:49,814] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:49,814] {logging_mixin.py:112} INFO - [2020-08-01 15:00:49,814] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:49,816] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:49,831] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:49,838] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:49,840] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:00:55,828] {scheduler_job.py:154} INFO - Started process (PID=60432) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:55,846] {logging_mixin.py:112} INFO - [2020-08-01 15:00:55,846] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:00:55,847] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:00:55,847] {logging_mixin.py:112} INFO - [2020-08-01 15:00:55,847] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:55,849] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:00:55,862] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:00:55,869] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:00:55,870] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:01:01,867] {scheduler_job.py:154} INFO - Started process (PID=60445) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:01,886] {logging_mixin.py:112} INFO - [2020-08-01 15:01:01,885] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:01,886] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:01,886] {logging_mixin.py:112} INFO - [2020-08-01 15:01:01,886] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:01,888] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:01,902] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:01,910] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:01,911] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:01:07,882] {scheduler_job.py:154} INFO - Started process (PID=60452) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:07,899] {logging_mixin.py:112} INFO - [2020-08-01 15:01:07,899] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:07,900] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:07,900] {logging_mixin.py:112} INFO - [2020-08-01 15:01:07,900] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:07,902] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:07,917] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:07,924] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:07,925] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:01:13,879] {scheduler_job.py:154} INFO - Started process (PID=60459) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:13,897] {logging_mixin.py:112} INFO - [2020-08-01 15:01:13,897] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:13,898] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:13,898] {logging_mixin.py:112} INFO - [2020-08-01 15:01:13,898] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:13,900] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:13,919] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:13,929] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:13,931] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 15:01:19,998] {scheduler_job.py:154} INFO - Started process (PID=60466) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:20,015] {logging_mixin.py:112} INFO - [2020-08-01 15:01:20,015] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:20,016] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:20,016] {logging_mixin.py:112} INFO - [2020-08-01 15:01:20,016] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:20,018] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:20,033] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:20,040] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:20,042] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:01:25,984] {scheduler_job.py:154} INFO - Started process (PID=60473) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:26,046] {logging_mixin.py:112} INFO - [2020-08-01 15:01:26,045] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:26,048] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:26,048] {logging_mixin.py:112} INFO - [2020-08-01 15:01:26,048] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:26,053] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:26,087] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:26,098] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:26,100] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.116 seconds
[2020-08-01 15:01:31,948] {scheduler_job.py:154} INFO - Started process (PID=60491) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:31,966] {logging_mixin.py:112} INFO - [2020-08-01 15:01:31,966] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:31,966] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:31,967] {logging_mixin.py:112} INFO - [2020-08-01 15:01:31,967] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:31,969] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:31,983] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:31,992] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:31,994] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:01:37,936] {scheduler_job.py:154} INFO - Started process (PID=60545) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:37,953] {logging_mixin.py:112} INFO - [2020-08-01 15:01:37,953] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:37,954] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:37,954] {logging_mixin.py:112} INFO - [2020-08-01 15:01:37,954] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:37,956] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:37,970] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:37,977] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:37,979] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:01:43,934] {scheduler_job.py:154} INFO - Started process (PID=60560) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:43,951] {logging_mixin.py:112} INFO - [2020-08-01 15:01:43,951] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:43,952] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:43,952] {logging_mixin.py:112} INFO - [2020-08-01 15:01:43,952] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:43,954] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:43,968] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:43,975] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:43,976] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:01:50,012] {scheduler_job.py:154} INFO - Started process (PID=60574) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:50,031] {logging_mixin.py:112} INFO - [2020-08-01 15:01:50,031] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:50,031] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:50,032] {logging_mixin.py:112} INFO - [2020-08-01 15:01:50,032] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:50,033] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:50,049] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:50,057] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:50,058] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:01:56,096] {scheduler_job.py:154} INFO - Started process (PID=60580) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:56,113] {logging_mixin.py:112} INFO - [2020-08-01 15:01:56,113] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:01:56,114] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:01:56,114] {logging_mixin.py:112} INFO - [2020-08-01 15:01:56,114] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:56,115] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:01:56,130] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:01:56,136] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:01:56,138] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:02:02,023] {scheduler_job.py:154} INFO - Started process (PID=60590) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:02,041] {logging_mixin.py:112} INFO - [2020-08-01 15:02:02,040] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:02,041] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:02,041] {logging_mixin.py:112} INFO - [2020-08-01 15:02:02,041] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:02,043] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:02,058] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:02,065] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:02,066] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:02:08,212] {scheduler_job.py:154} INFO - Started process (PID=60596) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:08,234] {logging_mixin.py:112} INFO - [2020-08-01 15:02:08,234] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:08,235] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:08,235] {logging_mixin.py:112} INFO - [2020-08-01 15:02:08,235] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:08,237] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:08,254] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:08,263] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:08,265] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 15:02:14,001] {scheduler_job.py:154} INFO - Started process (PID=60603) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:14,019] {logging_mixin.py:112} INFO - [2020-08-01 15:02:14,018] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:14,019] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:14,019] {logging_mixin.py:112} INFO - [2020-08-01 15:02:14,019] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:14,021] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:14,035] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:14,043] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:14,044] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:02:20,090] {scheduler_job.py:154} INFO - Started process (PID=60610) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:20,108] {logging_mixin.py:112} INFO - [2020-08-01 15:02:20,108] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:20,108] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:20,108] {logging_mixin.py:112} INFO - [2020-08-01 15:02:20,108] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:20,110] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:20,124] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:20,132] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:20,134] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:02:26,039] {scheduler_job.py:154} INFO - Started process (PID=60616) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:26,057] {logging_mixin.py:112} INFO - [2020-08-01 15:02:26,056] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:26,057] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:26,057] {logging_mixin.py:112} INFO - [2020-08-01 15:02:26,057] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:26,059] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:26,073] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:26,081] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:26,082] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:02:32,063] {scheduler_job.py:154} INFO - Started process (PID=60623) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:32,081] {logging_mixin.py:112} INFO - [2020-08-01 15:02:32,081] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:32,082] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:32,082] {logging_mixin.py:112} INFO - [2020-08-01 15:02:32,082] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:32,084] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:32,098] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:32,105] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:32,107] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:02:38,072] {scheduler_job.py:154} INFO - Started process (PID=60629) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:38,090] {logging_mixin.py:112} INFO - [2020-08-01 15:02:38,089] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:38,090] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:38,090] {logging_mixin.py:112} INFO - [2020-08-01 15:02:38,090] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:38,092] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:38,107] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:38,114] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:38,116] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:02:44,153] {scheduler_job.py:154} INFO - Started process (PID=60635) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:44,171] {logging_mixin.py:112} INFO - [2020-08-01 15:02:44,171] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:44,171] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:44,172] {logging_mixin.py:112} INFO - [2020-08-01 15:02:44,171] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:44,173] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:44,186] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:44,193] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:44,194] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:02:50,122] {scheduler_job.py:154} INFO - Started process (PID=60641) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:50,140] {logging_mixin.py:112} INFO - [2020-08-01 15:02:50,140] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:50,141] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:50,141] {logging_mixin.py:112} INFO - [2020-08-01 15:02:50,141] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:50,143] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:50,158] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:50,165] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:50,166] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:02:56,180] {scheduler_job.py:154} INFO - Started process (PID=60650) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:56,198] {logging_mixin.py:112} INFO - [2020-08-01 15:02:56,198] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:02:56,199] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:02:56,199] {logging_mixin.py:112} INFO - [2020-08-01 15:02:56,199] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:56,201] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:02:56,216] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:02:56,224] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:02:56,226] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:03:02,155] {scheduler_job.py:154} INFO - Started process (PID=60657) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:02,173] {logging_mixin.py:112} INFO - [2020-08-01 15:03:02,173] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:02,174] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:02,174] {logging_mixin.py:112} INFO - [2020-08-01 15:03:02,174] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:02,176] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:02,190] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:02,197] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:02,198] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:03:08,212] {scheduler_job.py:154} INFO - Started process (PID=60663) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:08,232] {logging_mixin.py:112} INFO - [2020-08-01 15:03:08,231] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:08,232] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:08,232] {logging_mixin.py:112} INFO - [2020-08-01 15:03:08,232] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:08,234] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:08,250] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:08,259] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:08,261] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 15:03:14,203] {scheduler_job.py:154} INFO - Started process (PID=60669) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:14,220] {logging_mixin.py:112} INFO - [2020-08-01 15:03:14,220] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:14,221] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:14,221] {logging_mixin.py:112} INFO - [2020-08-01 15:03:14,221] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:14,223] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:14,237] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:14,244] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:14,245] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:03:20,242] {scheduler_job.py:154} INFO - Started process (PID=60675) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:20,260] {logging_mixin.py:112} INFO - [2020-08-01 15:03:20,259] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:20,260] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:20,260] {logging_mixin.py:112} INFO - [2020-08-01 15:03:20,260] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:20,262] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:20,276] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:20,282] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:20,284] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:03:26,221] {scheduler_job.py:154} INFO - Started process (PID=60681) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:26,238] {logging_mixin.py:112} INFO - [2020-08-01 15:03:26,238] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:26,239] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:26,239] {logging_mixin.py:112} INFO - [2020-08-01 15:03:26,239] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:26,241] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:26,254] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:26,261] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:26,262] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:03:32,297] {scheduler_job.py:154} INFO - Started process (PID=60688) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:32,314] {logging_mixin.py:112} INFO - [2020-08-01 15:03:32,314] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:32,315] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:32,315] {logging_mixin.py:112} INFO - [2020-08-01 15:03:32,315] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:32,317] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:32,330] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:32,337] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:32,338] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:03:38,358] {scheduler_job.py:154} INFO - Started process (PID=60694) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:38,375] {logging_mixin.py:112} INFO - [2020-08-01 15:03:38,375] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:38,376] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:38,376] {logging_mixin.py:112} INFO - [2020-08-01 15:03:38,376] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:38,378] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:38,392] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:38,398] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:38,400] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:03:44,314] {scheduler_job.py:154} INFO - Started process (PID=60700) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:44,332] {logging_mixin.py:112} INFO - [2020-08-01 15:03:44,332] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:44,332] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:44,333] {logging_mixin.py:112} INFO - [2020-08-01 15:03:44,333] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:44,334] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:44,349] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:44,356] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:44,358] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:03:50,315] {scheduler_job.py:154} INFO - Started process (PID=60706) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:50,332] {logging_mixin.py:112} INFO - [2020-08-01 15:03:50,332] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:50,333] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:50,333] {logging_mixin.py:112} INFO - [2020-08-01 15:03:50,333] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:50,335] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:50,349] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:50,358] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:50,359] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:03:56,311] {scheduler_job.py:154} INFO - Started process (PID=60712) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:56,329] {logging_mixin.py:112} INFO - [2020-08-01 15:03:56,329] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:03:56,330] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:03:56,330] {logging_mixin.py:112} INFO - [2020-08-01 15:03:56,330] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:56,332] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:03:56,346] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:03:56,353] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:03:56,354] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:04:02,349] {scheduler_job.py:154} INFO - Started process (PID=60719) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:02,367] {logging_mixin.py:112} INFO - [2020-08-01 15:04:02,366] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:02,367] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:02,367] {logging_mixin.py:112} INFO - [2020-08-01 15:04:02,367] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:02,369] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:02,384] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:02,391] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:02,393] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:04:08,373] {scheduler_job.py:154} INFO - Started process (PID=60725) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:08,391] {logging_mixin.py:112} INFO - [2020-08-01 15:04:08,391] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:08,392] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:08,392] {logging_mixin.py:112} INFO - [2020-08-01 15:04:08,392] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:08,394] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:08,408] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:08,415] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:08,417] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:04:14,392] {scheduler_job.py:154} INFO - Started process (PID=60731) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:14,410] {logging_mixin.py:112} INFO - [2020-08-01 15:04:14,409] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:14,410] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:14,410] {logging_mixin.py:112} INFO - [2020-08-01 15:04:14,410] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:14,412] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:14,426] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:14,434] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:14,435] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:04:20,420] {scheduler_job.py:154} INFO - Started process (PID=60737) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:20,437] {logging_mixin.py:112} INFO - [2020-08-01 15:04:20,437] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:20,438] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:20,438] {logging_mixin.py:112} INFO - [2020-08-01 15:04:20,438] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:20,440] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:20,454] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:20,462] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:20,463] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:04:26,444] {scheduler_job.py:154} INFO - Started process (PID=60743) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:26,461] {logging_mixin.py:112} INFO - [2020-08-01 15:04:26,461] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:26,462] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:26,462] {logging_mixin.py:112} INFO - [2020-08-01 15:04:26,462] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:26,464] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:26,478] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:26,485] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:26,487] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:04:32,526] {scheduler_job.py:154} INFO - Started process (PID=60750) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:32,543] {logging_mixin.py:112} INFO - [2020-08-01 15:04:32,543] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:32,544] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:32,544] {logging_mixin.py:112} INFO - [2020-08-01 15:04:32,544] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:32,546] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:32,560] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:32,567] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:32,569] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:04:38,484] {scheduler_job.py:154} INFO - Started process (PID=60756) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:38,502] {logging_mixin.py:112} INFO - [2020-08-01 15:04:38,501] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:38,502] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:38,502] {logging_mixin.py:112} INFO - [2020-08-01 15:04:38,502] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:38,504] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:38,518] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:38,526] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:38,528] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:04:44,507] {scheduler_job.py:154} INFO - Started process (PID=60762) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:44,525] {logging_mixin.py:112} INFO - [2020-08-01 15:04:44,525] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:44,526] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:44,526] {logging_mixin.py:112} INFO - [2020-08-01 15:04:44,526] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:44,527] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:44,542] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:44,549] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:44,550] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:04:50,540] {scheduler_job.py:154} INFO - Started process (PID=60768) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:50,558] {logging_mixin.py:112} INFO - [2020-08-01 15:04:50,557] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:50,558] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:50,558] {logging_mixin.py:112} INFO - [2020-08-01 15:04:50,558] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:50,560] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:50,574] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:50,582] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:50,583] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:04:56,663] {scheduler_job.py:154} INFO - Started process (PID=60782) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:56,681] {logging_mixin.py:112} INFO - [2020-08-01 15:04:56,681] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:04:56,681] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:04:56,681] {logging_mixin.py:112} INFO - [2020-08-01 15:04:56,681] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:56,683] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:04:56,697] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:04:56,703] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:04:56,705] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:05:02,681] {scheduler_job.py:154} INFO - Started process (PID=60797) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:02,699] {logging_mixin.py:112} INFO - [2020-08-01 15:05:02,699] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:02,700] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:02,700] {logging_mixin.py:112} INFO - [2020-08-01 15:05:02,700] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:02,702] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:02,719] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:02,727] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:02,728] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:05:08,588] {scheduler_job.py:154} INFO - Started process (PID=60815) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:08,606] {logging_mixin.py:112} INFO - [2020-08-01 15:05:08,606] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:08,606] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:08,607] {logging_mixin.py:112} INFO - [2020-08-01 15:05:08,607] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:08,608] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:08,624] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:08,631] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:08,633] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:05:14,680] {scheduler_job.py:154} INFO - Started process (PID=60822) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:14,697] {logging_mixin.py:112} INFO - [2020-08-01 15:05:14,697] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:14,698] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:14,698] {logging_mixin.py:112} INFO - [2020-08-01 15:05:14,698] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:14,700] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:14,714] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:14,720] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:14,722] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:05:20,665] {scheduler_job.py:154} INFO - Started process (PID=60828) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:20,685] {logging_mixin.py:112} INFO - [2020-08-01 15:05:20,685] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:20,686] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:20,686] {logging_mixin.py:112} INFO - [2020-08-01 15:05:20,686] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:20,688] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:20,704] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:20,711] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:20,714] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:05:26,758] {scheduler_job.py:154} INFO - Started process (PID=60834) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:26,776] {logging_mixin.py:112} INFO - [2020-08-01 15:05:26,776] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:26,777] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:26,777] {logging_mixin.py:112} INFO - [2020-08-01 15:05:26,777] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:26,778] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:26,794] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:26,801] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:26,803] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:05:32,775] {scheduler_job.py:154} INFO - Started process (PID=60841) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:32,796] {logging_mixin.py:112} INFO - [2020-08-01 15:05:32,796] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:32,797] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:32,797] {logging_mixin.py:112} INFO - [2020-08-01 15:05:32,797] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:32,799] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:32,815] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:32,828] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:32,831] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.056 seconds
[2020-08-01 15:05:38,762] {scheduler_job.py:154} INFO - Started process (PID=60851) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:38,782] {logging_mixin.py:112} INFO - [2020-08-01 15:05:38,782] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:38,782] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:38,782] {logging_mixin.py:112} INFO - [2020-08-01 15:05:38,782] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:38,784] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:38,800] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:38,807] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:38,810] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:05:45,007] {scheduler_job.py:154} INFO - Started process (PID=60858) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:45,035] {logging_mixin.py:112} INFO - [2020-08-01 15:05:45,034] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:45,035] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:45,035] {logging_mixin.py:112} INFO - [2020-08-01 15:05:45,035] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:45,037] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:45,052] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:45,062] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:45,066] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.059 seconds
[2020-08-01 15:05:50,873] {scheduler_job.py:154} INFO - Started process (PID=60865) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:50,906] {logging_mixin.py:112} INFO - [2020-08-01 15:05:50,906] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:50,907] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:50,907] {logging_mixin.py:112} INFO - [2020-08-01 15:05:50,907] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:50,909] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:50,924] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:50,931] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:50,933] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.060 seconds
[2020-08-01 15:05:56,741] {scheduler_job.py:154} INFO - Started process (PID=60881) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:56,759] {logging_mixin.py:112} INFO - [2020-08-01 15:05:56,759] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:05:56,760] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:05:56,760] {logging_mixin.py:112} INFO - [2020-08-01 15:05:56,760] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:56,762] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:05:56,777] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:05:56,786] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:05:56,788] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:06:02,806] {scheduler_job.py:154} INFO - Started process (PID=60887) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:02,824] {logging_mixin.py:112} INFO - [2020-08-01 15:06:02,824] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:02,825] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:02,825] {logging_mixin.py:112} INFO - [2020-08-01 15:06:02,825] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:02,827] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:02,843] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:02,851] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:02,853] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:06:08,757] {scheduler_job.py:154} INFO - Started process (PID=60894) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:08,775] {logging_mixin.py:112} INFO - [2020-08-01 15:06:08,775] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:08,776] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:08,776] {logging_mixin.py:112} INFO - [2020-08-01 15:06:08,776] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:08,778] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:08,791] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:08,797] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:08,799] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:06:14,927] {scheduler_job.py:154} INFO - Started process (PID=60902) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:14,945] {logging_mixin.py:112} INFO - [2020-08-01 15:06:14,945] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:14,946] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:14,946] {logging_mixin.py:112} INFO - [2020-08-01 15:06:14,946] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:14,949] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:14,962] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:14,970] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:14,972] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:06:20,834] {scheduler_job.py:154} INFO - Started process (PID=60914) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:20,851] {logging_mixin.py:112} INFO - [2020-08-01 15:06:20,851] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:20,852] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:20,852] {logging_mixin.py:112} INFO - [2020-08-01 15:06:20,852] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:20,854] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:20,868] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:20,876] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:20,877] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:06:26,812] {scheduler_job.py:154} INFO - Started process (PID=60920) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:26,830] {logging_mixin.py:112} INFO - [2020-08-01 15:06:26,830] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:26,831] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:26,831] {logging_mixin.py:112} INFO - [2020-08-01 15:06:26,831] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:26,833] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:26,849] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:26,857] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:26,859] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:06:32,829] {scheduler_job.py:154} INFO - Started process (PID=60926) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:32,847] {logging_mixin.py:112} INFO - [2020-08-01 15:06:32,847] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:32,848] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:32,848] {logging_mixin.py:112} INFO - [2020-08-01 15:06:32,848] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:32,850] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:32,864] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:32,871] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:32,872] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:06:38,847] {scheduler_job.py:154} INFO - Started process (PID=60933) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:38,865] {logging_mixin.py:112} INFO - [2020-08-01 15:06:38,865] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:38,866] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:38,866] {logging_mixin.py:112} INFO - [2020-08-01 15:06:38,866] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:38,868] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:38,882] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:38,889] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:38,890] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:06:44,897] {scheduler_job.py:154} INFO - Started process (PID=60939) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:44,915] {logging_mixin.py:112} INFO - [2020-08-01 15:06:44,914] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:44,915] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:44,915] {logging_mixin.py:112} INFO - [2020-08-01 15:06:44,915] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:44,917] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:44,930] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:44,937] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:44,939] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:06:50,907] {scheduler_job.py:154} INFO - Started process (PID=60945) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:50,924] {logging_mixin.py:112} INFO - [2020-08-01 15:06:50,924] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:50,925] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:50,925] {logging_mixin.py:112} INFO - [2020-08-01 15:06:50,925] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:50,927] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:50,944] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:50,951] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:50,952] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:06:56,930] {scheduler_job.py:154} INFO - Started process (PID=60951) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:56,947] {logging_mixin.py:112} INFO - [2020-08-01 15:06:56,947] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:06:56,948] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:06:56,948] {logging_mixin.py:112} INFO - [2020-08-01 15:06:56,948] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:56,950] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:06:56,964] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:06:56,971] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:06:56,973] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:07:02,983] {scheduler_job.py:154} INFO - Started process (PID=60957) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:03,000] {logging_mixin.py:112} INFO - [2020-08-01 15:07:03,000] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:03,001] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:03,001] {logging_mixin.py:112} INFO - [2020-08-01 15:07:03,001] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:03,003] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:03,017] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:03,024] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:03,026] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:07:09,043] {scheduler_job.py:154} INFO - Started process (PID=60964) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:09,061] {logging_mixin.py:112} INFO - [2020-08-01 15:07:09,061] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:09,062] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:09,062] {logging_mixin.py:112} INFO - [2020-08-01 15:07:09,062] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:09,064] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:09,079] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:09,086] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:09,088] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:07:15,046] {scheduler_job.py:154} INFO - Started process (PID=60970) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:15,065] {logging_mixin.py:112} INFO - [2020-08-01 15:07:15,065] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:15,065] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:15,066] {logging_mixin.py:112} INFO - [2020-08-01 15:07:15,065] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:15,067] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:15,083] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:15,091] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:15,092] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:07:21,075] {scheduler_job.py:154} INFO - Started process (PID=60977) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:21,093] {logging_mixin.py:112} INFO - [2020-08-01 15:07:21,092] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:21,093] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:21,093] {logging_mixin.py:112} INFO - [2020-08-01 15:07:21,093] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:21,095] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:21,108] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:21,115] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:21,117] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:07:27,109] {scheduler_job.py:154} INFO - Started process (PID=60983) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:27,127] {logging_mixin.py:112} INFO - [2020-08-01 15:07:27,127] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:27,127] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:27,128] {logging_mixin.py:112} INFO - [2020-08-01 15:07:27,128] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:27,129] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:27,143] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:27,149] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:27,151] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:07:33,118] {scheduler_job.py:154} INFO - Started process (PID=60989) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:33,136] {logging_mixin.py:112} INFO - [2020-08-01 15:07:33,136] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:33,137] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:33,137] {logging_mixin.py:112} INFO - [2020-08-01 15:07:33,137] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:33,139] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:33,152] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:33,158] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:33,160] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:07:39,161] {scheduler_job.py:154} INFO - Started process (PID=60996) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:39,178] {logging_mixin.py:112} INFO - [2020-08-01 15:07:39,178] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:39,179] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:39,179] {logging_mixin.py:112} INFO - [2020-08-01 15:07:39,179] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:39,181] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:39,194] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:39,201] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:39,203] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:07:45,185] {scheduler_job.py:154} INFO - Started process (PID=61012) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:45,204] {logging_mixin.py:112} INFO - [2020-08-01 15:07:45,204] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:45,205] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:45,205] {logging_mixin.py:112} INFO - [2020-08-01 15:07:45,205] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:45,207] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:45,221] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:45,228] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:45,229] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:07:51,397] {scheduler_job.py:154} INFO - Started process (PID=61019) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:51,429] {logging_mixin.py:112} INFO - [2020-08-01 15:07:51,428] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:51,430] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:51,430] {logging_mixin.py:112} INFO - [2020-08-01 15:07:51,430] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:51,433] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:51,449] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:51,458] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:51,461] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.064 seconds
[2020-08-01 15:07:57,242] {scheduler_job.py:154} INFO - Started process (PID=61029) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:57,259] {logging_mixin.py:112} INFO - [2020-08-01 15:07:57,259] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:07:57,260] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:07:57,260] {logging_mixin.py:112} INFO - [2020-08-01 15:07:57,260] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:57,262] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:07:57,277] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:07:57,285] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:07:57,287] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:08:03,390] {scheduler_job.py:154} INFO - Started process (PID=61037) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:03,409] {logging_mixin.py:112} INFO - [2020-08-01 15:08:03,409] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:03,410] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:03,410] {logging_mixin.py:112} INFO - [2020-08-01 15:08:03,410] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:03,412] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:03,425] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:03,432] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:03,434] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:08:09,348] {scheduler_job.py:154} INFO - Started process (PID=61045) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:09,365] {logging_mixin.py:112} INFO - [2020-08-01 15:08:09,365] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:09,366] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:09,366] {logging_mixin.py:112} INFO - [2020-08-01 15:08:09,366] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:09,368] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:09,380] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:09,388] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:09,389] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:08:15,297] {scheduler_job.py:154} INFO - Started process (PID=61053) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:15,314] {logging_mixin.py:112} INFO - [2020-08-01 15:08:15,314] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:15,315] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:15,315] {logging_mixin.py:112} INFO - [2020-08-01 15:08:15,315] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:15,317] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:15,329] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:15,336] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:15,337] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:08:21,280] {scheduler_job.py:154} INFO - Started process (PID=61059) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:21,300] {logging_mixin.py:112} INFO - [2020-08-01 15:08:21,299] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:21,300] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:21,301] {logging_mixin.py:112} INFO - [2020-08-01 15:08:21,301] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:21,303] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:21,317] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:21,324] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:21,326] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:08:27,290] {scheduler_job.py:154} INFO - Started process (PID=61065) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:27,308] {logging_mixin.py:112} INFO - [2020-08-01 15:08:27,308] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:27,309] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:27,309] {logging_mixin.py:112} INFO - [2020-08-01 15:08:27,309] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:27,311] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:27,324] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:27,332] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:27,334] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:08:33,317] {scheduler_job.py:154} INFO - Started process (PID=61071) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:33,336] {logging_mixin.py:112} INFO - [2020-08-01 15:08:33,335] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:33,336] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:33,336] {logging_mixin.py:112} INFO - [2020-08-01 15:08:33,336] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:33,338] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:33,351] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:33,358] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:33,359] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:08:39,318] {scheduler_job.py:154} INFO - Started process (PID=61078) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:39,335] {logging_mixin.py:112} INFO - [2020-08-01 15:08:39,335] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:39,335] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:39,336] {logging_mixin.py:112} INFO - [2020-08-01 15:08:39,336] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:39,337] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:39,350] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:39,356] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:39,358] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 15:08:45,404] {scheduler_job.py:154} INFO - Started process (PID=61085) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:45,425] {logging_mixin.py:112} INFO - [2020-08-01 15:08:45,424] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:45,425] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:45,425] {logging_mixin.py:112} INFO - [2020-08-01 15:08:45,425] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:45,427] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:45,442] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:45,449] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:45,450] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:08:51,403] {scheduler_job.py:154} INFO - Started process (PID=61091) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:51,421] {logging_mixin.py:112} INFO - [2020-08-01 15:08:51,421] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:51,422] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:51,422] {logging_mixin.py:112} INFO - [2020-08-01 15:08:51,422] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:51,424] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:51,437] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:51,443] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:51,445] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:08:57,377] {scheduler_job.py:154} INFO - Started process (PID=61097) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:57,395] {logging_mixin.py:112} INFO - [2020-08-01 15:08:57,395] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:08:57,396] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:08:57,396] {logging_mixin.py:112} INFO - [2020-08-01 15:08:57,396] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:57,397] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:08:57,410] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:08:57,418] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:08:57,419] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:09:03,394] {scheduler_job.py:154} INFO - Started process (PID=61103) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:03,411] {logging_mixin.py:112} INFO - [2020-08-01 15:09:03,411] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:03,412] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:03,412] {logging_mixin.py:112} INFO - [2020-08-01 15:09:03,412] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:03,414] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:03,427] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:03,435] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:03,436] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:09:09,468] {scheduler_job.py:154} INFO - Started process (PID=61110) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:09,485] {logging_mixin.py:112} INFO - [2020-08-01 15:09:09,485] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:09,485] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:09,485] {logging_mixin.py:112} INFO - [2020-08-01 15:09:09,485] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:09,487] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:09,500] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:09,506] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:09,508] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 15:09:15,511] {scheduler_job.py:154} INFO - Started process (PID=61116) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:15,529] {logging_mixin.py:112} INFO - [2020-08-01 15:09:15,529] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:15,530] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:15,530] {logging_mixin.py:112} INFO - [2020-08-01 15:09:15,530] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:15,532] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:15,545] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:15,552] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:15,554] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:09:21,461] {scheduler_job.py:154} INFO - Started process (PID=61122) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:21,480] {logging_mixin.py:112} INFO - [2020-08-01 15:09:21,480] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:21,481] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:21,481] {logging_mixin.py:112} INFO - [2020-08-01 15:09:21,481] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:21,483] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:21,496] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:21,504] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:21,506] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:09:27,487] {scheduler_job.py:154} INFO - Started process (PID=61128) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:27,505] {logging_mixin.py:112} INFO - [2020-08-01 15:09:27,505] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:27,506] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:27,506] {logging_mixin.py:112} INFO - [2020-08-01 15:09:27,506] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:27,508] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:27,521] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:27,528] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:27,529] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:09:33,621] {scheduler_job.py:154} INFO - Started process (PID=61134) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:33,639] {logging_mixin.py:112} INFO - [2020-08-01 15:09:33,638] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:33,639] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:33,639] {logging_mixin.py:112} INFO - [2020-08-01 15:09:33,639] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:33,641] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:33,655] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:33,661] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:33,663] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:09:39,714] {scheduler_job.py:154} INFO - Started process (PID=61141) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:39,731] {logging_mixin.py:112} INFO - [2020-08-01 15:09:39,731] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:39,732] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:39,732] {logging_mixin.py:112} INFO - [2020-08-01 15:09:39,732] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:39,734] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:39,746] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:39,753] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:39,754] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:09:45,570] {scheduler_job.py:154} INFO - Started process (PID=61147) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:45,589] {logging_mixin.py:112} INFO - [2020-08-01 15:09:45,589] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:45,589] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:45,589] {logging_mixin.py:112} INFO - [2020-08-01 15:09:45,589] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:45,591] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:45,606] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:45,614] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:45,616] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:09:51,543] {scheduler_job.py:154} INFO - Started process (PID=61153) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:51,560] {logging_mixin.py:112} INFO - [2020-08-01 15:09:51,560] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:51,561] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:51,561] {logging_mixin.py:112} INFO - [2020-08-01 15:09:51,561] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:51,563] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:51,576] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:51,583] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:51,584] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:09:57,596] {scheduler_job.py:154} INFO - Started process (PID=61159) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:57,615] {logging_mixin.py:112} INFO - [2020-08-01 15:09:57,615] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:09:57,616] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:09:57,616] {logging_mixin.py:112} INFO - [2020-08-01 15:09:57,616] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:57,618] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:09:57,630] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:09:57,637] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:09:57,638] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:10:03,623] {scheduler_job.py:154} INFO - Started process (PID=61165) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:03,640] {logging_mixin.py:112} INFO - [2020-08-01 15:10:03,639] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:03,640] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:03,640] {logging_mixin.py:112} INFO - [2020-08-01 15:10:03,640] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:03,642] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:03,655] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:03,661] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:03,663] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 15:10:09,807] {scheduler_job.py:154} INFO - Started process (PID=61171) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:09,829] {logging_mixin.py:112} INFO - [2020-08-01 15:10:09,829] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:09,829] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:09,830] {logging_mixin.py:112} INFO - [2020-08-01 15:10:09,830] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:09,831] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:09,844] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:09,850] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:09,852] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:10:15,600] {scheduler_job.py:154} INFO - Started process (PID=61178) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:15,617] {logging_mixin.py:112} INFO - [2020-08-01 15:10:15,617] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:15,618] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:15,618] {logging_mixin.py:112} INFO - [2020-08-01 15:10:15,618] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:15,621] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:15,635] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:15,641] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:15,643] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:10:21,621] {scheduler_job.py:154} INFO - Started process (PID=61184) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:21,640] {logging_mixin.py:112} INFO - [2020-08-01 15:10:21,640] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:21,641] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:21,641] {logging_mixin.py:112} INFO - [2020-08-01 15:10:21,641] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:21,643] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:21,656] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:21,662] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:21,664] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:10:27,638] {scheduler_job.py:154} INFO - Started process (PID=61190) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:27,655] {logging_mixin.py:112} INFO - [2020-08-01 15:10:27,655] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:27,656] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:27,656] {logging_mixin.py:112} INFO - [2020-08-01 15:10:27,656] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:27,658] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:27,671] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:27,678] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:27,679] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:10:33,664] {scheduler_job.py:154} INFO - Started process (PID=61196) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:33,682] {logging_mixin.py:112} INFO - [2020-08-01 15:10:33,682] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:33,683] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:33,683] {logging_mixin.py:112} INFO - [2020-08-01 15:10:33,683] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:33,685] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:33,698] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:33,705] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:33,706] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:10:39,695] {scheduler_job.py:154} INFO - Started process (PID=61202) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:39,713] {logging_mixin.py:112} INFO - [2020-08-01 15:10:39,712] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:39,713] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:39,713] {logging_mixin.py:112} INFO - [2020-08-01 15:10:39,713] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:39,715] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:39,728] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:39,739] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:39,742] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:10:45,701] {scheduler_job.py:154} INFO - Started process (PID=61209) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:45,719] {logging_mixin.py:112} INFO - [2020-08-01 15:10:45,719] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:45,720] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:45,720] {logging_mixin.py:112} INFO - [2020-08-01 15:10:45,720] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:45,722] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:45,735] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:45,742] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:45,744] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:10:51,712] {scheduler_job.py:154} INFO - Started process (PID=61215) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:51,735] {logging_mixin.py:112} INFO - [2020-08-01 15:10:51,734] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:51,735] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:51,735] {logging_mixin.py:112} INFO - [2020-08-01 15:10:51,735] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:51,737] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:51,751] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:51,758] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:51,759] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:10:57,719] {scheduler_job.py:154} INFO - Started process (PID=61221) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:57,736] {logging_mixin.py:112} INFO - [2020-08-01 15:10:57,736] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:10:57,737] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:10:57,737] {logging_mixin.py:112} INFO - [2020-08-01 15:10:57,737] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:57,739] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:10:57,752] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:10:57,763] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:10:57,765] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:11:03,762] {scheduler_job.py:154} INFO - Started process (PID=61227) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:03,784] {logging_mixin.py:112} INFO - [2020-08-01 15:11:03,784] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:03,785] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:03,785] {logging_mixin.py:112} INFO - [2020-08-01 15:11:03,785] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:03,787] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:03,802] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:03,809] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:03,810] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 15:11:09,789] {scheduler_job.py:154} INFO - Started process (PID=61233) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:09,807] {logging_mixin.py:112} INFO - [2020-08-01 15:11:09,807] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:09,807] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:09,808] {logging_mixin.py:112} INFO - [2020-08-01 15:11:09,808] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:09,809] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:09,822] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:09,831] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:09,833] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:11:15,815] {scheduler_job.py:154} INFO - Started process (PID=61240) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:15,834] {logging_mixin.py:112} INFO - [2020-08-01 15:11:15,834] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:15,835] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:15,835] {logging_mixin.py:112} INFO - [2020-08-01 15:11:15,835] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:15,837] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:15,853] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:15,860] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:15,862] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:11:21,879] {scheduler_job.py:154} INFO - Started process (PID=61246) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:21,905] {logging_mixin.py:112} INFO - [2020-08-01 15:11:21,905] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:21,905] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:21,905] {logging_mixin.py:112} INFO - [2020-08-01 15:11:21,905] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:21,907] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:21,921] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:21,928] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:21,930] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 15:11:27,848] {scheduler_job.py:154} INFO - Started process (PID=61252) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:27,866] {logging_mixin.py:112} INFO - [2020-08-01 15:11:27,866] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:27,866] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:27,867] {logging_mixin.py:112} INFO - [2020-08-01 15:11:27,866] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:27,868] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:27,881] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:27,889] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:27,890] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:11:33,878] {scheduler_job.py:154} INFO - Started process (PID=61258) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:33,896] {logging_mixin.py:112} INFO - [2020-08-01 15:11:33,896] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:33,897] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:33,897] {logging_mixin.py:112} INFO - [2020-08-01 15:11:33,897] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:33,899] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:33,912] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:33,919] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:33,921] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:11:39,887] {scheduler_job.py:154} INFO - Started process (PID=61264) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:39,905] {logging_mixin.py:112} INFO - [2020-08-01 15:11:39,905] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:39,905] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:39,905] {logging_mixin.py:112} INFO - [2020-08-01 15:11:39,905] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:39,907] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:39,920] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:39,928] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:39,929] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:11:45,903] {scheduler_job.py:154} INFO - Started process (PID=61271) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:45,921] {logging_mixin.py:112} INFO - [2020-08-01 15:11:45,920] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:45,921] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:45,921] {logging_mixin.py:112} INFO - [2020-08-01 15:11:45,921] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:45,923] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:45,936] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:45,944] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:45,945] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:11:51,922] {scheduler_job.py:154} INFO - Started process (PID=61277) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:51,940] {logging_mixin.py:112} INFO - [2020-08-01 15:11:51,939] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:51,940] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:51,940] {logging_mixin.py:112} INFO - [2020-08-01 15:11:51,940] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:51,942] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:51,956] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:51,963] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:51,964] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:11:57,952] {scheduler_job.py:154} INFO - Started process (PID=61283) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:57,971] {logging_mixin.py:112} INFO - [2020-08-01 15:11:57,971] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:11:57,971] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:11:57,972] {logging_mixin.py:112} INFO - [2020-08-01 15:11:57,972] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:57,973] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:11:57,987] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:11:57,994] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:11:57,996] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:12:03,980] {scheduler_job.py:154} INFO - Started process (PID=61289) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:03,998] {logging_mixin.py:112} INFO - [2020-08-01 15:12:03,998] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:03,999] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:03,999] {logging_mixin.py:112} INFO - [2020-08-01 15:12:03,999] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:04,001] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:04,014] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:04,021] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:04,023] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:12:09,985] {scheduler_job.py:154} INFO - Started process (PID=61295) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:10,003] {logging_mixin.py:112} INFO - [2020-08-01 15:12:10,003] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:10,004] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:10,004] {logging_mixin.py:112} INFO - [2020-08-01 15:12:10,004] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:10,006] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:10,019] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:10,026] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:10,027] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:12:16,025] {scheduler_job.py:154} INFO - Started process (PID=61302) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:16,042] {logging_mixin.py:112} INFO - [2020-08-01 15:12:16,042] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:16,043] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:16,043] {logging_mixin.py:112} INFO - [2020-08-01 15:12:16,043] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:16,045] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:16,058] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:16,065] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:16,067] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:12:22,053] {scheduler_job.py:154} INFO - Started process (PID=61308) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:22,071] {logging_mixin.py:112} INFO - [2020-08-01 15:12:22,071] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:22,072] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:22,072] {logging_mixin.py:112} INFO - [2020-08-01 15:12:22,072] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:22,074] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:22,087] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:22,094] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:22,096] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:12:28,095] {scheduler_job.py:154} INFO - Started process (PID=61315) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:28,112] {logging_mixin.py:112} INFO - [2020-08-01 15:12:28,112] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:28,113] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:28,113] {logging_mixin.py:112} INFO - [2020-08-01 15:12:28,113] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:28,114] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:28,127] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:28,133] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:28,134] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 15:12:34,253] {scheduler_job.py:154} INFO - Started process (PID=61321) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:34,271] {logging_mixin.py:112} INFO - [2020-08-01 15:12:34,271] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:34,272] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:34,272] {logging_mixin.py:112} INFO - [2020-08-01 15:12:34,272] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:34,274] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:34,286] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:34,293] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:34,295] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:12:40,142] {scheduler_job.py:154} INFO - Started process (PID=61328) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:40,161] {logging_mixin.py:112} INFO - [2020-08-01 15:12:40,161] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:40,161] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:40,161] {logging_mixin.py:112} INFO - [2020-08-01 15:12:40,161] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:40,163] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:40,178] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:40,184] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:40,186] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:12:46,065] {scheduler_job.py:154} INFO - Started process (PID=61335) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:46,083] {logging_mixin.py:112} INFO - [2020-08-01 15:12:46,083] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:46,083] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:46,084] {logging_mixin.py:112} INFO - [2020-08-01 15:12:46,084] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:46,085] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:46,100] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:46,107] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:46,109] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:12:52,093] {scheduler_job.py:154} INFO - Started process (PID=61341) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:52,110] {logging_mixin.py:112} INFO - [2020-08-01 15:12:52,110] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:52,111] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:52,111] {logging_mixin.py:112} INFO - [2020-08-01 15:12:52,111] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:52,113] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:52,127] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:52,134] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:52,135] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:12:58,107] {scheduler_job.py:154} INFO - Started process (PID=61347) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:58,124] {logging_mixin.py:112} INFO - [2020-08-01 15:12:58,124] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:12:58,125] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:12:58,125] {logging_mixin.py:112} INFO - [2020-08-01 15:12:58,125] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:58,127] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:12:58,141] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:12:58,148] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:12:58,150] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:13:04,127] {scheduler_job.py:154} INFO - Started process (PID=61353) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:04,145] {logging_mixin.py:112} INFO - [2020-08-01 15:13:04,145] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:04,145] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:04,146] {logging_mixin.py:112} INFO - [2020-08-01 15:13:04,145] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:04,147] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:04,162] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:04,168] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:04,170] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:13:10,172] {scheduler_job.py:154} INFO - Started process (PID=61359) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:10,190] {logging_mixin.py:112} INFO - [2020-08-01 15:13:10,189] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:10,190] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:10,190] {logging_mixin.py:112} INFO - [2020-08-01 15:13:10,190] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:10,192] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:10,207] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:10,213] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:10,215] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:13:16,168] {scheduler_job.py:154} INFO - Started process (PID=61366) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:16,185] {logging_mixin.py:112} INFO - [2020-08-01 15:13:16,185] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:16,186] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:16,186] {logging_mixin.py:112} INFO - [2020-08-01 15:13:16,186] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:16,188] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:16,202] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:16,209] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:16,210] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:13:22,196] {scheduler_job.py:154} INFO - Started process (PID=61372) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:22,213] {logging_mixin.py:112} INFO - [2020-08-01 15:13:22,213] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:22,214] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:22,214] {logging_mixin.py:112} INFO - [2020-08-01 15:13:22,214] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:22,216] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:22,230] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:22,238] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:22,239] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:13:28,281] {scheduler_job.py:154} INFO - Started process (PID=61378) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:28,301] {logging_mixin.py:112} INFO - [2020-08-01 15:13:28,300] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:28,301] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:28,302] {logging_mixin.py:112} INFO - [2020-08-01 15:13:28,302] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:28,304] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:28,318] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:28,324] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:28,326] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:13:34,241] {scheduler_job.py:154} INFO - Started process (PID=61384) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:34,258] {logging_mixin.py:112} INFO - [2020-08-01 15:13:34,258] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:34,259] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:34,259] {logging_mixin.py:112} INFO - [2020-08-01 15:13:34,259] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:34,261] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:34,275] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:34,282] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:34,284] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:13:40,266] {scheduler_job.py:154} INFO - Started process (PID=61390) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:40,284] {logging_mixin.py:112} INFO - [2020-08-01 15:13:40,283] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:40,284] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:40,284] {logging_mixin.py:112} INFO - [2020-08-01 15:13:40,284] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:40,286] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:40,300] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:40,307] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:40,309] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:13:46,290] {scheduler_job.py:154} INFO - Started process (PID=61397) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:46,307] {logging_mixin.py:112} INFO - [2020-08-01 15:13:46,307] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:46,308] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:46,308] {logging_mixin.py:112} INFO - [2020-08-01 15:13:46,308] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:46,310] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:46,324] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:46,331] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:46,333] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:13:52,317] {scheduler_job.py:154} INFO - Started process (PID=61403) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:52,335] {logging_mixin.py:112} INFO - [2020-08-01 15:13:52,334] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:52,335] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:52,335] {logging_mixin.py:112} INFO - [2020-08-01 15:13:52,335] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:52,337] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:52,351] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:52,358] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:52,360] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:13:58,336] {scheduler_job.py:154} INFO - Started process (PID=61409) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:58,355] {logging_mixin.py:112} INFO - [2020-08-01 15:13:58,355] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:13:58,355] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:13:58,356] {logging_mixin.py:112} INFO - [2020-08-01 15:13:58,356] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:58,357] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:13:58,372] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:13:58,379] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:13:58,381] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:14:04,357] {scheduler_job.py:154} INFO - Started process (PID=61415) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:04,376] {logging_mixin.py:112} INFO - [2020-08-01 15:14:04,376] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:04,376] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:04,377] {logging_mixin.py:112} INFO - [2020-08-01 15:14:04,376] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:04,379] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:04,394] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:04,401] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:04,402] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:14:10,373] {scheduler_job.py:154} INFO - Started process (PID=61421) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:10,391] {logging_mixin.py:112} INFO - [2020-08-01 15:14:10,390] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:10,391] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:10,391] {logging_mixin.py:112} INFO - [2020-08-01 15:14:10,391] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:10,393] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:10,407] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:10,416] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:10,418] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:14:16,396] {scheduler_job.py:154} INFO - Started process (PID=61428) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:16,413] {logging_mixin.py:112} INFO - [2020-08-01 15:14:16,413] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:16,414] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:16,414] {logging_mixin.py:112} INFO - [2020-08-01 15:14:16,414] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:16,416] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:16,430] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:16,437] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:16,439] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:14:22,414] {scheduler_job.py:154} INFO - Started process (PID=61434) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:22,431] {logging_mixin.py:112} INFO - [2020-08-01 15:14:22,431] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:22,432] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:22,432] {logging_mixin.py:112} INFO - [2020-08-01 15:14:22,432] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:22,434] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:22,449] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:22,456] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:22,457] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:14:28,436] {scheduler_job.py:154} INFO - Started process (PID=61440) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:28,454] {logging_mixin.py:112} INFO - [2020-08-01 15:14:28,454] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:28,455] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:28,455] {logging_mixin.py:112} INFO - [2020-08-01 15:14:28,455] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:28,456] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:28,471] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:28,478] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:28,479] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:14:34,457] {scheduler_job.py:154} INFO - Started process (PID=61446) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:34,474] {logging_mixin.py:112} INFO - [2020-08-01 15:14:34,474] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:34,475] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:34,475] {logging_mixin.py:112} INFO - [2020-08-01 15:14:34,475] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:34,477] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:34,491] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:34,499] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:34,501] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:14:40,482] {scheduler_job.py:154} INFO - Started process (PID=61452) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:40,500] {logging_mixin.py:112} INFO - [2020-08-01 15:14:40,500] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:40,500] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:40,501] {logging_mixin.py:112} INFO - [2020-08-01 15:14:40,501] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:40,502] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:40,517] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:40,524] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:40,526] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:14:46,568] {scheduler_job.py:154} INFO - Started process (PID=61459) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:46,585] {logging_mixin.py:112} INFO - [2020-08-01 15:14:46,585] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:46,586] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:46,586] {logging_mixin.py:112} INFO - [2020-08-01 15:14:46,586] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:46,588] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:46,600] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:46,607] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:46,608] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 15:14:52,566] {scheduler_job.py:154} INFO - Started process (PID=61465) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:52,585] {logging_mixin.py:112} INFO - [2020-08-01 15:14:52,584] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:52,585] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:52,585] {logging_mixin.py:112} INFO - [2020-08-01 15:14:52,585] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:52,587] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:52,603] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:52,610] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:52,612] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:14:58,624] {scheduler_job.py:154} INFO - Started process (PID=61471) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:58,641] {logging_mixin.py:112} INFO - [2020-08-01 15:14:58,641] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:14:58,641] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:14:58,641] {logging_mixin.py:112} INFO - [2020-08-01 15:14:58,641] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:58,643] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:14:58,657] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:14:58,666] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:14:58,668] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:15:04,585] {scheduler_job.py:154} INFO - Started process (PID=61477) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:04,603] {logging_mixin.py:112} INFO - [2020-08-01 15:15:04,603] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:04,603] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:04,604] {logging_mixin.py:112} INFO - [2020-08-01 15:15:04,604] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:04,605] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:04,620] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:04,627] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:04,628] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:15:11,752] {scheduler_job.py:154} INFO - Started process (PID=61483) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:11,770] {logging_mixin.py:112} INFO - [2020-08-01 15:15:11,770] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:11,771] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:11,771] {logging_mixin.py:112} INFO - [2020-08-01 15:15:11,771] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:11,773] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:11,788] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:11,798] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:11,800] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:15:16,851] {scheduler_job.py:154} INFO - Started process (PID=61493) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:16,871] {logging_mixin.py:112} INFO - [2020-08-01 15:15:16,871] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:16,872] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:16,872] {logging_mixin.py:112} INFO - [2020-08-01 15:15:16,872] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:16,874] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:16,889] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:16,896] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:16,898] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:15:22,657] {scheduler_job.py:154} INFO - Started process (PID=61501) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:22,675] {logging_mixin.py:112} INFO - [2020-08-01 15:15:22,675] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:22,676] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:22,676] {logging_mixin.py:112} INFO - [2020-08-01 15:15:22,676] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:22,678] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:22,693] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:22,701] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:22,703] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:15:28,649] {scheduler_job.py:154} INFO - Started process (PID=61507) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:28,667] {logging_mixin.py:112} INFO - [2020-08-01 15:15:28,667] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:28,668] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:28,668] {logging_mixin.py:112} INFO - [2020-08-01 15:15:28,668] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:28,670] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:28,684] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:28,691] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:28,692] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:15:35,501] {scheduler_job.py:154} INFO - Started process (PID=61513) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:35,530] {logging_mixin.py:112} INFO - [2020-08-01 15:15:35,530] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:35,531] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:35,531] {logging_mixin.py:112} INFO - [2020-08-01 15:15:35,531] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:35,534] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:35,551] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:35,561] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:35,563] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.062 seconds
[2020-08-01 15:15:41,191] {scheduler_job.py:154} INFO - Started process (PID=61520) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:41,220] {logging_mixin.py:112} INFO - [2020-08-01 15:15:41,219] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:41,221] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:41,221] {logging_mixin.py:112} INFO - [2020-08-01 15:15:41,221] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:41,223] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:41,241] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:41,251] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:41,253] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.063 seconds
[2020-08-01 15:15:47,226] {scheduler_job.py:154} INFO - Started process (PID=61526) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:47,258] {logging_mixin.py:112} INFO - [2020-08-01 15:15:47,257] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:47,259] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:47,259] {logging_mixin.py:112} INFO - [2020-08-01 15:15:47,259] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:47,262] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:47,283] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:47,295] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:47,297] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.071 seconds
[2020-08-01 15:15:52,713] {scheduler_job.py:154} INFO - Started process (PID=61533) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:52,735] {logging_mixin.py:112} INFO - [2020-08-01 15:15:52,735] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:52,736] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:52,736] {logging_mixin.py:112} INFO - [2020-08-01 15:15:52,736] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:52,738] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:52,756] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:52,763] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:52,766] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 15:15:58,772] {scheduler_job.py:154} INFO - Started process (PID=61539) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:58,792] {logging_mixin.py:112} INFO - [2020-08-01 15:15:58,791] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:15:58,792] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:15:58,792] {logging_mixin.py:112} INFO - [2020-08-01 15:15:58,792] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:58,795] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:15:58,808] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:15:58,815] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:15:58,817] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:16:04,748] {scheduler_job.py:154} INFO - Started process (PID=61545) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:04,766] {logging_mixin.py:112} INFO - [2020-08-01 15:16:04,765] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:04,766] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:04,766] {logging_mixin.py:112} INFO - [2020-08-01 15:16:04,766] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:04,768] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:04,783] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:04,790] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:04,792] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:16:10,868] {scheduler_job.py:154} INFO - Started process (PID=61551) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:10,891] {logging_mixin.py:112} INFO - [2020-08-01 15:16:10,891] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:10,892] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:10,892] {logging_mixin.py:112} INFO - [2020-08-01 15:16:10,892] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:10,895] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:10,911] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:10,920] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:10,922] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.054 seconds
[2020-08-01 15:16:16,783] {scheduler_job.py:154} INFO - Started process (PID=61557) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:16,801] {logging_mixin.py:112} INFO - [2020-08-01 15:16:16,801] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:16,802] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:16,802] {logging_mixin.py:112} INFO - [2020-08-01 15:16:16,802] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:16,804] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:16,817] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:16,824] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:16,826] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:16:22,850] {scheduler_job.py:154} INFO - Started process (PID=61572) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:22,881] {logging_mixin.py:112} INFO - [2020-08-01 15:16:22,881] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:22,882] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:22,882] {logging_mixin.py:112} INFO - [2020-08-01 15:16:22,882] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:22,884] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:22,899] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:22,907] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:22,909] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.059 seconds
[2020-08-01 15:16:28,928] {scheduler_job.py:154} INFO - Started process (PID=61586) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:28,947] {logging_mixin.py:112} INFO - [2020-08-01 15:16:28,947] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:28,947] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:28,947] {logging_mixin.py:112} INFO - [2020-08-01 15:16:28,947] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:28,949] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:28,963] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:28,970] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:28,971] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:16:34,853] {scheduler_job.py:154} INFO - Started process (PID=61592) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:34,871] {logging_mixin.py:112} INFO - [2020-08-01 15:16:34,871] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:34,872] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:34,872] {logging_mixin.py:112} INFO - [2020-08-01 15:16:34,872] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:34,874] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:34,888] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:34,895] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:34,897] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:16:40,862] {scheduler_job.py:154} INFO - Started process (PID=61598) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:40,880] {logging_mixin.py:112} INFO - [2020-08-01 15:16:40,880] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:40,880] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:40,880] {logging_mixin.py:112} INFO - [2020-08-01 15:16:40,880] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:40,882] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:40,896] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:40,904] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:40,905] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:16:46,892] {scheduler_job.py:154} INFO - Started process (PID=61604) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:46,910] {logging_mixin.py:112} INFO - [2020-08-01 15:16:46,910] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:46,911] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:46,911] {logging_mixin.py:112} INFO - [2020-08-01 15:16:46,911] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:46,912] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:46,927] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:46,934] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:46,935] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:16:52,912] {scheduler_job.py:154} INFO - Started process (PID=61611) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:52,930] {logging_mixin.py:112} INFO - [2020-08-01 15:16:52,929] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:52,930] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:52,930] {logging_mixin.py:112} INFO - [2020-08-01 15:16:52,930] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:52,932] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:52,946] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:52,954] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:52,955] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:16:58,937] {scheduler_job.py:154} INFO - Started process (PID=61617) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:58,955] {logging_mixin.py:112} INFO - [2020-08-01 15:16:58,955] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:16:58,956] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:16:58,956] {logging_mixin.py:112} INFO - [2020-08-01 15:16:58,956] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:58,958] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:16:58,972] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:16:58,978] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:16:58,980] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:17:04,966] {scheduler_job.py:154} INFO - Started process (PID=61623) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:04,983] {logging_mixin.py:112} INFO - [2020-08-01 15:17:04,983] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:04,984] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:04,984] {logging_mixin.py:112} INFO - [2020-08-01 15:17:04,984] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:04,986] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:05,000] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:05,007] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:05,009] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:17:10,972] {scheduler_job.py:154} INFO - Started process (PID=61629) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:10,991] {logging_mixin.py:112} INFO - [2020-08-01 15:17:10,991] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:10,992] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:10,992] {logging_mixin.py:112} INFO - [2020-08-01 15:17:10,992] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:10,994] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:11,008] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:11,015] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:11,016] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:17:16,996] {scheduler_job.py:154} INFO - Started process (PID=61635) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:17,015] {logging_mixin.py:112} INFO - [2020-08-01 15:17:17,015] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:17,016] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:17,016] {logging_mixin.py:112} INFO - [2020-08-01 15:17:17,016] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:17,018] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:17,034] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:17,041] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:17,043] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:17:23,015] {scheduler_job.py:154} INFO - Started process (PID=61642) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:23,033] {logging_mixin.py:112} INFO - [2020-08-01 15:17:23,033] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:23,034] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:23,034] {logging_mixin.py:112} INFO - [2020-08-01 15:17:23,034] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:23,036] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:23,050] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:23,059] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:23,061] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:17:29,040] {scheduler_job.py:154} INFO - Started process (PID=61648) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:29,058] {logging_mixin.py:112} INFO - [2020-08-01 15:17:29,058] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:29,058] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:29,059] {logging_mixin.py:112} INFO - [2020-08-01 15:17:29,059] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:29,061] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:29,075] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:29,083] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:29,084] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:17:35,052] {scheduler_job.py:154} INFO - Started process (PID=61654) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:35,070] {logging_mixin.py:112} INFO - [2020-08-01 15:17:35,069] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:35,070] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:35,070] {logging_mixin.py:112} INFO - [2020-08-01 15:17:35,070] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:35,072] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:35,086] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:35,094] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:35,095] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:17:41,071] {scheduler_job.py:154} INFO - Started process (PID=61660) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:41,088] {logging_mixin.py:112} INFO - [2020-08-01 15:17:41,088] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:41,089] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:41,089] {logging_mixin.py:112} INFO - [2020-08-01 15:17:41,089] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:41,091] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:41,105] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:41,112] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:41,114] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:17:47,089] {scheduler_job.py:154} INFO - Started process (PID=61666) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:47,107] {logging_mixin.py:112} INFO - [2020-08-01 15:17:47,106] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:47,107] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:47,107] {logging_mixin.py:112} INFO - [2020-08-01 15:17:47,107] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:47,109] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:47,123] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:47,130] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:47,132] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:17:53,104] {scheduler_job.py:154} INFO - Started process (PID=61673) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:53,122] {logging_mixin.py:112} INFO - [2020-08-01 15:17:53,122] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:53,123] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:53,123] {logging_mixin.py:112} INFO - [2020-08-01 15:17:53,123] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:53,125] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:53,139] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:53,147] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:53,149] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:17:59,114] {scheduler_job.py:154} INFO - Started process (PID=61679) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:59,132] {logging_mixin.py:112} INFO - [2020-08-01 15:17:59,132] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:17:59,132] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:17:59,133] {logging_mixin.py:112} INFO - [2020-08-01 15:17:59,132] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:59,134] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:17:59,149] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:17:59,155] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:17:59,157] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:18:05,152] {scheduler_job.py:154} INFO - Started process (PID=61685) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:05,170] {logging_mixin.py:112} INFO - [2020-08-01 15:18:05,170] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:05,171] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:05,171] {logging_mixin.py:112} INFO - [2020-08-01 15:18:05,171] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:05,172] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:05,187] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:05,194] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:05,195] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:18:11,177] {scheduler_job.py:154} INFO - Started process (PID=61691) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:11,195] {logging_mixin.py:112} INFO - [2020-08-01 15:18:11,195] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:11,195] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:11,196] {logging_mixin.py:112} INFO - [2020-08-01 15:18:11,196] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:11,197] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:11,212] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:11,218] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:11,220] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:18:17,192] {scheduler_job.py:154} INFO - Started process (PID=61697) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:17,210] {logging_mixin.py:112} INFO - [2020-08-01 15:18:17,210] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:17,211] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:17,211] {logging_mixin.py:112} INFO - [2020-08-01 15:18:17,211] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:17,213] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:17,227] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:17,234] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:17,236] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:18:23,219] {scheduler_job.py:154} INFO - Started process (PID=61704) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:23,237] {logging_mixin.py:112} INFO - [2020-08-01 15:18:23,236] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:23,237] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:23,237] {logging_mixin.py:112} INFO - [2020-08-01 15:18:23,237] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:23,239] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:23,254] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:23,261] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:23,263] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:18:29,248] {scheduler_job.py:154} INFO - Started process (PID=61710) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:29,266] {logging_mixin.py:112} INFO - [2020-08-01 15:18:29,265] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:29,266] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:29,266] {logging_mixin.py:112} INFO - [2020-08-01 15:18:29,266] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:29,268] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:29,283] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:29,290] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:29,291] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:18:35,261] {scheduler_job.py:154} INFO - Started process (PID=61716) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:35,278] {logging_mixin.py:112} INFO - [2020-08-01 15:18:35,278] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:35,279] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:35,279] {logging_mixin.py:112} INFO - [2020-08-01 15:18:35,279] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:35,281] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:35,295] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:35,302] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:35,304] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:18:41,290] {scheduler_job.py:154} INFO - Started process (PID=61722) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:41,308] {logging_mixin.py:112} INFO - [2020-08-01 15:18:41,307] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:41,308] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:41,308] {logging_mixin.py:112} INFO - [2020-08-01 15:18:41,308] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:41,310] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:41,324] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:41,331] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:41,333] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:18:47,412] {scheduler_job.py:154} INFO - Started process (PID=61728) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:47,430] {logging_mixin.py:112} INFO - [2020-08-01 15:18:47,430] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:47,430] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:47,430] {logging_mixin.py:112} INFO - [2020-08-01 15:18:47,430] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:47,432] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:47,447] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:47,454] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:47,455] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:18:53,381] {scheduler_job.py:154} INFO - Started process (PID=61736) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:53,399] {logging_mixin.py:112} INFO - [2020-08-01 15:18:53,398] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:53,399] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:53,399] {logging_mixin.py:112} INFO - [2020-08-01 15:18:53,399] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:53,401] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:53,414] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:53,422] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:53,423] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:18:59,335] {scheduler_job.py:154} INFO - Started process (PID=61742) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:59,353] {logging_mixin.py:112} INFO - [2020-08-01 15:18:59,353] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:18:59,354] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:18:59,354] {logging_mixin.py:112} INFO - [2020-08-01 15:18:59,354] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:59,355] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:18:59,370] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:18:59,377] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:18:59,379] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:19:05,371] {scheduler_job.py:154} INFO - Started process (PID=61748) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:05,389] {logging_mixin.py:112} INFO - [2020-08-01 15:19:05,389] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:05,390] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:05,390] {logging_mixin.py:112} INFO - [2020-08-01 15:19:05,390] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:05,392] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:05,406] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:05,413] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:05,415] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:19:11,387] {scheduler_job.py:154} INFO - Started process (PID=61754) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:11,405] {logging_mixin.py:112} INFO - [2020-08-01 15:19:11,405] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:11,406] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:11,406] {logging_mixin.py:112} INFO - [2020-08-01 15:19:11,406] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:11,408] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:11,422] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:11,429] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:11,431] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:19:17,413] {scheduler_job.py:154} INFO - Started process (PID=61760) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:17,431] {logging_mixin.py:112} INFO - [2020-08-01 15:19:17,431] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:17,432] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:17,432] {logging_mixin.py:112} INFO - [2020-08-01 15:19:17,432] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:17,433] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:17,451] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:17,461] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:17,463] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 15:19:23,434] {scheduler_job.py:154} INFO - Started process (PID=61767) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:23,451] {logging_mixin.py:112} INFO - [2020-08-01 15:19:23,451] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:23,452] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:23,452] {logging_mixin.py:112} INFO - [2020-08-01 15:19:23,452] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:23,454] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:23,468] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:23,475] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:23,477] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:19:29,456] {scheduler_job.py:154} INFO - Started process (PID=61773) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:29,473] {logging_mixin.py:112} INFO - [2020-08-01 15:19:29,473] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:29,474] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:29,474] {logging_mixin.py:112} INFO - [2020-08-01 15:19:29,474] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:29,476] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:29,490] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:29,497] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:29,498] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:19:35,483] {scheduler_job.py:154} INFO - Started process (PID=61779) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:35,501] {logging_mixin.py:112} INFO - [2020-08-01 15:19:35,500] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:35,501] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:35,501] {logging_mixin.py:112} INFO - [2020-08-01 15:19:35,501] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:35,503] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:35,517] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:35,524] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:35,526] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:19:41,510] {scheduler_job.py:154} INFO - Started process (PID=61785) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:41,527] {logging_mixin.py:112} INFO - [2020-08-01 15:19:41,527] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:41,528] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:41,528] {logging_mixin.py:112} INFO - [2020-08-01 15:19:41,528] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:41,530] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:41,544] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:41,551] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:41,553] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:19:47,532] {scheduler_job.py:154} INFO - Started process (PID=61791) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:47,549] {logging_mixin.py:112} INFO - [2020-08-01 15:19:47,549] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:47,550] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:47,550] {logging_mixin.py:112} INFO - [2020-08-01 15:19:47,550] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:47,552] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:47,566] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:47,573] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:47,574] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:19:53,621] {scheduler_job.py:154} INFO - Started process (PID=61798) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:53,640] {logging_mixin.py:112} INFO - [2020-08-01 15:19:53,640] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:53,640] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:53,641] {logging_mixin.py:112} INFO - [2020-08-01 15:19:53,641] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:53,642] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:53,657] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:53,664] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:53,666] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:19:59,581] {scheduler_job.py:154} INFO - Started process (PID=61804) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:59,599] {logging_mixin.py:112} INFO - [2020-08-01 15:19:59,598] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:19:59,599] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:19:59,599] {logging_mixin.py:112} INFO - [2020-08-01 15:19:59,599] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:59,601] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:19:59,615] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:19:59,623] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:19:59,624] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:20:05,602] {scheduler_job.py:154} INFO - Started process (PID=61810) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:05,620] {logging_mixin.py:112} INFO - [2020-08-01 15:20:05,620] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:05,620] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:05,621] {logging_mixin.py:112} INFO - [2020-08-01 15:20:05,621] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:05,622] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:05,637] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:05,644] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:05,645] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:20:11,624] {scheduler_job.py:154} INFO - Started process (PID=61816) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:11,641] {logging_mixin.py:112} INFO - [2020-08-01 15:20:11,641] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:11,642] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:11,642] {logging_mixin.py:112} INFO - [2020-08-01 15:20:11,642] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:11,644] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:11,658] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:11,665] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:11,667] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:20:17,660] {scheduler_job.py:154} INFO - Started process (PID=61822) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:17,679] {logging_mixin.py:112} INFO - [2020-08-01 15:20:17,679] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:17,680] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:17,680] {logging_mixin.py:112} INFO - [2020-08-01 15:20:17,680] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:17,682] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:17,694] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:17,702] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:17,704] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:20:23,763] {scheduler_job.py:154} INFO - Started process (PID=61828) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:23,781] {logging_mixin.py:112} INFO - [2020-08-01 15:20:23,781] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:23,781] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:23,781] {logging_mixin.py:112} INFO - [2020-08-01 15:20:23,781] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:23,783] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:23,797] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:23,804] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:23,805] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:20:29,694] {scheduler_job.py:154} INFO - Started process (PID=61835) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:29,713] {logging_mixin.py:112} INFO - [2020-08-01 15:20:29,713] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:29,714] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:29,714] {logging_mixin.py:112} INFO - [2020-08-01 15:20:29,714] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:29,716] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:29,731] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:29,737] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:29,739] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:20:35,712] {scheduler_job.py:154} INFO - Started process (PID=61841) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:35,729] {logging_mixin.py:112} INFO - [2020-08-01 15:20:35,729] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:35,730] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:35,730] {logging_mixin.py:112} INFO - [2020-08-01 15:20:35,730] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:35,732] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:35,748] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:35,756] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:35,757] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:20:41,828] {scheduler_job.py:154} INFO - Started process (PID=61847) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:41,847] {logging_mixin.py:112} INFO - [2020-08-01 15:20:41,846] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:41,847] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:41,847] {logging_mixin.py:112} INFO - [2020-08-01 15:20:41,847] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:41,849] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:41,864] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:41,872] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:41,873] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:20:47,802] {scheduler_job.py:154} INFO - Started process (PID=61853) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:47,819] {logging_mixin.py:112} INFO - [2020-08-01 15:20:47,819] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:47,820] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:47,820] {logging_mixin.py:112} INFO - [2020-08-01 15:20:47,820] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:47,822] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:47,836] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:47,843] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:47,845] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:20:53,811] {scheduler_job.py:154} INFO - Started process (PID=61859) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:53,829] {logging_mixin.py:112} INFO - [2020-08-01 15:20:53,829] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:53,830] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:53,830] {logging_mixin.py:112} INFO - [2020-08-01 15:20:53,830] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:53,832] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:53,846] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:53,854] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:53,856] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:20:59,819] {scheduler_job.py:154} INFO - Started process (PID=61866) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:59,838] {logging_mixin.py:112} INFO - [2020-08-01 15:20:59,838] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:20:59,838] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:20:59,839] {logging_mixin.py:112} INFO - [2020-08-01 15:20:59,838] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:59,840] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:20:59,855] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:20:59,862] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:20:59,864] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:21:05,805] {scheduler_job.py:154} INFO - Started process (PID=61872) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:05,823] {logging_mixin.py:112} INFO - [2020-08-01 15:21:05,823] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:05,824] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:21:05,824] {logging_mixin.py:112} INFO - [2020-08-01 15:21:05,824] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:05,826] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:05,840] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:21:05,848] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:05,849] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:21:11,938] {scheduler_job.py:154} INFO - Started process (PID=61878) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:11,957] {logging_mixin.py:112} INFO - [2020-08-01 15:21:11,957] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:11,957] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:21:11,957] {logging_mixin.py:112} INFO - [2020-08-01 15:21:11,957] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:11,959] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:11,973] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:21:11,979] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:11,981] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:21:17,820] {scheduler_job.py:154} INFO - Started process (PID=61884) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:17,836] {logging_mixin.py:112} INFO - [2020-08-01 15:21:17,836] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:17,837] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:21:17,837] {logging_mixin.py:112} INFO - [2020-08-01 15:21:17,837] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:17,839] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:17,852] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:21:17,858] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:17,859] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 15:21:23,882] {scheduler_job.py:154} INFO - Started process (PID=61890) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:23,901] {logging_mixin.py:112} INFO - [2020-08-01 15:21:23,901] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:23,902] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:21:23,902] {logging_mixin.py:112} INFO - [2020-08-01 15:21:23,902] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:23,904] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:23,918] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:21:23,926] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:23,928] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:21:29,872] {scheduler_job.py:154} INFO - Started process (PID=61897) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:29,889] {logging_mixin.py:112} INFO - [2020-08-01 15:21:29,889] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:29,890] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:21:29,890] {logging_mixin.py:112} INFO - [2020-08-01 15:21:29,890] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:29,892] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:29,906] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:21:29,913] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:29,914] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:21:35,901] {scheduler_job.py:154} INFO - Started process (PID=61903) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:35,919] {logging_mixin.py:112} INFO - [2020-08-01 15:21:35,919] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:35,920] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:21:35,920] {logging_mixin.py:112} INFO - [2020-08-01 15:21:35,920] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:35,922] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:35,936] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:21:35,943] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:35,945] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:21:42,020] {scheduler_job.py:154} INFO - Started process (PID=61909) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:42,037] {logging_mixin.py:112} INFO - [2020-08-01 15:21:42,037] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:42,038] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:21:42,038] {logging_mixin.py:112} INFO - [2020-08-01 15:21:42,038] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:42,040] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:42,053] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:21:42,060] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:42,062] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:21:47,957] {scheduler_job.py:154} INFO - Started process (PID=61915) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:47,975] {logging_mixin.py:112} INFO - [2020-08-01 15:21:47,975] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:47,975] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:21:47,976] {logging_mixin.py:112} INFO - [2020-08-01 15:21:47,976] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:47,977] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:47,990] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:21:47,997] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:47,998] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:21:53,962] {scheduler_job.py:154} INFO - Started process (PID=61921) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:53,980] {logging_mixin.py:112} INFO - [2020-08-01 15:21:53,980] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:21:53,980] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:21:53,981] {logging_mixin.py:112} INFO - [2020-08-01 15:21:53,981] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:53,982] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:21:53,998] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:21:54,007] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:21:54,008] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:22:00,054] {scheduler_job.py:154} INFO - Started process (PID=61928) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:00,073] {logging_mixin.py:112} INFO - [2020-08-01 15:22:00,072] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:00,073] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:00,073] {logging_mixin.py:112} INFO - [2020-08-01 15:22:00,073] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:00,075] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:00,091] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:00,097] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:00,099] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:22:06,069] {scheduler_job.py:154} INFO - Started process (PID=61934) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:06,088] {logging_mixin.py:112} INFO - [2020-08-01 15:22:06,088] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:06,089] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:06,089] {logging_mixin.py:112} INFO - [2020-08-01 15:22:06,089] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:06,091] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:06,105] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:06,112] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:06,114] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:22:12,028] {scheduler_job.py:154} INFO - Started process (PID=61940) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:12,046] {logging_mixin.py:112} INFO - [2020-08-01 15:22:12,046] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:12,047] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:12,047] {logging_mixin.py:112} INFO - [2020-08-01 15:22:12,047] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:12,048] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:12,063] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:12,072] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:12,073] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:22:18,988] {scheduler_job.py:154} INFO - Started process (PID=61946) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:19,018] {logging_mixin.py:112} INFO - [2020-08-01 15:22:19,018] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:19,019] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:19,019] {logging_mixin.py:112} INFO - [2020-08-01 15:22:19,019] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:19,022] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:19,040] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:19,050] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:19,052] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.064 seconds
[2020-08-01 15:22:24,986] {scheduler_job.py:154} INFO - Started process (PID=61952) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:25,017] {logging_mixin.py:112} INFO - [2020-08-01 15:22:25,017] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:25,018] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:25,018] {logging_mixin.py:112} INFO - [2020-08-01 15:22:25,018] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:25,021] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:25,040] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:25,051] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:25,054] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-01 15:22:31,679] {scheduler_job.py:154} INFO - Started process (PID=61959) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:31,710] {logging_mixin.py:112} INFO - [2020-08-01 15:22:31,710] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:31,711] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:31,711] {logging_mixin.py:112} INFO - [2020-08-01 15:22:31,711] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:31,714] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:31,734] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:31,744] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:31,747] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-01 15:22:37,471] {scheduler_job.py:154} INFO - Started process (PID=61965) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:37,518] {logging_mixin.py:112} INFO - [2020-08-01 15:22:37,518] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:37,519] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:37,519] {logging_mixin.py:112} INFO - [2020-08-01 15:22:37,519] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:37,522] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:37,541] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:37,552] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:37,554] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.083 seconds
[2020-08-01 15:22:43,105] {scheduler_job.py:154} INFO - Started process (PID=61971) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:43,137] {logging_mixin.py:112} INFO - [2020-08-01 15:22:43,136] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:43,138] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:43,138] {logging_mixin.py:112} INFO - [2020-08-01 15:22:43,138] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:43,141] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:43,160] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:43,170] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:43,172] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.067 seconds
[2020-08-01 15:22:49,298] {scheduler_job.py:154} INFO - Started process (PID=61977) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:49,331] {logging_mixin.py:112} INFO - [2020-08-01 15:22:49,331] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:49,332] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:49,332] {logging_mixin.py:112} INFO - [2020-08-01 15:22:49,332] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:49,335] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:49,355] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:49,366] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:49,368] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.070 seconds
[2020-08-01 15:22:55,337] {scheduler_job.py:154} INFO - Started process (PID=61983) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:55,368] {logging_mixin.py:112} INFO - [2020-08-01 15:22:55,368] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:22:55,369] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:22:55,369] {logging_mixin.py:112} INFO - [2020-08-01 15:22:55,369] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:55,372] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:22:55,391] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:22:55,402] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:22:55,405] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-01 15:23:01,781] {scheduler_job.py:154} INFO - Started process (PID=61990) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:01,813] {logging_mixin.py:112} INFO - [2020-08-01 15:23:01,812] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:01,814] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:01,814] {logging_mixin.py:112} INFO - [2020-08-01 15:23:01,814] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:01,816] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:01,836] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:01,847] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:01,848] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.067 seconds
[2020-08-01 15:23:07,941] {scheduler_job.py:154} INFO - Started process (PID=61996) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:07,973] {logging_mixin.py:112} INFO - [2020-08-01 15:23:07,972] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:07,974] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:07,974] {logging_mixin.py:112} INFO - [2020-08-01 15:23:07,974] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:07,977] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:07,996] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:08,006] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:08,009] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.067 seconds
[2020-08-01 15:23:14,408] {scheduler_job.py:154} INFO - Started process (PID=62002) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:14,440] {logging_mixin.py:112} INFO - [2020-08-01 15:23:14,440] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:14,441] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:14,442] {logging_mixin.py:112} INFO - [2020-08-01 15:23:14,441] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:14,444] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:14,465] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:14,477] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:14,480] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.072 seconds
[2020-08-01 15:23:20,182] {scheduler_job.py:154} INFO - Started process (PID=62008) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:20,205] {logging_mixin.py:112} INFO - [2020-08-01 15:23:20,205] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:20,206] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:20,206] {logging_mixin.py:112} INFO - [2020-08-01 15:23:20,206] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:20,208] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:20,223] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:20,230] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:20,232] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 15:23:26,719] {scheduler_job.py:154} INFO - Started process (PID=62014) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:26,747] {logging_mixin.py:112} INFO - [2020-08-01 15:23:26,747] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:26,748] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:26,748] {logging_mixin.py:112} INFO - [2020-08-01 15:23:26,748] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:26,751] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:26,771] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:26,781] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:26,783] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 15:23:33,499] {scheduler_job.py:154} INFO - Started process (PID=62021) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:33,530] {logging_mixin.py:112} INFO - [2020-08-01 15:23:33,530] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:33,531] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:33,531] {logging_mixin.py:112} INFO - [2020-08-01 15:23:33,531] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:33,534] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:33,554] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:33,564] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:33,567] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-01 15:23:40,131] {scheduler_job.py:154} INFO - Started process (PID=62027) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:40,162] {logging_mixin.py:112} INFO - [2020-08-01 15:23:40,162] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:40,163] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:40,164] {logging_mixin.py:112} INFO - [2020-08-01 15:23:40,164] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:40,166] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:40,186] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:40,197] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:40,199] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.069 seconds
[2020-08-01 15:23:46,543] {scheduler_job.py:154} INFO - Started process (PID=62033) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:46,575] {logging_mixin.py:112} INFO - [2020-08-01 15:23:46,575] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:46,576] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:46,577] {logging_mixin.py:112} INFO - [2020-08-01 15:23:46,577] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:46,579] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:46,599] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:46,610] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:46,613] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.069 seconds
[2020-08-01 15:23:52,349] {scheduler_job.py:154} INFO - Started process (PID=62039) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:52,392] {logging_mixin.py:112} INFO - [2020-08-01 15:23:52,391] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:52,393] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:52,393] {logging_mixin.py:112} INFO - [2020-08-01 15:23:52,393] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:52,395] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:52,415] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:52,424] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:52,425] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.077 seconds
[2020-08-01 15:23:58,606] {scheduler_job.py:154} INFO - Started process (PID=62045) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:58,637] {logging_mixin.py:112} INFO - [2020-08-01 15:23:58,637] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:23:58,638] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:23:58,638] {logging_mixin.py:112} INFO - [2020-08-01 15:23:58,638] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:58,641] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:23:58,661] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:23:58,670] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:23:58,672] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.066 seconds
[2020-08-01 15:24:05,558] {scheduler_job.py:154} INFO - Started process (PID=62052) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:05,589] {logging_mixin.py:112} INFO - [2020-08-01 15:24:05,589] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:05,591] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:05,591] {logging_mixin.py:112} INFO - [2020-08-01 15:24:05,591] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:05,593] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:05,613] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:05,623] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:05,626] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.067 seconds
[2020-08-01 15:24:11,538] {scheduler_job.py:154} INFO - Started process (PID=62058) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:11,570] {logging_mixin.py:112} INFO - [2020-08-01 15:24:11,570] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:11,571] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:11,571] {logging_mixin.py:112} INFO - [2020-08-01 15:24:11,571] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:11,574] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:11,594] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:11,604] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:11,606] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-01 15:24:17,580] {scheduler_job.py:154} INFO - Started process (PID=62064) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:17,612] {logging_mixin.py:112} INFO - [2020-08-01 15:24:17,612] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:17,614] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:17,614] {logging_mixin.py:112} INFO - [2020-08-01 15:24:17,614] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:17,617] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:17,636] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:17,647] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:17,650] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.070 seconds
[2020-08-01 15:24:23,322] {scheduler_job.py:154} INFO - Started process (PID=62070) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:23,364] {logging_mixin.py:112} INFO - [2020-08-01 15:24:23,364] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:23,365] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:23,365] {logging_mixin.py:112} INFO - [2020-08-01 15:24:23,365] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:23,371] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:23,403] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:23,414] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:23,417] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.095 seconds
[2020-08-01 15:24:28,796] {scheduler_job.py:154} INFO - Started process (PID=62076) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:28,829] {logging_mixin.py:112} INFO - [2020-08-01 15:24:28,829] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:28,830] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:28,830] {logging_mixin.py:112} INFO - [2020-08-01 15:24:28,830] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:28,833] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:28,852] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:28,865] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:28,868] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.072 seconds
[2020-08-01 15:24:34,415] {scheduler_job.py:154} INFO - Started process (PID=62083) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:34,453] {logging_mixin.py:112} INFO - [2020-08-01 15:24:34,452] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:34,455] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:34,455] {logging_mixin.py:112} INFO - [2020-08-01 15:24:34,455] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:34,458] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:34,482] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:34,494] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:34,497] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.083 seconds
[2020-08-01 15:24:40,517] {scheduler_job.py:154} INFO - Started process (PID=62089) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:40,567] {logging_mixin.py:112} INFO - [2020-08-01 15:24:40,567] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:40,568] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:40,568] {logging_mixin.py:112} INFO - [2020-08-01 15:24:40,568] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:40,572] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:40,593] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:40,604] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:40,607] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.090 seconds
[2020-08-01 15:24:46,533] {scheduler_job.py:154} INFO - Started process (PID=62095) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:46,576] {logging_mixin.py:112} INFO - [2020-08-01 15:24:46,575] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:46,577] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:46,577] {logging_mixin.py:112} INFO - [2020-08-01 15:24:46,577] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:46,580] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:46,605] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:46,617] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:46,622] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.089 seconds
[2020-08-01 15:24:52,469] {scheduler_job.py:154} INFO - Started process (PID=62101) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:52,501] {logging_mixin.py:112} INFO - [2020-08-01 15:24:52,501] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:52,502] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:52,503] {logging_mixin.py:112} INFO - [2020-08-01 15:24:52,503] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:52,506] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:52,522] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:52,533] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:52,535] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 15:24:57,873] {scheduler_job.py:154} INFO - Started process (PID=62107) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:57,905] {logging_mixin.py:112} INFO - [2020-08-01 15:24:57,904] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:24:57,906] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:24:57,906] {logging_mixin.py:112} INFO - [2020-08-01 15:24:57,906] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:57,909] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:24:57,928] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:24:57,938] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:24:57,940] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-01 15:25:03,501] {scheduler_job.py:154} INFO - Started process (PID=62114) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:03,533] {logging_mixin.py:112} INFO - [2020-08-01 15:25:03,533] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:03,534] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:03,534] {logging_mixin.py:112} INFO - [2020-08-01 15:25:03,534] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:03,537] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:03,556] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:03,567] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:03,569] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-01 15:25:08,911] {scheduler_job.py:154} INFO - Started process (PID=62120) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:08,944] {logging_mixin.py:112} INFO - [2020-08-01 15:25:08,944] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:08,945] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:08,945] {logging_mixin.py:112} INFO - [2020-08-01 15:25:08,945] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:08,948] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:08,969] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:08,979] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:08,981] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.070 seconds
[2020-08-01 15:25:14,338] {scheduler_job.py:154} INFO - Started process (PID=62126) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:14,377] {logging_mixin.py:112} INFO - [2020-08-01 15:25:14,377] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:14,378] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:14,379] {logging_mixin.py:112} INFO - [2020-08-01 15:25:14,379] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:14,382] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:14,414] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:14,427] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:14,429] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.091 seconds
[2020-08-01 15:25:19,910] {scheduler_job.py:154} INFO - Started process (PID=62132) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:19,942] {logging_mixin.py:112} INFO - [2020-08-01 15:25:19,942] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:19,943] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:19,944] {logging_mixin.py:112} INFO - [2020-08-01 15:25:19,943] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:19,946] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:19,966] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:19,977] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:19,980] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.069 seconds
[2020-08-01 15:25:25,195] {scheduler_job.py:154} INFO - Started process (PID=62138) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:25,221] {logging_mixin.py:112} INFO - [2020-08-01 15:25:25,221] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:25,222] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:25,222] {logging_mixin.py:112} INFO - [2020-08-01 15:25:25,222] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:25,225] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:25,245] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:25,262] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:25,265] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.070 seconds
[2020-08-01 15:25:30,872] {scheduler_job.py:154} INFO - Started process (PID=62144) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:30,896] {logging_mixin.py:112} INFO - [2020-08-01 15:25:30,895] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:30,896] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:30,896] {logging_mixin.py:112} INFO - [2020-08-01 15:25:30,896] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:30,899] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:30,916] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:30,928] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:30,931] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.059 seconds
[2020-08-01 15:25:36,585] {scheduler_job.py:154} INFO - Started process (PID=62151) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:36,603] {logging_mixin.py:112} INFO - [2020-08-01 15:25:36,602] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:36,603] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:36,603] {logging_mixin.py:112} INFO - [2020-08-01 15:25:36,603] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:36,605] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:36,620] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:36,626] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:36,628] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:25:42,620] {scheduler_job.py:154} INFO - Started process (PID=62157) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:42,638] {logging_mixin.py:112} INFO - [2020-08-01 15:25:42,638] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:42,638] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:42,639] {logging_mixin.py:112} INFO - [2020-08-01 15:25:42,639] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:42,640] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:42,655] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:42,662] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:42,664] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:25:48,683] {scheduler_job.py:154} INFO - Started process (PID=62163) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:48,702] {logging_mixin.py:112} INFO - [2020-08-01 15:25:48,701] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:48,702] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:48,702] {logging_mixin.py:112} INFO - [2020-08-01 15:25:48,702] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:48,704] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:48,718] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:48,724] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:48,726] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:25:54,654] {scheduler_job.py:154} INFO - Started process (PID=62174) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:54,672] {logging_mixin.py:112} INFO - [2020-08-01 15:25:54,672] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:25:54,673] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:25:54,673] {logging_mixin.py:112} INFO - [2020-08-01 15:25:54,673] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:54,675] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:25:54,689] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:25:54,696] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:25:54,698] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:26:00,676] {scheduler_job.py:154} INFO - Started process (PID=62180) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:00,693] {logging_mixin.py:112} INFO - [2020-08-01 15:26:00,693] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:00,694] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:00,694] {logging_mixin.py:112} INFO - [2020-08-01 15:26:00,694] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:00,696] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:00,710] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:00,717] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:00,718] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:26:06,693] {scheduler_job.py:154} INFO - Started process (PID=62188) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:06,710] {logging_mixin.py:112} INFO - [2020-08-01 15:26:06,710] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:06,711] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:06,711] {logging_mixin.py:112} INFO - [2020-08-01 15:26:06,711] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:06,713] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:06,727] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:06,734] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:06,736] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:26:12,750] {scheduler_job.py:154} INFO - Started process (PID=62194) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:12,768] {logging_mixin.py:112} INFO - [2020-08-01 15:26:12,767] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:12,768] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:12,768] {logging_mixin.py:112} INFO - [2020-08-01 15:26:12,768] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:12,770] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:12,784] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:12,791] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:12,793] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:26:18,741] {scheduler_job.py:154} INFO - Started process (PID=62200) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:18,759] {logging_mixin.py:112} INFO - [2020-08-01 15:26:18,759] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:18,760] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:18,760] {logging_mixin.py:112} INFO - [2020-08-01 15:26:18,760] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:18,762] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:18,774] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:18,781] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:18,782] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:26:24,760] {scheduler_job.py:154} INFO - Started process (PID=62206) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:24,777] {logging_mixin.py:112} INFO - [2020-08-01 15:26:24,777] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:24,778] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:24,778] {logging_mixin.py:112} INFO - [2020-08-01 15:26:24,778] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:24,780] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:24,794] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:24,801] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:24,803] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:26:30,785] {scheduler_job.py:154} INFO - Started process (PID=62212) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:30,803] {logging_mixin.py:112} INFO - [2020-08-01 15:26:30,803] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:30,803] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:30,803] {logging_mixin.py:112} INFO - [2020-08-01 15:26:30,803] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:30,805] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:30,820] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:30,827] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:30,828] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:26:36,944] {scheduler_job.py:154} INFO - Started process (PID=62219) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:36,962] {logging_mixin.py:112} INFO - [2020-08-01 15:26:36,961] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:36,962] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:36,962] {logging_mixin.py:112} INFO - [2020-08-01 15:26:36,962] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:36,964] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:36,978] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:36,985] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:36,986] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:26:42,860] {scheduler_job.py:154} INFO - Started process (PID=62225) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:42,878] {logging_mixin.py:112} INFO - [2020-08-01 15:26:42,878] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:42,879] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:42,879] {logging_mixin.py:112} INFO - [2020-08-01 15:26:42,879] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:42,881] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:42,896] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:42,904] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:42,905] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:26:48,846] {scheduler_job.py:154} INFO - Started process (PID=62231) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:48,864] {logging_mixin.py:112} INFO - [2020-08-01 15:26:48,864] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:48,865] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:48,865] {logging_mixin.py:112} INFO - [2020-08-01 15:26:48,865] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:48,867] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:48,881] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:48,888] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:48,890] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:26:54,897] {scheduler_job.py:154} INFO - Started process (PID=62237) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:54,914] {logging_mixin.py:112} INFO - [2020-08-01 15:26:54,914] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:26:54,915] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:26:54,915] {logging_mixin.py:112} INFO - [2020-08-01 15:26:54,915] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:54,917] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:26:54,931] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:26:54,939] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:26:54,940] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:27:00,904] {scheduler_job.py:154} INFO - Started process (PID=62245) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:00,922] {logging_mixin.py:112} INFO - [2020-08-01 15:27:00,922] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:00,923] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:00,923] {logging_mixin.py:112} INFO - [2020-08-01 15:27:00,923] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:00,925] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:00,939] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:00,946] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:00,948] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:27:06,912] {scheduler_job.py:154} INFO - Started process (PID=62252) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:06,929] {logging_mixin.py:112} INFO - [2020-08-01 15:27:06,929] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:06,930] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:06,930] {logging_mixin.py:112} INFO - [2020-08-01 15:27:06,930] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:06,932] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:06,946] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:06,953] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:06,955] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:27:12,946] {scheduler_job.py:154} INFO - Started process (PID=62258) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:12,964] {logging_mixin.py:112} INFO - [2020-08-01 15:27:12,964] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:12,965] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:12,965] {logging_mixin.py:112} INFO - [2020-08-01 15:27:12,965] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:12,967] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:12,981] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:12,988] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:12,989] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:27:18,962] {scheduler_job.py:154} INFO - Started process (PID=62264) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:18,980] {logging_mixin.py:112} INFO - [2020-08-01 15:27:18,980] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:18,981] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:18,981] {logging_mixin.py:112} INFO - [2020-08-01 15:27:18,981] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:18,983] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:18,996] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:19,003] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:19,004] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:27:24,985] {scheduler_job.py:154} INFO - Started process (PID=62270) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:25,003] {logging_mixin.py:112} INFO - [2020-08-01 15:27:25,002] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:25,003] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:25,003] {logging_mixin.py:112} INFO - [2020-08-01 15:27:25,003] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:25,005] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:25,019] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:25,027] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:25,028] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:27:31,007] {scheduler_job.py:154} INFO - Started process (PID=62276) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:31,024] {logging_mixin.py:112} INFO - [2020-08-01 15:27:31,024] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:31,025] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:31,025] {logging_mixin.py:112} INFO - [2020-08-01 15:27:31,025] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:31,027] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:31,041] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:31,048] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:31,050] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:27:37,036] {scheduler_job.py:154} INFO - Started process (PID=62283) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:37,054] {logging_mixin.py:112} INFO - [2020-08-01 15:27:37,053] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:37,054] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:37,054] {logging_mixin.py:112} INFO - [2020-08-01 15:27:37,054] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:37,056] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:37,070] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:37,077] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:37,079] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:27:43,066] {scheduler_job.py:154} INFO - Started process (PID=62289) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:43,084] {logging_mixin.py:112} INFO - [2020-08-01 15:27:43,084] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:43,085] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:43,085] {logging_mixin.py:112} INFO - [2020-08-01 15:27:43,085] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:43,087] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:43,102] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:43,109] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:43,110] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:27:49,091] {scheduler_job.py:154} INFO - Started process (PID=62295) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:49,110] {logging_mixin.py:112} INFO - [2020-08-01 15:27:49,109] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:49,110] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:49,110] {logging_mixin.py:112} INFO - [2020-08-01 15:27:49,110] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:49,112] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:49,127] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:49,136] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:49,138] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:27:55,095] {scheduler_job.py:154} INFO - Started process (PID=62301) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:55,113] {logging_mixin.py:112} INFO - [2020-08-01 15:27:55,113] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:27:55,114] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:27:55,114] {logging_mixin.py:112} INFO - [2020-08-01 15:27:55,114] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:55,115] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:27:55,132] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:27:55,139] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:27:55,140] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:28:01,114] {scheduler_job.py:154} INFO - Started process (PID=62307) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:01,132] {logging_mixin.py:112} INFO - [2020-08-01 15:28:01,132] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:01,132] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:01,132] {logging_mixin.py:112} INFO - [2020-08-01 15:28:01,132] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:01,134] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:01,148] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:01,156] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:01,157] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:28:07,129] {scheduler_job.py:154} INFO - Started process (PID=62314) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:07,147] {logging_mixin.py:112} INFO - [2020-08-01 15:28:07,147] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:07,147] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:07,148] {logging_mixin.py:112} INFO - [2020-08-01 15:28:07,148] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:07,149] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:07,162] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:07,169] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:07,171] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:28:13,184] {scheduler_job.py:154} INFO - Started process (PID=62320) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:13,203] {logging_mixin.py:112} INFO - [2020-08-01 15:28:13,203] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:13,203] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:13,203] {logging_mixin.py:112} INFO - [2020-08-01 15:28:13,203] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:13,205] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:13,220] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:13,227] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:13,228] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:28:19,176] {scheduler_job.py:154} INFO - Started process (PID=62326) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:19,194] {logging_mixin.py:112} INFO - [2020-08-01 15:28:19,194] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:19,195] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:19,195] {logging_mixin.py:112} INFO - [2020-08-01 15:28:19,195] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:19,197] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:19,211] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:19,219] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:19,220] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:28:25,206] {scheduler_job.py:154} INFO - Started process (PID=62332) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:25,223] {logging_mixin.py:112} INFO - [2020-08-01 15:28:25,223] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:25,224] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:25,224] {logging_mixin.py:112} INFO - [2020-08-01 15:28:25,224] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:25,225] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:25,240] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:25,247] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:25,248] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:28:31,234] {scheduler_job.py:154} INFO - Started process (PID=62338) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:31,251] {logging_mixin.py:112} INFO - [2020-08-01 15:28:31,251] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:31,252] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:31,252] {logging_mixin.py:112} INFO - [2020-08-01 15:28:31,252] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:31,254] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:31,268] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:31,275] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:31,276] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:28:37,261] {scheduler_job.py:154} INFO - Started process (PID=62345) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:37,279] {logging_mixin.py:112} INFO - [2020-08-01 15:28:37,278] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:37,279] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:37,279] {logging_mixin.py:112} INFO - [2020-08-01 15:28:37,279] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:37,281] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:37,295] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:37,302] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:37,304] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:28:43,290] {scheduler_job.py:154} INFO - Started process (PID=62351) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:43,308] {logging_mixin.py:112} INFO - [2020-08-01 15:28:43,307] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:43,308] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:43,308] {logging_mixin.py:112} INFO - [2020-08-01 15:28:43,308] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:43,310] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:43,324] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:43,331] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:43,333] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:28:49,300] {scheduler_job.py:154} INFO - Started process (PID=62357) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:49,318] {logging_mixin.py:112} INFO - [2020-08-01 15:28:49,317] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:49,318] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:49,318] {logging_mixin.py:112} INFO - [2020-08-01 15:28:49,318] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:49,320] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:49,335] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:49,341] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:49,343] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:28:55,330] {scheduler_job.py:154} INFO - Started process (PID=62363) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:55,348] {logging_mixin.py:112} INFO - [2020-08-01 15:28:55,348] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:28:55,349] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:28:55,349] {logging_mixin.py:112} INFO - [2020-08-01 15:28:55,349] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:55,351] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:28:55,365] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:28:55,372] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:28:55,374] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:29:01,431] {scheduler_job.py:154} INFO - Started process (PID=62369) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:01,448] {logging_mixin.py:112} INFO - [2020-08-01 15:29:01,448] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:01,449] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:01,449] {logging_mixin.py:112} INFO - [2020-08-01 15:29:01,449] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:01,451] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:01,464] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:01,472] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:01,473] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:29:07,383] {scheduler_job.py:154} INFO - Started process (PID=62376) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:07,401] {logging_mixin.py:112} INFO - [2020-08-01 15:29:07,401] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:07,402] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:07,402] {logging_mixin.py:112} INFO - [2020-08-01 15:29:07,402] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:07,403] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:07,418] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:07,424] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:07,426] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:29:13,486] {scheduler_job.py:154} INFO - Started process (PID=62382) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:13,506] {logging_mixin.py:112} INFO - [2020-08-01 15:29:13,506] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:13,507] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:13,507] {logging_mixin.py:112} INFO - [2020-08-01 15:29:13,507] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:13,509] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:13,526] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:13,533] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:13,534] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:29:19,417] {scheduler_job.py:154} INFO - Started process (PID=62388) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:19,435] {logging_mixin.py:112} INFO - [2020-08-01 15:29:19,435] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:19,435] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:19,435] {logging_mixin.py:112} INFO - [2020-08-01 15:29:19,435] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:19,437] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:19,452] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:19,458] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:19,460] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:29:25,443] {scheduler_job.py:154} INFO - Started process (PID=62394) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:25,461] {logging_mixin.py:112} INFO - [2020-08-01 15:29:25,460] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:25,461] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:25,461] {logging_mixin.py:112} INFO - [2020-08-01 15:29:25,461] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:25,463] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:25,477] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:25,484] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:25,486] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:29:31,497] {scheduler_job.py:154} INFO - Started process (PID=62400) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:31,514] {logging_mixin.py:112} INFO - [2020-08-01 15:29:31,514] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:31,515] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:31,515] {logging_mixin.py:112} INFO - [2020-08-01 15:29:31,515] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:31,517] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:31,531] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:31,538] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:31,539] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:29:37,533] {scheduler_job.py:154} INFO - Started process (PID=62407) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:37,551] {logging_mixin.py:112} INFO - [2020-08-01 15:29:37,551] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:37,552] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:37,552] {logging_mixin.py:112} INFO - [2020-08-01 15:29:37,552] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:37,554] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:37,567] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:37,575] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:37,576] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:29:43,610] {scheduler_job.py:154} INFO - Started process (PID=62413) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:43,627] {logging_mixin.py:112} INFO - [2020-08-01 15:29:43,626] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:43,627] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:43,627] {logging_mixin.py:112} INFO - [2020-08-01 15:29:43,627] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:43,629] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:43,643] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:43,652] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:43,653] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:29:49,647] {scheduler_job.py:154} INFO - Started process (PID=62427) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:49,666] {logging_mixin.py:112} INFO - [2020-08-01 15:29:49,666] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:49,667] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:49,667] {logging_mixin.py:112} INFO - [2020-08-01 15:29:49,667] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:49,669] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:49,683] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:49,690] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:49,691] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:29:55,523] {scheduler_job.py:154} INFO - Started process (PID=62444) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:55,541] {logging_mixin.py:112} INFO - [2020-08-01 15:29:55,540] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:29:55,541] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:29:55,541] {logging_mixin.py:112} INFO - [2020-08-01 15:29:55,541] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:55,543] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:29:55,557] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:29:55,564] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:29:55,566] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:30:01,533] {scheduler_job.py:154} INFO - Started process (PID=62460) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:01,551] {logging_mixin.py:112} INFO - [2020-08-01 15:30:01,551] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:01,552] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:01,552] {logging_mixin.py:112} INFO - [2020-08-01 15:30:01,552] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:01,553] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:01,568] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:01,575] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:01,576] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:30:07,665] {scheduler_job.py:154} INFO - Started process (PID=62474) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:07,682] {logging_mixin.py:112} INFO - [2020-08-01 15:30:07,682] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:07,683] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:07,683] {logging_mixin.py:112} INFO - [2020-08-01 15:30:07,683] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:07,685] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:07,699] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:07,705] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:07,707] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:30:13,641] {scheduler_job.py:154} INFO - Started process (PID=62489) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:13,659] {logging_mixin.py:112} INFO - [2020-08-01 15:30:13,658] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:13,659] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:13,659] {logging_mixin.py:112} INFO - [2020-08-01 15:30:13,659] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:13,661] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:13,675] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:13,683] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:13,684] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:30:19,649] {scheduler_job.py:154} INFO - Started process (PID=62540) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:19,666] {logging_mixin.py:112} INFO - [2020-08-01 15:30:19,666] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:19,667] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:19,667] {logging_mixin.py:112} INFO - [2020-08-01 15:30:19,667] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:19,669] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:19,683] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:19,690] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:19,692] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:30:25,802] {scheduler_job.py:154} INFO - Started process (PID=62578) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:25,820] {logging_mixin.py:112} INFO - [2020-08-01 15:30:25,820] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:25,821] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:25,821] {logging_mixin.py:112} INFO - [2020-08-01 15:30:25,821] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:25,823] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:25,837] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:25,844] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:25,845] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:30:31,776] {scheduler_job.py:154} INFO - Started process (PID=62641) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:31,796] {logging_mixin.py:112} INFO - [2020-08-01 15:30:31,796] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:31,797] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:31,797] {logging_mixin.py:112} INFO - [2020-08-01 15:30:31,797] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:31,799] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:31,815] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:31,821] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:31,823] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:30:37,656] {scheduler_job.py:154} INFO - Started process (PID=62671) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:37,674] {logging_mixin.py:112} INFO - [2020-08-01 15:30:37,674] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:37,674] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:37,675] {logging_mixin.py:112} INFO - [2020-08-01 15:30:37,674] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:37,676] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:37,691] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:37,699] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:37,702] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:30:43,689] {scheduler_job.py:154} INFO - Started process (PID=62686) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:43,707] {logging_mixin.py:112} INFO - [2020-08-01 15:30:43,707] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:43,707] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:43,708] {logging_mixin.py:112} INFO - [2020-08-01 15:30:43,708] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:43,709] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:43,724] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:43,731] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:43,733] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:30:49,738] {scheduler_job.py:154} INFO - Started process (PID=62701) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:49,757] {logging_mixin.py:112} INFO - [2020-08-01 15:30:49,756] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:49,757] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:49,757] {logging_mixin.py:112} INFO - [2020-08-01 15:30:49,757] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:49,759] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:49,773] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:49,782] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:49,784] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:30:55,734] {scheduler_job.py:154} INFO - Started process (PID=62723) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:55,752] {logging_mixin.py:112} INFO - [2020-08-01 15:30:55,752] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:30:55,753] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:30:55,753] {logging_mixin.py:112} INFO - [2020-08-01 15:30:55,753] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:55,755] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:30:55,769] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:30:55,776] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:30:55,778] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:31:01,744] {scheduler_job.py:154} INFO - Started process (PID=62737) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:01,762] {logging_mixin.py:112} INFO - [2020-08-01 15:31:01,762] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:01,763] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:01,763] {logging_mixin.py:112} INFO - [2020-08-01 15:31:01,763] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:01,764] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:01,779] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:01,787] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:01,789] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:31:07,773] {scheduler_job.py:154} INFO - Started process (PID=62751) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:07,792] {logging_mixin.py:112} INFO - [2020-08-01 15:31:07,792] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:07,793] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:07,793] {logging_mixin.py:112} INFO - [2020-08-01 15:31:07,793] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:07,795] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:07,810] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:07,817] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:07,818] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:31:13,805] {scheduler_job.py:154} INFO - Started process (PID=62766) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:13,824] {logging_mixin.py:112} INFO - [2020-08-01 15:31:13,824] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:13,825] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:13,825] {logging_mixin.py:112} INFO - [2020-08-01 15:31:13,825] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:13,826] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:13,841] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:13,848] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:13,849] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:31:19,824] {scheduler_job.py:154} INFO - Started process (PID=62780) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:19,841] {logging_mixin.py:112} INFO - [2020-08-01 15:31:19,841] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:19,842] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:19,842] {logging_mixin.py:112} INFO - [2020-08-01 15:31:19,842] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:19,844] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:19,858] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:19,865] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:19,866] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:31:25,881] {scheduler_job.py:154} INFO - Started process (PID=62794) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:25,899] {logging_mixin.py:112} INFO - [2020-08-01 15:31:25,899] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:25,899] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:25,900] {logging_mixin.py:112} INFO - [2020-08-01 15:31:25,899] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:25,901] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:25,916] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:25,922] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:25,924] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:31:31,874] {scheduler_job.py:154} INFO - Started process (PID=62816) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:31,892] {logging_mixin.py:112} INFO - [2020-08-01 15:31:31,891] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:31,892] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:31,892] {logging_mixin.py:112} INFO - [2020-08-01 15:31:31,892] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:31,894] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:31,908] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:31,915] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:31,917] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:31:37,906] {scheduler_job.py:154} INFO - Started process (PID=62830) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:37,924] {logging_mixin.py:112} INFO - [2020-08-01 15:31:37,924] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:37,924] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:37,925] {logging_mixin.py:112} INFO - [2020-08-01 15:31:37,925] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:37,926] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:37,941] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:37,948] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:37,950] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:31:43,930] {scheduler_job.py:154} INFO - Started process (PID=62845) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:43,948] {logging_mixin.py:112} INFO - [2020-08-01 15:31:43,948] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:43,948] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:43,949] {logging_mixin.py:112} INFO - [2020-08-01 15:31:43,948] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:43,950] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:43,964] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:43,972] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:43,974] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:31:49,949] {scheduler_job.py:154} INFO - Started process (PID=62859) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:49,967] {logging_mixin.py:112} INFO - [2020-08-01 15:31:49,967] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:49,968] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:49,968] {logging_mixin.py:112} INFO - [2020-08-01 15:31:49,968] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:49,969] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:49,984] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:49,992] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:49,994] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:31:56,003] {scheduler_job.py:154} INFO - Started process (PID=62873) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:56,021] {logging_mixin.py:112} INFO - [2020-08-01 15:31:56,021] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:31:56,021] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:31:56,021] {logging_mixin.py:112} INFO - [2020-08-01 15:31:56,021] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:56,023] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:31:56,037] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:31:56,044] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:31:56,046] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:32:02,029] {scheduler_job.py:154} INFO - Started process (PID=62895) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:02,047] {logging_mixin.py:112} INFO - [2020-08-01 15:32:02,047] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:02,048] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:02,048] {logging_mixin.py:112} INFO - [2020-08-01 15:32:02,048] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:02,050] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:02,064] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:02,071] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:02,073] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:32:08,028] {scheduler_job.py:154} INFO - Started process (PID=62909) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:08,046] {logging_mixin.py:112} INFO - [2020-08-01 15:32:08,046] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:08,046] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:08,046] {logging_mixin.py:112} INFO - [2020-08-01 15:32:08,046] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:08,048] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:08,062] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:08,069] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:08,071] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:32:14,058] {scheduler_job.py:154} INFO - Started process (PID=62924) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:14,076] {logging_mixin.py:112} INFO - [2020-08-01 15:32:14,076] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:14,077] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:14,077] {logging_mixin.py:112} INFO - [2020-08-01 15:32:14,077] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:14,079] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:14,093] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:14,100] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:14,102] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:32:20,074] {scheduler_job.py:154} INFO - Started process (PID=62938) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:20,092] {logging_mixin.py:112} INFO - [2020-08-01 15:32:20,092] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:20,093] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:20,093] {logging_mixin.py:112} INFO - [2020-08-01 15:32:20,093] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:20,095] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:20,109] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:20,116] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:20,117] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:32:26,094] {scheduler_job.py:154} INFO - Started process (PID=62952) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:26,112] {logging_mixin.py:112} INFO - [2020-08-01 15:32:26,112] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:26,113] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:26,113] {logging_mixin.py:112} INFO - [2020-08-01 15:32:26,113] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:26,115] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:26,129] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:26,136] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:26,137] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:32:32,151] {scheduler_job.py:154} INFO - Started process (PID=62966) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:32,169] {logging_mixin.py:112} INFO - [2020-08-01 15:32:32,169] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:32,170] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:32,170] {logging_mixin.py:112} INFO - [2020-08-01 15:32:32,170] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:32,172] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:32,186] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:32,194] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:32,195] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:32:38,138] {scheduler_job.py:154} INFO - Started process (PID=62988) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:38,155] {logging_mixin.py:112} INFO - [2020-08-01 15:32:38,155] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:38,156] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:38,156] {logging_mixin.py:112} INFO - [2020-08-01 15:32:38,156] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:38,158] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:38,172] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:38,179] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:38,181] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:32:44,167] {scheduler_job.py:154} INFO - Started process (PID=63003) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:44,186] {logging_mixin.py:112} INFO - [2020-08-01 15:32:44,186] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:44,187] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:44,187] {logging_mixin.py:112} INFO - [2020-08-01 15:32:44,187] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:44,189] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:44,201] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:44,208] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:44,210] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:32:50,171] {scheduler_job.py:154} INFO - Started process (PID=63017) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:50,189] {logging_mixin.py:112} INFO - [2020-08-01 15:32:50,189] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:50,190] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:50,190] {logging_mixin.py:112} INFO - [2020-08-01 15:32:50,190] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:50,192] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:50,206] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:50,213] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:50,215] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:32:56,192] {scheduler_job.py:154} INFO - Started process (PID=63031) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:56,210] {logging_mixin.py:112} INFO - [2020-08-01 15:32:56,209] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:32:56,210] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:32:56,210] {logging_mixin.py:112} INFO - [2020-08-01 15:32:56,210] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:56,212] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:32:56,226] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:32:56,234] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:32:56,235] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:33:02,241] {scheduler_job.py:154} INFO - Started process (PID=63045) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:02,258] {logging_mixin.py:112} INFO - [2020-08-01 15:33:02,258] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:02,259] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:02,259] {logging_mixin.py:112} INFO - [2020-08-01 15:33:02,259] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:02,261] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:02,275] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:02,282] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:02,283] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:33:08,245] {scheduler_job.py:154} INFO - Started process (PID=63067) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:08,262] {logging_mixin.py:112} INFO - [2020-08-01 15:33:08,262] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:08,263] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:08,263] {logging_mixin.py:112} INFO - [2020-08-01 15:33:08,263] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:08,265] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:08,279] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:08,289] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:08,291] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:33:14,300] {scheduler_job.py:154} INFO - Started process (PID=63082) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:14,319] {logging_mixin.py:112} INFO - [2020-08-01 15:33:14,319] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:14,320] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:14,320] {logging_mixin.py:112} INFO - [2020-08-01 15:33:14,320] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:14,323] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:14,336] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:14,343] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:14,344] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:33:20,347] {scheduler_job.py:154} INFO - Started process (PID=63112) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:20,368] {logging_mixin.py:112} INFO - [2020-08-01 15:33:20,368] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:20,369] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:20,369] {logging_mixin.py:112} INFO - [2020-08-01 15:33:20,369] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:20,372] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:20,388] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:20,395] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:20,397] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 15:33:26,334] {scheduler_job.py:154} INFO - Started process (PID=63126) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:26,352] {logging_mixin.py:112} INFO - [2020-08-01 15:33:26,352] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:26,352] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:26,353] {logging_mixin.py:112} INFO - [2020-08-01 15:33:26,353] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:26,354] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:26,368] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:26,375] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:26,377] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:33:32,276] {scheduler_job.py:154} INFO - Started process (PID=63157) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:32,294] {logging_mixin.py:112} INFO - [2020-08-01 15:33:32,293] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:32,294] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:32,294] {logging_mixin.py:112} INFO - [2020-08-01 15:33:32,294] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:32,296] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:32,310] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:32,318] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:32,320] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:33:38,374] {scheduler_job.py:154} INFO - Started process (PID=63171) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:38,395] {logging_mixin.py:112} INFO - [2020-08-01 15:33:38,395] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:38,395] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:38,396] {logging_mixin.py:112} INFO - [2020-08-01 15:33:38,396] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:38,397] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:38,412] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:38,420] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:38,422] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:33:44,364] {scheduler_job.py:154} INFO - Started process (PID=63195) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:44,383] {logging_mixin.py:112} INFO - [2020-08-01 15:33:44,383] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:44,384] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:44,384] {logging_mixin.py:112} INFO - [2020-08-01 15:33:44,384] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:44,386] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:44,401] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:44,408] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:44,409] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:33:50,394] {scheduler_job.py:154} INFO - Started process (PID=63209) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:50,412] {logging_mixin.py:112} INFO - [2020-08-01 15:33:50,412] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:50,413] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:50,413] {logging_mixin.py:112} INFO - [2020-08-01 15:33:50,413] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:50,414] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:50,429] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:50,436] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:50,438] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:33:56,409] {scheduler_job.py:154} INFO - Started process (PID=63223) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:56,427] {logging_mixin.py:112} INFO - [2020-08-01 15:33:56,427] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:33:56,428] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:33:56,428] {logging_mixin.py:112} INFO - [2020-08-01 15:33:56,428] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:56,430] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:33:56,444] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:33:56,452] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:33:56,454] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:34:02,366] {scheduler_job.py:154} INFO - Started process (PID=63238) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:02,385] {logging_mixin.py:112} INFO - [2020-08-01 15:34:02,385] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:02,386] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:02,386] {logging_mixin.py:112} INFO - [2020-08-01 15:34:02,386] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:02,388] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:02,402] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:02,409] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:02,410] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:34:08,465] {scheduler_job.py:154} INFO - Started process (PID=63252) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:08,482] {logging_mixin.py:112} INFO - [2020-08-01 15:34:08,482] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:08,483] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:08,483] {logging_mixin.py:112} INFO - [2020-08-01 15:34:08,483] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:08,485] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:08,499] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:08,506] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:08,507] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:34:14,525] {scheduler_job.py:154} INFO - Started process (PID=63270) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:14,544] {logging_mixin.py:112} INFO - [2020-08-01 15:34:14,544] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:14,544] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:14,545] {logging_mixin.py:112} INFO - [2020-08-01 15:34:14,545] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:14,546] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:14,562] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:14,569] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:14,570] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:34:20,445] {scheduler_job.py:154} INFO - Started process (PID=63290) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:20,473] {logging_mixin.py:112} INFO - [2020-08-01 15:34:20,473] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:20,474] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:20,474] {logging_mixin.py:112} INFO - [2020-08-01 15:34:20,474] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:20,476] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:20,492] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:20,500] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:20,501] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.057 seconds
[2020-08-01 15:34:26,469] {scheduler_job.py:154} INFO - Started process (PID=63304) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:26,487] {logging_mixin.py:112} INFO - [2020-08-01 15:34:26,487] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:26,488] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:26,488] {logging_mixin.py:112} INFO - [2020-08-01 15:34:26,488] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:26,490] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:26,504] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:26,513] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:26,515] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:34:32,516] {scheduler_job.py:154} INFO - Started process (PID=63319) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:32,533] {logging_mixin.py:112} INFO - [2020-08-01 15:34:32,533] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:32,534] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:32,534] {logging_mixin.py:112} INFO - [2020-08-01 15:34:32,534] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:32,536] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:32,550] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:32,557] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:32,558] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:34:38,496] {scheduler_job.py:154} INFO - Started process (PID=63333) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:38,514] {logging_mixin.py:112} INFO - [2020-08-01 15:34:38,514] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:38,514] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:38,515] {logging_mixin.py:112} INFO - [2020-08-01 15:34:38,514] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:38,516] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:38,530] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:38,537] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:38,539] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:34:44,640] {scheduler_job.py:154} INFO - Started process (PID=63349) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:44,659] {logging_mixin.py:112} INFO - [2020-08-01 15:34:44,658] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:44,659] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:44,660] {logging_mixin.py:112} INFO - [2020-08-01 15:34:44,660] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:44,662] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:44,676] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:44,684] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:44,686] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:34:50,593] {scheduler_job.py:154} INFO - Started process (PID=63371) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:50,611] {logging_mixin.py:112} INFO - [2020-08-01 15:34:50,611] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:50,612] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:50,612] {logging_mixin.py:112} INFO - [2020-08-01 15:34:50,612] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:50,614] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:50,627] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:50,635] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:50,637] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:34:56,542] {scheduler_job.py:154} INFO - Started process (PID=63385) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:56,560] {logging_mixin.py:112} INFO - [2020-08-01 15:34:56,560] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:34:56,561] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:34:56,561] {logging_mixin.py:112} INFO - [2020-08-01 15:34:56,561] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:56,563] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:34:56,576] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:34:56,583] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:34:56,585] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:35:02,534] {scheduler_job.py:154} INFO - Started process (PID=63417) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:02,552] {logging_mixin.py:112} INFO - [2020-08-01 15:35:02,551] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:02,552] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:35:02,552] {logging_mixin.py:112} INFO - [2020-08-01 15:35:02,552] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:02,554] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:02,569] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:35:02,576] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:02,578] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:35:10,656] {scheduler_job.py:154} INFO - Started process (PID=63458) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:10,675] {logging_mixin.py:112} INFO - [2020-08-01 15:35:10,675] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:10,676] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:35:10,676] {logging_mixin.py:112} INFO - [2020-08-01 15:35:10,676] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:10,678] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:10,692] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:35:10,699] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:10,701] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:35:18,643] {scheduler_job.py:154} INFO - Started process (PID=63468) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:18,660] {logging_mixin.py:112} INFO - [2020-08-01 15:35:18,660] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:18,661] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:35:18,661] {logging_mixin.py:112} INFO - [2020-08-01 15:35:18,661] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:18,663] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:18,677] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:35:18,683] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:18,685] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:35:26,616] {scheduler_job.py:154} INFO - Started process (PID=63492) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:26,633] {logging_mixin.py:112} INFO - [2020-08-01 15:35:26,633] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:26,634] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:35:26,634] {logging_mixin.py:112} INFO - [2020-08-01 15:35:26,634] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:26,636] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:26,650] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:35:26,657] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:26,658] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:35:34,743] {scheduler_job.py:154} INFO - Started process (PID=63524) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:34,761] {logging_mixin.py:112} INFO - [2020-08-01 15:35:34,761] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:34,762] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:35:34,762] {logging_mixin.py:112} INFO - [2020-08-01 15:35:34,762] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:34,763] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:34,778] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:35:34,786] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:34,788] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:35:42,700] {scheduler_job.py:154} INFO - Started process (PID=63564) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:42,719] {logging_mixin.py:112} INFO - [2020-08-01 15:35:42,718] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:42,719] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:35:42,719] {logging_mixin.py:112} INFO - [2020-08-01 15:35:42,719] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:42,721] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:42,735] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:35:42,743] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:42,745] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:35:50,764] {scheduler_job.py:154} INFO - Started process (PID=63582) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:50,782] {logging_mixin.py:112} INFO - [2020-08-01 15:35:50,782] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:50,783] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:35:50,783] {logging_mixin.py:112} INFO - [2020-08-01 15:35:50,783] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:50,785] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:50,799] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:35:50,806] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:50,808] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:35:58,714] {scheduler_job.py:154} INFO - Started process (PID=63606) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:58,732] {logging_mixin.py:112} INFO - [2020-08-01 15:35:58,731] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:35:58,732] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:35:58,732] {logging_mixin.py:112} INFO - [2020-08-01 15:35:58,732] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:58,734] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:35:58,748] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:35:58,756] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:35:58,757] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:36:06,758] {scheduler_job.py:154} INFO - Started process (PID=63631) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:06,776] {logging_mixin.py:112} INFO - [2020-08-01 15:36:06,775] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:06,776] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:36:06,776] {logging_mixin.py:112} INFO - [2020-08-01 15:36:06,776] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:06,778] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:06,792] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:36:06,800] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:06,802] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:36:14,793] {scheduler_job.py:154} INFO - Started process (PID=63647) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:14,811] {logging_mixin.py:112} INFO - [2020-08-01 15:36:14,810] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:14,811] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:36:14,811] {logging_mixin.py:112} INFO - [2020-08-01 15:36:14,811] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:14,813] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:14,828] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:36:14,835] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:14,837] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:36:22,838] {scheduler_job.py:154} INFO - Started process (PID=63672) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:22,855] {logging_mixin.py:112} INFO - [2020-08-01 15:36:22,855] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:22,856] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:36:22,856] {logging_mixin.py:112} INFO - [2020-08-01 15:36:22,856] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:22,858] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:22,872] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:36:22,879] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:22,881] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:36:30,871] {scheduler_job.py:154} INFO - Started process (PID=63688) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:30,889] {logging_mixin.py:112} INFO - [2020-08-01 15:36:30,889] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:30,890] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:36:30,890] {logging_mixin.py:112} INFO - [2020-08-01 15:36:30,890] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:30,892] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:30,906] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:36:30,913] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:30,915] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:36:38,872] {scheduler_job.py:154} INFO - Started process (PID=63712) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:38,889] {logging_mixin.py:112} INFO - [2020-08-01 15:36:38,889] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:38,890] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:36:38,890] {logging_mixin.py:112} INFO - [2020-08-01 15:36:38,890] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:38,892] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:38,906] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:36:38,913] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:38,915] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:36:46,989] {scheduler_job.py:154} INFO - Started process (PID=63733) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:47,007] {logging_mixin.py:112} INFO - [2020-08-01 15:36:47,007] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:47,007] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:36:47,008] {logging_mixin.py:112} INFO - [2020-08-01 15:36:47,008] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:47,009] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:47,024] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:36:47,033] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:47,035] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:36:54,954] {scheduler_job.py:154} INFO - Started process (PID=63754) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:54,971] {logging_mixin.py:112} INFO - [2020-08-01 15:36:54,971] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:36:54,972] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:36:54,972] {logging_mixin.py:112} INFO - [2020-08-01 15:36:54,972] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:54,974] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:36:54,988] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:36:54,995] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:36:54,997] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:37:02,972] {scheduler_job.py:154} INFO - Started process (PID=63778) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:02,990] {logging_mixin.py:112} INFO - [2020-08-01 15:37:02,990] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:02,991] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:37:02,991] {logging_mixin.py:112} INFO - [2020-08-01 15:37:02,991] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:02,993] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:03,007] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:37:03,014] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:03,015] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:37:10,993] {scheduler_job.py:154} INFO - Started process (PID=63794) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:11,011] {logging_mixin.py:112} INFO - [2020-08-01 15:37:11,010] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:11,011] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:37:11,011] {logging_mixin.py:112} INFO - [2020-08-01 15:37:11,011] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:11,013] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:11,027] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:37:11,034] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:11,035] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:37:19,037] {scheduler_job.py:154} INFO - Started process (PID=63819) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:19,055] {logging_mixin.py:112} INFO - [2020-08-01 15:37:19,055] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:19,056] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:37:19,056] {logging_mixin.py:112} INFO - [2020-08-01 15:37:19,056] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:19,058] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:19,072] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:37:19,078] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:19,080] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:37:27,073] {scheduler_job.py:154} INFO - Started process (PID=63835) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:27,090] {logging_mixin.py:112} INFO - [2020-08-01 15:37:27,090] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:27,091] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:37:27,091] {logging_mixin.py:112} INFO - [2020-08-01 15:37:27,091] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:27,093] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:27,107] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:37:27,115] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:27,117] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:37:35,093] {scheduler_job.py:154} INFO - Started process (PID=63859) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:35,111] {logging_mixin.py:112} INFO - [2020-08-01 15:37:35,110] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:35,111] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:37:35,111] {logging_mixin.py:112} INFO - [2020-08-01 15:37:35,111] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:35,113] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:35,128] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:37:35,135] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:35,137] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:37:43,169] {scheduler_job.py:154} INFO - Started process (PID=63883) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:43,187] {logging_mixin.py:112} INFO - [2020-08-01 15:37:43,187] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:43,187] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:37:43,187] {logging_mixin.py:112} INFO - [2020-08-01 15:37:43,187] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:43,189] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:43,204] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:37:43,212] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:43,215] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:37:51,190] {scheduler_job.py:154} INFO - Started process (PID=63901) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:51,208] {logging_mixin.py:112} INFO - [2020-08-01 15:37:51,207] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:51,208] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:37:51,209] {logging_mixin.py:112} INFO - [2020-08-01 15:37:51,209] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:51,211] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:51,226] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:37:51,233] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:51,234] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:37:59,241] {scheduler_job.py:154} INFO - Started process (PID=63926) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:59,259] {logging_mixin.py:112} INFO - [2020-08-01 15:37:59,259] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:37:59,259] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:37:59,260] {logging_mixin.py:112} INFO - [2020-08-01 15:37:59,260] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:59,261] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:37:59,275] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:37:59,283] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:37:59,285] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:38:07,196] {scheduler_job.py:154} INFO - Started process (PID=63942) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:07,214] {logging_mixin.py:112} INFO - [2020-08-01 15:38:07,214] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:07,215] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:38:07,215] {logging_mixin.py:112} INFO - [2020-08-01 15:38:07,215] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:07,217] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:07,230] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:38:07,237] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:07,238] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:38:15,263] {scheduler_job.py:154} INFO - Started process (PID=63967) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:15,286] {logging_mixin.py:112} INFO - [2020-08-01 15:38:15,285] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:15,287] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:38:15,287] {logging_mixin.py:112} INFO - [2020-08-01 15:38:15,287] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:15,289] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:15,308] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:38:15,317] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:15,319] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.056 seconds
[2020-08-01 15:38:23,304] {scheduler_job.py:154} INFO - Started process (PID=63984) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:23,321] {logging_mixin.py:112} INFO - [2020-08-01 15:38:23,321] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:23,322] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:38:23,322] {logging_mixin.py:112} INFO - [2020-08-01 15:38:23,322] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:23,324] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:23,338] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:38:23,345] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:23,346] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:38:31,285] {scheduler_job.py:154} INFO - Started process (PID=64009) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:31,303] {logging_mixin.py:112} INFO - [2020-08-01 15:38:31,302] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:31,303] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:38:31,303] {logging_mixin.py:112} INFO - [2020-08-01 15:38:31,303] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:31,305] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:31,319] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:38:31,326] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:31,328] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:38:39,361] {scheduler_job.py:154} INFO - Started process (PID=64033) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:39,379] {logging_mixin.py:112} INFO - [2020-08-01 15:38:39,378] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:39,379] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:38:39,379] {logging_mixin.py:112} INFO - [2020-08-01 15:38:39,379] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:39,381] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:39,396] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:38:39,406] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:39,408] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:38:47,367] {scheduler_job.py:154} INFO - Started process (PID=64050) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:47,390] {logging_mixin.py:112} INFO - [2020-08-01 15:38:47,390] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:47,391] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:38:47,391] {logging_mixin.py:112} INFO - [2020-08-01 15:38:47,391] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:47,393] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:47,408] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:38:47,415] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:47,417] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 15:38:55,391] {scheduler_job.py:154} INFO - Started process (PID=64075) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:55,407] {logging_mixin.py:112} INFO - [2020-08-01 15:38:55,407] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:38:55,408] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:38:55,408] {logging_mixin.py:112} INFO - [2020-08-01 15:38:55,408] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:55,410] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:38:55,424] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:38:55,430] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:38:55,432] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:39:03,395] {scheduler_job.py:154} INFO - Started process (PID=64092) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:03,413] {logging_mixin.py:112} INFO - [2020-08-01 15:39:03,412] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:03,413] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:39:03,413] {logging_mixin.py:112} INFO - [2020-08-01 15:39:03,413] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:03,415] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:03,429] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:39:03,435] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:03,437] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:39:11,431] {scheduler_job.py:154} INFO - Started process (PID=64116) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:11,448] {logging_mixin.py:112} INFO - [2020-08-01 15:39:11,448] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:11,449] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:39:11,449] {logging_mixin.py:112} INFO - [2020-08-01 15:39:11,449] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:11,451] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:11,465] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:39:11,473] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:11,474] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:39:19,531] {scheduler_job.py:154} INFO - Started process (PID=64150) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:19,552] {logging_mixin.py:112} INFO - [2020-08-01 15:39:19,551] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:19,553] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:39:19,553] {logging_mixin.py:112} INFO - [2020-08-01 15:39:19,553] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:19,555] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:19,571] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:39:19,580] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:19,582] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 15:39:27,444] {scheduler_job.py:154} INFO - Started process (PID=64175) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:27,464] {logging_mixin.py:112} INFO - [2020-08-01 15:39:27,464] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:27,465] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:39:27,465] {logging_mixin.py:112} INFO - [2020-08-01 15:39:27,465] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:27,467] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:27,480] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:39:27,487] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:27,489] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:39:35,461] {scheduler_job.py:154} INFO - Started process (PID=64200) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:35,479] {logging_mixin.py:112} INFO - [2020-08-01 15:39:35,479] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:35,479] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:39:35,480] {logging_mixin.py:112} INFO - [2020-08-01 15:39:35,480] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:35,481] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:35,496] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:39:35,503] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:35,505] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:39:43,494] {scheduler_job.py:154} INFO - Started process (PID=64216) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:43,512] {logging_mixin.py:112} INFO - [2020-08-01 15:39:43,511] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:43,512] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:39:43,512] {logging_mixin.py:112} INFO - [2020-08-01 15:39:43,512] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:43,514] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:43,528] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:39:43,537] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:43,538] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:39:51,504] {scheduler_job.py:154} INFO - Started process (PID=64242) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:51,521] {logging_mixin.py:112} INFO - [2020-08-01 15:39:51,521] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:51,522] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:39:51,522] {logging_mixin.py:112} INFO - [2020-08-01 15:39:51,522] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:51,523] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:51,537] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:39:51,544] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:51,545] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:39:59,553] {scheduler_job.py:154} INFO - Started process (PID=64262) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:59,571] {logging_mixin.py:112} INFO - [2020-08-01 15:39:59,571] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:39:59,572] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:39:59,572] {logging_mixin.py:112} INFO - [2020-08-01 15:39:59,572] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:59,574] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:39:59,587] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:39:59,594] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:39:59,596] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:40:07,576] {scheduler_job.py:154} INFO - Started process (PID=64286) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:07,594] {logging_mixin.py:112} INFO - [2020-08-01 15:40:07,594] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:07,595] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:40:07,595] {logging_mixin.py:112} INFO - [2020-08-01 15:40:07,595] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:07,597] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:07,610] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:40:07,616] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:07,618] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:40:15,626] {scheduler_job.py:154} INFO - Started process (PID=64303) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:15,643] {logging_mixin.py:112} INFO - [2020-08-01 15:40:15,643] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:15,644] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:40:15,644] {logging_mixin.py:112} INFO - [2020-08-01 15:40:15,644] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:15,646] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:15,660] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:40:15,667] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:15,669] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:40:23,623] {scheduler_job.py:154} INFO - Started process (PID=64328) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:23,640] {logging_mixin.py:112} INFO - [2020-08-01 15:40:23,640] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:23,641] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:40:23,641] {logging_mixin.py:112} INFO - [2020-08-01 15:40:23,641] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:23,643] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:23,657] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:40:23,664] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:23,666] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:40:31,672] {scheduler_job.py:154} INFO - Started process (PID=64352) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:31,690] {logging_mixin.py:112} INFO - [2020-08-01 15:40:31,690] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:31,691] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:40:31,691] {logging_mixin.py:112} INFO - [2020-08-01 15:40:31,691] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:31,693] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:31,708] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:40:31,717] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:31,719] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:40:39,664] {scheduler_job.py:154} INFO - Started process (PID=64368) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:39,681] {logging_mixin.py:112} INFO - [2020-08-01 15:40:39,681] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:39,682] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:40:39,682] {logging_mixin.py:112} INFO - [2020-08-01 15:40:39,682] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:39,684] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:39,698] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:40:39,705] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:39,706] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:40:47,703] {scheduler_job.py:154} INFO - Started process (PID=64392) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:47,720] {logging_mixin.py:112} INFO - [2020-08-01 15:40:47,719] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:47,720] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:40:47,720] {logging_mixin.py:112} INFO - [2020-08-01 15:40:47,720] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:47,722] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:47,736] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:40:47,743] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:47,746] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:40:55,719] {scheduler_job.py:154} INFO - Started process (PID=64409) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:55,739] {logging_mixin.py:112} INFO - [2020-08-01 15:40:55,739] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:40:55,740] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:40:55,740] {logging_mixin.py:112} INFO - [2020-08-01 15:40:55,740] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:55,742] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:40:55,757] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:40:55,765] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:40:55,766] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:41:03,798] {scheduler_job.py:154} INFO - Started process (PID=64433) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:03,816] {logging_mixin.py:112} INFO - [2020-08-01 15:41:03,815] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:03,816] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:41:03,816] {logging_mixin.py:112} INFO - [2020-08-01 15:41:03,816] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:03,818] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:03,833] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:41:03,842] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:03,843] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:41:11,752] {scheduler_job.py:154} INFO - Started process (PID=64441) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:11,770] {logging_mixin.py:112} INFO - [2020-08-01 15:41:11,770] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:11,770] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:41:11,771] {logging_mixin.py:112} INFO - [2020-08-01 15:41:11,771] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:11,772] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:11,787] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:41:11,794] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:11,796] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:41:19,850] {scheduler_job.py:154} INFO - Started process (PID=64449) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:19,867] {logging_mixin.py:112} INFO - [2020-08-01 15:41:19,867] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:19,868] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:41:19,868] {logging_mixin.py:112} INFO - [2020-08-01 15:41:19,868] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:19,870] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:19,884] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:41:19,891] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:19,892] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:41:27,820] {scheduler_job.py:154} INFO - Started process (PID=64458) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:27,838] {logging_mixin.py:112} INFO - [2020-08-01 15:41:27,837] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:27,838] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:41:27,838] {logging_mixin.py:112} INFO - [2020-08-01 15:41:27,838] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:27,840] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:27,855] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:41:27,865] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:27,867] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:41:35,895] {scheduler_job.py:154} INFO - Started process (PID=64470) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:35,913] {logging_mixin.py:112} INFO - [2020-08-01 15:41:35,913] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:35,913] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:41:35,913] {logging_mixin.py:112} INFO - [2020-08-01 15:41:35,913] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:35,916] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:35,929] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:41:35,936] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:35,937] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:41:43,873] {scheduler_job.py:154} INFO - Started process (PID=64494) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:43,891] {logging_mixin.py:112} INFO - [2020-08-01 15:41:43,891] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:43,892] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:41:43,892] {logging_mixin.py:112} INFO - [2020-08-01 15:41:43,892] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:43,894] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:43,908] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:41:43,915] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:43,917] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:41:51,903] {scheduler_job.py:154} INFO - Started process (PID=64531) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:51,920] {logging_mixin.py:112} INFO - [2020-08-01 15:41:51,920] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:51,921] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:41:51,921] {logging_mixin.py:112} INFO - [2020-08-01 15:41:51,921] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:51,923] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:51,937] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:41:51,944] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:51,946] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:41:59,890] {scheduler_job.py:154} INFO - Started process (PID=64573) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:59,907] {logging_mixin.py:112} INFO - [2020-08-01 15:41:59,907] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:41:59,908] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:41:59,908] {logging_mixin.py:112} INFO - [2020-08-01 15:41:59,908] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:59,910] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:41:59,924] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:41:59,934] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:41:59,936] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:42:07,954] {scheduler_job.py:154} INFO - Started process (PID=64589) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:07,972] {logging_mixin.py:112} INFO - [2020-08-01 15:42:07,972] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:07,972] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:42:07,972] {logging_mixin.py:112} INFO - [2020-08-01 15:42:07,972] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:07,974] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:07,988] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:42:07,994] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:07,996] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:42:16,027] {scheduler_job.py:154} INFO - Started process (PID=64614) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:16,043] {logging_mixin.py:112} INFO - [2020-08-01 15:42:16,043] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:16,044] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:42:16,044] {logging_mixin.py:112} INFO - [2020-08-01 15:42:16,044] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:16,046] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:16,060] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:42:16,067] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:16,068] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:42:24,159] {scheduler_job.py:154} INFO - Started process (PID=64672) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:24,178] {logging_mixin.py:112} INFO - [2020-08-01 15:42:24,178] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:24,179] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:42:24,179] {logging_mixin.py:112} INFO - [2020-08-01 15:42:24,179] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:24,181] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:24,196] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:42:24,204] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:24,205] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:42:32,051] {scheduler_job.py:154} INFO - Started process (PID=64690) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:32,068] {logging_mixin.py:112} INFO - [2020-08-01 15:42:32,068] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:32,069] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:42:32,069] {logging_mixin.py:112} INFO - [2020-08-01 15:42:32,069] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:32,071] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:32,085] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:42:32,093] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:32,095] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:42:40,218] {scheduler_job.py:154} INFO - Started process (PID=64723) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:40,241] {logging_mixin.py:112} INFO - [2020-08-01 15:42:40,241] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:40,242] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:42:40,242] {logging_mixin.py:112} INFO - [2020-08-01 15:42:40,242] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:40,245] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:40,264] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:42:40,271] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:40,273] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.055 seconds
[2020-08-01 15:42:48,036] {scheduler_job.py:154} INFO - Started process (PID=64731) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:48,054] {logging_mixin.py:112} INFO - [2020-08-01 15:42:48,054] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:48,055] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:42:48,055] {logging_mixin.py:112} INFO - [2020-08-01 15:42:48,055] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:48,057] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:48,070] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:42:48,077] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:48,079] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:42:56,155] {scheduler_job.py:154} INFO - Started process (PID=64740) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:56,178] {logging_mixin.py:112} INFO - [2020-08-01 15:42:56,177] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:42:56,178] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:42:56,178] {logging_mixin.py:112} INFO - [2020-08-01 15:42:56,178] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:56,180] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:42:56,194] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:42:56,202] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:42:56,203] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:43:04,156] {scheduler_job.py:154} INFO - Started process (PID=64756) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:04,178] {logging_mixin.py:112} INFO - [2020-08-01 15:43:04,178] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:04,179] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:43:04,179] {logging_mixin.py:112} INFO - [2020-08-01 15:43:04,179] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:04,181] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:04,196] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:43:04,204] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:04,205] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 15:43:12,210] {scheduler_job.py:154} INFO - Started process (PID=64772) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:12,227] {logging_mixin.py:112} INFO - [2020-08-01 15:43:12,227] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:12,228] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:43:12,228] {logging_mixin.py:112} INFO - [2020-08-01 15:43:12,228] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:12,230] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:12,244] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:43:12,252] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:12,254] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:43:20,232] {scheduler_job.py:154} INFO - Started process (PID=64797) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:20,250] {logging_mixin.py:112} INFO - [2020-08-01 15:43:20,250] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:20,251] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:43:20,251] {logging_mixin.py:112} INFO - [2020-08-01 15:43:20,251] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:20,253] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:20,267] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:43:20,274] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:20,275] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:43:28,170] {scheduler_job.py:154} INFO - Started process (PID=64808) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:28,188] {logging_mixin.py:112} INFO - [2020-08-01 15:43:28,188] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:28,189] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:43:28,189] {logging_mixin.py:112} INFO - [2020-08-01 15:43:28,189] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:28,191] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:28,205] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:43:28,213] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:28,215] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:43:36,201] {scheduler_job.py:154} INFO - Started process (PID=64818) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:36,218] {logging_mixin.py:112} INFO - [2020-08-01 15:43:36,218] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:36,219] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:43:36,219] {logging_mixin.py:112} INFO - [2020-08-01 15:43:36,219] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:36,221] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:36,235] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:43:36,243] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:36,244] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:43:44,234] {scheduler_job.py:154} INFO - Started process (PID=64826) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:44,252] {logging_mixin.py:112} INFO - [2020-08-01 15:43:44,252] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:44,253] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:43:44,253] {logging_mixin.py:112} INFO - [2020-08-01 15:43:44,253] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:44,255] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:44,269] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:43:44,276] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:44,278] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:43:52,243] {scheduler_job.py:154} INFO - Started process (PID=64836) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:52,261] {logging_mixin.py:112} INFO - [2020-08-01 15:43:52,261] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:43:52,262] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:43:52,262] {logging_mixin.py:112} INFO - [2020-08-01 15:43:52,262] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:52,264] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:43:52,278] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:43:52,285] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:43:52,287] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:44:00,296] {scheduler_job.py:154} INFO - Started process (PID=64845) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:00,314] {logging_mixin.py:112} INFO - [2020-08-01 15:44:00,314] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:00,314] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:44:00,315] {logging_mixin.py:112} INFO - [2020-08-01 15:44:00,315] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:00,316] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:00,331] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:44:00,340] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:00,342] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:44:08,355] {scheduler_job.py:154} INFO - Started process (PID=64855) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:08,375] {logging_mixin.py:112} INFO - [2020-08-01 15:44:08,375] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:08,376] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:44:08,376] {logging_mixin.py:112} INFO - [2020-08-01 15:44:08,376] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:08,378] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:08,390] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:44:08,397] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:08,399] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:44:16,302] {scheduler_job.py:154} INFO - Started process (PID=64863) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:16,320] {logging_mixin.py:112} INFO - [2020-08-01 15:44:16,320] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:16,321] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:44:16,321] {logging_mixin.py:112} INFO - [2020-08-01 15:44:16,321] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:16,323] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:16,337] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:44:16,345] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:16,347] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:44:24,360] {scheduler_job.py:154} INFO - Started process (PID=64881) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:24,379] {logging_mixin.py:112} INFO - [2020-08-01 15:44:24,378] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:24,379] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:44:24,379] {logging_mixin.py:112} INFO - [2020-08-01 15:44:24,379] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:24,381] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:24,396] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:44:24,404] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:24,405] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:44:32,341] {scheduler_job.py:154} INFO - Started process (PID=64958) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:32,358] {logging_mixin.py:112} INFO - [2020-08-01 15:44:32,358] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:32,359] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:44:32,359] {logging_mixin.py:112} INFO - [2020-08-01 15:44:32,359] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:32,361] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:32,375] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:44:32,383] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:32,384] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:44:40,626] {scheduler_job.py:154} INFO - Started process (PID=64974) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:40,645] {logging_mixin.py:112} INFO - [2020-08-01 15:44:40,644] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:40,645] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:44:40,646] {logging_mixin.py:112} INFO - [2020-08-01 15:44:40,646] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:40,648] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:40,663] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:44:40,669] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:40,671] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:44:48,411] {scheduler_job.py:154} INFO - Started process (PID=64983) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:48,429] {logging_mixin.py:112} INFO - [2020-08-01 15:44:48,429] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:48,430] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:44:48,430] {logging_mixin.py:112} INFO - [2020-08-01 15:44:48,430] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:48,432] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:48,446] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:44:48,452] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:48,454] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:44:56,430] {scheduler_job.py:154} INFO - Started process (PID=64991) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:56,448] {logging_mixin.py:112} INFO - [2020-08-01 15:44:56,448] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:44:56,448] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:44:56,449] {logging_mixin.py:112} INFO - [2020-08-01 15:44:56,449] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:56,450] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:44:56,464] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:44:56,472] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:44:56,473] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:45:04,422] {scheduler_job.py:154} INFO - Started process (PID=65008) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:04,440] {logging_mixin.py:112} INFO - [2020-08-01 15:45:04,440] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:04,441] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:45:04,441] {logging_mixin.py:112} INFO - [2020-08-01 15:45:04,441] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:04,442] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:04,457] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:45:04,464] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:04,466] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:45:12,496] {scheduler_job.py:154} INFO - Started process (PID=65024) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:12,517] {logging_mixin.py:112} INFO - [2020-08-01 15:45:12,517] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:12,518] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:45:12,518] {logging_mixin.py:112} INFO - [2020-08-01 15:45:12,518] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:12,519] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:12,534] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:45:12,543] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:12,545] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 15:45:20,540] {scheduler_job.py:154} INFO - Started process (PID=65059) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:20,558] {logging_mixin.py:112} INFO - [2020-08-01 15:45:20,557] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:20,558] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:45:20,558] {logging_mixin.py:112} INFO - [2020-08-01 15:45:20,558] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:20,560] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:20,576] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:45:20,583] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:20,584] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:45:28,618] {scheduler_job.py:154} INFO - Started process (PID=65072) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:28,641] {logging_mixin.py:112} INFO - [2020-08-01 15:45:28,641] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:28,641] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:45:28,641] {logging_mixin.py:112} INFO - [2020-08-01 15:45:28,641] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:28,643] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:28,657] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:45:28,664] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:28,666] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:45:36,544] {scheduler_job.py:154} INFO - Started process (PID=65080) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:36,561] {logging_mixin.py:112} INFO - [2020-08-01 15:45:36,561] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:36,562] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:45:36,562] {logging_mixin.py:112} INFO - [2020-08-01 15:45:36,562] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:36,564] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:36,578] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:45:36,586] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:36,588] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:45:44,586] {scheduler_job.py:154} INFO - Started process (PID=65116) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:44,604] {logging_mixin.py:112} INFO - [2020-08-01 15:45:44,604] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:44,605] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:45:44,605] {logging_mixin.py:112} INFO - [2020-08-01 15:45:44,605] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:44,607] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:44,621] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:45:44,629] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:44,631] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:45:52,585] {scheduler_job.py:154} INFO - Started process (PID=65149) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:52,602] {logging_mixin.py:112} INFO - [2020-08-01 15:45:52,602] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:45:52,603] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:45:52,603] {logging_mixin.py:112} INFO - [2020-08-01 15:45:52,603] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:52,605] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:45:52,619] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:45:52,627] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:45:52,629] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:46:00,764] {scheduler_job.py:154} INFO - Started process (PID=65175) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:00,781] {logging_mixin.py:112} INFO - [2020-08-01 15:46:00,781] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:00,782] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:46:00,782] {logging_mixin.py:112} INFO - [2020-08-01 15:46:00,782] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:00,783] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:00,798] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:46:00,806] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:00,807] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:46:08,795] {scheduler_job.py:154} INFO - Started process (PID=65224) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:08,819] {logging_mixin.py:112} INFO - [2020-08-01 15:46:08,819] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:08,820] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:46:08,820] {logging_mixin.py:112} INFO - [2020-08-01 15:46:08,820] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:08,822] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:08,836] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:46:08,847] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:08,849] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.054 seconds
[2020-08-01 15:46:16,641] {scheduler_job.py:154} INFO - Started process (PID=65286) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:16,660] {logging_mixin.py:112} INFO - [2020-08-01 15:46:16,659] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:16,660] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:46:16,660] {logging_mixin.py:112} INFO - [2020-08-01 15:46:16,660] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:16,662] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:16,675] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:46:16,682] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:16,684] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:46:24,651] {scheduler_job.py:154} INFO - Started process (PID=65310) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:24,668] {logging_mixin.py:112} INFO - [2020-08-01 15:46:24,668] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:24,669] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:46:24,669] {logging_mixin.py:112} INFO - [2020-08-01 15:46:24,669] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:24,671] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:24,684] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:46:24,691] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:24,693] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:46:32,731] {scheduler_job.py:154} INFO - Started process (PID=65345) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:32,748] {logging_mixin.py:112} INFO - [2020-08-01 15:46:32,748] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:32,749] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:46:32,749] {logging_mixin.py:112} INFO - [2020-08-01 15:46:32,749] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:32,750] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:32,764] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:46:32,771] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:32,772] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:46:40,715] {scheduler_job.py:154} INFO - Started process (PID=65403) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:40,733] {logging_mixin.py:112} INFO - [2020-08-01 15:46:40,732] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:40,733] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:46:40,733] {logging_mixin.py:112} INFO - [2020-08-01 15:46:40,733] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:40,735] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:40,749] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:46:40,758] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:40,761] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:46:48,784] {scheduler_job.py:154} INFO - Started process (PID=65414) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:48,804] {logging_mixin.py:112} INFO - [2020-08-01 15:46:48,804] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:48,805] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:46:48,805] {logging_mixin.py:112} INFO - [2020-08-01 15:46:48,805] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:48,807] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:48,826] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:46:48,835] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:48,837] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 15:46:56,720] {scheduler_job.py:154} INFO - Started process (PID=65424) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:56,738] {logging_mixin.py:112} INFO - [2020-08-01 15:46:56,738] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:46:56,739] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:46:56,739] {logging_mixin.py:112} INFO - [2020-08-01 15:46:56,739] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:56,741] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:46:56,755] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:46:56,762] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:46:56,763] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:47:04,776] {scheduler_job.py:154} INFO - Started process (PID=65433) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:04,795] {logging_mixin.py:112} INFO - [2020-08-01 15:47:04,794] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:04,795] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:47:04,795] {logging_mixin.py:112} INFO - [2020-08-01 15:47:04,795] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:04,797] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:04,813] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:47:04,821] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:04,823] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:47:12,773] {scheduler_job.py:154} INFO - Started process (PID=65441) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:12,791] {logging_mixin.py:112} INFO - [2020-08-01 15:47:12,791] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:12,792] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:47:12,792] {logging_mixin.py:112} INFO - [2020-08-01 15:47:12,792] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:12,794] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:12,808] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:47:12,815] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:12,817] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:47:20,933] {scheduler_job.py:154} INFO - Started process (PID=65449) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:20,952] {logging_mixin.py:112} INFO - [2020-08-01 15:47:20,952] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:20,952] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:47:20,953] {logging_mixin.py:112} INFO - [2020-08-01 15:47:20,953] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:20,954] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:20,969] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:47:20,976] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:20,977] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:47:28,919] {scheduler_job.py:154} INFO - Started process (PID=65466) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:28,939] {logging_mixin.py:112} INFO - [2020-08-01 15:47:28,939] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:28,940] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:47:28,940] {logging_mixin.py:112} INFO - [2020-08-01 15:47:28,940] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:28,942] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:28,960] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:47:28,967] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:28,969] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 15:47:36,832] {scheduler_job.py:154} INFO - Started process (PID=65477) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:36,850] {logging_mixin.py:112} INFO - [2020-08-01 15:47:36,850] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:36,851] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:47:36,851] {logging_mixin.py:112} INFO - [2020-08-01 15:47:36,851] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:36,853] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:36,867] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:47:36,874] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:36,876] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:47:44,940] {scheduler_job.py:154} INFO - Started process (PID=65487) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:44,958] {logging_mixin.py:112} INFO - [2020-08-01 15:47:44,957] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:44,958] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:47:44,958] {logging_mixin.py:112} INFO - [2020-08-01 15:47:44,958] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:44,960] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:44,974] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:47:44,981] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:44,983] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:47:53,109] {scheduler_job.py:154} INFO - Started process (PID=65495) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:53,127] {logging_mixin.py:112} INFO - [2020-08-01 15:47:53,127] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:47:53,127] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:47:53,128] {logging_mixin.py:112} INFO - [2020-08-01 15:47:53,128] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:53,129] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:47:53,143] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:47:53,151] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:47:53,152] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:48:00,941] {scheduler_job.py:154} INFO - Started process (PID=65503) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:00,959] {logging_mixin.py:112} INFO - [2020-08-01 15:48:00,959] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:00,960] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:48:00,960] {logging_mixin.py:112} INFO - [2020-08-01 15:48:00,960] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:00,962] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:00,977] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:48:00,984] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:00,985] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:48:08,970] {scheduler_job.py:154} INFO - Started process (PID=65512) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:08,988] {logging_mixin.py:112} INFO - [2020-08-01 15:48:08,988] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:08,989] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:48:08,989] {logging_mixin.py:112} INFO - [2020-08-01 15:48:08,989] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:08,991] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:09,006] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:48:09,013] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:09,014] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:48:16,995] {scheduler_job.py:154} INFO - Started process (PID=65520) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:17,013] {logging_mixin.py:112} INFO - [2020-08-01 15:48:17,013] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:17,014] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:48:17,014] {logging_mixin.py:112} INFO - [2020-08-01 15:48:17,014] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:17,016] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:17,030] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:48:17,039] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:17,040] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:48:25,254] {scheduler_job.py:154} INFO - Started process (PID=65528) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:25,283] {logging_mixin.py:112} INFO - [2020-08-01 15:48:25,282] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:25,283] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:48:25,284] {logging_mixin.py:112} INFO - [2020-08-01 15:48:25,284] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:25,286] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:25,307] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:48:25,319] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:25,322] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.068 seconds
[2020-08-01 15:48:33,112] {scheduler_job.py:154} INFO - Started process (PID=65537) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:33,131] {logging_mixin.py:112} INFO - [2020-08-01 15:48:33,130] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:33,132] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:48:33,132] {logging_mixin.py:112} INFO - [2020-08-01 15:48:33,132] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:33,137] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:33,156] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:48:33,163] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:33,164] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 15:48:41,099] {scheduler_job.py:154} INFO - Started process (PID=65545) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:41,125] {logging_mixin.py:112} INFO - [2020-08-01 15:48:41,124] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:41,125] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:48:41,126] {logging_mixin.py:112} INFO - [2020-08-01 15:48:41,126] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:41,129] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:41,143] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:48:41,150] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:41,152] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 15:48:49,124] {scheduler_job.py:154} INFO - Started process (PID=65553) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:49,141] {logging_mixin.py:112} INFO - [2020-08-01 15:48:49,141] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:49,142] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:48:49,142] {logging_mixin.py:112} INFO - [2020-08-01 15:48:49,142] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:49,144] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:49,158] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:48:49,165] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:49,167] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:48:57,071] {scheduler_job.py:154} INFO - Started process (PID=65561) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:57,089] {logging_mixin.py:112} INFO - [2020-08-01 15:48:57,089] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:48:57,090] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:48:57,090] {logging_mixin.py:112} INFO - [2020-08-01 15:48:57,090] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:57,092] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:48:57,106] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:48:57,113] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:48:57,115] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:49:05,099] {scheduler_job.py:154} INFO - Started process (PID=65570) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:05,117] {logging_mixin.py:112} INFO - [2020-08-01 15:49:05,117] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:05,118] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:49:05,118] {logging_mixin.py:112} INFO - [2020-08-01 15:49:05,118] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:05,120] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:05,134] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:49:05,142] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:05,143] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:49:13,137] {scheduler_job.py:154} INFO - Started process (PID=65578) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:13,156] {logging_mixin.py:112} INFO - [2020-08-01 15:49:13,155] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:13,156] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:49:13,156] {logging_mixin.py:112} INFO - [2020-08-01 15:49:13,156] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:13,158] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:13,173] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:49:13,179] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:13,181] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:49:21,210] {scheduler_job.py:154} INFO - Started process (PID=65586) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:21,228] {logging_mixin.py:112} INFO - [2020-08-01 15:49:21,228] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:21,228] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:49:21,228] {logging_mixin.py:112} INFO - [2020-08-01 15:49:21,228] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:21,230] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:21,247] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:49:21,254] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:21,256] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:49:29,198] {scheduler_job.py:154} INFO - Started process (PID=65595) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:29,216] {logging_mixin.py:112} INFO - [2020-08-01 15:49:29,216] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:29,216] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:49:29,217] {logging_mixin.py:112} INFO - [2020-08-01 15:49:29,217] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:29,218] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:29,234] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:49:29,242] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:29,244] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:49:37,245] {scheduler_job.py:154} INFO - Started process (PID=65620) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:37,264] {logging_mixin.py:112} INFO - [2020-08-01 15:49:37,264] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:37,265] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:49:37,265] {logging_mixin.py:112} INFO - [2020-08-01 15:49:37,265] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:37,267] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:37,283] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:49:37,292] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:37,294] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:49:45,319] {scheduler_job.py:154} INFO - Started process (PID=65636) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:45,341] {logging_mixin.py:112} INFO - [2020-08-01 15:49:45,341] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:45,341] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:49:45,342] {logging_mixin.py:112} INFO - [2020-08-01 15:49:45,341] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:45,343] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:45,359] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:49:45,366] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:45,367] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 15:49:53,272] {scheduler_job.py:154} INFO - Started process (PID=65660) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:53,290] {logging_mixin.py:112} INFO - [2020-08-01 15:49:53,290] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:49:53,291] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:49:53,291] {logging_mixin.py:112} INFO - [2020-08-01 15:49:53,291] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:53,293] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:49:53,307] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:49:53,315] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:49:53,316] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:50:01,276] {scheduler_job.py:154} INFO - Started process (PID=65676) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:01,293] {logging_mixin.py:112} INFO - [2020-08-01 15:50:01,293] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:01,294] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:50:01,294] {logging_mixin.py:112} INFO - [2020-08-01 15:50:01,294] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:01,296] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:01,310] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:50:01,318] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:01,320] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:50:09,281] {scheduler_job.py:154} INFO - Started process (PID=65701) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:09,299] {logging_mixin.py:112} INFO - [2020-08-01 15:50:09,298] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:09,299] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:50:09,299] {logging_mixin.py:112} INFO - [2020-08-01 15:50:09,299] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:09,301] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:09,315] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:50:09,322] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:09,324] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:50:17,326] {scheduler_job.py:154} INFO - Started process (PID=65717) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:17,348] {logging_mixin.py:112} INFO - [2020-08-01 15:50:17,348] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:17,349] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:50:17,349] {logging_mixin.py:112} INFO - [2020-08-01 15:50:17,349] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:17,351] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:17,365] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:50:17,373] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:17,375] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 15:50:25,338] {scheduler_job.py:154} INFO - Started process (PID=65741) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:25,357] {logging_mixin.py:112} INFO - [2020-08-01 15:50:25,357] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:25,357] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:50:25,358] {logging_mixin.py:112} INFO - [2020-08-01 15:50:25,358] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:25,359] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:25,374] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:50:25,381] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:25,383] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:50:33,365] {scheduler_job.py:154} INFO - Started process (PID=65765) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:33,383] {logging_mixin.py:112} INFO - [2020-08-01 15:50:33,383] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:33,383] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:50:33,384] {logging_mixin.py:112} INFO - [2020-08-01 15:50:33,384] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:33,385] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:33,400] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:50:33,407] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:33,409] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:50:41,385] {scheduler_job.py:154} INFO - Started process (PID=65782) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:41,403] {logging_mixin.py:112} INFO - [2020-08-01 15:50:41,402] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:41,403] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:50:41,403] {logging_mixin.py:112} INFO - [2020-08-01 15:50:41,403] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:41,405] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:41,419] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:50:41,426] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:41,428] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:50:49,416] {scheduler_job.py:154} INFO - Started process (PID=65806) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:49,434] {logging_mixin.py:112} INFO - [2020-08-01 15:50:49,434] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:49,435] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:50:49,435] {logging_mixin.py:112} INFO - [2020-08-01 15:50:49,435] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:49,437] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:49,451] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:50:49,459] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:49,460] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:50:57,479] {scheduler_job.py:154} INFO - Started process (PID=65822) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:57,498] {logging_mixin.py:112} INFO - [2020-08-01 15:50:57,498] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:50:57,498] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:50:57,498] {logging_mixin.py:112} INFO - [2020-08-01 15:50:57,498] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:57,500] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:50:57,513] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:50:57,520] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:50:57,521] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:51:05,591] {scheduler_job.py:154} INFO - Started process (PID=65846) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:05,608] {logging_mixin.py:112} INFO - [2020-08-01 15:51:05,608] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:05,609] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:51:05,609] {logging_mixin.py:112} INFO - [2020-08-01 15:51:05,609] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:05,611] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:05,625] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:51:05,631] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:05,633] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:51:13,536] {scheduler_job.py:154} INFO - Started process (PID=65870) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:13,555] {logging_mixin.py:112} INFO - [2020-08-01 15:51:13,555] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:13,557] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:51:13,557] {logging_mixin.py:112} INFO - [2020-08-01 15:51:13,557] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:13,560] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:13,575] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:51:13,582] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:13,584] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:51:21,547] {scheduler_job.py:154} INFO - Started process (PID=65887) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:21,565] {logging_mixin.py:112} INFO - [2020-08-01 15:51:21,565] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:21,566] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:51:21,566] {logging_mixin.py:112} INFO - [2020-08-01 15:51:21,566] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:21,567] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:21,582] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:51:21,589] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:21,590] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:51:29,571] {scheduler_job.py:154} INFO - Started process (PID=65911) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:29,589] {logging_mixin.py:112} INFO - [2020-08-01 15:51:29,589] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:29,590] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:51:29,590] {logging_mixin.py:112} INFO - [2020-08-01 15:51:29,590] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:29,592] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:29,607] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:51:29,615] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:29,616] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:51:37,609] {scheduler_job.py:154} INFO - Started process (PID=65928) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:37,626] {logging_mixin.py:112} INFO - [2020-08-01 15:51:37,626] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:37,627] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:51:37,627] {logging_mixin.py:112} INFO - [2020-08-01 15:51:37,627] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:37,629] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:37,643] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:51:37,651] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:37,653] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:51:45,751] {scheduler_job.py:154} INFO - Started process (PID=65944) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:45,770] {logging_mixin.py:112} INFO - [2020-08-01 15:51:45,770] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:45,771] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:51:45,771] {logging_mixin.py:112} INFO - [2020-08-01 15:51:45,771] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:45,773] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:45,787] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:51:45,795] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:45,797] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:51:53,766] {scheduler_job.py:154} INFO - Started process (PID=65952) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:53,785] {logging_mixin.py:112} INFO - [2020-08-01 15:51:53,785] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:51:53,785] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:51:53,786] {logging_mixin.py:112} INFO - [2020-08-01 15:51:53,785] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:53,787] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:51:53,802] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:51:53,809] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:51:53,812] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:52:07,254] {scheduler_job.py:154} INFO - Started process (PID=65967) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:07,271] {logging_mixin.py:112} INFO - [2020-08-01 15:52:07,271] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:07,272] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:52:07,272] {logging_mixin.py:112} INFO - [2020-08-01 15:52:07,272] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:07,274] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:07,288] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:52:07,296] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:07,298] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:52:15,213] {scheduler_job.py:154} INFO - Started process (PID=65976) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:15,231] {logging_mixin.py:112} INFO - [2020-08-01 15:52:15,231] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:15,232] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:52:15,232] {logging_mixin.py:112} INFO - [2020-08-01 15:52:15,232] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:15,234] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:15,248] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:52:15,257] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:15,259] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:52:23,240] {scheduler_job.py:154} INFO - Started process (PID=65984) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:23,259] {logging_mixin.py:112} INFO - [2020-08-01 15:52:23,259] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:23,260] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:52:23,260] {logging_mixin.py:112} INFO - [2020-08-01 15:52:23,260] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:23,262] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:23,277] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:52:23,284] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:23,286] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:52:31,259] {scheduler_job.py:154} INFO - Started process (PID=65992) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:31,277] {logging_mixin.py:112} INFO - [2020-08-01 15:52:31,276] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:31,277] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:52:31,277] {logging_mixin.py:112} INFO - [2020-08-01 15:52:31,277] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:31,279] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:31,293] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:52:31,303] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:31,305] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:52:39,296] {scheduler_job.py:154} INFO - Started process (PID=66001) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:39,314] {logging_mixin.py:112} INFO - [2020-08-01 15:52:39,314] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:39,315] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:52:39,315] {logging_mixin.py:112} INFO - [2020-08-01 15:52:39,315] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:39,317] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:39,331] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:52:39,338] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:39,339] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:52:47,329] {scheduler_job.py:154} INFO - Started process (PID=66009) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:47,346] {logging_mixin.py:112} INFO - [2020-08-01 15:52:47,346] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:47,347] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:52:47,347] {logging_mixin.py:112} INFO - [2020-08-01 15:52:47,347] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:47,349] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:47,363] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:52:47,371] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:47,373] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:52:55,348] {scheduler_job.py:154} INFO - Started process (PID=66017) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:55,365] {logging_mixin.py:112} INFO - [2020-08-01 15:52:55,365] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:52:55,366] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:52:55,366] {logging_mixin.py:112} INFO - [2020-08-01 15:52:55,366] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:55,368] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:52:55,382] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:52:55,390] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:52:55,392] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:53:03,434] {scheduler_job.py:154} INFO - Started process (PID=66025) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:03,452] {logging_mixin.py:112} INFO - [2020-08-01 15:53:03,452] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:03,453] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:53:03,453] {logging_mixin.py:112} INFO - [2020-08-01 15:53:03,453] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:03,455] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:03,470] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:53:03,479] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:03,480] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:53:11,414] {scheduler_job.py:154} INFO - Started process (PID=66050) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:11,431] {logging_mixin.py:112} INFO - [2020-08-01 15:53:11,431] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:11,432] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:53:11,432] {logging_mixin.py:112} INFO - [2020-08-01 15:53:11,432] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:11,434] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:11,448] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:53:11,456] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:11,458] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:53:19,443] {scheduler_job.py:154} INFO - Started process (PID=66067) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:19,461] {logging_mixin.py:112} INFO - [2020-08-01 15:53:19,461] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:19,461] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:53:19,461] {logging_mixin.py:112} INFO - [2020-08-01 15:53:19,461] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:19,463] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:19,477] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:53:19,485] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:19,487] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:53:27,474] {scheduler_job.py:154} INFO - Started process (PID=66091) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:27,491] {logging_mixin.py:112} INFO - [2020-08-01 15:53:27,491] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:27,492] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:53:27,492] {logging_mixin.py:112} INFO - [2020-08-01 15:53:27,492] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:27,494] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:27,508] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:53:27,515] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:27,517] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:53:35,508] {scheduler_job.py:154} INFO - Started process (PID=66107) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:35,526] {logging_mixin.py:112} INFO - [2020-08-01 15:53:35,526] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:35,527] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:53:35,527] {logging_mixin.py:112} INFO - [2020-08-01 15:53:35,527] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:35,529] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:35,543] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:53:35,553] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:35,555] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:53:43,502] {scheduler_job.py:154} INFO - Started process (PID=66132) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:43,520] {logging_mixin.py:112} INFO - [2020-08-01 15:53:43,520] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:43,521] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:53:43,521] {logging_mixin.py:112} INFO - [2020-08-01 15:53:43,521] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:43,523] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:43,537] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:53:43,546] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:43,549] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:53:51,729] {scheduler_job.py:154} INFO - Started process (PID=66159) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:51,747] {logging_mixin.py:112} INFO - [2020-08-01 15:53:51,746] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:51,747] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:53:51,747] {logging_mixin.py:112} INFO - [2020-08-01 15:53:51,747] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:51,749] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:51,763] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:53:51,770] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:51,772] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:53:59,638] {scheduler_job.py:154} INFO - Started process (PID=66210) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:59,655] {logging_mixin.py:112} INFO - [2020-08-01 15:53:59,655] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:53:59,656] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:53:59,656] {logging_mixin.py:112} INFO - [2020-08-01 15:53:59,656] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:59,658] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:53:59,671] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:53:59,677] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:53:59,679] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 15:54:07,686] {scheduler_job.py:154} INFO - Started process (PID=66220) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:07,737] {logging_mixin.py:112} INFO - [2020-08-01 15:54:07,736] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:07,738] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:54:07,739] {logging_mixin.py:112} INFO - [2020-08-01 15:54:07,739] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:07,741] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:07,756] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:54:07,765] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:07,767] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.081 seconds
[2020-08-01 15:54:15,771] {scheduler_job.py:154} INFO - Started process (PID=66296) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:15,790] {logging_mixin.py:112} INFO - [2020-08-01 15:54:15,790] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:15,790] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:54:15,790] {logging_mixin.py:112} INFO - [2020-08-01 15:54:15,790] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:15,792] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:15,805] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:54:15,812] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:15,814] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:54:23,739] {scheduler_job.py:154} INFO - Started process (PID=66306) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:23,757] {logging_mixin.py:112} INFO - [2020-08-01 15:54:23,757] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:23,757] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:54:23,757] {logging_mixin.py:112} INFO - [2020-08-01 15:54:23,757] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:23,759] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:23,774] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:54:23,781] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:23,783] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:54:31,814] {scheduler_job.py:154} INFO - Started process (PID=66314) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:31,874] {logging_mixin.py:112} INFO - [2020-08-01 15:54:31,873] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:31,875] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:54:31,875] {logging_mixin.py:112} INFO - [2020-08-01 15:54:31,875] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:31,880] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:31,905] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:54:31,916] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:31,920] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.107 seconds
[2020-08-01 15:54:39,892] {scheduler_job.py:154} INFO - Started process (PID=66322) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:39,912] {logging_mixin.py:112} INFO - [2020-08-01 15:54:39,912] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:39,913] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:54:39,913] {logging_mixin.py:112} INFO - [2020-08-01 15:54:39,913] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:39,915] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:39,929] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:54:39,937] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:39,939] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:54:47,888] {scheduler_job.py:154} INFO - Started process (PID=66331) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:47,911] {logging_mixin.py:112} INFO - [2020-08-01 15:54:47,911] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:54:47,912] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:54:47,912] {logging_mixin.py:112} INFO - [2020-08-01 15:54:47,912] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:47,916] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:54:47,932] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:54:47,947] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:54:47,950] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.062 seconds
[2020-08-01 15:55:01,163] {scheduler_job.py:154} INFO - Started process (PID=66342) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:01,182] {logging_mixin.py:112} INFO - [2020-08-01 15:55:01,182] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:01,183] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:55:01,183] {logging_mixin.py:112} INFO - [2020-08-01 15:55:01,183] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:01,184] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:01,199] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:55:01,207] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:01,209] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:55:09,165] {scheduler_job.py:154} INFO - Started process (PID=66350) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:09,183] {logging_mixin.py:112} INFO - [2020-08-01 15:55:09,183] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:09,184] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:55:09,184] {logging_mixin.py:112} INFO - [2020-08-01 15:55:09,184] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:09,186] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:09,200] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:55:09,207] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:09,209] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:55:17,207] {scheduler_job.py:154} INFO - Started process (PID=66359) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:17,225] {logging_mixin.py:112} INFO - [2020-08-01 15:55:17,225] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:17,226] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:55:17,226] {logging_mixin.py:112} INFO - [2020-08-01 15:55:17,226] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:17,228] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:17,242] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:55:17,250] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:17,251] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:55:25,221] {scheduler_job.py:154} INFO - Started process (PID=66367) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:25,239] {logging_mixin.py:112} INFO - [2020-08-01 15:55:25,239] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:25,240] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:55:25,240] {logging_mixin.py:112} INFO - [2020-08-01 15:55:25,240] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:25,242] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:25,256] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:55:25,265] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:25,266] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:55:33,257] {scheduler_job.py:154} INFO - Started process (PID=66375) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:33,276] {logging_mixin.py:112} INFO - [2020-08-01 15:55:33,276] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:33,276] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:55:33,277] {logging_mixin.py:112} INFO - [2020-08-01 15:55:33,276] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:33,279] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:33,293] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:55:33,301] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:33,304] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:55:41,357] {scheduler_job.py:154} INFO - Started process (PID=66391) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:41,382] {logging_mixin.py:112} INFO - [2020-08-01 15:55:41,382] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:41,383] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:55:41,383] {logging_mixin.py:112} INFO - [2020-08-01 15:55:41,383] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:41,385] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:41,399] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:55:41,408] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:41,410] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 15:55:49,292] {scheduler_job.py:154} INFO - Started process (PID=66416) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:49,309] {logging_mixin.py:112} INFO - [2020-08-01 15:55:49,309] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:49,310] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:55:49,310] {logging_mixin.py:112} INFO - [2020-08-01 15:55:49,310] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:49,312] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:49,329] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:55:49,339] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:49,341] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 15:55:57,323] {scheduler_job.py:154} INFO - Started process (PID=66440) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:57,342] {logging_mixin.py:112} INFO - [2020-08-01 15:55:57,342] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:55:57,343] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:55:57,343] {logging_mixin.py:112} INFO - [2020-08-01 15:55:57,343] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:57,345] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:55:57,359] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:55:57,368] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:55:57,370] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:56:05,345] {scheduler_job.py:154} INFO - Started process (PID=66456) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:05,363] {logging_mixin.py:112} INFO - [2020-08-01 15:56:05,363] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:05,364] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:56:05,364] {logging_mixin.py:112} INFO - [2020-08-01 15:56:05,364] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:05,366] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:05,381] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:56:05,389] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:05,390] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:56:13,383] {scheduler_job.py:154} INFO - Started process (PID=66481) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:13,400] {logging_mixin.py:112} INFO - [2020-08-01 15:56:13,400] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:13,401] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:56:13,401] {logging_mixin.py:112} INFO - [2020-08-01 15:56:13,401] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:13,403] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:13,417] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:56:13,424] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:13,426] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:56:21,408] {scheduler_job.py:154} INFO - Started process (PID=66497) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:21,427] {logging_mixin.py:112} INFO - [2020-08-01 15:56:21,426] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:21,427] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:56:21,427] {logging_mixin.py:112} INFO - [2020-08-01 15:56:21,427] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:21,429] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:21,444] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:56:21,451] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:21,453] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:56:29,516] {scheduler_job.py:154} INFO - Started process (PID=66521) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:29,534] {logging_mixin.py:112} INFO - [2020-08-01 15:56:29,534] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:29,535] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:56:29,535] {logging_mixin.py:112} INFO - [2020-08-01 15:56:29,535] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:29,537] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:29,552] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:56:29,560] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:29,561] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:56:37,507] {scheduler_job.py:154} INFO - Started process (PID=66537) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:37,527] {logging_mixin.py:112} INFO - [2020-08-01 15:56:37,527] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:37,527] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:56:37,528] {logging_mixin.py:112} INFO - [2020-08-01 15:56:37,528] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:37,529] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:37,543] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:56:37,551] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:37,552] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:56:45,486] {scheduler_job.py:154} INFO - Started process (PID=66563) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:45,503] {logging_mixin.py:112} INFO - [2020-08-01 15:56:45,503] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:45,504] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:56:45,504] {logging_mixin.py:112} INFO - [2020-08-01 15:56:45,504] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:45,506] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:45,520] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:56:45,527] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:45,529] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:56:53,617] {scheduler_job.py:154} INFO - Started process (PID=66621) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:53,634] {logging_mixin.py:112} INFO - [2020-08-01 15:56:53,634] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:56:53,635] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:56:53,635] {logging_mixin.py:112} INFO - [2020-08-01 15:56:53,635] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:53,637] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:56:53,651] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:56:53,657] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:56:53,659] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:57:01,596] {scheduler_job.py:154} INFO - Started process (PID=66672) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:01,614] {logging_mixin.py:112} INFO - [2020-08-01 15:57:01,614] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:01,615] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:57:01,615] {logging_mixin.py:112} INFO - [2020-08-01 15:57:01,615] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:01,616] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:01,631] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:57:01,639] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:01,641] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:57:13,959] {scheduler_job.py:154} INFO - Started process (PID=66691) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:13,978] {logging_mixin.py:112} INFO - [2020-08-01 15:57:13,977] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:13,978] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:57:13,978] {logging_mixin.py:112} INFO - [2020-08-01 15:57:13,978] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:13,980] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:13,996] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:57:14,003] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:14,005] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:57:20,732] {scheduler_job.py:154} INFO - Started process (PID=66709) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:20,751] {logging_mixin.py:112} INFO - [2020-08-01 15:57:20,751] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:20,751] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:57:20,751] {logging_mixin.py:112} INFO - [2020-08-01 15:57:20,751] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:20,753] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:20,767] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:57:20,777] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:20,779] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:57:28,646] {scheduler_job.py:154} INFO - Started process (PID=66717) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:28,664] {logging_mixin.py:112} INFO - [2020-08-01 15:57:28,664] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:28,665] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:57:28,665] {logging_mixin.py:112} INFO - [2020-08-01 15:57:28,665] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:28,667] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:28,681] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:57:28,689] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:28,691] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:57:36,698] {scheduler_job.py:154} INFO - Started process (PID=66725) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:36,716] {logging_mixin.py:112} INFO - [2020-08-01 15:57:36,716] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:36,716] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:57:36,717] {logging_mixin.py:112} INFO - [2020-08-01 15:57:36,717] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:36,718] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:36,733] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:57:36,741] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:36,743] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:57:44,880] {scheduler_job.py:154} INFO - Started process (PID=66741) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:44,900] {logging_mixin.py:112} INFO - [2020-08-01 15:57:44,899] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:44,900] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:57:44,900] {logging_mixin.py:112} INFO - [2020-08-01 15:57:44,900] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:44,902] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:44,916] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:57:44,923] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:44,925] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:57:52,776] {scheduler_job.py:154} INFO - Started process (PID=66766) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:52,793] {logging_mixin.py:112} INFO - [2020-08-01 15:57:52,793] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:57:52,794] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:57:52,794] {logging_mixin.py:112} INFO - [2020-08-01 15:57:52,794] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:52,796] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:57:52,810] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:57:52,817] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:57:52,819] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:58:00,875] {scheduler_job.py:154} INFO - Started process (PID=66783) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:00,894] {logging_mixin.py:112} INFO - [2020-08-01 15:58:00,894] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:00,895] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:58:00,895] {logging_mixin.py:112} INFO - [2020-08-01 15:58:00,895] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:00,897] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:00,911] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:58:00,918] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:00,920] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:58:08,847] {scheduler_job.py:154} INFO - Started process (PID=66807) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:08,867] {logging_mixin.py:112} INFO - [2020-08-01 15:58:08,867] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:08,868] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:58:08,868] {logging_mixin.py:112} INFO - [2020-08-01 15:58:08,868] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:08,870] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:08,884] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:58:08,892] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:08,893] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:58:16,803] {scheduler_job.py:154} INFO - Started process (PID=66833) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:16,821] {logging_mixin.py:112} INFO - [2020-08-01 15:58:16,820] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:16,821] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:58:16,821] {logging_mixin.py:112} INFO - [2020-08-01 15:58:16,821] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:16,823] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:16,838] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:58:16,846] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:16,847] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:58:24,874] {scheduler_job.py:154} INFO - Started process (PID=66900) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:24,892] {logging_mixin.py:112} INFO - [2020-08-01 15:58:24,892] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:24,892] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:58:24,892] {logging_mixin.py:112} INFO - [2020-08-01 15:58:24,892] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:24,894] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:24,908] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:58:24,915] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:24,917] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:58:32,855] {scheduler_job.py:154} INFO - Started process (PID=66936) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:32,873] {logging_mixin.py:112} INFO - [2020-08-01 15:58:32,873] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:32,873] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:58:32,874] {logging_mixin.py:112} INFO - [2020-08-01 15:58:32,873] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:32,875] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:32,890] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:58:32,898] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:32,900] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 15:58:40,997] {scheduler_job.py:154} INFO - Started process (PID=66952) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:41,020] {logging_mixin.py:112} INFO - [2020-08-01 15:58:41,020] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:41,021] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:58:41,021] {logging_mixin.py:112} INFO - [2020-08-01 15:58:41,021] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:41,023] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:41,042] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:58:41,051] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:41,052] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.055 seconds
[2020-08-01 15:58:48,954] {scheduler_job.py:154} INFO - Started process (PID=66961) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:48,971] {logging_mixin.py:112} INFO - [2020-08-01 15:58:48,971] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:48,972] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:58:48,972] {logging_mixin.py:112} INFO - [2020-08-01 15:58:48,972] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:48,974] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:48,988] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:58:48,995] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:48,996] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:58:56,993] {scheduler_job.py:154} INFO - Started process (PID=66977) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:57,011] {logging_mixin.py:112} INFO - [2020-08-01 15:58:57,011] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:58:57,012] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:58:57,012] {logging_mixin.py:112} INFO - [2020-08-01 15:58:57,012] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:57,014] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:58:57,028] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:58:57,037] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:58:57,040] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 15:59:05,041] {scheduler_job.py:154} INFO - Started process (PID=67051) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:05,059] {logging_mixin.py:112} INFO - [2020-08-01 15:59:05,059] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:05,060] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:59:05,060] {logging_mixin.py:112} INFO - [2020-08-01 15:59:05,060] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:05,062] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:05,076] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:59:05,083] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:05,085] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 15:59:13,031] {scheduler_job.py:154} INFO - Started process (PID=67059) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:13,048] {logging_mixin.py:112} INFO - [2020-08-01 15:59:13,048] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:13,049] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:59:13,050] {logging_mixin.py:112} INFO - [2020-08-01 15:59:13,049] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:13,052] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:13,066] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:59:13,074] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:13,075] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:59:21,010] {scheduler_job.py:154} INFO - Started process (PID=67074) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:21,029] {logging_mixin.py:112} INFO - [2020-08-01 15:59:21,028] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:21,029] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:59:21,029] {logging_mixin.py:112} INFO - [2020-08-01 15:59:21,029] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:21,031] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:21,046] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:59:21,054] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:21,056] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:59:29,092] {scheduler_job.py:154} INFO - Started process (PID=67083) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:29,109] {logging_mixin.py:112} INFO - [2020-08-01 15:59:29,109] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:29,110] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:59:29,110] {logging_mixin.py:112} INFO - [2020-08-01 15:59:29,110] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:29,112] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:29,125] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:59:29,133] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:29,134] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 15:59:37,052] {scheduler_job.py:154} INFO - Started process (PID=67091) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:37,071] {logging_mixin.py:112} INFO - [2020-08-01 15:59:37,070] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:37,071] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:59:37,071] {logging_mixin.py:112} INFO - [2020-08-01 15:59:37,071] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:37,073] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:37,087] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:59:37,096] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:37,097] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 15:59:45,092] {scheduler_job.py:154} INFO - Started process (PID=67172) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:45,111] {logging_mixin.py:112} INFO - [2020-08-01 15:59:45,110] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:45,111] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:59:45,111] {logging_mixin.py:112} INFO - [2020-08-01 15:59:45,111] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:45,113] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:45,127] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:59:45,135] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:45,136] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 15:59:53,056] {scheduler_job.py:154} INFO - Started process (PID=67197) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:53,074] {logging_mixin.py:112} INFO - [2020-08-01 15:59:53,074] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 15:59:53,074] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 15:59:53,075] {logging_mixin.py:112} INFO - [2020-08-01 15:59:53,075] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:53,076] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 15:59:53,091] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 15:59:53,098] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 15:59:53,100] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:00:01,127] {scheduler_job.py:154} INFO - Started process (PID=67213) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:01,145] {logging_mixin.py:112} INFO - [2020-08-01 16:00:01,145] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:01,146] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:00:01,146] {logging_mixin.py:112} INFO - [2020-08-01 16:00:01,146] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:01,148] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:01,162] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:00:01,169] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:01,171] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:00:09,126] {scheduler_job.py:154} INFO - Started process (PID=67237) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:09,144] {logging_mixin.py:112} INFO - [2020-08-01 16:00:09,144] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:09,144] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:00:09,145] {logging_mixin.py:112} INFO - [2020-08-01 16:00:09,145] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:09,146] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:09,161] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:00:09,169] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:09,170] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:00:17,233] {scheduler_job.py:154} INFO - Started process (PID=67261) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:17,250] {logging_mixin.py:112} INFO - [2020-08-01 16:00:17,250] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:17,251] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:00:17,251] {logging_mixin.py:112} INFO - [2020-08-01 16:00:17,251] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:17,253] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:17,267] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:00:17,274] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:17,275] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:00:25,186] {scheduler_job.py:154} INFO - Started process (PID=67278) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:25,203] {logging_mixin.py:112} INFO - [2020-08-01 16:00:25,203] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:25,204] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:00:25,204] {logging_mixin.py:112} INFO - [2020-08-01 16:00:25,204] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:25,206] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:25,220] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:00:25,228] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:25,229] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:00:33,209] {scheduler_job.py:154} INFO - Started process (PID=67303) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:33,227] {logging_mixin.py:112} INFO - [2020-08-01 16:00:33,227] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:33,228] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:00:33,228] {logging_mixin.py:112} INFO - [2020-08-01 16:00:33,228] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:33,230] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:33,244] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:00:33,251] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:33,253] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:00:41,298] {scheduler_job.py:154} INFO - Started process (PID=67319) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:41,320] {logging_mixin.py:112} INFO - [2020-08-01 16:00:41,319] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:41,321] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:00:41,321] {logging_mixin.py:112} INFO - [2020-08-01 16:00:41,321] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:41,323] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:41,340] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:00:41,348] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:41,350] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 16:00:49,359] {scheduler_job.py:154} INFO - Started process (PID=67344) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:49,377] {logging_mixin.py:112} INFO - [2020-08-01 16:00:49,377] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:49,378] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:00:49,378] {logging_mixin.py:112} INFO - [2020-08-01 16:00:49,378] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:49,380] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:49,396] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:00:49,404] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:49,406] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:00:57,335] {scheduler_job.py:154} INFO - Started process (PID=67396) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:57,353] {logging_mixin.py:112} INFO - [2020-08-01 16:00:57,352] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:00:57,353] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:00:57,353] {logging_mixin.py:112} INFO - [2020-08-01 16:00:57,353] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:57,355] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:00:57,371] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:00:57,378] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:00:57,381] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:01:05,340] {scheduler_job.py:154} INFO - Started process (PID=67421) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:05,370] {logging_mixin.py:112} INFO - [2020-08-01 16:01:05,370] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:05,371] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:01:05,371] {logging_mixin.py:112} INFO - [2020-08-01 16:01:05,371] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:05,373] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:05,390] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:01:05,400] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:05,403] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.063 seconds
[2020-08-01 16:01:13,330] {scheduler_job.py:154} INFO - Started process (PID=67462) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:13,348] {logging_mixin.py:112} INFO - [2020-08-01 16:01:13,348] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:13,349] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:01:13,349] {logging_mixin.py:112} INFO - [2020-08-01 16:01:13,349] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:13,351] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:13,365] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:01:13,372] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:13,374] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:01:21,347] {scheduler_job.py:154} INFO - Started process (PID=67481) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:21,365] {logging_mixin.py:112} INFO - [2020-08-01 16:01:21,365] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:21,366] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:01:21,366] {logging_mixin.py:112} INFO - [2020-08-01 16:01:21,366] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:21,368] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:21,382] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:01:21,389] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:21,390] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:01:29,364] {scheduler_job.py:154} INFO - Started process (PID=67505) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:29,382] {logging_mixin.py:112} INFO - [2020-08-01 16:01:29,382] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:29,383] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:01:29,383] {logging_mixin.py:112} INFO - [2020-08-01 16:01:29,383] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:29,385] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:29,399] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:01:29,407] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:29,409] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:01:37,392] {scheduler_job.py:154} INFO - Started process (PID=67522) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:37,410] {logging_mixin.py:112} INFO - [2020-08-01 16:01:37,410] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:37,411] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:01:37,411] {logging_mixin.py:112} INFO - [2020-08-01 16:01:37,411] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:37,413] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:37,427] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:01:37,433] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:37,435] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:01:45,435] {scheduler_job.py:154} INFO - Started process (PID=67546) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:45,453] {logging_mixin.py:112} INFO - [2020-08-01 16:01:45,452] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:45,453] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:01:45,453] {logging_mixin.py:112} INFO - [2020-08-01 16:01:45,453] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:45,455] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:45,470] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:01:45,478] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:45,479] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:01:53,459] {scheduler_job.py:154} INFO - Started process (PID=67564) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:53,477] {logging_mixin.py:112} INFO - [2020-08-01 16:01:53,477] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:01:53,477] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:01:53,477] {logging_mixin.py:112} INFO - [2020-08-01 16:01:53,477] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:53,479] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:01:53,494] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:01:53,503] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:01:53,506] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:02:01,453] {scheduler_job.py:154} INFO - Started process (PID=67588) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:01,471] {logging_mixin.py:112} INFO - [2020-08-01 16:02:01,471] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:01,471] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:02:01,472] {logging_mixin.py:112} INFO - [2020-08-01 16:02:01,472] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:01,473] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:01,488] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:02:01,494] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:01,496] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:02:09,486] {scheduler_job.py:154} INFO - Started process (PID=67612) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:09,504] {logging_mixin.py:112} INFO - [2020-08-01 16:02:09,504] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:09,504] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:02:09,505] {logging_mixin.py:112} INFO - [2020-08-01 16:02:09,504] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:09,506] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:09,521] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:02:09,529] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:09,531] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:02:17,492] {scheduler_job.py:154} INFO - Started process (PID=67629) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:17,510] {logging_mixin.py:112} INFO - [2020-08-01 16:02:17,510] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:17,511] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:02:17,511] {logging_mixin.py:112} INFO - [2020-08-01 16:02:17,511] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:17,513] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:17,527] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:02:17,534] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:17,535] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:02:25,524] {scheduler_job.py:154} INFO - Started process (PID=67654) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:25,542] {logging_mixin.py:112} INFO - [2020-08-01 16:02:25,541] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:25,542] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:02:25,542] {logging_mixin.py:112} INFO - [2020-08-01 16:02:25,542] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:25,544] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:25,558] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:02:25,566] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:25,567] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:02:33,554] {scheduler_job.py:154} INFO - Started process (PID=67671) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:33,571] {logging_mixin.py:112} INFO - [2020-08-01 16:02:33,571] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:33,572] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:02:33,572] {logging_mixin.py:112} INFO - [2020-08-01 16:02:33,572] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:33,574] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:33,588] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:02:33,596] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:33,597] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:02:41,644] {scheduler_job.py:154} INFO - Started process (PID=67695) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:41,662] {logging_mixin.py:112} INFO - [2020-08-01 16:02:41,662] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:41,663] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:02:41,663] {logging_mixin.py:112} INFO - [2020-08-01 16:02:41,663] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:41,665] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:41,678] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:02:41,685] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:41,687] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:02:49,673] {scheduler_job.py:154} INFO - Started process (PID=67712) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:49,690] {logging_mixin.py:112} INFO - [2020-08-01 16:02:49,690] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:49,690] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:02:49,691] {logging_mixin.py:112} INFO - [2020-08-01 16:02:49,690] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:49,692] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:49,705] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:02:49,713] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:49,716] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:02:57,690] {scheduler_job.py:154} INFO - Started process (PID=67721) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:57,707] {logging_mixin.py:112} INFO - [2020-08-01 16:02:57,707] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:02:57,707] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:02:57,708] {logging_mixin.py:112} INFO - [2020-08-01 16:02:57,708] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:57,709] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:02:57,722] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:02:57,729] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:02:57,730] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:03:05,708] {scheduler_job.py:154} INFO - Started process (PID=67730) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:05,726] {logging_mixin.py:112} INFO - [2020-08-01 16:03:05,726] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:05,726] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:03:05,726] {logging_mixin.py:112} INFO - [2020-08-01 16:03:05,726] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:05,728] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:05,741] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:03:05,749] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:05,751] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:03:13,733] {scheduler_job.py:154} INFO - Started process (PID=67738) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:13,751] {logging_mixin.py:112} INFO - [2020-08-01 16:03:13,751] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:13,751] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:03:13,751] {logging_mixin.py:112} INFO - [2020-08-01 16:03:13,751] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:13,753] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:13,767] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:03:13,774] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:13,776] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:03:21,867] {scheduler_job.py:154} INFO - Started process (PID=67758) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:21,892] {logging_mixin.py:112} INFO - [2020-08-01 16:03:21,892] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:21,893] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:03:21,894] {logging_mixin.py:112} INFO - [2020-08-01 16:03:21,894] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:21,896] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:21,913] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:03:21,922] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:21,924] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.057 seconds
[2020-08-01 16:03:29,714] {scheduler_job.py:154} INFO - Started process (PID=67768) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:29,732] {logging_mixin.py:112} INFO - [2020-08-01 16:03:29,731] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:29,732] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:03:29,732] {logging_mixin.py:112} INFO - [2020-08-01 16:03:29,732] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:29,734] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:29,749] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:03:29,756] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:29,757] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:03:37,745] {scheduler_job.py:154} INFO - Started process (PID=67776) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:37,763] {logging_mixin.py:112} INFO - [2020-08-01 16:03:37,762] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:37,763] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:03:37,763] {logging_mixin.py:112} INFO - [2020-08-01 16:03:37,763] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:37,765] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:37,780] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:03:37,786] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:37,788] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:03:45,775] {scheduler_job.py:154} INFO - Started process (PID=67784) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:45,793] {logging_mixin.py:112} INFO - [2020-08-01 16:03:45,793] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:45,793] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:03:45,794] {logging_mixin.py:112} INFO - [2020-08-01 16:03:45,794] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:45,795] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:45,810] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:03:45,818] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:45,820] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:03:53,804] {scheduler_job.py:154} INFO - Started process (PID=67793) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:53,821] {logging_mixin.py:112} INFO - [2020-08-01 16:03:53,820] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:03:53,821] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:03:53,821] {logging_mixin.py:112} INFO - [2020-08-01 16:03:53,821] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:53,823] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:03:53,837] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:03:53,844] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:03:53,845] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:04:01,826] {scheduler_job.py:154} INFO - Started process (PID=67801) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:01,843] {logging_mixin.py:112} INFO - [2020-08-01 16:04:01,843] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:01,844] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:04:01,844] {logging_mixin.py:112} INFO - [2020-08-01 16:04:01,844] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:01,846] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:01,860] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:04:01,866] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:01,868] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:04:09,870] {scheduler_job.py:154} INFO - Started process (PID=67809) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:09,887] {logging_mixin.py:112} INFO - [2020-08-01 16:04:09,887] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:09,888] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:04:09,888] {logging_mixin.py:112} INFO - [2020-08-01 16:04:09,888] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:09,890] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:09,905] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:04:09,912] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:09,914] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:04:17,988] {scheduler_job.py:154} INFO - Started process (PID=67817) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:18,006] {logging_mixin.py:112} INFO - [2020-08-01 16:04:18,006] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:18,007] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:04:18,007] {logging_mixin.py:112} INFO - [2020-08-01 16:04:18,007] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:18,008] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:18,023] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:04:18,030] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:18,032] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:04:25,940] {scheduler_job.py:154} INFO - Started process (PID=67827) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:25,958] {logging_mixin.py:112} INFO - [2020-08-01 16:04:25,958] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:25,958] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:04:25,959] {logging_mixin.py:112} INFO - [2020-08-01 16:04:25,958] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:25,960] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:25,975] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:04:25,983] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:25,985] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:04:33,941] {scheduler_job.py:154} INFO - Started process (PID=67835) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:33,959] {logging_mixin.py:112} INFO - [2020-08-01 16:04:33,958] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:33,959] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:04:33,959] {logging_mixin.py:112} INFO - [2020-08-01 16:04:33,959] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:33,961] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:33,976] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:04:33,983] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:33,985] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:04:41,958] {scheduler_job.py:154} INFO - Started process (PID=67843) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:41,975] {logging_mixin.py:112} INFO - [2020-08-01 16:04:41,975] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:41,976] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:04:41,976] {logging_mixin.py:112} INFO - [2020-08-01 16:04:41,976] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:41,978] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:41,992] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:04:41,999] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:42,001] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:04:49,996] {scheduler_job.py:154} INFO - Started process (PID=67851) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:50,013] {logging_mixin.py:112} INFO - [2020-08-01 16:04:50,013] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:50,014] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:04:50,014] {logging_mixin.py:112} INFO - [2020-08-01 16:04:50,014] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:50,016] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:50,030] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:04:50,037] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:50,039] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:04:58,050] {scheduler_job.py:154} INFO - Started process (PID=67860) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:58,067] {logging_mixin.py:112} INFO - [2020-08-01 16:04:58,067] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:04:58,068] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:04:58,068] {logging_mixin.py:112} INFO - [2020-08-01 16:04:58,068] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:58,070] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:04:58,084] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:04:58,091] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:04:58,092] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:05:06,065] {scheduler_job.py:154} INFO - Started process (PID=67868) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:06,083] {logging_mixin.py:112} INFO - [2020-08-01 16:05:06,083] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:06,083] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:05:06,084] {logging_mixin.py:112} INFO - [2020-08-01 16:05:06,084] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:06,085] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:06,100] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:05:06,108] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:06,109] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:05:14,095] {scheduler_job.py:154} INFO - Started process (PID=67876) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:14,112] {logging_mixin.py:112} INFO - [2020-08-01 16:05:14,112] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:14,113] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:05:14,113] {logging_mixin.py:112} INFO - [2020-08-01 16:05:14,113] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:14,115] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:14,129] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:05:14,136] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:14,138] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:05:22,130] {scheduler_job.py:154} INFO - Started process (PID=67884) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:22,148] {logging_mixin.py:112} INFO - [2020-08-01 16:05:22,148] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:22,149] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:05:22,149] {logging_mixin.py:112} INFO - [2020-08-01 16:05:22,149] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:22,151] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:22,165] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:05:22,173] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:22,175] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:05:30,155] {scheduler_job.py:154} INFO - Started process (PID=67893) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:30,172] {logging_mixin.py:112} INFO - [2020-08-01 16:05:30,172] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:30,173] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:05:30,173] {logging_mixin.py:112} INFO - [2020-08-01 16:05:30,173] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:30,175] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:30,189] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:05:30,197] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:30,198] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:05:38,188] {scheduler_job.py:154} INFO - Started process (PID=67901) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:38,205] {logging_mixin.py:112} INFO - [2020-08-01 16:05:38,205] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:38,206] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:05:38,206] {logging_mixin.py:112} INFO - [2020-08-01 16:05:38,206] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:38,208] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:38,222] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:05:38,229] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:38,231] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:05:46,227] {scheduler_job.py:154} INFO - Started process (PID=67909) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:46,245] {logging_mixin.py:112} INFO - [2020-08-01 16:05:46,244] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:46,245] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:05:46,245] {logging_mixin.py:112} INFO - [2020-08-01 16:05:46,245] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:46,247] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:46,261] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:05:46,269] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:46,271] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:05:54,264] {scheduler_job.py:154} INFO - Started process (PID=67917) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:54,282] {logging_mixin.py:112} INFO - [2020-08-01 16:05:54,282] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:05:54,283] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:05:54,283] {logging_mixin.py:112} INFO - [2020-08-01 16:05:54,283] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:54,285] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:05:54,299] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:05:54,307] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:05:54,309] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:06:02,309] {scheduler_job.py:154} INFO - Started process (PID=67937) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:02,328] {logging_mixin.py:112} INFO - [2020-08-01 16:06:02,328] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:02,329] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:06:02,329] {logging_mixin.py:112} INFO - [2020-08-01 16:06:02,329] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:02,331] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:02,344] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:06:02,350] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:02,352] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:06:10,394] {scheduler_job.py:154} INFO - Started process (PID=67961) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:10,419] {logging_mixin.py:112} INFO - [2020-08-01 16:06:10,419] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:10,420] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:06:10,420] {logging_mixin.py:112} INFO - [2020-08-01 16:06:10,420] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:10,425] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:10,443] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:06:10,452] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:10,454] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.060 seconds
[2020-08-01 16:06:18,415] {scheduler_job.py:154} INFO - Started process (PID=67978) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:18,434] {logging_mixin.py:112} INFO - [2020-08-01 16:06:18,434] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:18,435] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:06:18,435] {logging_mixin.py:112} INFO - [2020-08-01 16:06:18,435] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:18,437] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:18,450] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:06:18,457] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:18,459] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:06:26,506] {scheduler_job.py:154} INFO - Started process (PID=68002) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:26,523] {logging_mixin.py:112} INFO - [2020-08-01 16:06:26,523] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:26,524] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:06:26,524] {logging_mixin.py:112} INFO - [2020-08-01 16:06:26,524] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:26,525] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:26,538] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:06:26,545] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:26,546] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 16:06:34,498] {scheduler_job.py:154} INFO - Started process (PID=68020) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:34,516] {logging_mixin.py:112} INFO - [2020-08-01 16:06:34,516] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:34,517] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:06:34,517] {logging_mixin.py:112} INFO - [2020-08-01 16:06:34,517] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:34,519] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:34,534] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:06:34,540] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:34,542] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:06:42,533] {scheduler_job.py:154} INFO - Started process (PID=68044) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:42,551] {logging_mixin.py:112} INFO - [2020-08-01 16:06:42,551] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:42,551] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:06:42,551] {logging_mixin.py:112} INFO - [2020-08-01 16:06:42,551] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:42,553] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:42,567] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:06:42,579] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:42,581] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:06:50,500] {scheduler_job.py:154} INFO - Started process (PID=68069) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:50,519] {logging_mixin.py:112} INFO - [2020-08-01 16:06:50,519] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:50,519] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:06:50,519] {logging_mixin.py:112} INFO - [2020-08-01 16:06:50,519] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:50,521] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:50,537] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:06:50,544] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:50,546] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:06:58,562] {scheduler_job.py:154} INFO - Started process (PID=68087) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:58,582] {logging_mixin.py:112} INFO - [2020-08-01 16:06:58,582] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:06:58,583] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:06:58,583] {logging_mixin.py:112} INFO - [2020-08-01 16:06:58,583] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:58,585] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:06:58,599] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:06:58,608] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:06:58,611] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 16:07:06,648] {scheduler_job.py:154} INFO - Started process (PID=68112) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:06,674] {logging_mixin.py:112} INFO - [2020-08-01 16:07:06,674] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:06,675] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:07:06,675] {logging_mixin.py:112} INFO - [2020-08-01 16:07:06,675] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:06,677] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:06,689] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:07:06,697] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:06,699] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 16:07:14,659] {scheduler_job.py:154} INFO - Started process (PID=68128) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:14,676] {logging_mixin.py:112} INFO - [2020-08-01 16:07:14,676] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:14,677] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:07:14,677] {logging_mixin.py:112} INFO - [2020-08-01 16:07:14,677] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:14,679] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:14,692] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:07:14,699] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:14,701] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:07:22,640] {scheduler_job.py:154} INFO - Started process (PID=68153) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:22,661] {logging_mixin.py:112} INFO - [2020-08-01 16:07:22,660] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:22,661] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:07:22,661] {logging_mixin.py:112} INFO - [2020-08-01 16:07:22,661] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:22,663] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:22,677] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:07:22,684] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:22,686] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:07:30,575] {scheduler_job.py:154} INFO - Started process (PID=68171) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:30,594] {logging_mixin.py:112} INFO - [2020-08-01 16:07:30,594] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:30,594] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:07:30,595] {logging_mixin.py:112} INFO - [2020-08-01 16:07:30,595] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:30,596] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:30,613] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:07:30,621] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:30,622] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:07:38,582] {scheduler_job.py:154} INFO - Started process (PID=68195) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:38,599] {logging_mixin.py:112} INFO - [2020-08-01 16:07:38,599] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:38,600] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:07:38,600] {logging_mixin.py:112} INFO - [2020-08-01 16:07:38,600] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:38,602] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:38,615] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:07:38,621] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:38,623] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:07:46,652] {scheduler_job.py:154} INFO - Started process (PID=68212) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:46,669] {logging_mixin.py:112} INFO - [2020-08-01 16:07:46,669] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:46,669] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:07:46,670] {logging_mixin.py:112} INFO - [2020-08-01 16:07:46,669] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:46,672] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:46,686] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:07:46,693] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:46,694] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:07:54,637] {scheduler_job.py:154} INFO - Started process (PID=68236) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:54,655] {logging_mixin.py:112} INFO - [2020-08-01 16:07:54,655] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:07:54,655] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:07:54,656] {logging_mixin.py:112} INFO - [2020-08-01 16:07:54,655] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:54,657] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:07:54,672] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:07:54,680] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:07:54,681] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:08:02,676] {scheduler_job.py:154} INFO - Started process (PID=68262) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:02,694] {logging_mixin.py:112} INFO - [2020-08-01 16:08:02,693] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:02,694] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:08:02,694] {logging_mixin.py:112} INFO - [2020-08-01 16:08:02,694] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:02,696] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:02,709] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:08:02,716] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:02,717] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:08:10,748] {scheduler_job.py:154} INFO - Started process (PID=68278) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:10,768] {logging_mixin.py:112} INFO - [2020-08-01 16:08:10,768] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:10,769] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:08:10,769] {logging_mixin.py:112} INFO - [2020-08-01 16:08:10,769] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:10,771] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:10,787] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:08:10,795] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:10,797] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 16:08:18,754] {scheduler_job.py:154} INFO - Started process (PID=68303) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:18,771] {logging_mixin.py:112} INFO - [2020-08-01 16:08:18,771] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:18,772] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:08:18,772] {logging_mixin.py:112} INFO - [2020-08-01 16:08:18,772] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:18,774] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:18,788] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:08:18,795] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:18,797] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:08:26,789] {scheduler_job.py:154} INFO - Started process (PID=68319) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:26,812] {logging_mixin.py:112} INFO - [2020-08-01 16:08:26,812] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:26,813] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:08:26,813] {logging_mixin.py:112} INFO - [2020-08-01 16:08:26,813] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:26,816] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:26,833] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:08:26,842] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:26,843] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.055 seconds
[2020-08-01 16:08:34,757] {scheduler_job.py:154} INFO - Started process (PID=68345) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:34,776] {logging_mixin.py:112} INFO - [2020-08-01 16:08:34,776] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:34,777] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:08:34,777] {logging_mixin.py:112} INFO - [2020-08-01 16:08:34,777] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:34,778] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:34,794] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:08:34,801] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:34,802] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:08:42,860] {scheduler_job.py:154} INFO - Started process (PID=68362) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:42,884] {logging_mixin.py:112} INFO - [2020-08-01 16:08:42,884] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:42,885] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:08:42,885] {logging_mixin.py:112} INFO - [2020-08-01 16:08:42,885] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:42,887] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:42,902] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:08:42,908] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:42,910] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 16:08:50,828] {scheduler_job.py:154} INFO - Started process (PID=68387) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:50,846] {logging_mixin.py:112} INFO - [2020-08-01 16:08:50,845] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:50,846] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:08:50,846] {logging_mixin.py:112} INFO - [2020-08-01 16:08:50,846] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:50,848] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:50,863] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:08:50,871] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:50,872] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:08:58,832] {scheduler_job.py:154} INFO - Started process (PID=68411) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:58,849] {logging_mixin.py:112} INFO - [2020-08-01 16:08:58,849] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:08:58,850] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:08:58,850] {logging_mixin.py:112} INFO - [2020-08-01 16:08:58,850] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:58,852] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:08:58,866] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:08:58,873] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:08:58,875] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:09:06,847] {scheduler_job.py:154} INFO - Started process (PID=68429) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:06,865] {logging_mixin.py:112} INFO - [2020-08-01 16:09:06,865] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:06,866] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:09:06,866] {logging_mixin.py:112} INFO - [2020-08-01 16:09:06,866] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:06,867] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:06,882] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:09:06,889] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:06,890] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:09:14,956] {scheduler_job.py:154} INFO - Started process (PID=68453) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:14,975] {logging_mixin.py:112} INFO - [2020-08-01 16:09:14,974] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:14,975] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:09:14,975] {logging_mixin.py:112} INFO - [2020-08-01 16:09:14,975] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:14,977] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:14,991] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:09:14,998] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:15,000] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:09:22,925] {scheduler_job.py:154} INFO - Started process (PID=68470) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:22,943] {logging_mixin.py:112} INFO - [2020-08-01 16:09:22,942] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:22,943] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:09:22,943] {logging_mixin.py:112} INFO - [2020-08-01 16:09:22,943] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:22,945] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:22,959] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:09:22,968] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:22,970] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:09:31,041] {scheduler_job.py:154} INFO - Started process (PID=68496) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:31,060] {logging_mixin.py:112} INFO - [2020-08-01 16:09:31,059] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:31,060] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:09:31,060] {logging_mixin.py:112} INFO - [2020-08-01 16:09:31,060] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:31,062] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:31,076] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:09:31,085] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:31,087] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:09:38,972] {scheduler_job.py:154} INFO - Started process (PID=68512) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:38,989] {logging_mixin.py:112} INFO - [2020-08-01 16:09:38,989] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:38,990] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:09:38,990] {logging_mixin.py:112} INFO - [2020-08-01 16:09:38,990] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:38,992] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:39,006] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:09:39,013] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:39,014] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:09:46,997] {scheduler_job.py:154} INFO - Started process (PID=68639) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:47,015] {logging_mixin.py:112} INFO - [2020-08-01 16:09:47,014] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:47,015] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:09:47,015] {logging_mixin.py:112} INFO - [2020-08-01 16:09:47,015] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:47,017] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:47,032] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:09:47,039] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:47,041] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:09:55,005] {scheduler_job.py:154} INFO - Started process (PID=68680) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:55,023] {logging_mixin.py:112} INFO - [2020-08-01 16:09:55,022] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:09:55,023] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:09:55,023] {logging_mixin.py:112} INFO - [2020-08-01 16:09:55,023] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:55,025] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:09:55,040] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:09:55,048] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:09:55,050] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:10:02,993] {scheduler_job.py:154} INFO - Started process (PID=68698) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:03,010] {logging_mixin.py:112} INFO - [2020-08-01 16:10:03,010] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:03,011] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:10:03,011] {logging_mixin.py:112} INFO - [2020-08-01 16:10:03,011] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:03,013] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:03,027] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:10:03,034] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:03,035] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:10:11,030] {scheduler_job.py:154} INFO - Started process (PID=68722) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:11,047] {logging_mixin.py:112} INFO - [2020-08-01 16:10:11,047] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:11,048] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:10:11,048] {logging_mixin.py:112} INFO - [2020-08-01 16:10:11,048] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:11,050] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:11,064] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:10:11,072] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:11,073] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:10:19,096] {scheduler_job.py:154} INFO - Started process (PID=68738) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:19,113] {logging_mixin.py:112} INFO - [2020-08-01 16:10:19,113] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:19,113] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:10:19,114] {logging_mixin.py:112} INFO - [2020-08-01 16:10:19,114] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:19,115] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:19,129] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:10:19,136] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:19,138] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:10:27,127] {scheduler_job.py:154} INFO - Started process (PID=68762) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:27,146] {logging_mixin.py:112} INFO - [2020-08-01 16:10:27,146] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:27,147] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:10:27,147] {logging_mixin.py:112} INFO - [2020-08-01 16:10:27,147] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:27,149] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:27,163] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:10:27,172] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:27,174] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:10:35,224] {scheduler_job.py:154} INFO - Started process (PID=68817) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:35,242] {logging_mixin.py:112} INFO - [2020-08-01 16:10:35,242] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:35,242] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:10:35,242] {logging_mixin.py:112} INFO - [2020-08-01 16:10:35,242] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:35,244] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:35,257] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:10:35,263] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:35,265] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.040 seconds
[2020-08-01 16:10:43,153] {scheduler_job.py:154} INFO - Started process (PID=68832) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:43,171] {logging_mixin.py:112} INFO - [2020-08-01 16:10:43,171] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:43,171] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:10:43,172] {logging_mixin.py:112} INFO - [2020-08-01 16:10:43,172] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:43,174] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:43,187] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:10:43,195] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:43,197] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:10:51,161] {scheduler_job.py:154} INFO - Started process (PID=68841) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:51,178] {logging_mixin.py:112} INFO - [2020-08-01 16:10:51,178] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:51,179] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:10:51,179] {logging_mixin.py:112} INFO - [2020-08-01 16:10:51,179] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:51,181] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:51,195] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:10:51,201] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:51,203] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:10:59,247] {scheduler_job.py:154} INFO - Started process (PID=68858) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:59,265] {logging_mixin.py:112} INFO - [2020-08-01 16:10:59,264] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:10:59,265] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:10:59,265] {logging_mixin.py:112} INFO - [2020-08-01 16:10:59,265] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:59,267] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:10:59,281] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:10:59,288] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:10:59,290] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:11:07,232] {scheduler_job.py:154} INFO - Started process (PID=68884) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:07,250] {logging_mixin.py:112} INFO - [2020-08-01 16:11:07,250] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:07,250] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:11:07,251] {logging_mixin.py:112} INFO - [2020-08-01 16:11:07,251] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:07,252] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:07,267] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:11:07,275] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:07,276] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:11:15,309] {scheduler_job.py:154} INFO - Started process (PID=69003) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:15,326] {logging_mixin.py:112} INFO - [2020-08-01 16:11:15,326] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:15,327] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:11:15,327] {logging_mixin.py:112} INFO - [2020-08-01 16:11:15,327] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:15,329] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:15,343] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:11:15,350] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:15,352] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:11:23,296] {scheduler_job.py:154} INFO - Started process (PID=69021) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:23,314] {logging_mixin.py:112} INFO - [2020-08-01 16:11:23,314] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:23,314] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:11:23,314] {logging_mixin.py:112} INFO - [2020-08-01 16:11:23,314] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:23,316] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:23,330] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:11:23,342] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:23,343] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:11:31,282] {scheduler_job.py:154} INFO - Started process (PID=69029) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:31,300] {logging_mixin.py:112} INFO - [2020-08-01 16:11:31,300] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:31,301] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:11:31,301] {logging_mixin.py:112} INFO - [2020-08-01 16:11:31,301] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:31,303] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:31,317] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:11:31,324] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:31,326] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:11:39,363] {scheduler_job.py:154} INFO - Started process (PID=69046) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:39,389] {logging_mixin.py:112} INFO - [2020-08-01 16:11:39,389] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:39,390] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:11:39,390] {logging_mixin.py:112} INFO - [2020-08-01 16:11:39,390] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:39,393] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:39,409] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:11:39,416] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:39,417] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.054 seconds
[2020-08-01 16:11:47,335] {scheduler_job.py:154} INFO - Started process (PID=69057) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:47,357] {logging_mixin.py:112} INFO - [2020-08-01 16:11:47,357] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:47,358] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:11:47,358] {logging_mixin.py:112} INFO - [2020-08-01 16:11:47,358] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:47,360] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:47,376] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:11:47,383] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:47,384] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 16:11:55,293] {scheduler_job.py:154} INFO - Started process (PID=69065) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:55,311] {logging_mixin.py:112} INFO - [2020-08-01 16:11:55,311] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:11:55,312] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:11:55,312] {logging_mixin.py:112} INFO - [2020-08-01 16:11:55,312] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:55,314] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:11:55,328] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:11:55,335] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:11:55,337] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:12:03,473] {scheduler_job.py:154} INFO - Started process (PID=69081) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:03,491] {logging_mixin.py:112} INFO - [2020-08-01 16:12:03,491] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:03,491] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:12:03,491] {logging_mixin.py:112} INFO - [2020-08-01 16:12:03,491] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:03,493] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:03,506] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:12:03,514] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:03,515] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:12:11,348] {scheduler_job.py:154} INFO - Started process (PID=69090) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:11,365] {logging_mixin.py:112} INFO - [2020-08-01 16:12:11,365] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:11,366] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:12:11,366] {logging_mixin.py:112} INFO - [2020-08-01 16:12:11,366] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:11,368] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:11,382] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:12:11,390] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:11,392] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:12:19,517] {scheduler_job.py:154} INFO - Started process (PID=69107) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:19,534] {logging_mixin.py:112} INFO - [2020-08-01 16:12:19,534] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:19,535] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:12:19,535] {logging_mixin.py:112} INFO - [2020-08-01 16:12:19,535] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:19,537] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:19,555] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:12:19,562] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:19,564] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:12:27,408] {scheduler_job.py:154} INFO - Started process (PID=69115) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:27,426] {logging_mixin.py:112} INFO - [2020-08-01 16:12:27,426] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:27,427] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:12:27,427] {logging_mixin.py:112} INFO - [2020-08-01 16:12:27,427] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:27,428] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:27,443] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:12:27,450] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:27,451] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:12:35,482] {scheduler_job.py:154} INFO - Started process (PID=69124) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:35,499] {logging_mixin.py:112} INFO - [2020-08-01 16:12:35,499] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:35,500] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:12:35,500] {logging_mixin.py:112} INFO - [2020-08-01 16:12:35,500] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:35,502] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:35,516] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:12:35,524] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:35,526] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:12:43,569] {scheduler_job.py:154} INFO - Started process (PID=69148) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:43,586] {logging_mixin.py:112} INFO - [2020-08-01 16:12:43,586] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:43,586] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:12:43,587] {logging_mixin.py:112} INFO - [2020-08-01 16:12:43,587] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:43,588] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:43,603] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:12:43,612] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:43,614] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:12:51,501] {scheduler_job.py:154} INFO - Started process (PID=69218) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:51,518] {logging_mixin.py:112} INFO - [2020-08-01 16:12:51,518] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:51,519] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:12:51,519] {logging_mixin.py:112} INFO - [2020-08-01 16:12:51,519] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:51,520] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:51,533] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:12:51,540] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:51,542] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:12:59,535] {scheduler_job.py:154} INFO - Started process (PID=69228) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:59,552] {logging_mixin.py:112} INFO - [2020-08-01 16:12:59,552] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:12:59,553] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:12:59,553] {logging_mixin.py:112} INFO - [2020-08-01 16:12:59,553] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:59,555] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:12:59,567] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:12:59,575] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:12:59,577] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:13:07,679] {scheduler_job.py:154} INFO - Started process (PID=69240) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:07,698] {logging_mixin.py:112} INFO - [2020-08-01 16:13:07,697] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:07,698] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:13:07,698] {logging_mixin.py:112} INFO - [2020-08-01 16:13:07,698] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:07,700] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:07,716] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:13:07,723] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:07,724] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:13:15,545] {scheduler_job.py:154} INFO - Started process (PID=69265) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:15,563] {logging_mixin.py:112} INFO - [2020-08-01 16:13:15,563] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:15,563] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:13:15,563] {logging_mixin.py:112} INFO - [2020-08-01 16:13:15,563] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:15,565] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:15,579] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:13:15,586] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:15,588] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:13:23,626] {scheduler_job.py:154} INFO - Started process (PID=69281) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:23,644] {logging_mixin.py:112} INFO - [2020-08-01 16:13:23,644] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:23,644] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:13:23,645] {logging_mixin.py:112} INFO - [2020-08-01 16:13:23,645] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:23,646] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:23,663] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:13:23,671] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:23,674] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:13:31,649] {scheduler_job.py:154} INFO - Started process (PID=69306) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:31,671] {logging_mixin.py:112} INFO - [2020-08-01 16:13:31,670] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:31,672] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:13:31,672] {logging_mixin.py:112} INFO - [2020-08-01 16:13:31,672] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:31,674] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:31,687] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:13:31,693] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:31,695] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:13:39,671] {scheduler_job.py:154} INFO - Started process (PID=69331) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:39,689] {logging_mixin.py:112} INFO - [2020-08-01 16:13:39,689] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:39,689] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:13:39,690] {logging_mixin.py:112} INFO - [2020-08-01 16:13:39,690] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:39,691] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:39,705] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:13:39,711] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:39,713] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:13:47,713] {scheduler_job.py:154} INFO - Started process (PID=69348) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:47,739] {logging_mixin.py:112} INFO - [2020-08-01 16:13:47,739] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:47,740] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:13:47,740] {logging_mixin.py:112} INFO - [2020-08-01 16:13:47,740] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:47,742] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:47,756] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:13:47,763] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:47,765] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 16:13:55,662] {scheduler_job.py:154} INFO - Started process (PID=69372) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:55,683] {logging_mixin.py:112} INFO - [2020-08-01 16:13:55,682] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:13:55,683] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:13:55,683] {logging_mixin.py:112} INFO - [2020-08-01 16:13:55,683] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:55,685] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:13:55,700] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:13:55,708] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:13:55,710] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:14:03,781] {scheduler_job.py:154} INFO - Started process (PID=69389) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:03,821] {logging_mixin.py:112} INFO - [2020-08-01 16:14:03,820] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:03,821] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:14:03,821] {logging_mixin.py:112} INFO - [2020-08-01 16:14:03,821] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:03,824] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:03,837] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:14:03,844] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:03,846] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 16:14:11,739] {scheduler_job.py:154} INFO - Started process (PID=69414) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:11,756] {logging_mixin.py:112} INFO - [2020-08-01 16:14:11,756] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:11,757] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:14:11,757] {logging_mixin.py:112} INFO - [2020-08-01 16:14:11,757] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:11,759] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:11,773] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:14:11,780] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:11,781] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:14:19,758] {scheduler_job.py:154} INFO - Started process (PID=69431) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:19,775] {logging_mixin.py:112} INFO - [2020-08-01 16:14:19,775] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:19,776] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:14:19,776] {logging_mixin.py:112} INFO - [2020-08-01 16:14:19,776] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:19,778] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:19,792] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:14:19,800] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:19,801] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:14:27,772] {scheduler_job.py:154} INFO - Started process (PID=69455) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:27,790] {logging_mixin.py:112} INFO - [2020-08-01 16:14:27,790] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:27,791] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:14:27,791] {logging_mixin.py:112} INFO - [2020-08-01 16:14:27,791] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:27,793] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:27,808] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:14:27,815] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:27,816] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:14:35,868] {scheduler_job.py:154} INFO - Started process (PID=69480) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:35,887] {logging_mixin.py:112} INFO - [2020-08-01 16:14:35,887] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:35,888] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:14:35,888] {logging_mixin.py:112} INFO - [2020-08-01 16:14:35,888] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:35,890] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:35,903] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:14:35,911] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:35,913] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:14:43,954] {scheduler_job.py:154} INFO - Started process (PID=69497) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:43,972] {logging_mixin.py:112} INFO - [2020-08-01 16:14:43,972] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:43,973] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:14:43,973] {logging_mixin.py:112} INFO - [2020-08-01 16:14:43,973] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:43,976] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:43,990] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:14:43,997] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:43,999] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:14:51,931] {scheduler_job.py:154} INFO - Started process (PID=69522) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:51,954] {logging_mixin.py:112} INFO - [2020-08-01 16:14:51,954] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:51,955] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:14:51,955] {logging_mixin.py:112} INFO - [2020-08-01 16:14:51,955] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:51,957] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:51,970] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:14:51,976] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:51,978] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:14:59,874] {scheduler_job.py:154} INFO - Started process (PID=69539) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:59,892] {logging_mixin.py:112} INFO - [2020-08-01 16:14:59,892] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:14:59,893] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:14:59,893] {logging_mixin.py:112} INFO - [2020-08-01 16:14:59,893] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:59,896] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:14:59,911] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:14:59,920] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:14:59,922] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:15:07,994] {scheduler_job.py:154} INFO - Started process (PID=69564) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:08,013] {logging_mixin.py:112} INFO - [2020-08-01 16:15:08,013] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:08,014] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:15:08,014] {logging_mixin.py:112} INFO - [2020-08-01 16:15:08,014] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:08,017] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:08,029] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:15:08,037] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:08,039] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:15:15,922] {scheduler_job.py:154} INFO - Started process (PID=69587) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:15,940] {logging_mixin.py:112} INFO - [2020-08-01 16:15:15,940] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:15,941] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:15:15,941] {logging_mixin.py:112} INFO - [2020-08-01 16:15:15,941] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:15,943] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:15,957] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:15:15,963] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:15,964] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:15:23,860] {scheduler_job.py:154} INFO - Started process (PID=69606) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:23,878] {logging_mixin.py:112} INFO - [2020-08-01 16:15:23,878] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:23,878] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:15:23,879] {logging_mixin.py:112} INFO - [2020-08-01 16:15:23,879] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:23,880] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:23,895] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:15:23,903] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:23,904] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:15:31,957] {scheduler_job.py:154} INFO - Started process (PID=69631) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:31,976] {logging_mixin.py:112} INFO - [2020-08-01 16:15:31,976] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:31,977] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:15:31,977] {logging_mixin.py:112} INFO - [2020-08-01 16:15:31,977] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:31,979] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:31,992] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:15:32,000] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:32,002] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:15:40,035] {scheduler_job.py:154} INFO - Started process (PID=69648) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:40,053] {logging_mixin.py:112} INFO - [2020-08-01 16:15:40,052] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:40,053] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:15:40,053] {logging_mixin.py:112} INFO - [2020-08-01 16:15:40,053] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:40,055] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:40,069] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:15:40,076] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:40,078] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:15:48,026] {scheduler_job.py:154} INFO - Started process (PID=69673) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:48,044] {logging_mixin.py:112} INFO - [2020-08-01 16:15:48,044] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:48,045] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:15:48,045] {logging_mixin.py:112} INFO - [2020-08-01 16:15:48,045] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:48,047] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:48,060] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:15:48,067] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:48,069] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:15:56,050] {scheduler_job.py:154} INFO - Started process (PID=69689) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:56,068] {logging_mixin.py:112} INFO - [2020-08-01 16:15:56,068] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:15:56,068] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:15:56,069] {logging_mixin.py:112} INFO - [2020-08-01 16:15:56,069] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:56,070] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:15:56,085] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:15:56,092] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:15:56,094] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:16:04,044] {scheduler_job.py:154} INFO - Started process (PID=69717) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:04,062] {logging_mixin.py:112} INFO - [2020-08-01 16:16:04,062] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:04,063] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:16:04,063] {logging_mixin.py:112} INFO - [2020-08-01 16:16:04,063] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:04,065] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:04,080] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:16:04,087] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:04,089] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:16:12,077] {scheduler_job.py:154} INFO - Started process (PID=69742) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:12,095] {logging_mixin.py:112} INFO - [2020-08-01 16:16:12,094] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:12,095] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:16:12,095] {logging_mixin.py:112} INFO - [2020-08-01 16:16:12,095] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:12,097] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:12,112] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:16:12,120] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:12,121] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:16:20,053] {scheduler_job.py:154} INFO - Started process (PID=69759) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:20,078] {logging_mixin.py:112} INFO - [2020-08-01 16:16:20,078] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:20,079] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:16:20,079] {logging_mixin.py:112} INFO - [2020-08-01 16:16:20,079] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:20,081] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:20,097] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:16:20,105] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:20,106] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.054 seconds
[2020-08-01 16:16:28,059] {scheduler_job.py:154} INFO - Started process (PID=69817) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:28,077] {logging_mixin.py:112} INFO - [2020-08-01 16:16:28,076] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:28,077] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:16:28,077] {logging_mixin.py:112} INFO - [2020-08-01 16:16:28,077] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:28,079] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:28,094] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:16:28,102] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:28,104] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:16:36,097] {scheduler_job.py:154} INFO - Started process (PID=69834) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:36,115] {logging_mixin.py:112} INFO - [2020-08-01 16:16:36,115] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:36,115] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:16:36,116] {logging_mixin.py:112} INFO - [2020-08-01 16:16:36,116] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:36,117] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:36,132] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:16:36,140] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:36,141] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:16:44,103] {scheduler_job.py:154} INFO - Started process (PID=69893) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:44,120] {logging_mixin.py:112} INFO - [2020-08-01 16:16:44,120] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:44,121] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:16:44,121] {logging_mixin.py:112} INFO - [2020-08-01 16:16:44,121] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:44,123] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:44,137] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:16:44,147] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:44,149] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:16:52,193] {scheduler_job.py:154} INFO - Started process (PID=69927) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:52,211] {logging_mixin.py:112} INFO - [2020-08-01 16:16:52,211] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:16:52,212] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:16:52,212] {logging_mixin.py:112} INFO - [2020-08-01 16:16:52,212] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:52,214] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:16:52,228] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:16:52,235] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:16:52,236] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:17:00,251] {scheduler_job.py:154} INFO - Started process (PID=69935) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:00,275] {logging_mixin.py:112} INFO - [2020-08-01 16:17:00,274] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:00,276] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:17:00,276] {logging_mixin.py:112} INFO - [2020-08-01 16:17:00,276] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:00,278] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:00,292] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:17:00,301] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:00,304] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 16:17:08,201] {scheduler_job.py:154} INFO - Started process (PID=69945) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:08,226] {logging_mixin.py:112} INFO - [2020-08-01 16:17:08,226] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:08,227] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:17:08,227] {logging_mixin.py:112} INFO - [2020-08-01 16:17:08,227] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:08,229] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:08,244] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:17:08,251] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:08,253] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 16:17:16,423] {scheduler_job.py:154} INFO - Started process (PID=69963) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:16,450] {logging_mixin.py:112} INFO - [2020-08-01 16:17:16,450] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:16,452] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:17:16,452] {logging_mixin.py:112} INFO - [2020-08-01 16:17:16,452] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:16,455] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:16,470] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:17:16,478] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:16,479] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.057 seconds
[2020-08-01 16:17:24,247] {scheduler_job.py:154} INFO - Started process (PID=69987) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:24,265] {logging_mixin.py:112} INFO - [2020-08-01 16:17:24,265] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:24,266] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:17:24,266] {logging_mixin.py:112} INFO - [2020-08-01 16:17:24,266] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:24,268] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:24,288] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:17:24,296] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:24,297] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 16:17:32,342] {scheduler_job.py:154} INFO - Started process (PID=70004) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:32,359] {logging_mixin.py:112} INFO - [2020-08-01 16:17:32,359] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:32,360] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:17:32,360] {logging_mixin.py:112} INFO - [2020-08-01 16:17:32,360] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:32,362] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:32,375] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:17:32,382] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:32,383] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:17:40,266] {scheduler_job.py:154} INFO - Started process (PID=70030) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:40,284] {logging_mixin.py:112} INFO - [2020-08-01 16:17:40,283] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:40,284] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:17:40,284] {logging_mixin.py:112} INFO - [2020-08-01 16:17:40,284] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:40,286] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:40,300] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:17:40,307] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:40,309] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:17:48,381] {scheduler_job.py:154} INFO - Started process (PID=70116) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:48,399] {logging_mixin.py:112} INFO - [2020-08-01 16:17:48,399] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:48,399] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:17:48,400] {logging_mixin.py:112} INFO - [2020-08-01 16:17:48,399] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:48,401] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:48,413] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:17:48,421] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:48,423] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:17:56,316] {scheduler_job.py:154} INFO - Started process (PID=70134) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:56,334] {logging_mixin.py:112} INFO - [2020-08-01 16:17:56,334] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:17:56,334] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:17:56,334] {logging_mixin.py:112} INFO - [2020-08-01 16:17:56,334] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:56,336] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:17:56,351] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:17:56,359] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:17:56,361] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:18:04,332] {scheduler_job.py:154} INFO - Started process (PID=70143) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:04,351] {logging_mixin.py:112} INFO - [2020-08-01 16:18:04,350] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:04,351] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:18:04,351] {logging_mixin.py:112} INFO - [2020-08-01 16:18:04,351] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:04,353] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:04,368] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:18:04,375] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:04,376] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:18:12,491] {scheduler_job.py:154} INFO - Started process (PID=70151) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:12,508] {logging_mixin.py:112} INFO - [2020-08-01 16:18:12,508] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:12,509] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:18:12,509] {logging_mixin.py:112} INFO - [2020-08-01 16:18:12,509] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:12,511] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:12,524] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:18:12,531] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:12,533] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:18:20,426] {scheduler_job.py:154} INFO - Started process (PID=70160) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:20,444] {logging_mixin.py:112} INFO - [2020-08-01 16:18:20,443] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:20,444] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:18:20,444] {logging_mixin.py:112} INFO - [2020-08-01 16:18:20,444] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:20,446] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:20,460] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:18:20,468] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:20,470] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:18:28,522] {scheduler_job.py:154} INFO - Started process (PID=70168) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:28,558] {logging_mixin.py:112} INFO - [2020-08-01 16:18:28,558] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:28,560] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:18:28,560] {logging_mixin.py:112} INFO - [2020-08-01 16:18:28,560] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:28,563] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:28,580] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:18:28,586] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:28,588] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 16:18:36,397] {scheduler_job.py:154} INFO - Started process (PID=70192) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:36,415] {logging_mixin.py:112} INFO - [2020-08-01 16:18:36,415] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:36,416] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:18:36,416] {logging_mixin.py:112} INFO - [2020-08-01 16:18:36,416] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:36,418] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:36,432] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:18:36,439] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:36,441] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:18:44,461] {scheduler_job.py:154} INFO - Started process (PID=70209) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:44,478] {logging_mixin.py:112} INFO - [2020-08-01 16:18:44,478] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:44,479] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:18:44,479] {logging_mixin.py:112} INFO - [2020-08-01 16:18:44,479] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:44,481] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:44,493] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:18:44,501] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:44,502] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:18:52,446] {scheduler_job.py:154} INFO - Started process (PID=70234) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:52,464] {logging_mixin.py:112} INFO - [2020-08-01 16:18:52,463] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:18:52,464] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:18:52,464] {logging_mixin.py:112} INFO - [2020-08-01 16:18:52,464] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:52,466] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:18:52,481] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:18:52,490] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:18:52,492] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:19:00,486] {scheduler_job.py:154} INFO - Started process (PID=70258) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:00,503] {logging_mixin.py:112} INFO - [2020-08-01 16:19:00,503] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:00,504] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:19:00,504] {logging_mixin.py:112} INFO - [2020-08-01 16:19:00,504] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:00,506] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:00,520] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:19:00,528] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:00,529] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:19:08,515] {scheduler_job.py:154} INFO - Started process (PID=70274) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:08,533] {logging_mixin.py:112} INFO - [2020-08-01 16:19:08,533] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:08,533] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:19:08,534] {logging_mixin.py:112} INFO - [2020-08-01 16:19:08,534] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:08,535] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:08,550] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:19:08,557] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:08,559] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:19:16,635] {scheduler_job.py:154} INFO - Started process (PID=70300) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:16,652] {logging_mixin.py:112} INFO - [2020-08-01 16:19:16,652] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:16,653] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:19:16,653] {logging_mixin.py:112} INFO - [2020-08-01 16:19:16,653] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:16,655] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:16,669] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:19:16,676] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:16,678] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:19:24,639] {scheduler_job.py:154} INFO - Started process (PID=70316) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:24,658] {logging_mixin.py:112} INFO - [2020-08-01 16:19:24,658] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:24,659] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:19:24,659] {logging_mixin.py:112} INFO - [2020-08-01 16:19:24,659] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:24,661] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:24,677] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:19:24,684] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:24,686] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:19:32,655] {scheduler_job.py:154} INFO - Started process (PID=70358) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:32,680] {logging_mixin.py:112} INFO - [2020-08-01 16:19:32,679] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:32,680] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:19:32,680] {logging_mixin.py:112} INFO - [2020-08-01 16:19:32,680] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:32,682] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:32,699] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:19:32,708] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:32,709] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.054 seconds
[2020-08-01 16:19:40,714] {scheduler_job.py:154} INFO - Started process (PID=70376) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:40,732] {logging_mixin.py:112} INFO - [2020-08-01 16:19:40,732] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:40,733] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:19:40,733] {logging_mixin.py:112} INFO - [2020-08-01 16:19:40,733] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:40,735] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:40,750] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:19:40,760] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:40,765] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 16:19:48,635] {scheduler_job.py:154} INFO - Started process (PID=70411) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:48,655] {logging_mixin.py:112} INFO - [2020-08-01 16:19:48,654] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:48,655] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:19:48,655] {logging_mixin.py:112} INFO - [2020-08-01 16:19:48,655] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:48,657] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:48,671] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:19:48,678] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:48,679] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:19:56,647] {scheduler_job.py:154} INFO - Started process (PID=70419) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:56,664] {logging_mixin.py:112} INFO - [2020-08-01 16:19:56,664] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:19:56,665] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:19:56,665] {logging_mixin.py:112} INFO - [2020-08-01 16:19:56,665] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:56,667] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:19:56,681] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:19:56,689] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:19:56,691] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:20:04,689] {scheduler_job.py:154} INFO - Started process (PID=70427) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:04,707] {logging_mixin.py:112} INFO - [2020-08-01 16:20:04,707] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:04,708] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:20:04,708] {logging_mixin.py:112} INFO - [2020-08-01 16:20:04,708] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:04,710] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:04,724] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:20:04,731] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:04,733] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:20:12,728] {scheduler_job.py:154} INFO - Started process (PID=70435) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:12,746] {logging_mixin.py:112} INFO - [2020-08-01 16:20:12,746] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:12,747] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:20:12,747] {logging_mixin.py:112} INFO - [2020-08-01 16:20:12,747] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:12,749] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:12,763] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:20:12,770] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:12,772] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:20:20,761] {scheduler_job.py:154} INFO - Started process (PID=70444) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:20,779] {logging_mixin.py:112} INFO - [2020-08-01 16:20:20,779] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:20,780] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:20:20,780] {logging_mixin.py:112} INFO - [2020-08-01 16:20:20,780] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:20,781] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:20,795] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:20:20,802] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:20,804] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:20:28,792] {scheduler_job.py:154} INFO - Started process (PID=70452) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:28,810] {logging_mixin.py:112} INFO - [2020-08-01 16:20:28,809] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:28,810] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:20:28,810] {logging_mixin.py:112} INFO - [2020-08-01 16:20:28,810] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:28,812] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:28,827] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:20:28,836] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:28,837] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:20:36,840] {scheduler_job.py:154} INFO - Started process (PID=70460) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:36,858] {logging_mixin.py:112} INFO - [2020-08-01 16:20:36,858] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:36,859] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:20:36,859] {logging_mixin.py:112} INFO - [2020-08-01 16:20:36,859] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:36,861] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:36,875] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:20:36,883] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:36,885] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:20:44,860] {scheduler_job.py:154} INFO - Started process (PID=70468) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:44,877] {logging_mixin.py:112} INFO - [2020-08-01 16:20:44,877] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:44,878] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:20:44,878] {logging_mixin.py:112} INFO - [2020-08-01 16:20:44,878] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:44,880] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:44,894] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:20:44,900] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:44,902] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:20:52,897] {scheduler_job.py:154} INFO - Started process (PID=70485) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:52,914] {logging_mixin.py:112} INFO - [2020-08-01 16:20:52,914] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:20:52,915] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:20:52,915] {logging_mixin.py:112} INFO - [2020-08-01 16:20:52,915] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:52,917] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:20:52,931] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:20:52,938] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:20:52,940] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:21:00,918] {scheduler_job.py:154} INFO - Started process (PID=70501) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:00,936] {logging_mixin.py:112} INFO - [2020-08-01 16:21:00,936] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:00,937] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:21:00,937] {logging_mixin.py:112} INFO - [2020-08-01 16:21:00,937] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:00,939] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:00,953] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:21:00,961] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:00,963] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:21:08,943] {scheduler_job.py:154} INFO - Started process (PID=70525) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:08,961] {logging_mixin.py:112} INFO - [2020-08-01 16:21:08,961] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:08,961] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:21:08,961] {logging_mixin.py:112} INFO - [2020-08-01 16:21:08,961] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:08,963] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:08,978] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:21:08,985] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:08,987] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:21:17,066] {scheduler_job.py:154} INFO - Started process (PID=70542) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:17,085] {logging_mixin.py:112} INFO - [2020-08-01 16:21:17,085] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:17,085] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:21:17,086] {logging_mixin.py:112} INFO - [2020-08-01 16:21:17,085] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:17,087] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:17,106] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:21:17,113] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:17,115] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 16:21:25,044] {scheduler_job.py:154} INFO - Started process (PID=70566) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:25,062] {logging_mixin.py:112} INFO - [2020-08-01 16:21:25,062] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:25,063] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:21:25,063] {logging_mixin.py:112} INFO - [2020-08-01 16:21:25,063] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:25,065] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:25,079] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:21:25,086] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:25,088] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:21:33,083] {scheduler_job.py:154} INFO - Started process (PID=70582) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:33,103] {logging_mixin.py:112} INFO - [2020-08-01 16:21:33,103] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:33,104] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:21:33,104] {logging_mixin.py:112} INFO - [2020-08-01 16:21:33,104] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:33,107] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:33,121] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:21:33,130] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:33,131] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 16:21:41,051] {scheduler_job.py:154} INFO - Started process (PID=70606) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:41,069] {logging_mixin.py:112} INFO - [2020-08-01 16:21:41,069] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:41,069] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:21:41,070] {logging_mixin.py:112} INFO - [2020-08-01 16:21:41,070] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:41,071] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:41,086] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:21:41,093] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:41,095] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:21:49,070] {scheduler_job.py:154} INFO - Started process (PID=70631) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:49,088] {logging_mixin.py:112} INFO - [2020-08-01 16:21:49,088] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:49,089] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:21:49,089] {logging_mixin.py:112} INFO - [2020-08-01 16:21:49,089] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:49,091] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:49,107] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:21:49,114] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:49,116] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:21:57,084] {scheduler_job.py:154} INFO - Started process (PID=70647) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:57,103] {logging_mixin.py:112} INFO - [2020-08-01 16:21:57,103] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:21:57,104] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:21:57,104] {logging_mixin.py:112} INFO - [2020-08-01 16:21:57,104] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:57,106] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:21:57,124] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:21:57,132] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:21:57,134] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 16:22:05,199] {scheduler_job.py:154} INFO - Started process (PID=70671) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:05,217] {logging_mixin.py:112} INFO - [2020-08-01 16:22:05,216] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:05,217] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:22:05,217] {logging_mixin.py:112} INFO - [2020-08-01 16:22:05,217] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:05,219] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:05,232] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:22:05,239] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:05,241] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:22:13,137] {scheduler_job.py:154} INFO - Started process (PID=70687) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:13,154] {logging_mixin.py:112} INFO - [2020-08-01 16:22:13,154] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:13,155] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:22:13,155] {logging_mixin.py:112} INFO - [2020-08-01 16:22:13,155] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:13,157] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:13,171] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:22:13,179] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:13,180] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:22:21,234] {scheduler_job.py:154} INFO - Started process (PID=70713) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:21,251] {logging_mixin.py:112} INFO - [2020-08-01 16:22:21,251] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:21,252] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:22:21,252] {logging_mixin.py:112} INFO - [2020-08-01 16:22:21,252] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:21,254] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:21,268] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:22:21,274] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:21,276] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:22:29,224] {scheduler_job.py:154} INFO - Started process (PID=70729) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:29,241] {logging_mixin.py:112} INFO - [2020-08-01 16:22:29,241] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:29,242] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:22:29,242] {logging_mixin.py:112} INFO - [2020-08-01 16:22:29,242] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:29,244] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:29,258] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:22:29,265] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:29,266] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:22:37,218] {scheduler_job.py:154} INFO - Started process (PID=70754) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:37,237] {logging_mixin.py:112} INFO - [2020-08-01 16:22:37,237] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:37,237] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:22:37,238] {logging_mixin.py:112} INFO - [2020-08-01 16:22:37,237] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:37,239] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:37,253] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:22:37,260] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:37,263] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:22:45,272] {scheduler_job.py:154} INFO - Started process (PID=70778) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:45,290] {logging_mixin.py:112} INFO - [2020-08-01 16:22:45,290] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:45,290] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:22:45,290] {logging_mixin.py:112} INFO - [2020-08-01 16:22:45,290] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:45,292] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:45,305] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:22:45,312] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:45,314] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:22:53,263] {scheduler_job.py:154} INFO - Started process (PID=70796) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:53,281] {logging_mixin.py:112} INFO - [2020-08-01 16:22:53,280] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:22:53,281] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:22:53,281] {logging_mixin.py:112} INFO - [2020-08-01 16:22:53,281] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:53,283] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:22:53,296] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:22:53,304] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:22:53,305] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:23:01,287] {scheduler_job.py:154} INFO - Started process (PID=70855) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:01,304] {logging_mixin.py:112} INFO - [2020-08-01 16:23:01,304] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:01,305] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:23:01,305] {logging_mixin.py:112} INFO - [2020-08-01 16:23:01,305] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:01,307] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:01,321] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:23:01,329] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:01,331] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:23:09,352] {scheduler_job.py:154} INFO - Started process (PID=70905) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:09,370] {logging_mixin.py:112} INFO - [2020-08-01 16:23:09,370] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:09,371] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:23:09,371] {logging_mixin.py:112} INFO - [2020-08-01 16:23:09,371] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:09,373] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:09,386] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:23:09,393] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:09,394] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:23:17,383] {scheduler_job.py:154} INFO - Started process (PID=70923) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:17,401] {logging_mixin.py:112} INFO - [2020-08-01 16:23:17,401] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:17,402] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:23:17,402] {logging_mixin.py:112} INFO - [2020-08-01 16:23:17,402] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:17,404] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:17,418] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:23:17,425] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:17,427] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:23:25,517] {scheduler_job.py:154} INFO - Started process (PID=70976) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:25,535] {logging_mixin.py:112} INFO - [2020-08-01 16:23:25,535] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:25,536] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:23:25,536] {logging_mixin.py:112} INFO - [2020-08-01 16:23:25,536] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:25,538] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:25,551] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:23:25,558] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:25,560] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:23:33,381] {scheduler_job.py:154} INFO - Started process (PID=70985) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:33,399] {logging_mixin.py:112} INFO - [2020-08-01 16:23:33,398] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:33,399] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:23:33,399] {logging_mixin.py:112} INFO - [2020-08-01 16:23:33,399] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:33,401] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:33,416] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:23:33,424] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:33,425] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:23:41,433] {scheduler_job.py:154} INFO - Started process (PID=70995) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:41,451] {logging_mixin.py:112} INFO - [2020-08-01 16:23:41,451] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:41,451] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:23:41,452] {logging_mixin.py:112} INFO - [2020-08-01 16:23:41,451] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:41,453] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:41,466] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:23:41,473] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:41,475] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:23:49,703] {scheduler_job.py:154} INFO - Started process (PID=71003) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:49,729] {logging_mixin.py:112} INFO - [2020-08-01 16:23:49,729] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:49,730] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:23:49,730] {logging_mixin.py:112} INFO - [2020-08-01 16:23:49,730] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:49,733] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:49,749] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:23:49,759] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:49,761] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.059 seconds
[2020-08-01 16:23:57,441] {scheduler_job.py:154} INFO - Started process (PID=71030) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:57,458] {logging_mixin.py:112} INFO - [2020-08-01 16:23:57,458] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:23:57,459] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:23:57,459] {logging_mixin.py:112} INFO - [2020-08-01 16:23:57,459] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:57,461] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:23:57,474] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:23:57,481] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:23:57,483] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:24:05,470] {scheduler_job.py:154} INFO - Started process (PID=71047) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:05,487] {logging_mixin.py:112} INFO - [2020-08-01 16:24:05,487] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:05,488] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:24:05,488] {logging_mixin.py:112} INFO - [2020-08-01 16:24:05,488] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:05,490] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:05,504] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:24:05,512] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:05,513] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:24:13,486] {scheduler_job.py:154} INFO - Started process (PID=71071) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:13,504] {logging_mixin.py:112} INFO - [2020-08-01 16:24:13,504] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:13,505] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:24:13,505] {logging_mixin.py:112} INFO - [2020-08-01 16:24:13,505] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:13,507] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:13,521] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:24:13,529] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:13,530] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:24:21,557] {scheduler_job.py:154} INFO - Started process (PID=71096) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:21,573] {logging_mixin.py:112} INFO - [2020-08-01 16:24:21,573] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:21,574] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:24:21,574] {logging_mixin.py:112} INFO - [2020-08-01 16:24:21,574] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:21,576] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:21,589] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:24:21,596] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:21,598] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:24:29,542] {scheduler_job.py:154} INFO - Started process (PID=71104) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:29,560] {logging_mixin.py:112} INFO - [2020-08-01 16:24:29,560] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:29,560] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:24:29,560] {logging_mixin.py:112} INFO - [2020-08-01 16:24:29,560] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:29,562] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:29,576] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:24:29,583] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:29,585] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:24:37,563] {scheduler_job.py:154} INFO - Started process (PID=71112) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:37,581] {logging_mixin.py:112} INFO - [2020-08-01 16:24:37,581] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:37,581] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:24:37,582] {logging_mixin.py:112} INFO - [2020-08-01 16:24:37,581] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:37,583] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:37,598] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:24:37,606] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:37,607] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:24:45,616] {scheduler_job.py:154} INFO - Started process (PID=71128) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:45,635] {logging_mixin.py:112} INFO - [2020-08-01 16:24:45,635] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:45,635] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:24:45,635] {logging_mixin.py:112} INFO - [2020-08-01 16:24:45,635] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:45,637] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:45,652] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:24:45,659] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:45,661] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:24:53,633] {scheduler_job.py:154} INFO - Started process (PID=71154) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:53,650] {logging_mixin.py:112} INFO - [2020-08-01 16:24:53,650] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:24:53,651] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:24:53,651] {logging_mixin.py:112} INFO - [2020-08-01 16:24:53,651] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:53,653] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:24:53,666] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:24:53,674] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:24:53,675] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:25:01,747] {scheduler_job.py:154} INFO - Started process (PID=71171) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:01,764] {logging_mixin.py:112} INFO - [2020-08-01 16:25:01,764] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:01,765] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:25:01,765] {logging_mixin.py:112} INFO - [2020-08-01 16:25:01,765] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:01,767] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:01,781] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:25:01,787] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:01,789] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:25:09,724] {scheduler_job.py:154} INFO - Started process (PID=71195) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:09,742] {logging_mixin.py:112} INFO - [2020-08-01 16:25:09,742] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:09,743] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:25:09,743] {logging_mixin.py:112} INFO - [2020-08-01 16:25:09,743] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:09,745] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:09,760] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:25:09,768] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:09,769] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:25:17,817] {scheduler_job.py:154} INFO - Started process (PID=71263) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:17,843] {logging_mixin.py:112} INFO - [2020-08-01 16:25:17,843] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:17,844] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:25:17,844] {logging_mixin.py:112} INFO - [2020-08-01 16:25:17,844] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:17,846] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:17,860] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:25:17,868] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:17,870] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 16:25:25,764] {scheduler_job.py:154} INFO - Started process (PID=71276) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:25,781] {logging_mixin.py:112} INFO - [2020-08-01 16:25:25,781] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:25,782] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:25:25,782] {logging_mixin.py:112} INFO - [2020-08-01 16:25:25,782] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:25,784] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:25,799] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:25:25,806] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:25,808] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:25:33,847] {scheduler_job.py:154} INFO - Started process (PID=71285) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:33,864] {logging_mixin.py:112} INFO - [2020-08-01 16:25:33,864] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:33,865] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:25:33,865] {logging_mixin.py:112} INFO - [2020-08-01 16:25:33,865] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:33,867] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:33,882] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:25:33,888] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:33,890] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:25:41,825] {scheduler_job.py:154} INFO - Started process (PID=71293) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:41,843] {logging_mixin.py:112} INFO - [2020-08-01 16:25:41,843] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:41,844] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:25:41,844] {logging_mixin.py:112} INFO - [2020-08-01 16:25:41,844] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:41,846] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:41,859] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:25:41,867] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:41,868] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:25:49,849] {scheduler_job.py:154} INFO - Started process (PID=71302) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:49,867] {logging_mixin.py:112} INFO - [2020-08-01 16:25:49,867] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:49,868] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:25:49,868] {logging_mixin.py:112} INFO - [2020-08-01 16:25:49,868] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:49,870] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:49,884] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:25:49,891] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:49,893] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:25:57,847] {scheduler_job.py:154} INFO - Started process (PID=71311) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:57,865] {logging_mixin.py:112} INFO - [2020-08-01 16:25:57,865] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:25:57,865] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:25:57,865] {logging_mixin.py:112} INFO - [2020-08-01 16:25:57,865] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:57,867] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:25:57,882] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:25:57,889] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:25:57,890] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:26:05,898] {scheduler_job.py:154} INFO - Started process (PID=71327) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:05,917] {logging_mixin.py:112} INFO - [2020-08-01 16:26:05,917] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:05,918] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:26:05,918] {logging_mixin.py:112} INFO - [2020-08-01 16:26:05,918] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:05,920] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:05,935] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:26:05,943] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:05,946] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:26:13,925] {scheduler_job.py:154} INFO - Started process (PID=71397) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:13,947] {logging_mixin.py:112} INFO - [2020-08-01 16:26:13,946] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:13,947] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:26:13,947] {logging_mixin.py:112} INFO - [2020-08-01 16:26:13,947] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:13,949] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:13,962] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:26:13,970] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:13,972] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:26:21,901] {scheduler_job.py:154} INFO - Started process (PID=71409) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:21,919] {logging_mixin.py:112} INFO - [2020-08-01 16:26:21,918] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:21,919] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:26:21,919] {logging_mixin.py:112} INFO - [2020-08-01 16:26:21,919] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:21,921] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:21,936] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:26:21,944] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:21,945] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:26:29,983] {scheduler_job.py:154} INFO - Started process (PID=71419) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:30,000] {logging_mixin.py:112} INFO - [2020-08-01 16:26:30,000] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:30,001] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:26:30,001] {logging_mixin.py:112} INFO - [2020-08-01 16:26:30,001] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:30,003] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:30,016] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:26:30,022] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:30,024] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:26:37,938] {scheduler_job.py:154} INFO - Started process (PID=71428) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:37,956] {logging_mixin.py:112} INFO - [2020-08-01 16:26:37,956] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:37,956] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:26:37,956] {logging_mixin.py:112} INFO - [2020-08-01 16:26:37,956] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:37,958] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:37,973] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:26:37,980] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:37,982] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:26:46,470] {scheduler_job.py:154} INFO - Started process (PID=71440) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:46,498] {logging_mixin.py:112} INFO - [2020-08-01 16:26:46,497] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:46,499] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:26:46,499] {logging_mixin.py:112} INFO - [2020-08-01 16:26:46,499] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:46,501] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:46,519] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:26:46,529] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:46,531] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.061 seconds
[2020-08-01 16:26:54,576] {scheduler_job.py:154} INFO - Started process (PID=71448) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:54,610] {logging_mixin.py:112} INFO - [2020-08-01 16:26:54,610] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:26:54,611] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:26:54,611] {logging_mixin.py:112} INFO - [2020-08-01 16:26:54,611] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:54,614] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:26:54,633] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:26:54,644] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:26:54,646] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.070 seconds
[2020-08-01 16:27:02,562] {scheduler_job.py:154} INFO - Started process (PID=71457) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:02,592] {logging_mixin.py:112} INFO - [2020-08-01 16:27:02,592] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:02,593] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:27:02,593] {logging_mixin.py:112} INFO - [2020-08-01 16:27:02,593] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:02,596] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:02,614] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:27:02,625] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:02,627] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 16:27:10,338] {scheduler_job.py:154} INFO - Started process (PID=71465) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:10,368] {logging_mixin.py:112} INFO - [2020-08-01 16:27:10,367] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:10,368] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:27:10,369] {logging_mixin.py:112} INFO - [2020-08-01 16:27:10,369] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:10,371] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:10,390] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:27:10,400] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:10,402] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 16:27:18,608] {scheduler_job.py:154} INFO - Started process (PID=71473) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:18,639] {logging_mixin.py:112} INFO - [2020-08-01 16:27:18,638] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:18,640] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:27:18,640] {logging_mixin.py:112} INFO - [2020-08-01 16:27:18,640] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:18,642] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:18,660] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:27:18,670] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:18,672] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.064 seconds
[2020-08-01 16:27:26,606] {scheduler_job.py:154} INFO - Started process (PID=71482) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:26,627] {logging_mixin.py:112} INFO - [2020-08-01 16:27:26,627] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:26,628] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:27:26,628] {logging_mixin.py:112} INFO - [2020-08-01 16:27:26,628] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:26,630] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:26,641] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:27:26,649] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:26,651] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:27:35,055] {scheduler_job.py:154} INFO - Started process (PID=71493) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:35,102] {logging_mixin.py:112} INFO - [2020-08-01 16:27:35,102] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:35,104] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:27:35,104] {logging_mixin.py:112} INFO - [2020-08-01 16:27:35,104] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:35,107] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:35,129] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:27:35,141] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:35,144] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.089 seconds
[2020-08-01 16:27:42,738] {scheduler_job.py:154} INFO - Started process (PID=71501) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:42,769] {logging_mixin.py:112} INFO - [2020-08-01 16:27:42,768] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:42,770] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:27:42,770] {logging_mixin.py:112} INFO - [2020-08-01 16:27:42,770] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:42,772] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:42,789] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:27:42,799] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:42,801] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.063 seconds
[2020-08-01 16:27:50,289] {scheduler_job.py:154} INFO - Started process (PID=71509) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:50,307] {logging_mixin.py:112} INFO - [2020-08-01 16:27:50,307] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:50,308] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:27:50,308] {logging_mixin.py:112} INFO - [2020-08-01 16:27:50,308] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:50,310] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:50,325] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:27:50,333] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:50,334] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:27:58,376] {scheduler_job.py:154} INFO - Started process (PID=71526) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:58,397] {logging_mixin.py:112} INFO - [2020-08-01 16:27:58,397] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:27:58,398] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:27:58,398] {logging_mixin.py:112} INFO - [2020-08-01 16:27:58,398] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:58,400] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:27:58,414] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:27:58,420] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:27:58,422] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:28:06,447] {scheduler_job.py:154} INFO - Started process (PID=71595) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:06,478] {logging_mixin.py:112} INFO - [2020-08-01 16:28:06,478] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:06,479] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:28:06,479] {logging_mixin.py:112} INFO - [2020-08-01 16:28:06,479] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:06,482] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:06,517] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:28:06,529] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:06,532] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.085 seconds
[2020-08-01 16:28:14,380] {scheduler_job.py:154} INFO - Started process (PID=71604) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:14,399] {logging_mixin.py:112} INFO - [2020-08-01 16:28:14,398] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:14,399] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:28:14,399] {logging_mixin.py:112} INFO - [2020-08-01 16:28:14,399] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:14,401] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:14,413] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:28:14,419] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:14,421] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:28:22,520] {scheduler_job.py:154} INFO - Started process (PID=71621) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:22,537] {logging_mixin.py:112} INFO - [2020-08-01 16:28:22,537] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:22,537] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:28:22,538] {logging_mixin.py:112} INFO - [2020-08-01 16:28:22,538] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:22,539] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:22,552] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:28:22,559] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:22,562] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:28:30,389] {scheduler_job.py:154} INFO - Started process (PID=71641) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:30,409] {logging_mixin.py:112} INFO - [2020-08-01 16:28:30,409] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:30,410] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:28:30,410] {logging_mixin.py:112} INFO - [2020-08-01 16:28:30,410] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:30,412] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:30,423] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:28:30,430] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:30,432] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:28:38,398] {scheduler_job.py:154} INFO - Started process (PID=71665) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:38,416] {logging_mixin.py:112} INFO - [2020-08-01 16:28:38,416] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:38,416] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:28:38,417] {logging_mixin.py:112} INFO - [2020-08-01 16:28:38,416] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:38,418] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:38,432] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:28:38,440] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:38,442] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:28:46,419] {scheduler_job.py:154} INFO - Started process (PID=71681) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:46,437] {logging_mixin.py:112} INFO - [2020-08-01 16:28:46,437] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:46,438] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:28:46,438] {logging_mixin.py:112} INFO - [2020-08-01 16:28:46,438] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:46,439] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:46,453] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:28:46,459] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:46,461] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:28:54,454] {scheduler_job.py:154} INFO - Started process (PID=71707) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:54,472] {logging_mixin.py:112} INFO - [2020-08-01 16:28:54,472] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:28:54,473] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:28:54,473] {logging_mixin.py:112} INFO - [2020-08-01 16:28:54,473] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:54,474] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:28:54,489] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:28:54,495] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:28:54,497] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:29:02,499] {scheduler_job.py:154} INFO - Started process (PID=71724) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:02,517] {logging_mixin.py:112} INFO - [2020-08-01 16:29:02,516] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:02,517] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:29:02,517] {logging_mixin.py:112} INFO - [2020-08-01 16:29:02,517] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:02,519] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:02,533] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:29:02,541] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:02,543] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:29:10,509] {scheduler_job.py:154} INFO - Started process (PID=71748) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:10,527] {logging_mixin.py:112} INFO - [2020-08-01 16:29:10,527] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:10,527] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:29:10,527] {logging_mixin.py:112} INFO - [2020-08-01 16:29:10,527] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:10,529] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:10,543] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:29:10,551] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:10,553] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:29:18,568] {scheduler_job.py:154} INFO - Started process (PID=71774) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:18,586] {logging_mixin.py:112} INFO - [2020-08-01 16:29:18,586] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:18,587] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:29:18,587] {logging_mixin.py:112} INFO - [2020-08-01 16:29:18,587] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:18,588] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:18,602] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:29:18,608] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:18,610] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:29:26,578] {scheduler_job.py:154} INFO - Started process (PID=71790) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:26,596] {logging_mixin.py:112} INFO - [2020-08-01 16:29:26,595] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:26,596] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:29:26,596] {logging_mixin.py:112} INFO - [2020-08-01 16:29:26,596] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:26,598] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:26,612] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:29:26,619] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:26,621] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:29:34,585] {scheduler_job.py:154} INFO - Started process (PID=71815) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:34,603] {logging_mixin.py:112} INFO - [2020-08-01 16:29:34,603] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:34,603] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:29:34,604] {logging_mixin.py:112} INFO - [2020-08-01 16:29:34,603] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:34,605] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:34,620] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:29:34,628] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:34,629] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:29:42,607] {scheduler_job.py:154} INFO - Started process (PID=71831) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:42,625] {logging_mixin.py:112} INFO - [2020-08-01 16:29:42,625] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:42,626] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:29:42,626] {logging_mixin.py:112} INFO - [2020-08-01 16:29:42,626] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:42,628] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:42,641] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:29:42,648] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:42,649] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:29:50,666] {scheduler_job.py:154} INFO - Started process (PID=71855) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:50,684] {logging_mixin.py:112} INFO - [2020-08-01 16:29:50,684] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:50,685] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:29:50,685] {logging_mixin.py:112} INFO - [2020-08-01 16:29:50,685] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:50,687] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:50,701] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:29:50,708] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:50,709] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:29:58,800] {scheduler_job.py:154} INFO - Started process (PID=71871) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:58,817] {logging_mixin.py:112} INFO - [2020-08-01 16:29:58,817] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:29:58,818] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:29:58,818] {logging_mixin.py:112} INFO - [2020-08-01 16:29:58,818] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:58,820] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:29:58,832] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:29:58,839] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:29:58,841] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:30:06,709] {scheduler_job.py:154} INFO - Started process (PID=71897) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:06,726] {logging_mixin.py:112} INFO - [2020-08-01 16:30:06,726] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:06,727] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:30:06,727] {logging_mixin.py:112} INFO - [2020-08-01 16:30:06,727] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:06,729] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:06,743] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:30:06,750] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:06,751] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:30:14,747] {scheduler_job.py:154} INFO - Started process (PID=71921) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:14,765] {logging_mixin.py:112} INFO - [2020-08-01 16:30:14,765] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:14,766] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:30:14,766] {logging_mixin.py:112} INFO - [2020-08-01 16:30:14,766] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:14,768] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:14,782] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:30:14,790] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:14,791] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:30:22,840] {scheduler_job.py:154} INFO - Started process (PID=71937) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:22,857] {logging_mixin.py:112} INFO - [2020-08-01 16:30:22,857] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:22,858] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:30:22,858] {logging_mixin.py:112} INFO - [2020-08-01 16:30:22,858] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:22,860] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:22,874] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:30:22,881] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:22,882] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:30:30,804] {scheduler_job.py:154} INFO - Started process (PID=71946) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:30,822] {logging_mixin.py:112} INFO - [2020-08-01 16:30:30,822] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:30,823] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:30:30,823] {logging_mixin.py:112} INFO - [2020-08-01 16:30:30,823] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:30,825] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:30,840] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:30:30,847] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:30,848] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:30:39,364] {scheduler_job.py:154} INFO - Started process (PID=71955) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:39,393] {logging_mixin.py:112} INFO - [2020-08-01 16:30:39,393] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:39,394] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:30:39,394] {logging_mixin.py:112} INFO - [2020-08-01 16:30:39,394] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:39,397] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:39,416] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:30:39,426] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:39,428] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.064 seconds
[2020-08-01 16:30:47,376] {scheduler_job.py:154} INFO - Started process (PID=71965) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:47,406] {logging_mixin.py:112} INFO - [2020-08-01 16:30:47,406] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:47,407] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:30:47,407] {logging_mixin.py:112} INFO - [2020-08-01 16:30:47,407] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:47,409] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:47,427] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:30:47,437] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:47,439] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.063 seconds
[2020-08-01 16:30:55,527] {scheduler_job.py:154} INFO - Started process (PID=71973) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:55,559] {logging_mixin.py:112} INFO - [2020-08-01 16:30:55,559] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:30:55,560] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:30:55,560] {logging_mixin.py:112} INFO - [2020-08-01 16:30:55,560] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:55,562] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:30:55,580] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:30:55,590] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:30:55,592] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.065 seconds
[2020-08-01 16:31:03,491] {scheduler_job.py:154} INFO - Started process (PID=71982) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:03,522] {logging_mixin.py:112} INFO - [2020-08-01 16:31:03,521] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:03,522] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:31:03,523] {logging_mixin.py:112} INFO - [2020-08-01 16:31:03,523] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:03,525] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:03,542] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:31:03,552] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:03,555] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.063 seconds
[2020-08-01 16:31:11,475] {scheduler_job.py:154} INFO - Started process (PID=71991) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:11,504] {logging_mixin.py:112} INFO - [2020-08-01 16:31:11,504] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:11,505] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:31:11,505] {logging_mixin.py:112} INFO - [2020-08-01 16:31:11,505] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:11,508] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:11,526] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:31:11,537] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:11,539] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.064 seconds
[2020-08-01 16:31:19,520] {scheduler_job.py:154} INFO - Started process (PID=72000) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:19,550] {logging_mixin.py:112} INFO - [2020-08-01 16:31:19,550] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:19,551] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:31:19,551] {logging_mixin.py:112} INFO - [2020-08-01 16:31:19,551] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:19,554] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:19,571] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:31:19,581] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:19,584] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.063 seconds
[2020-08-01 16:31:27,556] {scheduler_job.py:154} INFO - Started process (PID=72008) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:27,591] {logging_mixin.py:112} INFO - [2020-08-01 16:31:27,591] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:27,592] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:31:27,593] {logging_mixin.py:112} INFO - [2020-08-01 16:31:27,592] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:27,596] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:27,614] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:31:27,625] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:27,627] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.071 seconds
[2020-08-01 16:31:35,517] {scheduler_job.py:154} INFO - Started process (PID=72017) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:35,541] {logging_mixin.py:112} INFO - [2020-08-01 16:31:35,541] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:35,542] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:31:35,542] {logging_mixin.py:112} INFO - [2020-08-01 16:31:35,542] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:35,545] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:35,558] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:31:35,567] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:35,570] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 16:31:43,005] {scheduler_job.py:154} INFO - Started process (PID=72026) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:43,024] {logging_mixin.py:112} INFO - [2020-08-01 16:31:43,023] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:43,024] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:31:43,024] {logging_mixin.py:112} INFO - [2020-08-01 16:31:43,024] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:43,026] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:43,040] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:31:43,047] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:43,049] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:31:51,106] {scheduler_job.py:154} INFO - Started process (PID=72034) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:51,125] {logging_mixin.py:112} INFO - [2020-08-01 16:31:51,124] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:51,125] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:31:51,125] {logging_mixin.py:112} INFO - [2020-08-01 16:31:51,125] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:51,127] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:51,143] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:31:51,150] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:51,151] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:31:59,158] {scheduler_job.py:154} INFO - Started process (PID=72042) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:59,174] {logging_mixin.py:112} INFO - [2020-08-01 16:31:59,174] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:31:59,175] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:31:59,175] {logging_mixin.py:112} INFO - [2020-08-01 16:31:59,175] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:59,177] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:31:59,191] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:31:59,198] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:31:59,199] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.041 seconds
[2020-08-01 16:32:08,345] {scheduler_job.py:154} INFO - Started process (PID=72069) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:08,387] {logging_mixin.py:112} INFO - [2020-08-01 16:32:08,387] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:08,388] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:32:08,388] {logging_mixin.py:112} INFO - [2020-08-01 16:32:08,388] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:08,393] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:08,531] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:32:08,563] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:08,565] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.220 seconds
[2020-08-01 16:32:15,654] {scheduler_job.py:154} INFO - Started process (PID=72149) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:15,672] {logging_mixin.py:112} INFO - [2020-08-01 16:32:15,672] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:15,672] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:32:15,673] {logging_mixin.py:112} INFO - [2020-08-01 16:32:15,672] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:15,674] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:15,689] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:32:15,696] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:15,698] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:32:23,174] {scheduler_job.py:154} INFO - Started process (PID=72167) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:23,193] {logging_mixin.py:112} INFO - [2020-08-01 16:32:23,193] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:23,194] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:32:23,194] {logging_mixin.py:112} INFO - [2020-08-01 16:32:23,194] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:23,196] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:23,211] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:32:23,218] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:23,220] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:32:31,117] {scheduler_job.py:154} INFO - Started process (PID=72200) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:31,134] {logging_mixin.py:112} INFO - [2020-08-01 16:32:31,134] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:31,135] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:32:31,135] {logging_mixin.py:112} INFO - [2020-08-01 16:32:31,135] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:31,137] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:31,151] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:32:31,158] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:31,160] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:32:39,207] {scheduler_job.py:154} INFO - Started process (PID=72219) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:39,224] {logging_mixin.py:112} INFO - [2020-08-01 16:32:39,224] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:39,225] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:32:39,225] {logging_mixin.py:112} INFO - [2020-08-01 16:32:39,225] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:39,227] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:39,239] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:32:39,246] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:39,248] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:32:47,205] {scheduler_job.py:154} INFO - Started process (PID=72252) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:47,224] {logging_mixin.py:112} INFO - [2020-08-01 16:32:47,224] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:47,225] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:32:47,225] {logging_mixin.py:112} INFO - [2020-08-01 16:32:47,225] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:47,227] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:47,242] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:32:47,249] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:47,251] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:32:55,241] {scheduler_job.py:154} INFO - Started process (PID=72277) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:55,260] {logging_mixin.py:112} INFO - [2020-08-01 16:32:55,260] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:32:55,261] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:32:55,261] {logging_mixin.py:112} INFO - [2020-08-01 16:32:55,261] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:55,263] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:32:55,293] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:32:55,321] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:32:55,324] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.083 seconds
[2020-08-01 16:33:04,374] {scheduler_job.py:154} INFO - Started process (PID=72308) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:04,401] {logging_mixin.py:112} INFO - [2020-08-01 16:33:04,401] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:04,402] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:33:04,402] {logging_mixin.py:112} INFO - [2020-08-01 16:33:04,402] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:04,404] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:04,422] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:33:04,431] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:04,434] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.060 seconds
[2020-08-01 16:33:13,071] {scheduler_job.py:154} INFO - Started process (PID=72631) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:13,091] {logging_mixin.py:112} INFO - [2020-08-01 16:33:13,091] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:13,091] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:33:13,092] {logging_mixin.py:112} INFO - [2020-08-01 16:33:13,092] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:13,093] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:13,109] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:33:13,117] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:13,118] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:33:19,268] {scheduler_job.py:154} INFO - Started process (PID=72647) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:19,285] {logging_mixin.py:112} INFO - [2020-08-01 16:33:19,285] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:19,286] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:33:19,286] {logging_mixin.py:112} INFO - [2020-08-01 16:33:19,286] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:19,288] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:19,305] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:33:19,314] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:19,316] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:33:27,665] {scheduler_job.py:154} INFO - Started process (PID=72664) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:27,684] {logging_mixin.py:112} INFO - [2020-08-01 16:33:27,684] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:27,685] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:33:27,685] {logging_mixin.py:112} INFO - [2020-08-01 16:33:27,685] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:27,687] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:27,707] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:33:27,716] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:27,718] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.053 seconds
[2020-08-01 16:33:35,476] {scheduler_job.py:154} INFO - Started process (PID=72756) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:35,493] {logging_mixin.py:112} INFO - [2020-08-01 16:33:35,493] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:35,493] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:33:35,493] {logging_mixin.py:112} INFO - [2020-08-01 16:33:35,493] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:35,495] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:35,509] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:33:35,516] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:35,517] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:33:43,874] {scheduler_job.py:154} INFO - Started process (PID=72771) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:43,893] {logging_mixin.py:112} INFO - [2020-08-01 16:33:43,893] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:43,894] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:33:43,894] {logging_mixin.py:112} INFO - [2020-08-01 16:33:43,894] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:43,896] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:43,911] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:33:43,919] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:43,920] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:33:51,449] {scheduler_job.py:154} INFO - Started process (PID=72787) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:51,468] {logging_mixin.py:112} INFO - [2020-08-01 16:33:51,467] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:51,468] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:33:51,468] {logging_mixin.py:112} INFO - [2020-08-01 16:33:51,468] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:51,470] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:51,486] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:33:51,495] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:51,497] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:33:59,426] {scheduler_job.py:154} INFO - Started process (PID=72853) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:59,443] {logging_mixin.py:112} INFO - [2020-08-01 16:33:59,443] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:33:59,444] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:33:59,444] {logging_mixin.py:112} INFO - [2020-08-01 16:33:59,444] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:59,445] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:33:59,462] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:33:59,469] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:33:59,471] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:34:07,377] {scheduler_job.py:154} INFO - Started process (PID=72878) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:07,398] {logging_mixin.py:112} INFO - [2020-08-01 16:34:07,398] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:07,398] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:34:07,399] {logging_mixin.py:112} INFO - [2020-08-01 16:34:07,398] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:07,400] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:07,417] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:34:07,425] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:07,427] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.051 seconds
[2020-08-01 16:34:15,396] {scheduler_job.py:154} INFO - Started process (PID=72895) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:15,415] {logging_mixin.py:112} INFO - [2020-08-01 16:34:15,414] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:15,415] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:34:15,415] {logging_mixin.py:112} INFO - [2020-08-01 16:34:15,415] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:15,417] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:15,434] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:34:15,442] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:15,444] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:34:23,433] {scheduler_job.py:154} INFO - Started process (PID=72919) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:23,451] {logging_mixin.py:112} INFO - [2020-08-01 16:34:23,450] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:23,451] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:34:23,451] {logging_mixin.py:112} INFO - [2020-08-01 16:34:23,451] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:23,453] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:23,467] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:34:23,474] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:23,476] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:34:31,491] {scheduler_job.py:154} INFO - Started process (PID=72935) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:31,508] {logging_mixin.py:112} INFO - [2020-08-01 16:34:31,508] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:31,509] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:34:31,509] {logging_mixin.py:112} INFO - [2020-08-01 16:34:31,509] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:31,511] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:31,528] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:34:31,536] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:31,537] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:34:39,503] {scheduler_job.py:154} INFO - Started process (PID=72961) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:39,521] {logging_mixin.py:112} INFO - [2020-08-01 16:34:39,521] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:39,522] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:34:39,522] {logging_mixin.py:112} INFO - [2020-08-01 16:34:39,522] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:39,524] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:39,538] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:34:39,545] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:39,547] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:34:47,583] {scheduler_job.py:154} INFO - Started process (PID=72985) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:47,605] {logging_mixin.py:112} INFO - [2020-08-01 16:34:47,605] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:47,606] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:34:47,606] {logging_mixin.py:112} INFO - [2020-08-01 16:34:47,606] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:47,609] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:47,624] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:34:47,638] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:47,640] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.057 seconds
[2020-08-01 16:34:55,543] {scheduler_job.py:154} INFO - Started process (PID=73034) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:55,561] {logging_mixin.py:112} INFO - [2020-08-01 16:34:55,560] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:34:55,561] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:34:55,561] {logging_mixin.py:112} INFO - [2020-08-01 16:34:55,561] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:55,563] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:34:55,577] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:34:55,584] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:34:55,586] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:35:03,541] {scheduler_job.py:154} INFO - Started process (PID=73058) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:03,558] {logging_mixin.py:112} INFO - [2020-08-01 16:35:03,558] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:03,559] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:35:03,559] {logging_mixin.py:112} INFO - [2020-08-01 16:35:03,559] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:03,561] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:03,575] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:35:03,584] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:03,585] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:35:11,561] {scheduler_job.py:154} INFO - Started process (PID=73075) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:11,578] {logging_mixin.py:112} INFO - [2020-08-01 16:35:11,578] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:11,579] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:35:11,579] {logging_mixin.py:112} INFO - [2020-08-01 16:35:11,579] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:11,581] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:11,597] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:35:11,608] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:11,609] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 16:35:19,582] {scheduler_job.py:154} INFO - Started process (PID=73099) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:19,601] {logging_mixin.py:112} INFO - [2020-08-01 16:35:19,600] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:19,601] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:35:19,602] {logging_mixin.py:112} INFO - [2020-08-01 16:35:19,601] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:19,604] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:19,619] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:35:19,626] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:19,627] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:35:27,640] {scheduler_job.py:154} INFO - Started process (PID=73115) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:27,658] {logging_mixin.py:112} INFO - [2020-08-01 16:35:27,658] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:27,659] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:35:27,659] {logging_mixin.py:112} INFO - [2020-08-01 16:35:27,659] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:27,661] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:27,676] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:35:27,684] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:27,685] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:35:35,674] {scheduler_job.py:154} INFO - Started process (PID=73141) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:35,692] {logging_mixin.py:112} INFO - [2020-08-01 16:35:35,692] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:35,692] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:35:35,692] {logging_mixin.py:112} INFO - [2020-08-01 16:35:35,692] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:35,694] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:35,711] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:35:35,721] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:35,724] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 16:35:43,704] {scheduler_job.py:154} INFO - Started process (PID=73168) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:43,722] {logging_mixin.py:112} INFO - [2020-08-01 16:35:43,722] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:43,723] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:35:43,723] {logging_mixin.py:112} INFO - [2020-08-01 16:35:43,723] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:43,724] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:43,739] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:35:43,747] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:43,749] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:35:51,708] {scheduler_job.py:154} INFO - Started process (PID=73184) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:51,726] {logging_mixin.py:112} INFO - [2020-08-01 16:35:51,725] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:51,726] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:35:51,726] {logging_mixin.py:112} INFO - [2020-08-01 16:35:51,726] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:51,728] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:51,743] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:35:51,750] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:51,752] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:35:59,755] {scheduler_job.py:154} INFO - Started process (PID=73208) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:59,773] {logging_mixin.py:112} INFO - [2020-08-01 16:35:59,773] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:35:59,773] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:35:59,773] {logging_mixin.py:112} INFO - [2020-08-01 16:35:59,773] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:59,775] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:35:59,791] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:35:59,798] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:35:59,800] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:36:07,869] {scheduler_job.py:154} INFO - Started process (PID=73224) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:07,887] {logging_mixin.py:112} INFO - [2020-08-01 16:36:07,887] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:07,888] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:36:07,888] {logging_mixin.py:112} INFO - [2020-08-01 16:36:07,888] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:07,889] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:07,903] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:36:07,910] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:07,911] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:36:15,836] {scheduler_job.py:154} INFO - Started process (PID=73249) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:15,855] {logging_mixin.py:112} INFO - [2020-08-01 16:36:15,855] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:15,856] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:36:15,856] {logging_mixin.py:112} INFO - [2020-08-01 16:36:15,856] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:15,858] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:15,873] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:36:15,881] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:15,882] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:36:23,857] {scheduler_job.py:154} INFO - Started process (PID=73265) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:23,875] {logging_mixin.py:112} INFO - [2020-08-01 16:36:23,874] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:23,875] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:36:23,875] {logging_mixin.py:112} INFO - [2020-08-01 16:36:23,875] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:23,877] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:23,894] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:36:23,903] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:23,904] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:36:31,861] {scheduler_job.py:154} INFO - Started process (PID=73289) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:31,879] {logging_mixin.py:112} INFO - [2020-08-01 16:36:31,879] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:31,880] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:36:31,880] {logging_mixin.py:112} INFO - [2020-08-01 16:36:31,880] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:31,882] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:31,895] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:36:31,902] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:31,903] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:36:39,906] {scheduler_job.py:154} INFO - Started process (PID=73314) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:39,924] {logging_mixin.py:112} INFO - [2020-08-01 16:36:39,924] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:39,925] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:36:39,925] {logging_mixin.py:112} INFO - [2020-08-01 16:36:39,925] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:39,927] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:39,945] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:36:39,953] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:39,955] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 16:36:47,922] {scheduler_job.py:154} INFO - Started process (PID=73330) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:47,939] {logging_mixin.py:112} INFO - [2020-08-01 16:36:47,939] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:47,939] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:36:47,940] {logging_mixin.py:112} INFO - [2020-08-01 16:36:47,940] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:47,941] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:47,955] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:36:47,962] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:47,964] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:36:55,953] {scheduler_job.py:154} INFO - Started process (PID=73354) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:55,971] {logging_mixin.py:112} INFO - [2020-08-01 16:36:55,970] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:36:55,971] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:36:55,971] {logging_mixin.py:112} INFO - [2020-08-01 16:36:55,971] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:55,973] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:36:55,990] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:36:55,998] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:36:56,000] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:37:03,972] {scheduler_job.py:154} INFO - Started process (PID=73370) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:03,990] {logging_mixin.py:112} INFO - [2020-08-01 16:37:03,989] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:03,990] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:37:03,990] {logging_mixin.py:112} INFO - [2020-08-01 16:37:03,990] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:03,992] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:04,006] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:37:04,013] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:04,015] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:37:11,988] {scheduler_job.py:154} INFO - Started process (PID=73395) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:12,005] {logging_mixin.py:112} INFO - [2020-08-01 16:37:12,005] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:12,006] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:37:12,006] {logging_mixin.py:112} INFO - [2020-08-01 16:37:12,006] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:12,008] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:12,022] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:37:12,031] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:12,032] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:37:20,049] {scheduler_job.py:154} INFO - Started process (PID=73411) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:20,066] {logging_mixin.py:112} INFO - [2020-08-01 16:37:20,066] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:20,067] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:37:20,067] {logging_mixin.py:112} INFO - [2020-08-01 16:37:20,067] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:20,069] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:20,085] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:37:20,093] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:20,095] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:37:28,036] {scheduler_job.py:154} INFO - Started process (PID=73435) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:28,056] {logging_mixin.py:112} INFO - [2020-08-01 16:37:28,055] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:28,056] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:37:28,056] {logging_mixin.py:112} INFO - [2020-08-01 16:37:28,056] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:28,058] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:28,072] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:37:28,080] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:28,082] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:37:36,073] {scheduler_job.py:154} INFO - Started process (PID=73459) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:36,090] {logging_mixin.py:112} INFO - [2020-08-01 16:37:36,090] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:36,091] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:37:36,091] {logging_mixin.py:112} INFO - [2020-08-01 16:37:36,091] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:36,093] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:36,107] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:37:36,116] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:36,118] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.045 seconds
[2020-08-01 16:37:44,103] {scheduler_job.py:154} INFO - Started process (PID=73476) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:44,122] {logging_mixin.py:112} INFO - [2020-08-01 16:37:44,122] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:44,123] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:37:44,124] {logging_mixin.py:112} INFO - [2020-08-01 16:37:44,123] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:44,125] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:44,140] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:37:44,148] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:44,150] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:37:52,215] {scheduler_job.py:154} INFO - Started process (PID=73516) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:52,235] {logging_mixin.py:112} INFO - [2020-08-01 16:37:52,235] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:37:52,235] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:37:52,236] {logging_mixin.py:112} INFO - [2020-08-01 16:37:52,235] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:52,237] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:37:52,253] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:37:52,262] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:37:52,264] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:38:00,160] {scheduler_job.py:154} INFO - Started process (PID=73533) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:00,178] {logging_mixin.py:112} INFO - [2020-08-01 16:38:00,178] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:00,179] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:38:00,179] {logging_mixin.py:112} INFO - [2020-08-01 16:38:00,179] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:00,182] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:00,196] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:38:00,205] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:00,206] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:38:08,181] {scheduler_job.py:154} INFO - Started process (PID=73557) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:08,202] {logging_mixin.py:112} INFO - [2020-08-01 16:38:08,201] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:08,202] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:38:08,202] {logging_mixin.py:112} INFO - [2020-08-01 16:38:08,202] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:08,204] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:08,221] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:38:08,229] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:08,231] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.050 seconds
[2020-08-01 16:38:16,272] {scheduler_job.py:154} INFO - Started process (PID=73575) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:16,295] {logging_mixin.py:112} INFO - [2020-08-01 16:38:16,295] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:16,295] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:38:16,296] {logging_mixin.py:112} INFO - [2020-08-01 16:38:16,295] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:16,297] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:16,312] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:38:16,319] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:16,322] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.049 seconds
[2020-08-01 16:38:24,278] {scheduler_job.py:154} INFO - Started process (PID=73600) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:24,296] {logging_mixin.py:112} INFO - [2020-08-01 16:38:24,295] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:24,296] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:38:24,296] {logging_mixin.py:112} INFO - [2020-08-01 16:38:24,296] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:24,298] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:24,313] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:38:24,321] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:24,322] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:38:32,275] {scheduler_job.py:154} INFO - Started process (PID=73624) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:32,293] {logging_mixin.py:112} INFO - [2020-08-01 16:38:32,292] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:32,293] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:38:32,293] {logging_mixin.py:112} INFO - [2020-08-01 16:38:32,293] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:32,295] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:32,309] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:38:32,318] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:32,320] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:38:40,831] {scheduler_job.py:154} INFO - Started process (PID=73641) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:40,848] {logging_mixin.py:112} INFO - [2020-08-01 16:38:40,848] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:40,849] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:38:40,849] {logging_mixin.py:112} INFO - [2020-08-01 16:38:40,849] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:40,851] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:40,864] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:38:40,872] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:40,873] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:38:48,422] {scheduler_job.py:154} INFO - Started process (PID=73698) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:48,441] {logging_mixin.py:112} INFO - [2020-08-01 16:38:48,441] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:48,441] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:38:48,441] {logging_mixin.py:112} INFO - [2020-08-01 16:38:48,441] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:48,443] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:48,457] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:38:48,465] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:48,466] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:38:56,514] {scheduler_job.py:154} INFO - Started process (PID=73732) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:56,531] {logging_mixin.py:112} INFO - [2020-08-01 16:38:56,531] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:38:56,532] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:38:56,532] {logging_mixin.py:112} INFO - [2020-08-01 16:38:56,532] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:56,533] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:38:56,547] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:38:56,555] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:38:56,556] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
[2020-08-01 16:39:05,179] {scheduler_job.py:154} INFO - Started process (PID=73744) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:05,210] {logging_mixin.py:112} INFO - [2020-08-01 16:39:05,210] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:05,211] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:39:05,211] {logging_mixin.py:112} INFO - [2020-08-01 16:39:05,211] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:05,215] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:05,235] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:39:05,243] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:05,246] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.067 seconds
[2020-08-01 16:39:12,881] {scheduler_job.py:154} INFO - Started process (PID=73754) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:12,906] {logging_mixin.py:112} INFO - [2020-08-01 16:39:12,905] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:12,907] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:39:12,907] {logging_mixin.py:112} INFO - [2020-08-01 16:39:12,907] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:12,910] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:12,924] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:39:12,932] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:12,933] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.052 seconds
[2020-08-01 16:39:20,493] {scheduler_job.py:154} INFO - Started process (PID=73763) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:20,512] {logging_mixin.py:112} INFO - [2020-08-01 16:39:20,512] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:20,513] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:39:20,513] {logging_mixin.py:112} INFO - [2020-08-01 16:39:20,513] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:20,515] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:20,540] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:39:20,548] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:20,550] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.057 seconds
[2020-08-01 16:39:28,494] {scheduler_job.py:154} INFO - Started process (PID=73771) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:28,512] {logging_mixin.py:112} INFO - [2020-08-01 16:39:28,512] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:28,512] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:39:28,513] {logging_mixin.py:112} INFO - [2020-08-01 16:39:28,513] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:28,514] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:28,530] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:39:28,538] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:28,540] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:39:49,070] {scheduler_job.py:154} INFO - Started process (PID=73851) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:49,088] {logging_mixin.py:112} INFO - [2020-08-01 16:39:49,087] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:39:49,088] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:39:49,088] {logging_mixin.py:112} INFO - [2020-08-01 16:39:49,088] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:49,090] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:39:49,107] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:39:49,115] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:39:49,117] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:40:02,548] {scheduler_job.py:154} INFO - Started process (PID=73880) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:02,566] {logging_mixin.py:112} INFO - [2020-08-01 16:40:02,566] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:02,567] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:40:02,567] {logging_mixin.py:112} INFO - [2020-08-01 16:40:02,567] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:02,568] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:02,583] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:40:02,591] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:02,592] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:40:10,576] {scheduler_job.py:154} INFO - Started process (PID=73904) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:10,606] {logging_mixin.py:112} INFO - [2020-08-01 16:40:10,606] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:10,607] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:40:10,607] {logging_mixin.py:112} INFO - [2020-08-01 16:40:10,607] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:10,609] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:10,624] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:40:10,630] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:10,632] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.056 seconds
[2020-08-01 16:40:18,523] {scheduler_job.py:154} INFO - Started process (PID=73921) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:18,541] {logging_mixin.py:112} INFO - [2020-08-01 16:40:18,541] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:18,541] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:40:18,541] {logging_mixin.py:112} INFO - [2020-08-01 16:40:18,541] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:18,543] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:18,560] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:40:18,567] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:18,569] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.046 seconds
[2020-08-01 16:40:26,535] {scheduler_job.py:154} INFO - Started process (PID=73945) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:26,555] {logging_mixin.py:112} INFO - [2020-08-01 16:40:26,555] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:26,555] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:40:26,556] {logging_mixin.py:112} INFO - [2020-08-01 16:40:26,555] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:26,557] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:26,571] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:40:26,578] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:26,579] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.044 seconds
[2020-08-01 16:40:34,594] {scheduler_job.py:154} INFO - Started process (PID=73961) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:34,612] {logging_mixin.py:112} INFO - [2020-08-01 16:40:34,612] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:34,612] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:40:34,613] {logging_mixin.py:112} INFO - [2020-08-01 16:40:34,613] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:34,614] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:34,631] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:40:34,639] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:34,642] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.048 seconds
[2020-08-01 16:40:42,591] {scheduler_job.py:154} INFO - Started process (PID=73985) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:42,609] {logging_mixin.py:112} INFO - [2020-08-01 16:40:42,609] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:42,610] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:40:42,610] {logging_mixin.py:112} INFO - [2020-08-01 16:40:42,610] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:42,612] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:42,628] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:40:42,637] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:42,639] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:40:50,782] {scheduler_job.py:154} INFO - Started process (PID=74049) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:50,799] {logging_mixin.py:112} INFO - [2020-08-01 16:40:50,799] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:50,800] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:40:50,800] {logging_mixin.py:112} INFO - [2020-08-01 16:40:50,800] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:50,802] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:50,816] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:40:50,823] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:50,825] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:40:58,631] {scheduler_job.py:154} INFO - Started process (PID=74074) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:58,648] {logging_mixin.py:112} INFO - [2020-08-01 16:40:58,648] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:40:58,649] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:40:58,649] {logging_mixin.py:112} INFO - [2020-08-01 16:40:58,649] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:58,651] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:40:58,665] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:40:58,672] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:40:58,674] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.043 seconds
[2020-08-01 16:41:06,654] {scheduler_job.py:154} INFO - Started process (PID=74098) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:41:06,672] {logging_mixin.py:112} INFO - [2020-08-01 16:41:06,671] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:41:06,672] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:41:06,672] {logging_mixin.py:112} INFO - [2020-08-01 16:41:06,672] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:41:06,674] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:41:06,691] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:41:06,699] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:41:06,701] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.047 seconds
[2020-08-01 16:41:14,882] {scheduler_job.py:154} INFO - Started process (PID=74114) to work on /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:41:14,900] {logging_mixin.py:112} INFO - [2020-08-01 16:41:14,900] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-08-01 16:41:14,901] {scheduler_job.py:1571} INFO - Processing file /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py for tasks to queue
[2020-08-01 16:41:14,901] {logging_mixin.py:112} INFO - [2020-08-01 16:41:14,901] {dagbag.py:396} INFO - Filling up the DagBag from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:41:14,903] {scheduler_job.py:1583} INFO - DAG(s) dict_keys(['bash_pipeline']) retrieved from /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py
[2020-08-01 16:41:14,916] {scheduler_job.py:1287} INFO - Processing bash_pipeline
[2020-08-01 16:41:14,923] {scheduler_job.py:454} INFO - Skipping SLA check for <DAG: bash_pipeline> because no tasks in DAG have SLAs
[2020-08-01 16:41:14,924] {scheduler_job.py:162} INFO - Processing /Users/thanamat/train/airflow/airflow-for-odds/airflow/dags/bash_pipeline.py took 0.042 seconds
